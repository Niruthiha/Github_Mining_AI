[
  {
    "issue_number": 5474,
    "title": "Hello, I encountered some issues during the installation of Detectron2.",
    "author": "isakkk3",
    "state": "open",
    "created_at": "2025-06-12T07:30:13Z",
    "updated_at": "2025-06-12T07:30:13Z",
    "labels": [
      "documentation"
    ],
    "body": "\nninja: build stopped: subcommand failed.\n    Traceback (most recent call last):\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 2100, in _run_ninja_build\n        subprocess.run(\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\subprocess.py\", line 516, in run\n        raise CalledProcessError(retcode, process.args,\n    subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n   \n    The above exception was the direct cause of the following exception:\n   \n    Traceback (most recent call last):\n      File \"<string>\", line 2, in <module>\n      File \"<pip-setuptools-caller>\", line 34, in <module>\n      File \"D:\\isak\\detectron2\\setup.py\", line 147, in <module>\n        setup(\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\__init__.py\", line 117, in setup\n        return distutils.core.setup(**attrs)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 183, in setup\n        return run_commands(dist)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 199, in run_commands\n        dist.run_commands()\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 954, in run_commands\n        self.run_command(cmd)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\dist.py\", line 999, in run_command\n        super().run_command(command)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_command\n        cmd_obj.run()\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\command\\develop.py\", line 35, in run\n        self.install_for_development()\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\command\\develop.py\", line 112, in install_for_development\n        self.run_command('build_ext')\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 316, in run_command\n        self.distribution.run_command(command)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\dist.py\", line 999, in run_command\n        super().run_command(command)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_command\n        cmd_obj.run()\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\command\\build_ext.py\", line 98, in run\n        _build_ext.run(self)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 359, in run\n        self.build_extensions()\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 873, in build_extensions\n        build_ext.build_extensions(self)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 476, in build_extensions\n        self._build_extensions_serial()\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 502, in _build_extensions_serial\n        self.build_extension(ext)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\command\\build_ext.py\", line 263, in build_extension\n        _build_ext.build_extension(self, ext)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\Cython\\Distutils\\build_ext.py\", line 136, in build_extension\n        super().build_extension(ext)\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 557, in build_extension\n        objects = self.compiler.compile(\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 845, in win_wrap_ninja_compile\n        _write_ninja_file_and_compile_objects(\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 1774, in _write_ninja_file_and_compile_objects\n        _run_ninja_build(\n      File \"C:\\ProgramData\\anaconda3\\envs\\image\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 2116, in _run_ninja_build\n        raise RuntimeError(message) from e\n    RuntimeError: Error compiling objects for extension\n    [end of output]\n\nnote: This error originates from a subprocess, and is likely not a problem with pip.\n\n\n",
    "comments": []
  },
  {
    "issue_number": 5453,
    "title": "install detectron2 meets some problems",
    "author": "CGL-learner",
    "state": "open",
    "created_at": "2025-03-31T02:42:56Z",
    "updated_at": "2025-06-07T19:20:21Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\n1. \n```\n--> python -m pip install -e detectron2\nLooking in indexes: http://mirrors.aliyun.com/pypi/simple\nObtaining file:///root/rcbevdet/detectron2\n  Installing build dependencies ... done\n  Checking if build backend supports build_editable ... done\n  Getting requirements to build editable ... error\n  error: subprocess-exited-with-error\n  \n  √ó Getting requirements to build editable did not run successfully.\n  ‚îÇ exit code: 1\n  ‚ï∞‚îÄ> [19 lines of output]\n      Traceback (most recent call last):\n        File \"/root/rcbevdet/myenv/lib/python3.8/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n          main()\n        File \"/root/rcbevdet/myenv/lib/python3.8/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n          json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n        File \"/root/rcbevdet/myenv/lib/python3.8/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 157, in get_requires_for_build_editable\n          return hook(config_settings)\n        File \"/tmp/pip-build-env-8zw8gi3a/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 482, in get_requires_for_build_editable\n          return self.get_requires_for_build_wheel(config_settings)\n        File \"/tmp/pip-build-env-8zw8gi3a/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 333, in get_requires_for_build_wheel\n          return self._get_build_requires(config_settings, requirements=[])\n        File \"/tmp/pip-build-env-8zw8gi3a/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 303, in _get_build_requires\n          self.run_setup()\n        File \"/tmp/pip-build-env-8zw8gi3a/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 521, in run_setup\n          super().run_setup(setup_script=setup_script)\n        File \"/tmp/pip-build-env-8zw8gi3a/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 319, in run_setup\n          exec(code, locals())\n        File \"<string>\", line 10, in <module>\n      ModuleNotFoundError: No module named 'torch'\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: subprocess-exited-with-error\n\n√ó Getting requirements to build editable did not run successfully.\n‚îÇ exit code: 1\n‚ï∞‚îÄ> See above for output.\n\nnote: This error originates from a subprocess, and is likely not a problem with pip.\n\n```\n2. What exact command you run:  python -m pip install -e detectron2\nI don't konw why this problem appears and I use many methods to solve this problem but they do not work.\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Your Environment\"; "
      },
      {
        "user": "CGL-learner",
        "body": "cuda 11.3 pytorch1.11.0 python3.8.10"
      },
      {
        "user": "PrinceAlmeida",
        "body": "Even I was facing the same problem Below steps worked for me.\n\nThis is because detectron2 library has only wheels for <= Python 3.9.\"\n\nOpen a terminal or command prompt. Create a new environment called detectron2-env with the following command\nconda create --name detectron2-env python==3.9 -y\n\nLinux\nconda activate detectron2-env\n\nwindows\nactivate detectron2-env\n\nInstall the dependencies\n\npip3 install torch torchvision torchaudio\ngit clone https://github.com/facebookresearch/detectron2.git\npython -m pip install -e detectron2\n\n\nplease refer to the following documentation:\n\nhttps://detectron2.readthedocs.io/en/latest/tutorials/install.html"
      }
    ]
  },
  {
    "issue_number": 5339,
    "title": "Inference time discrepancy when using TorchScript vs ONNX exported model",
    "author": "jonassoebro",
    "state": "closed",
    "created_at": "2024-08-02T13:30:00Z",
    "updated_at": "2025-06-06T02:20:08Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "I've been experimenting with converting my model to ONNX format, however while I am able to get the model exported and run with identical outputs between torchscript and ONNX, the inference time is much slower compared to using the torchscript format - around twice as long per image when using ONNX compared to torchscript on CPU.\r\n\r\nHas anyone faced similar issues with inference speed being slow when using ONNX format compared to torchscript ported models? The inference test was done on CPU for both ONNX and torchscript.\r\n\r\nThe model I have implemented uses a 'mask_rcnn_R_50_FPN_100ep_LSJ' config, with the backbone swapped out for a ConvNext rather than the default ResNet.\r\n\r\nI convert my models to torchscript using the following function:\r\n\r\nI am using the following versions of torch, onnx and detectron:\r\n\r\npytorch-lightning           2.0.1.post0\r\ntorch                       2.0.0\r\ntorchmetrics                0.11.4\r\ntorchvision                 0.15.1\r\ndetectron2                  0.6\r\n\r\nFor the ONNX I am using the STABLE_ONNX_OPSET_VERSION = 16\r\n\r\n`\r\ndef convert_model_torchscript(model_artefact_dir: Path, export_dir: Path, example_image: torch.Tensor, device: str) -> tuple[torch.nn.Module, Path]:\r\n    \"\"\"\r\n    Converts the model to torchscript\r\n\r\n    :param Path model_artefact_dir: the model artefact dir to load the model from.\r\n    :param Path export_dir: export directory to save the converted model in\r\n    :param torch.Tensor example_image: an example input\r\n    :param str device: device to convert the model to\r\n    :return tuple[torch.nn.Module, Path]: the loaded model, and the path to the torchscript conversion\r\n    \"\"\"\r\n    # load model\r\n    wrapped_model = util.load_model_from_artefact_dir(model_artefact_dir)\r\n    wrapped_model.eval()\r\n    wrapped_model.to(device)\r\n    model: torch.nn.Module = wrapped_model.model  # type: ignore\r\n\r\n    # remove other unused keys\r\n    example_image = example_image.to(device)\r\n    inputs = [{\"image\": example_image}]\r\n\r\n    def _inference(model, inputs):\r\n        # postprocessing is not tracing compatible.\r\n        inst = model.inference(inputs, do_postprocess=False)[0]\r\n        return [{\"instances\": inst}]\r\n\r\n    traceable_model = TracingAdapter(model, inputs, _inference)\r\n    ts_model = torch.jit.trace(traceable_model, (example_image,))\r\n\r\n    ts_file = Path(export_dir, f\"model_{device}.ts\")\r\n    with ts_file.open(mode=\"wb\") as f:\r\n        torch.jit.save(ts_model, f)\r\n\r\n    print(\"Exported model to Traced TorchScript\")\r\n    print(\"Inputs schema: \" + str(traceable_model.inputs_schema))\r\n    print(\"Outputs schema: \" + str(traceable_model.outputs_schema))\r\n    return model, ts_file\r\n`\r\n\r\nI export my model to ONNX using the following function:\r\n\r\n`\r\ndef convert_model_onnx(model_artefact_dir: Path, export_dir: Path, example_image: torch.Tensor) -> tuple[torch.nn.Module, Path]:\r\n    \"\"\"\r\n    Converts the model to ONNX\r\n\r\n    :param Path model_artefact_dir: the model artefact dir to load the model from.\r\n    :param Path export_dir: export directory to save the converted model in\r\n    :param torch.Tensor example_image: an example input\r\n    :return tuple[torch.nn.Module, Path]: the loaded model, and the path to the ONNX conversion\r\n    \"\"\"\r\n    wrapped_model = util.load_model_from_artefact_dir(model_artefact_dir)\r\n    wrapped_model.eval()\r\n    model: torch.nn.Module = wrapped_model.model\r\n\r\n    image = example_image.numpy().astype(np.float32)\r\n\r\n    #example_image_working, height, width = get_alternative_sample()  # Testcase\r\n    #torch_image_working = torch.from_numpy(np.ascontiguousarray(example_image_working.transpose(2, 0, 1))) # testcase\r\n\r\n    torch_image = torch.from_numpy(np.ascontiguousarray(image))\r\n    inputs = (torch_image.clone(),)\r\n\r\n    dynamic_axes_dict = {'images': [1, 2]}\r\n\r\n    def _inference_func(model, images):\r\n        with warnings.catch_warnings(record=True):\r\n            inputs = [{\"image\": image} for image in images]\r\n        inst = model.inference(inputs, do_postprocess=False)[0]\r\n        return [{\"instances\": inst}]\r\n\r\n    f = io.BytesIO()\r\n    adapter_model = TracingAdapter(model, inputs, _inference_func)\r\n    adapter_model.eval()\r\n    with torch.no_grad():\r\n        try:\r\n            torch.onnx.enable_log()\r\n        except AttributeError:\r\n            pass\r\n        torch.onnx.export(\r\n            adapter_model,\r\n            adapter_model.flattened_inputs,\r\n            f,\r\n            training=torch.onnx.TrainingMode.EVAL,\r\n            opset_version=STABLE_ONNX_OPSET_VERSION,\r\n            input_names=[\"images\"],\r\n            dynamic_axes=dynamic_axes_dict,\r\n            verbose=True,\r\n        )\r\n\r\n    onnx_model = onnx.load_from_string(f.getvalue())\r\n    onnx_file = export_dir / \"model.onnx\"\r\n    onnx.save(onnx_model, onnx_file)\r\n    return model, onnx_file\r\n`\r\n\r\nTo run inference with the ONNX model, I am doing the following:\r\n\r\n`\r\nproviders = ['CUDAExecutionProvider'] if device == 'cuda' else ['CPUExecutionProvider']\r\n    ort_session = onnxruntime.InferenceSession(str(onnx_file), providers=providers)\r\n    \r\n    onnx_image_input = np.ascontiguousarray(example_image)\r\n\r\n    onnx_outputs = ort_session.run(\r\n        None,\r\n        {\"images\": onnx_image_input},\r\n    )\r\n`\r\n\r\n\r\nAdditionally, while I was able to get my model to run inference producing expected outputs using the ONNX format, I got an error after a while on an image I was running on - if anyone has faced a similar issue please let me know what could be the cause:\r\n\r\n`2024-08-02 10:22:35.2303512 [E:onnxruntime:, sequential_executor.cc:516 onnxruntime::ExecuteKernel] Non-zero status code returned while running TopK node. Name:'/proposal_generator/TopK_3' Status Message: bad allocation\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\x\\Desktop\\pyinstaller-test\\test-onnx\\run_test.py\", line 39, in <module>\r\n    main()\r\n  File \"C:\\Users\\x\\Desktop\\pyinstaller-test\\test-onnx\\run_test.py\", line 23, in main\r\n    out = model.predict(img, \"threshold\", apply_t=False, merge_bb=False)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\x\\Desktop\\pyinstaller-test\\test-onnx\\onnx_model_artifact\\bounding_box_wrapper_onnx.py\", line 183, in predict\r\n    ort_outs = self._model.run(None, ort_inputs)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\x\\Desktop\\pyinstaller-test\\onnx_env\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\", line 220, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nonnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running TopK node. Name:'/proposal_generator/TopK_3' Status Message: bad allocation`",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5337,
    "title": "Exporting Model with TorchScript scripting option requires libtorchvision c++ library install contrary to what instructions claim.",
    "author": "starlipernl",
    "state": "closed",
    "created_at": "2024-08-01T03:41:17Z",
    "updated_at": "2025-06-05T02:20:31Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "I am using detectron2/tools/deploy/export_model.py to export the Faster-RCNN network as so:\r\n\r\n`./export_model.py --config-file ../../configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml --output ./fasterrcnn --export-method scripting --format torchscript MODEL.WEIGHTS /RAID/home/nstarliper/detectron2/tools/deploy/model_final_b275ba.pkl MODEL.DEVICE cuda`\r\n\r\nWhich works fine with no issue. However when trying to load the .ts network into my C++ code using torch.jit.load(model.ts) I am getting the following error:\r\n\r\n**Unknown builtin op: torchvision::nms.\r\nCould not find any similar ops to torchvision::nms. This op may not exist or may not be currently supported in TorchScript.**\r\n\r\nBoth my python and C++ torch versions are:\r\ntorch 1.9.0 + cuda 11.1\r\n\r\nHowever, I do not have the libtorchvision c++ library installed.\r\n\r\nAccording to the deploy wiki, \"scripting\" export mode should not require libtorchvision C++ library but it seems as though my system is trying to load the NMS plugin from libtorchvision. \r\n\r\nEnvironment:\r\nsys.platform                     linux\r\nPython                           3.9.12 (main, Jun  1 2022, 11:38:51) [GCC 7.5.0]\r\nnumpy                            1.26.4\r\ndetectron2                       0.6 @/RAID/home/nstarliper/detectron2/detectron2\r\ndetectron2._C                    not built correctly: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.26' not found (required by /RAID/home/nstarliper/detectron2/detectron2/_C.cpython-39-x86_64-linux-gnu.so)\r\nCompiler ($CXX)                  c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\r\nCUDA compiler                    Build cuda_11.6.r11.6/compiler.31057947_0\r\ndetectron2 arch flags            8.6\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          1.9.0+cu111 @/RAID/home/nstarliper/.conda/envs/detectron2/lib/python3.9/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0,1,2                        NVIDIA RTX A6000 (arch=8.6)\r\nDriver version                   545.29.06\r\nCUDA_HOME                        /usr/local/cuda\r\nPillow                           10.4.0\r\ntorchvision                      0.10.0+cu111 @/RAID/home/nstarliper/.conda/envs/detectron2/lib/python3.9/site-packages/torchvision\r\ntorchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.10.0\r\n\r\n\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5335,
    "title": "KeyError: \"Encountered category_id=2 but this id does not exist in 'categories' of the json file.\"",
    "author": "ALIOSKUPER",
    "state": "closed",
    "created_at": "2024-07-29T05:50:54Z",
    "updated_at": "2025-06-02T02:23:56Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Hello, in using your own coco format dataset for data registration (register_coco_instances), use coco_val_metadata = metadatacatalg.get (\"self_coco_val\")\r\ndataset_dicts = DatasetCatalog.get(\"self_coco_val\") The following problems arise when looking at the registered datasets\r\nKeyError: \"Encountered category_id=2 but this id does not exist in 'categories' of the json file.\"\r\nWhere my tag is labeled as\r\nDATA_ALL_CATEGORIES = [\r\n{'id': 0, 'name': 'embedded'},\r\n{'id': 1, 'name': 'isolated'},\r\n]\r\nI don't know how to deal with this problem. I hope to get your help",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5324,
    "title": "how to change the num_instances when i detect the image? ",
    "author": "apan666555",
    "state": "open",
    "created_at": "2024-07-10T11:14:42Z",
    "updated_at": "2025-05-31T07:53:01Z",
    "labels": [
      "documentation"
    ],
    "body": "## üìö Documentation Issue\r\n\r\nI predict the image show:detected 100 instances in 0.69s,and i print the predictor:Instances(num_instances=100, image_height=1080,\r\nmy weight only have  2 class, i want to change the num_instances ,please tell me how to change",
    "comments": [
      {
        "user": "Programmer-RD-AI",
        "body": "To change the number of instances detected in the image, modify the detection threshold or apply post-processing to filter out unwanted instances based on your criteria.\r\n\r\n```# Assuming you have already loaded the predictor\r\nfrom detectron2.engine import DefaultPredictor\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2 import model_zoo\r\n\r\n# Load the model configuration and set the desired threshold\r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\r\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # Set your desired threshold here\r\ncfg.MODEL.WEIGHTS = \"path/to/your/model_weights.pth\"  # Update with your model weights\r\n\r\npredictor = DefaultPredictor(cfg)\r\n\r\n# Run the prediction\r\nimage = cv2.imread(\"path/to/your/image.jpg\")  # Replace with the path to your image\r\noutputs = predictor(image)\r\n\r\n# Post-processing to filter the instances if needed\r\ninstances = outputs[\"instances\"]\r\nfiltered_instances = instances[instances.scores > 0.7]  # Filtering based on score threshold\r\n\r\nprint(f\"Number of detected instances: {len(filtered_instances)}\")\r\n```"
      },
      {
        "user": "micedevai",
        "body": "In your case, you're working with Detectron2 and performing object detection on images or videos, where the number of instances detected is printed as `Instances(num_instances=100, image_height=1080, ...)`. To modify the number of instances (`num_instances`), you would need to control the model's behavior related to object detection, including adjusting the thresholds or the classes.\r\n\r\nHowever, if you're looking to control or limit the number of detected instances based on certain criteria, such as a confidence threshold, here are a few strategies you can consider:\r\n\r\n### 1. **Modify Confidence Threshold**\r\nBy default, Detectron2 might detect a lot of instances, but you can filter detections based on the confidence score. For example, if you want to only keep instances that have a high confidence score, you can adjust the `SCORE_THRESH` parameter.\r\n\r\nHere's how you can adjust the confidence threshold:\r\n\r\n```python\r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\r\ncfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n\r\n# Adjust the confidence threshold here\r\ncfg.TEST.DETECTIONS_PER_IMAGE = 100  # Control how many instances per image to output (optional)\r\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # Set a score threshold for detections\r\n\r\npredictor = DefaultPredictor(cfg)\r\n\r\n# Perform prediction as usual\r\noutputs = predictor(frame)\r\n```\r\n\r\nBy increasing the threshold, you can reduce the number of detections, as only instances with a confidence above the threshold will be returned.\r\n\r\n### 2. **Post-Processing to Limit Instances**\r\nYou can also manually limit the number of instances that are considered after the predictions are made. For instance, you can take only the top N instances (with the highest scores). Here's how you could modify the detection results to keep only a specified number of instances:\r\n\r\n```python\r\noutputs = predictor(frame)\r\ninstances = outputs[\"instances\"]\r\n\r\n# Let's say you only want the top 50 instances based on the highest scores\r\nnum_instances = 50\r\nscores = instances.scores.cpu().numpy()\r\nindices = np.argsort(scores)[::-1][:num_instances]  # Sort scores and get the indices of the top N\r\n\r\n# Keep only the top N instances\r\ninstances = instances[indices]\r\n\r\n# Use the filtered instances for visualization\r\nboxes = instances.pred_boxes if instances.has(\"pred_boxes\") else None\r\n```\r\n\r\n### 3. **Limiting Instances Based on Class**\r\nIf you have a custom dataset with only 2 classes, you can modify the class indices to make sure you're only detecting objects from your desired classes. You can filter based on class labels, like this:\r\n\r\n```python\r\n# Assume you want to filter only instances belonging to class 0 or class 1\r\nclasses_to_keep = [0, 1]\r\n\r\n# Filter instances based on class\r\nfiltered_instances = instances[torch.isin(instances.pred_classes, torch.tensor(classes_to_keep))]\r\n```\r\n\r\n### 4. **Modify the Model's Config (for Custom Models)**\r\nIf you're training a custom model, you can also change the number of classes the model detects. To do this, you would modify the number of output classes in the model configuration during training. For instance:\r\n\r\n```python\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # Set the number of classes your model detects\r\n```\r\n\r\nThis change affects the training phase, and it ensures that only your specified classes are used during detection."
      },
      {
        "user": "obdwinston",
        "body": "Just to add, if you're using the \"newer\" models from projects which uses lazy config, refer to #4384 to change the number of predicted instances per image."
      }
    ]
  },
  {
    "issue_number": 4475,
    "title": " defining DETECTIONS_PER_IMAGE in the lazy config",
    "author": "nechir123",
    "state": "open",
    "created_at": "2022-08-12T06:50:18Z",
    "updated_at": "2025-05-31T07:19:09Z",
    "labels": [
      "enhancement"
    ],
    "body": "I wanna export my model that has been trained by the lazyconfig_train_net.py. The default value for DETECTIONS_PER_IMAGE= 100 i assume. How can i set this via lazy? When the training was done in the normal way, i could just override the value cfg.TEST.DETECTIONS_PER_IMAGE = 1000.",
    "comments": [
      {
        "user": "obdwinston",
        "body": "Did you figure this out? i'm currently fine-tuning ViTDet and I'm facing the same issue where I cannot change the default number of detections to more than 100."
      }
    ]
  },
  {
    "issue_number": 5332,
    "title": "error raised during installation",
    "author": "LSKhappychild",
    "state": "closed",
    "created_at": "2024-07-24T12:59:46Z",
    "updated_at": "2025-05-30T02:18:41Z",
    "labels": [],
    "body": "## Instructions To Reproduce the Issue:\r\n\r\n```\r\npython -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\n```\r\n```\r\nninja: build stopped: subcommand failed.\r\n      Traceback (most recent call last):\r\n        File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 2107, in _run_ninja_build\r\n          subprocess.run(\r\n        File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\r\n          raise CalledProcessError(retcode, process.args,\r\n      subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\r\n```\r\n\r\n\r\n## Environment:\r\n\r\nPaste the output of the following command:\r\n```\r\nPyTorch version: 2.3.1+cu121\r\nOS: Ubuntu 20.04.6 LTS (x86_64)\r\nCUDA runtime version: 12.1.105\r\nGCC version: (Ubuntu 8.4.0-3ubuntu2) 8.4.0\r\nClang version: 10.0.0-4ubuntu1\r\nCMake version: version 3.28.1\r\nLibc version: glibc-2.31\r\n```\r\n\r\n",
    "comments": [
      {
        "user": "jackkolb",
        "body": "I'm getting this error too."
      },
      {
        "user": "stevemanavalan",
        "body": "i am facing this problem as well during installation. The installation used to work earlier"
      },
      {
        "user": "LSKhappychild",
        "body": "In the full log, which I didn't saved tho, there existed a separate error log showing why the ninja build failed. I'm closing this, since I just found I didn't prepared one required library. To whom it may concern, may take a look at any error log shown."
      }
    ]
  },
  {
    "issue_number": 5338,
    "title": "AttributeError: Attempted to set XXX to XXX, but CfgNode is immutable",
    "author": "Darrenheihei",
    "state": "closed",
    "created_at": "2024-08-01T08:31:00Z",
    "updated_at": "2025-05-29T02:19:43Z",
    "labels": [
      "needs-more-info"
    ],
    "body": "              same, any updates? thanks a lot\r\n\r\n_Originally posted by @Paddy-Xu in https://github.com/facebookresearch/detectron2/issues/911#issuecomment-656584881_\r\n            \r\n\r\nFor anyone who might be encountering this issue as well, the problem is due to `cfg` being frozen and thus becoming immutable.\r\n\r\nMy solution is to first unfreeze `cfg` using `defrost()`, do the modification, then freeze it again using `freeze()`.\r\n\r\n```python\r\ncfg = get_cfg()\r\ncfg.defrost() # unfreeze\r\ncfg.OUTPUT_DIR = './checkpoint' # do the modification you want\r\ncfg.freeze() # freeze it again\r\n```",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      }
    ]
  },
  {
    "issue_number": 5471,
    "title": "Densepose model weights required | Requesting a new mirror",
    "author": "m01ali",
    "state": "open",
    "created_at": "2025-05-27T07:48:33Z",
    "updated_at": "2025-05-27T07:48:33Z",
    "labels": [
      "documentation"
    ],
    "body": "Requesting a new mirror for `model_final_162be9.pkl`. Can someone please provide.\n\nTried the following links:\n\nGot **\"Access Denied\"** error from https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x/161926933/model_final_162be9.pkl \n\n**HuggingFace Mirror:**\nhttps://huggingface.co/akhaliq/densepose/resolve/main/model_final_162be9.pkl\n\n**Google Drive Community Mirror:** \nhttps://drive.google.com/file/d/1wYvT3bWXi4tJ7Qx4zjJZ9rBv_8OJOXcD/view?usp=sharing\n\n\nAll of the above links are down.\n\nBasically i want to use the `densepose_rcnn_R_50_FPN_s1x` for [stableVITON](https://github.com/rlawjdghek/StableVITON). It requires the densepose estimates from `densepose_rcnn_R_50_FPN_s1x` as one of its inputs.",
    "comments": []
  },
  {
    "issue_number": 5329,
    "title": "Cannot install Detectron2",
    "author": "Ly-Lynn",
    "state": "closed",
    "created_at": "2024-07-18T15:58:51Z",
    "updated_at": "2025-05-24T02:16:25Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "![image](https://github.com/user-attachments/assets/6b8c220a-5c09-4fb4-92af-d31c37929083)\r\nThe problem occurred when I try to `python -m pip install -e detectron2` after cloning the repo.\r\nThis is torch and python version\r\n![image](https://github.com/user-attachments/assets/f5c272fb-a200-498a-a6c7-86722510ace5)\r\nThank you!",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "Programmer-RD-AI",
        "body": "Hi,\r\nPlease refer to: #5162\r\nThank You"
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5347,
    "title": "`torch.export` fails when model uses `ImageList.from_tensors`",
    "author": "dgcnz",
    "state": "closed",
    "created_at": "2024-08-13T10:16:17Z",
    "updated_at": "2025-05-22T17:00:11Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\n```py\r\nfrom detectron2.structures import ImageList\r\nfrom torch.export import export\r\nimport torch\r\n\r\nclass M(torch.nn.Module):\r\n    def forward(self, images: list[torch.Tensor]):\r\n        images = ImageList.from_tensors(images)\r\n        return images.tensor\r\n    \r\n\r\nexample_kwargs = {\r\n    \"images\": list(torch.randn(1, 3, 24, 24)),\r\n}\r\nexported_program: torch.export.ExportedProgram = export(\r\n    M(), (), kwargs=example_kwargs\r\n)\r\n```\r\n2. What exact command you run:\r\n3. __Full logs__ or other relevant observations:\r\n```\r\nGuardOnDataDependentSymNode: Could not guard on data-dependent expression u1 < 0 (unhinted: u1 < 0).  (Size-like symbols: none)\r\n\r\nPotential framework code culprit (scroll up for full backtrace):\r\n  File \".venv/lib/python3.10/site-packages/torch/_refs/__init__.py\", line 2849, in constant_pad_nd\r\n    if pad[pad_idx + 1] < 0:\r\n```\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\n## Expected behavior:\r\n\r\nIf there are no obvious error in \"full logs\" provided above,\r\nplease tell us the expected behavior.\r\n\r\n## Environment:\r\n\r\n```\r\n-------------------------------  ----------------------------------------------------------------------------------------------\r\nsys.platform                     darwin\r\nPython                           3.10.12 (main, Dec  4 2023, 21:38:54) [Clang 14.0.3 (clang-1403.0.22.14.1)]\r\nnumpy                            1.26.4\r\ndetectron2                       0.6 @/Users/dgcnz/development/amsterdam/edge/detrex/detectron2/detectron2\r\nCompiler                         clang 15.0.0\r\nCUDA compiler                    not available\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.3.1 @/Users/dgcnz/development/amsterdam/edge/.venv/lib/python3.10/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    No: torch.cuda.is_available() == False\r\nPillow                           10.4.0\r\ntorchvision                      0.18.1 @/Users/dgcnz/development/amsterdam/edge/.venv/lib/python3.10/site-packages/torchvision\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.10.0\r\n-------------------------------  ----------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 4.2\r\n  - C++ Version: 201703\r\n  - clang 14.0.3\r\n  - OpenMP 201811\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: NO AVX\r\n  - Build settings: BLAS_INFO=accelerate, BUILD_TYPE=Release, CXX_COMPILER=/Applications/Xcode_14.3.1.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_PYTORCH_METAL_EXPORT -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DUSE_COREML_DELEGATE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=braced-scalar-init -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wvla-extension -Wsuggest-override -Wnewline-eof -Winconsistent-missing-override -Winconsistent-missing-destructor-override -Wno-pass-failed -Wno-error=pedantic -Wno-error=old-style-cast -Wno-error=inconsistent-missing-override -Wno-error=inconsistent-missing-destructor-override -Wconstant-conversion -Wno-invalid-partial-specialization -Wno-missing-braces -Qunused-arguments -fcolor-diagnostics -faligned-new -Wno-unused-but-set-variable -fno-math-errno -fno-trapping-math -Werror=format -DUSE_MPS -Wno-unused-private-field -Wno-missing-braces, LAPACK_INFO=accelerate, TORCH_VERSION=2.3.1, USE_CUDA=OFF, USE_CUDNN=OFF, USE_CUSPARSELT=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \r\n```",
    "comments": [
      {
        "user": "lodgegao",
        "body": "Met this problem as well, wondering how to fix it "
      },
      {
        "user": "yushangdi",
        "body": "I tried on the nightly branch of pytroch and can reproduce the `GuardOnDataDependentSymNode` error (I got a different GuardOnDataDependentSymNode error than the one in the orignal post though. ) To fix:\n\nOption 1 is you can use draft_export, like \n```\nexported_program: torch.export.ExportedProgram = draft_export(\n    M(), (), kwargs=example_kwargs\n)\n```\n\n\nOption 2, which is the proper fix, is you need to add some `torch._check` calls in `detectron2` code to give export some hint on dynamic shapes. \n\nThe fix you need is https://github.com/facebookresearch/detectron2/pull/5467\n\n```\n        if len(tensors) == 1:\n            # This seems slightly (2%) faster.\n            # TODO: check whether it's faster for multiple images as well\n            image_size = image_sizes[0]\n            u0 = ( max_size[-1] - image_size[1]).item()\n            u1 = ( max_size[-2] - image_size[0]).item()\n\n            padding_size = [0, u0, 0, u1]\n            torch._check(u0 >= 0)\n            torch._check(u1 >= 0)\n            batched_imgs = F.pad(tensors[0], padding_size, value=pad_value).unsqueeze_(0)\n```\n\ncc @angelayi @pianpwk "
      }
    ]
  },
  {
    "issue_number": 46,
    "title": "Convert models to TorchScript",
    "author": "bfortuner",
    "state": "closed",
    "created_at": "2019-10-13T05:26:36Z",
    "updated_at": "2025-05-20T05:10:27Z",
    "labels": [
      "enhancement"
    ],
    "body": "Do you have any examples of how to convert these models into a format runnable in C++? ",
    "comments": [
      {
        "user": "ppwwyyxx",
        "body": "Torchscript does not currently support these models."
      },
      {
        "user": "bfortuner",
        "body": "Got it. Is that because some of the ops aren't supported yet? Is there another way to deploy these models to a c++ environment? (E.g. onnx --> caffe2 or tensorrt)\r\n\r\nIs this lack of support true for object detection models in general? Or is this more specific to the SOTA implementations in detectron?\r\n\r\nHow much work would it be to get one of these models into a c++ compatible format?\r\n\r\nThanks!"
      },
      {
        "user": "ppwwyyxx",
        "body": "We're working on getting TorchScript support. onnx/caffe2 deployment support (discussed in #8) is <del>internal for now, but will also be released later</del> released already. "
      }
    ]
  },
  {
    "issue_number": 4007,
    "title": "Detectron2 should free memory after training.",
    "author": "ExtReMLapin",
    "state": "closed",
    "created_at": "2022-03-02T08:29:50Z",
    "updated_at": "2025-05-15T14:45:22Z",
    "labels": [],
    "body": "Hello, \r\n\r\nLong story short : Detectron isn't freeing the VRAM torch allocations after training and on a system with multiple instances, it can lead to incorrect report of \"no more memory available\"\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nsee attached code, it was trained with `faster_rcnn_R_50_FPN_3x` but the behavior should be the same with any other model from Zoo.\r\n\r\n[solotrainer.zip](https://github.com/facebookresearch/detectron2/files/8167953/solotrainer.zip)\r\n\r\n\r\n#### VRAM USAGE\r\n\r\n1. Before training : **0.6Gb**\r\n2. During training : **4.8Gb**\r\n3. After training finished (didn't close python process) : **4.8Gb**\r\n4. __After manually calling__ `torch.cuda.empty_cache()` : **1.4Gb** (Forcing garbage collection doesn't do anything)\r\n5. Closing process : **0.6Gb**\r\n\r\n\r\n--------------------\r\n\r\n\r\n## Expected behavior:\r\n\r\n\r\nFrom what I understood, torch uses a process-wide memory allocation system instead of a system-wide allocation system (for obvious reasons).\r\n\r\n\r\nThe thing is, -from what i understand- doing this, is taking the risk of having multiple torch memory allocators on one system.\r\n\r\n\r\n-------------------\r\n\r\n\r\nProcess A1 takes 6Gb of vram but doesn't automatically releases them because \"it could need it later\", and same for process A2 running another torch project.\r\n\r\nProcess B1 tries to allocate 3Gb of VRAM but cuda won't because it has no \"free vram page\" to distribute, while in reality A1 and A2 are just reserving VRAM for *nothing*.\r\n\r\n\r\n-------------------\r\n\r\nThis is why as GPUs don't have *yet* a proper memory managment system and torch isn't a system-wide allocator, you should probably free memory as soon as you can using either `torch.cuda.empty_cache()` or any other torch function call that could manually free pages/memory blocks.\r\n\r\nI would have expected you to plug the `DefaultTrainer` garbage collection to `torch.cuda.empty_cache()` or a more specific memory \"liberator\" function.\r\n\r\n\r\nYou can hook garbage collection using [`ffi.gc`](https://cffi.readthedocs.io/en/latest/ref.html?highlight=ffi.gc#ffi-gc) (not directly on the `DefaultTrainer` class, obviously but on the specific variable that -by garbage collection cascade effect-, will be collected)\r\n\r\n## Environment:\r\n\r\nTested on W10 x64 + GTX 1080 detectron2 @ ef2c3abbd36d4093a604f874243037691f634c2f\r\n\r\nAlso tested on Ubuntu with two Tesla V100S 32Gb\r\n\r\n\r\n\r\nW10 env : \r\n```txt\r\n----------------------  -----------------------------------------------------------------------------------------------------------------\r\nsys.platform            win32\r\nPython                  3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]\r\nnumpy                   1.22.2\r\ndetectron2              0.6 @e:\\CENSORED\\detectron2\\detectron2\r\ndetectron2._C           not built correctly: DLL load failed while importing _C: La proc√©dure sp√©cifi√©e est introuvable.\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.10.2+cu113 @C:\\Users\\xxx\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\r\nPyTorch debug build     False\r\nGPU available           Yes\r\nGPU 0                   NVIDIA GeForce GTX 1080 (arch=6.1)\r\nDriver version          511.23\r\nCUDA_HOME               C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\r\nPillow                  8.2.0\r\ntorchvision             0.11.3+cu113 @C:\\Users\\xxx\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\r\ntorchvision arch flags  C:\\Users\\xxx\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\_C.pyd; cannot find cuobjdump\r\nfvcore                  0.1.5.post20211023\r\niopath                  0.1.9\r\ncv2                     4.5.2\r\n----------------------  -----------------------------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - C++ Version: 199711\r\n  - MSVC 192829337\r\n  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\r\n  - OpenMP 2019\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 11.3\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 8.2\r\n  - Magma 2.5.4\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON,\r\n```\r\n\r\nPlease keep understand I'm new to this GPU Calculation/AI computer science subset and I may have misunderstood something.",
    "comments": [
      {
        "user": "ppwwyyxx",
        "body": "The behavior is expected, and as you noted, it is how pytorch works.\r\n\r\nOne addition we could add is to let trainer call `empty_cache()` at the end of training - this sounds reasonable to me. However, users can easily do this themselves if they need. So this doesn't sound like something that has to be added to our trainer.\r\n\r\nI can't think of any other reasonable solutions that can be added in detectron2 to change the memory allocation behavior. In particular I don't think we can \"hook the garbage collector\", whatever that means. Please tell us if you have any concrete suggestions."
      },
      {
        "user": "ExtReMLapin",
        "body": "Thank you for your answer, after a short investigation on how the PyTorch CUDA Memory manager works and how python GC works here is what I found : \r\n\r\n\r\n* [`PyObject_GC_Track(PyObject *op)`](https://docs.python.org/3/c-api/gcsupport.html#c.PyObject_GC_Track) can be used to track an object and hook it's garbage collection.\r\nAs far as I understood, detectron2 is a pure python project so it's not a reasonable approach.\r\n\r\n* PyTorch has\r\n   * `torch.cuda.empty_cache()`\r\n   * `torch.cuda.caching_allocator_alloc()`\r\n   * `torch.cuda.caching_allocator_delete()`\r\nThe two last function are the one that could be interesting but `torch.cuda.caching_allocator_alloc()` isn't used at all as it uses `torch.as_tensor()`\r\n\r\n\r\nWhile implementing `__del__ ` with manually calling `torch.cuda.empty_cache()` inside  sounds inelegant, [maybe calling manually right after the training finished is the best way to handle this problem ?](https://en.wikipedia.org/wiki/KISS_principle)"
      }
    ]
  },
  {
    "issue_number": 5395,
    "title": "Install Detectron2",
    "author": "sizhongzhang1",
    "state": "closed",
    "created_at": "2024-11-20T07:33:16Z",
    "updated_at": "2025-05-14T18:51:22Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": " \r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(187): warning C4624: ‚Äúc10::constexpr_storage_t<T>‚Äù: Â∑≤Â∞ÜÊûêÊûÑÂáΩÊï∞ÈöêÂºèÂÆö‰πâ‰∏∫‚ÄúÂ∑≤Âà†Èô§‚Äù\r\n              with\r\n              [\r\n                  T=std::vector<double,std::allocator<double>>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(187): note: Ê®°ÊùøÂÆû‰æãÂåñ‰∏ä‰∏ãÊñá(ÊúÄÊó©ÁöÑÂÆû‰æãÂåñ ‰∏ä‰∏ãÊñá)‰∏∫\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/options/upsampling.h(26): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Á±ª Ê®°Êùø ÂÆû‰æãÂåñ‚Äúc10::optional<std::vector<T,std::allocator<T>>>‚ÄùÁöÑÂºïÁî®\r\n              with\r\n              [\r\n                  T=double\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(540): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Âà´Âêç Ê®°Êùø ÂÆû ‰æãÂåñ‚Äúc10::OptionalBase<T>‚ÄùÁöÑÂºïÁî®\r\n              with\r\n              [\r\n                  T=std::vector<double,std::allocator<double>>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(528): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Á±ª Ê®°Êùø ÂÆû‰æã Âåñ‚Äúc10::trivially_copyable_optimization_optional_base<T>‚ÄùÁöÑÂºïÁî®\r\n              with\r\n              [\r\n                  T=std::vector<double,std::allocator<double>>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(397): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Á±ª Ê®°Êùø ÂÆû‰æã Âåñ‚Äúc10::constexpr_storage_t<T>‚ÄùÁöÑÂºïÁî®\r\n              with\r\n              [\r\n                  T=std::vector<double,std::allocator<double>>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(395): warning C4624: ‚Äúc10::trivially_copyable_optimization_optional_base<T>‚Äù: Â∑≤Â∞ÜÊûêÊûÑÂáΩÊï∞ÈöêÂºèÂÆö‰πâ‰∏∫‚ÄúÂ∑≤Âà†Èô§‚Äù\r\n              with\r\n              [\r\n                  T=std::vector<double,std::allocator<double>>\r\n              ]\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/functional/vision.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/options/vision.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/functional/instancenorm.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/options/instancenorm.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/init.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/common.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/container/any.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/container/functional.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/container/moduledict.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/container/modulelist.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/container/named_any.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/container/sequential.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/container/parameterdict.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/container/parameterlist.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/adaptive.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/linear.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/options/adaptive.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/batchnorm.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/instancenorm.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/conv.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/overloaded.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/dropout.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/distance.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/embedding.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/fold.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/loss.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/padding.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/pooling.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/rnn.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/options/rnn.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/utils/rnn.h\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(187): warning C4624: ‚Äúc10::constexpr_storage_t<T>‚Äù: Â∑≤Â∞ÜÊûêÊûÑÂáΩÊï∞ÈöêÂºèÂÆö‰πâ‰∏∫‚ÄúÂ∑≤Âà†Èô§‚Äù\r\n              with\r\n              [\r\n                  T=std::tuple<at::Tensor,at::Tensor>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(187): note: Ê®°ÊùøÂÆû‰æãÂåñ‰∏ä‰∏ãÊñá(ÊúÄÊó©ÁöÑÂÆû‰æãÂåñ ‰∏ä‰∏ãÊñá)‰∏∫\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/rnn.h(155): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Á±ª Ê®°Êùø ÂÆû‰æãÂåñ‚Äúc10::optional<std::tuple<at::Tensor,at::Tensor>>‚ÄùÁöÑÂºïÁî®\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(540): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Âà´Âêç Ê®°Êùø ÂÆû ‰æãÂåñ‚Äúc10::OptionalBase<T>‚ÄùÁöÑÂºïÁî®\r\n              with\r\n              [\r\n                  T=std::tuple<at::Tensor,at::Tensor>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(528): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Á±ª Ê®°Êùø ÂÆû‰æã Âåñ‚Äúc10::trivially_copyable_optimization_optional_base<T>‚ÄùÁöÑÂºïÁî®\r\n              with\r\n              [\r\n                  T=std::tuple<at::Tensor,at::Tensor>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(397): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Á±ª Ê®°Êùø ÂÆû‰æã Âåñ‚Äúc10::constexpr_storage_t<T>‚ÄùÁöÑÂºïÁî®\r\n              with\r\n              [\r\n                  T=std::tuple<at::Tensor,at::Tensor>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(395): warning C4624: ‚Äúc10::trivially_copyable_optimization_optional_base<T>‚Äù: Â∑≤Â∞ÜÊûêÊûÑÂáΩÊï∞ÈöêÂºèÂÆö‰πâ‰∏∫‚ÄúÂ∑≤Âà†Èô§‚Äù\r\n              with\r\n              [\r\n                  T=std::tuple<at::Tensor,at::Tensor>\r\n              ]\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/pixelshuffle.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/upsampling.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/activation.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/normalization.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/_functions.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/autograd/custom_function.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:         D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/autograd/function.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:          D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/autograd/anomaly_mode.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:          D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/autograd/saved_variable.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:           D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/autograd/saved_variable_hooks.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:          D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/autograd/input_metadata.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/transformerlayer.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/options/transformerlayer.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/transformercoder.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/options/transformercoder.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/modules/transformer.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/options/transformer.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/options.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/utils.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/utils/clip_grad.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/nn/utils/convert_parameters.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/adagrad.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/optimizer.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/serialize.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/adam.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/adamw.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/lbfgs.h\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(187): warning C4624: ‚Äúc10::constexpr_storage_t<T>‚Äù: Â∑≤Â∞ÜÊûêÊûÑÂáΩÊï∞ÈöêÂºèÂÆö‰πâ‰∏∫‚ÄúÂ∑≤Âà†Èô§‚Äù\r\n              with\r\n              [\r\n                  T=std::vector<at::Tensor,std::allocator<at::Tensor>>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(187): note: Ê®°ÊùøÂÆû‰æãÂåñ‰∏ä‰∏ãÊñá(ÊúÄÊó©ÁöÑÂÆû‰æãÂåñ ‰∏ä‰∏ãÊñá)‰∏∫\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/lbfgs.h(46): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Á±ª Ê®°Êùø ÂÆû‰æãÂåñ‚Äúc10::optional<std::vector<at::Tensor,std::allocator<at::Tensor>>>‚ÄùÁöÑÂºïÁî®\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(540): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Âà´Âêç Ê®°Êùø ÂÆû ‰æãÂåñ‚Äúc10::OptionalBase<T>‚ÄùÁöÑÂºïÁî®\r\n              with\r\n              [\r\n                  T=std::vector<at::Tensor,std::allocator<at::Tensor>>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(528): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Á±ª Ê®°Êùø ÂÆû‰æã Âåñ‚Äúc10::trivially_copyable_optimization_optional_base<T>‚ÄùÁöÑÂºïÁî®\r\n              with\r\n              [\r\n                  T=std::vector<at::Tensor,std::allocator<at::Tensor>>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(397): note: Êü•ÁúãÂØπÊ≠£Âú®ÁºñËØëÁöÑ Á±ª Ê®°Êùø ÂÆû‰æã Âåñ‚Äúc10::constexpr_storage_t<T>‚ÄùÁöÑÂºïÁî®\r\n              with\r\n              [\r\n                  T=std::vector<at::Tensor,std::allocator<at::Tensor>>\r\n              ]\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\c10/util/Optional.h(395): warning C4624: ‚Äúc10::trivially_copyable_optimization_optional_base<T>‚Äù: Â∑≤Â∞ÜÊûêÊûÑÂáΩÊï∞ÈöêÂºèÂÆö‰πâ‰∏∫‚ÄúÂ∑≤Âà†Èô§‚Äù\r\n              with\r\n              [\r\n                  T=std::vector<at::Tensor,std::allocator<at::Tensor>>\r\n              ]\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/rmsprop.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/sgd.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/schedulers/lr_scheduler.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/optim/schedulers/step_lr.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/sparse.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/special.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/autograd.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/autograd/autograd.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/autograd/autograd_not_implemented_fallback.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/version.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:   D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include\\torch/python.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/Device.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/python_headers.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\include\\Python.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\patchlevel.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pyconfig.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\\io.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:         C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\\corecrt_io.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        C:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\\basetsd.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pymacconfig.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\\assert.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pyport.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\\math.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pymacro.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pymath.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pytime.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\object.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:         D:\\conda\\envs\\openmmlab\\include\\pymem.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:          D:\\conda\\envs\\openmmlab\\include\\cpython/pymem.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:         D:\\conda\\envs\\openmmlab\\include\\cpython/object.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\objimpl.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\cpython/objimpl.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\typeslots.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pyhash.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pydebug.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\bytearrayobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\include\\stdarg.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\bytesobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\unicodeobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\cpython/unicodeobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\longobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\longintrepr.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\boolobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\floatobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\complexobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\rangeobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\memoryobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\tupleobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\cpython/tupleobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\listobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\dictobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\cpython/dictobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\odictobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\enumobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\setobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\methodobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\moduleobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\funcobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\classobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\fileobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\cpython/fileobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pycapsule.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\traceback.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\cpython/traceback.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\sliceobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\cellobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\iterobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\genobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\pystate.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:         D:\\conda\\envs\\openmmlab\\include\\pythread.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:         D:\\conda\\envs\\openmmlab\\include\\cpython/pystate.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:          D:\\conda\\envs\\openmmlab\\include\\cpython/initconfig.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\descrobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\warnings.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\weakrefobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\structseq.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\namespaceobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\picklebufobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\codecs.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pyerrors.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\cpython/pyerrors.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\context.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pyarena.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\modsupport.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\compile.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\code.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pythonrun.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pylifecycle.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\cpython/pylifecycle.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\ceval.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\sysmodule.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\cpython/sysmodule.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\osmodule.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\intrcheck.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\import.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\abstract.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\include\\cpython/abstract.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\bltinmodule.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\eval.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pyctype.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pystrtod.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pystrcmp.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\dtoa.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\fileutils.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\pyfpe.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\include\\tracemalloc.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/Dtype.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/DynamicTypes.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/utils/pybind.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11/pybind11.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\attr.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\cast.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\pytypes.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:         D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\detail/common.h\r\n      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\detail/common.h(108): warning C4005: ‚ÄúHAVE_SNPRINTF‚Äù: ÂÆèÈáçÂÆö‰πâ\r\n      D:\\conda\\envs\\openmmlab\\include\\pyerrors.h(315): note: ÂèÇËßÅ‚ÄúHAVE_SNPRINTF‚ÄùÁöÑÂâç‰∏Ä‰∏™ÂÆö‰πâ\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:          D:\\conda\\envs\\openmmlab\\include\\frameobject.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:         D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\buffer_info.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\detail/typeid.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\detail/descr.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:        D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\detail/internals.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\options.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\detail/class.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\detail/init.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11/stl.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.42.34433\\include\\valarray\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/autograd/python_variable.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/Exceptions.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/utils/auto_gil.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/utils/cpp_stacktraces.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/jit/runtime/jit_exception.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\ATen/detail/FunctionTraits.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/utils/python_tuples.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/utils/object_ptr.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:      D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/utils/python_numbers.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/jit/frontend/tracer.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:       D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/utils/tensor_numpy.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:     D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\torch/csrc/Generator.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:  C:\\Users\\27227\\AppData\\Local\\Temp\\pip-req-build-_y0t9pkx\\detectron2\\layers\\csrc\\ROIAlignRotated/ROIAlignRotated.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:  C:\\Users\\27227\\AppData\\Local\\Temp\\pip-req-build-_y0t9pkx\\detectron2\\layers\\csrc\\box_iou_rotated/box_iou_rotated.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:  C:\\Users\\27227\\AppData\\Local\\Temp\\pip-req-build-_y0t9pkx\\detectron2\\layers\\csrc\\cocoeval/cocoeval.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:   D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11/numpy.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\complex.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:   D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11/stl_bind.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:    D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\include\\pybind11\\operators.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:  C:\\Users\\27227\\AppData\\Local\\Temp\\pip-req-build-_y0t9pkx\\detectron2\\layers\\csrc\\deformable/deform_conv.h\r\n      Ê≥®ÊÑè: ÂåÖÂê´Êñá‰ª∂:  C:\\Users\\27227\\AppData\\Local\\Temp\\pip-req-build-_y0t9pkx\\detectron2\\layers\\csrc\\nms_rotated/nms_rotated.h\r\n      ninja: build stopped: subcommand failed.\r\n      Traceback (most recent call last):\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 1808, in _run_ninja_build\r\n          subprocess.run(\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\subprocess.py\", line 516, in run\r\n          raise CalledProcessError(retcode, process.args,\r\n      subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\r\n\r\n      The above exception was the direct cause of the following exception:\r\n\r\n      Traceback (most recent call last):\r\n        File \"<string>\", line 2, in <module>\r\n        File \"<pip-setuptools-caller>\", line 34, in <module>\r\n        File \"C:\\Users\\27227\\AppData\\Local\\Temp\\pip-req-build-_y0t9pkx\\setup.py\", line 151, in <module>\r\n          setup(\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\__init__.py\", line 87, in setup\r\n          return distutils.core.setup(**attrs)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\r\n          return run_commands(dist)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\r\n          dist.run_commands()\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 968, in run_commands\r\n          self.run_command(cmd)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\r\n          super().run_command(command)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 987, in run_command\r\n          cmd_obj.run()\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\command\\install.py\", line 68, in run\r\n          return orig.install.run(self)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\command\\install.py\", line 698, in run\r\n          self.run_command('build')\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\r\n          self.distribution.run_command(command)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\r\n          super().run_command(command)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 987, in run_command\r\n          cmd_obj.run()\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 132, in run\r\n          self.run_command(cmd_name)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\r\n          self.distribution.run_command(command)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\r\n          super().run_command(command)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 987, in run_command\r\n          cmd_obj.run()\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\command\\build_ext.py\", line 84, in run\r\n          _build_ext.run(self)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\Cython\\Distutils\\old_build_ext.py\", line 186, in run\r\n          _build_ext.build_ext.run(self)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 346, in run\r\n          self.build_extensions()\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 765, in build_extensions\r\n          build_ext.build_extensions(self)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\Cython\\Distutils\\old_build_ext.py\", line 195, in build_extensions\r\n          _build_ext.build_ext.build_extensions(self)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 466, in build_extensions\r\n          self._build_extensions_serial()\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 492, in _build_extensions_serial\r\n          self.build_extension(ext)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\command\\build_ext.py\", line 246, in build_extension\r\n          _build_ext.build_extension(self, ext)\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 547, in build_extension\r\n          objects = self.compiler.compile(\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 738, in win_wrap_ninja_compile\r\n          _write_ninja_file_and_compile_objects(\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 1487, in _write_ninja_file_and_compile_objects\r\n          _run_ninja_build(\r\n        File \"D:\\conda\\envs\\openmmlab\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 1824, in _run_ninja_build\r\n          raise RuntimeError(message) from e\r\n      RuntimeError: Error compiling objects for extension\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: legacy-install-failure\r\n\r\n√ó Encountered error while trying to install package.\r\n‚ï∞‚îÄ> detectron2\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for output from the failure.\r\nI encountered the above problem when installing Detectron2 in Window, how can I solve it\r\nPackage                      Version            Editable project location\r\n---------------------------- ------------------ ----------------------------\r\nabsl-py                      1.3.0\r\nadal                         1.2.7\r\naddict                       2.4.0\r\naiofiles                     23.2.1\r\naiohttp                      3.8.4\r\naiosignal                    1.3.1\r\nannotated-types              0.7.0\r\nantlr4-python3-runtime       4.9.3\r\nanyio                        3.6.2\r\nappdirs                      1.4.4\r\nargcomplete                  3.5.0\r\nargon2-cffi                  21.3.0\r\nargon2-cffi-bindings         21.2.0\r\nasttokens                    2.2.0\r\nastunparse                   1.6.3\r\nasync-timeout                4.0.2\r\nattrs                        22.1.0\r\naudioread                    3.0.0\r\nazure-common                 1.1.28\r\nazure-core                   1.30.2\r\nazure-graphrbac              0.61.1\r\nazure-mgmt-authorization     4.0.0\r\nazure-mgmt-containerregistry 10.3.0\r\nazure-mgmt-core              1.4.0\r\nazure-mgmt-keyvault          10.3.1\r\nazure-mgmt-network           26.0.0\r\nazure-mgmt-resource          23.1.1\r\nazure-mgmt-storage           21.2.1\r\nazureml-core                 1.57.0\r\nbackcall                     0.2.0\r\nbackports.tempfile           1.0\r\nbackports.weakref            1.0.post1\r\nbcrypt                       4.2.0\r\nbeautifulsoup4               4.11.1\r\nblack                        22.12.0\r\nbleach                       5.0.1\r\nbrotlipy                     0.7.0\r\ncachetools                   5.2.0\r\ncalplot                      0.1.7.5\r\ncertifi                      2023.7.22\r\ncffi                         1.15.1\r\ncharset-normalizer           2.0.4\r\nchex                         0.1.6\r\nclick                        8.1.3\r\ncloudpickle                  2.2.1\r\ncmdstanpy                    1.1.0\r\ncolorama                     0.4.6\r\ncommonmark                   0.9.1\r\nConfigArgParse               1.5.3\r\ncontextlib2                  21.6.0\r\ncontourpy                    1.0.6\r\nconvertdate                  2.4.0\r\ncryptography                 38.0.1\r\ncycler                       0.11.0\r\nCython                       0.29.32\r\ndash                         2.7.1\r\ndash-core-components         2.0.0\r\ndash-html-components         2.0.0\r\ndash-table                   5.0.0\r\ndearpygui                    1.8.0\r\ndebugpy                      1.6.4\r\ndecorator                    5.1.1\r\ndefusedxml                   0.7.1\r\nDeprecated                   1.2.14\r\ndescartes                    1.1.0\r\ndimod                        0.12.6\r\ndiskcache                    5.6.1\r\ndlib                         19.24.0\r\ndm-pix                       0.4.0\r\ndm-tree                      0.1.8\r\ndocker                       7.1.0\r\ndocker-pycreds               0.4.0\r\ndwave-cloud-client           0.10.5\r\ndwave-greedy                 0.3.0\r\ndwave-hybrid                 0.6.10\r\ndwave-inspector              0.4.2\r\ndwave-neal                   0.6.0\r\ndwave-networkx               0.8.14\r\ndwave-ocean-sdk              6.4.0\r\ndwave-preprocessing          0.5.4\r\ndwave-samplers               1.0.0\r\ndwave-system                 1.19.0\r\ndwave-tabu                   0.5.0\r\ndwavebinarycsp               0.2.0\r\neasyocr                      1.6.2\r\neinops                       0.7.0\r\nentrypoints                  0.4\r\nephem                        4.1.4\r\net-xmlfile                   1.1.0\r\nete3                         3.1.3\r\netils                        1.0.0\r\nexceptiongroup               1.0.4\r\nexecuting                    1.2.0\r\nfastapi                      0.115.4\r\nfastdtw                      0.3.4\r\nfasteners                    0.18\r\nfastjsonschema               2.16.2\r\nffmpy                        0.4.0\r\nfilelock                     3.9.0\r\nfire                         0.5.0\r\nflake8                       6.0.0\r\nFlask                        2.2.2\r\nflatbuffers                  2.0.7\r\nflax                         0.3.3\r\nflit_core                    3.6.0\r\nfontmeta                     1.6.1\r\nfonttools                    4.38.0\r\nfrozenlist                   1.3.3\r\nfsspec                       2024.9.0\r\nfunctorch                    1.13.1\r\nfuture                       1.0.0\r\nfvcore                       0.1.5.post20221221\r\ngast                         0.4.0\r\ngdown                        4.6.4\r\ngeomdl                       5.3.1\r\ngin                          0.1.6\r\ngin-config                   0.5.0\r\ngitdb                        4.0.7\r\nGitPython                    3.1.30\r\ngoogle-auth                  2.15.0\r\ngoogle-auth-oauthlib         0.4.6\r\ngoogle-pasta                 0.2.0\r\ngradio                       4.44.1\r\ngradio_client                1.3.0\r\ngrpcio                       1.51.1\r\nh11                          0.14.0\r\nh5py                         3.8.0\r\nholidays                     0.29\r\nhomebase                     1.0.1\r\nhttpcore                     1.0.6\r\nhttpx                        0.27.2\r\nhuggingface-hub              0.24.6\r\nhumanfriendly                10.0\r\nhydra-core                   1.3.2\r\nidna                         3.4\r\nimageio                      2.22.4\r\nimageio-ffmpeg               0.4.8\r\nimportlib-metadata           6.8.0\r\nimportlib-resources          5.10.0\r\niniconfig                    1.1.1\r\ninstall                      1.3.5\r\niopath                       0.1.9\r\nipykernel                    6.17.1\r\nipython                      8.7.0\r\nipython-genutils             0.2.0\r\nipywidgets                   8.0.2\r\nisodate                      0.6.1\r\nitsdangerous                 2.1.2\r\njax                          0.4.1\r\njaxlib                       0.3.25\r\njedi                         0.18.2\r\njeepney                      0.8.0\r\nJinja2                       3.1.2\r\njmespath                     1.0.1\r\njoblib                       1.3.2\r\njsonpickle                   3.3.0\r\njsonschema                   4.17.3\r\njupyter                      1.0.0\r\njupyter_client               7.4.7\r\njupyter-console              6.4.4\r\njupyter_core                 5.1.0\r\njupyter-server               1.23.3\r\njupyterlab-pygments          0.2.2\r\njupyterlab-widgets           3.0.3\r\nkeras                        2.7.0\r\nKeras-Preprocessing          1.1.2\r\nkiwisolver                   1.4.4\r\nknack                        0.11.0\r\nlibclang                     15.0.6.1\r\nlibrosa                      0.9.2\r\nlightgbm                     4.3.0\r\nlightning-utilities          0.7.1\r\nllvmlite                     0.40.1\r\nLunarCalendar                0.0.9\r\nlyft-dataset-sdk             0.0.8\r\nMarkdown                     3.4.1\r\nMarkupSafe                   2.1.1\r\nmatplotlib                   3.6.2\r\nmatplotlib-inline            0.1.6\r\nmccabe                       0.7.0\r\nmediapy                      1.1.6\r\nminorminer                   0.2.11\r\nmistune                      2.0.4\r\nmkl-fft                      1.3.1\r\nmkl-random                   1.2.2\r\nmkl-service                  2.4.0\r\nmmcls                        0.25.0\r\nmmcv-full                    1.7.0\r\nmmsegmentation               0.29.1\r\nmock                         5.1.0\r\nmodel-index                  0.1.11\r\nmore-itertools               9.1.0\r\nmplfonts                     0.0.8\r\nmsal                         1.30.0\r\nmsal-extensions              1.2.0\r\nmsgpack                      1.0.4\r\nmsrest                       0.7.1\r\nmsrestazure                  0.6.4.post1\r\nmultidict                    6.0.4\r\nmunkres                      1.1.4\r\nmypy-extensions              0.4.3\r\nnbclassic                    0.4.8\r\nnbclient                     0.7.2\r\nnbconvert                    7.2.5\r\nnbformat                     5.5.0\r\nndg-httpsclient              0.5.1\r\nnest-asyncio                 1.5.6\r\nnetworkx                     2.8.8\r\nninja                        1.11.1\r\nnose                         1.3.7\r\nnotebook                     6.5.2\r\nnotebook_shim                0.2.2\r\nnumba                        0.57.1\r\nnumpy                        1.23.4\r\nnuscenes-devkit              1.1.9\r\noauthlib                     3.2.2\r\nomegaconf                    2.3.0\r\nopen3d                       0.16.0\r\nopencv-contrib-python        4.6.0.66\r\nopencv-python                4.6.0.66\r\nopenmim                      0.3.3\r\nopenpyxl                     3.0.10\r\nopt-einsum                   3.3.0\r\nordered-set                  4.1.0\r\norjson                       3.10.11\r\npackaging                    22.0\r\npandas                       1.5.2\r\npandocfilters                1.5.0\r\nparamiko                     3.4.1\r\nparso                        0.8.3\r\npathspec                     0.10.3\r\npathtools                    0.1.2\r\npatsy                        0.5.3\r\npenaltymodel                 1.0.2\r\npickleshare                  0.7.5\r\nPillow                       9.2.0\r\npip                          22.2.2\r\npiqa                         1.2.2\r\npkginfo                      1.11.1\r\npkgutil_resolve_name         1.3.10\r\nplatformdirs                 2.5.4\r\nplotly                       5.11.0\r\nplucky                       0.4.3\r\npluggy                       1.0.0\r\nplyfile                      0.7.4\r\npooch                        1.6.0\r\nportalocker                  2.10.1\r\nprettytable                  3.5.0\r\nprometheus-client            0.15.0\r\nprompt-toolkit               3.0.33\r\nprophet                      1.1.4\r\nprotobuf                     3.20.3\r\npsutil                       5.9.4\r\npure-eval                    0.2.2\r\npyasn1                       0.4.8\r\npyasn1-modules               0.2.8\r\npyclipper                    1.3.0.post4\r\npycocotools                  2.0.6\r\npycodestyle                  2.10.0\r\npycparser                    2.21\r\npydantic                     2.9.2\r\npydantic_core                2.23.4\r\npydot                        3.0.2\r\npydub                        0.25.1\r\npyflakes                     3.0.1\r\npygame                       2.1.2\r\nPygments                     2.13.0\r\nPyJWT                        2.9.0\r\nPyMeeus                      0.5.12\r\nPyNaCl                       1.5.0\r\nPyOpenGL                     3.1.6\r\npyOpenSSL                    22.0.0\r\npyparsing                    3.0.9\r\npyproject-toml               0.0.11\r\npyquaternion                 0.9.9\r\npyqubo                       1.4.0\r\npyreadline3                  3.4.1\r\npyrsistent                   0.19.2\r\nPySocks                      1.7.1\r\npystan                       2.19.1.1\r\npytest                       7.2.0\r\npython-bidi                  0.4.2\r\npython-dateutil              2.8.2\r\npython-multipart             0.0.17\r\npython-speech-features       0.6\r\npytorch-lightning            1.9.3\r\npyts                         0.13.0\r\npytz                         2022.6\r\nPyWavelets                   1.4.1\r\npywin32                      305\r\npywinpty                     2.0.9\r\nPyYAML                       6.0\r\npyzbar                       0.1.9\r\npyzmq                        24.0.1\r\nqtconsole                    5.4.0\r\nQtPy                         2.3.0\r\nrawpy                        0.18.0\r\nrectangle-packer             2.0.1\r\nregex                        2022.10.31\r\nrequests                     2.32.3\r\nrequests-oauthlib            1.3.1\r\nresampy                      0.4.2\r\nrich                         12.6.0\r\nrsa                          4.9\r\nruff                         0.7.3\r\nsafetensors                  0.4.4\r\nscikit-image                 0.19.3\r\nscikit-learn                 1.3.0\r\nscipy                        1.9.3\r\nseaborn                      0.12.2\r\nSecretStorage                3.3.3\r\nsemantic-version             2.10.0\r\nSend2Trash                   1.8.0\r\nsentry-sdk                   1.9.0\r\nsetproctitle                 1.2.2\r\nsetuptools                   65.5.0\r\nsetuptools-git               1.2\r\nShapely                      1.8.5.post1\r\nshellingham                  1.5.4\r\nsix                          1.16.0\r\nsmmap                        4.0.0\r\nsniffio                      1.3.0\r\nsoundfile                    0.11.0\r\nsoupsieve                    2.3.2.post1\r\nstack-data                   0.6.2\r\nstarlette                    0.41.2\r\nstatsmodels                  0.14.0\r\ntabulate                     0.9.0\r\ntenacity                     8.1.0\r\ntensorboard                  2.11.0\r\ntensorboard-data-server      0.6.1\r\ntensorboard-plugin-wit       1.8.1\r\ntensorboardX                 2.5.1\r\ntensorflow-estimator         2.7.0\r\ntensorflow-gpu               2.7.0\r\ntensorflow-io-gcs-filesystem 0.31.0\r\ntensorflow-probability       0.7.0\r\ntermcolor                    2.1.1\r\nterminado                    0.17.0\r\nterminaltables               3.1.10\r\ntexttable                    1.6.7\r\nthreadpoolctl                3.2.0\r\ntifffile                     2022.10.10\r\ntinycss2                     1.2.1\r\ntokenizers                   0.19.1\r\ntoml                         0.10.2\r\ntomli                        2.0.1\r\ntomlkit                      0.12.0\r\ntoolz                        0.12.0\r\ntorch                        1.12.1\r\ntorch-cluster                1.6.0+pt112cu113\r\ntorch-efficient-distloss     0.1.3\r\ntorch-ema                    0.3\r\ntorch-geometric              2.2.0\r\ntorch-scatter                2.1.0+pt112cu113\r\ntorch-sparse                 0.6.16+pt112cu113\r\ntorch-spline-conv            1.2.1+pt112cu113\r\ntorchaudio                   0.12.1\r\ntorchmetrics                 0.11.1\r\ntorchvision                  0.13.1\r\ntornado                      6.2\r\ntqdm                         4.64.1\r\ntraitlets                    5.6.0\r\ntransformers                 4.44.2\r\ntrimesh                      2.35.39\r\ntslearn                      0.6.1\r\ntsod                         0.1.4\r\ntyper                        0.13.0\r\ntyping_extensions            4.12.2\r\nunicodedata2                 15.0.0\r\nurllib3                      2.2.3\r\nuvicorn                      0.32.0\r\nwandb                        0.13.10\r\nwcwidth                      0.2.5\r\nwebencodings                 0.5.1\r\nwebsocket-client             1.4.2\r\nwebsockets                   12.0\r\nWerkzeug                     2.2.2\r\nwheel                        0.37.1\r\nwidgetsnbextension           4.0.3\r\nwin-inet-pton                1.1.0\r\nwincertstore                 0.2\r\nwrapt                        1.15.0\r\nxlrd                         2.0.1\r\nyacs                         0.1.8\r\nyapf                         0.32.0\r\nyarl                         1.8.2\r\nzipp                         3.16.2",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "lezasantaizi",
        "body": "          name: linux_gpu_tests_pytorch2.1.1\r\n          pytorch_version: \"2.1.1\"\r\n          torchvision_version: \"0.16.1\"\r\n          cuda_version: \"12.1\"\r\n          python_version: \"3.11\"\r\n          pytorch_index: \"https://download.pytorch.org/whl/nightly/cu121\""
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 4994,
    "title": "`ERROR: Failed building wheel for detectron2` when installing detectron2 through a docker image in a DigitalOcean droplet",
    "author": "eRuaro",
    "state": "open",
    "created_at": "2023-06-09T10:59:24Z",
    "updated_at": "2025-05-13T02:53:27Z",
    "labels": [],
    "body": "I'm running into an error when installing `detectron2` in a docker image in a digital ocean droplet but it works with no problems when I build the docker image in my local machine.\r\n\r\nEDIT: Upon rebuilding with `--no-cache` the dockerfile below doesn't include detectron when building for some reason. Didn't have this before.\r\n\r\nHere's my dockerfile:\r\n```\r\nFROM python:3.10-slim-buster\r\n\r\n# Update package lists\r\nRUN apt-get update && apt-get install ffmpeg libsm6 libxext6 gcc g++ git build-essential libpoppler-cpp-dev pkg-config poppler-utils tesseract-ocr libtesseract-dev -y\r\n\r\n# Make working directories\r\nRUN  mkdir -p  /app\r\nWORKDIR  /app\r\n# Copy the requirements.txt file to the container\r\nCOPY requirements.txt .\r\n\r\n# Install dependencies\r\nRUN pip install --upgrade pip\r\n\r\nRUN pip install torch torchvision torchaudio\r\n\r\nRUN pip install -r requirements.txt\r\n\r\nRUN pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2'\r\n\r\n# Copy the .env file to the container\r\nCOPY .env .\r\n\r\n# Copy every file in the source folder to the created working directory\r\nCOPY  . .\r\n\r\n# Expose the port that the application will run on\r\nEXPOSE 8080\r\n\r\n# Start the application\r\nCMD [\"python3.10\", \"uvicorn\", \"-m\", \"main:app\", \"--proxy-headers\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\r\n```\r\n\r\nI'm using a basic digital ocean droplet with 2 GB Memory / 2 Intel vCPUs / 60 GB Disk / and running Ubuntu 22.10 x64.\r\n\r\nHere's the error:\r\n```\r\nBuilding wheels for collected packages: detectron2, fvcore\r\n  Building wheel for detectron2 (setup.py): started\r\n  Building wheel for detectron2 (setup.py): still running...\r\n  Building wheel for detectron2 (setup.py): still running...\r\n  Building wheel for detectron2 (setup.py): finished with status 'error'\r\n  error: subprocess-exited-with-error\r\n\r\n  √ó python setup.py bdist_wheel did not run successfully.\r\n  ‚îÇ exit code: 1\r\n  ‚ï∞‚îÄ> [397 lines of output]\r\n      running bdist_wheel\r\n      /usr/local/lib/python3.10/site-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\r\n        \r\n...\r\n...\r\n...\r\n\r\n                       from /tmp/pip-req-build-1jp0qvnm/detectron2/layers/csrc/vision.cpp:3:\r\n      /usr/local/lib/python3.10/site-packages/torch/include/pybind11/pybind11.h: In instantiation of ‚Äòclass pybind11::class_<detectron2::COCOeval::InstanceAnnotation>‚Äô:\r\n      /tmp/pip-req-build-1jp0qvnm/detectron2/layers/csrc/vision.cpp:105:73:   required from here\r\n      /usr/local/lib/python3.10/site-packages/torch/include/pybind11/pybind11.h:1479:7: warning: ‚Äòpybind11::class_<detectron2::COCOeval::InstanceAnnotation>‚Äô declared with greater visibility than its base ‚Äòpybind11::detail::generic_type‚Äô [-Wattributes]\r\n       class class_ : public detail::generic_type {\r\n             ^~~~~~\r\n      /usr/local/lib/python3.10/site-packages/torch/include/pybind11/pybind11.h: In instantiation of ‚Äòclass pybind11::class_<detectron2::COCOeval::ImageEvaluation>‚Äô:\r\n      /tmp/pip-req-build-1jp0qvnm/detectron2/layers/csrc/vision.cpp:107:67:   required from here\r\n      /usr/local/lib/python3.10/site-packages/torch/include/pybind11/pybind11.h:1479:7: warning: ‚Äòpybind11::class_<detectron2::COCOeval::ImageEvaluation>‚Äô declared with greater visibility than its base ‚Äòpybind11::detail::generic_type‚Äô [-Wattributes]\r\n      gcc: fatal error: Killed signal terminated program cc1plus\r\n      compilation terminated.\r\n      error: command '/usr/bin/gcc' failed with exit code 1\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for detectron2\r\n  Running setup.py clean for detectron2\r\n  Building wheel for fvcore (setup.py): started\r\n  Building wheel for fvcore (setup.py): finished with status 'done'\r\n  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61405 sha256=f68cb822c5d8cc162abe548a6080cc96afae83ad7f5dfdcc836fe6cf5ae14b81\r\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\r\nSuccessfully built fvcore\r\nFailed to build detectron2\r\nERROR: Could not build wheels for detectron2, which is required to install pyproject.toml-based projects\r\n```\r\n\r\nI've also tried with this dockerfile:\r\n```\r\nFROM python:3.10-slim-buster\r\n\r\n# Update package lists\r\nRUN apt-get update && apt-get install ffmpeg libsm6 libxext6 gcc g++ git build-essential libpoppler-cpp-dev pkg-config poppler-utils tesseract-ocr libtesseract-dev -y\r\n\r\n# Make working directories\r\nRUN  mkdir -p  /app\r\nWORKDIR  /app\r\n# Copy the requirements.txt file to the container\r\nCOPY requirements.txt .\r\n\r\n# Install dependencies\r\nRUN pip install --upgrade pip\r\n\r\nRUN pip install torch torchvision torchaudio\r\n\r\nRUN pip install -r requirements.txt\r\n\r\nRUN pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\n\r\n# Copy the .env file to the container\r\nCOPY .env .\r\n\r\n# Copy every file in the source folder to the created working directory\r\nCOPY  . .\r\n\r\n# Expose the port that the application will run on\r\nEXPOSE 8080\r\n\r\n# Start the application\r\nCMD [\"python3.10\", \"-m\", \"uvicorn\", \"main:app\", \"--proxy-headers\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\r\n```\r\n\r\nBut it doesn't install detectron on my local machine.",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "arunchandra23",
        "body": "Try running `pip install git+https://github.com/facebookresearch/iopath@8f359cf63bec091969ad8f30fa14c17d3218c347#egg=iopath` before detectron2"
      },
      {
        "user": "rahelbeloch",
        "body": "We had the same issue and it came down to memory limitations. Running our docker file with the command `RUN pip install 'git+https://github.com/facebookresearch/detectron2.git'` required up to 30GB memory on the machine where it was running.\r\n\r\nMaybe you can use some memory visualisation tool of your machine to see if the memory is running full while building the image... "
      }
    ]
  },
  {
    "issue_number": 2367,
    "title": "Should `MODEL.ROI_HEADS.NUM_CLASSES` include background? ",
    "author": "FraPochetti",
    "state": "closed",
    "created_at": "2020-12-10T12:24:39Z",
    "updated_at": "2025-05-12T02:57:01Z",
    "labels": [
      "documentation"
    ],
    "body": "Hello everybody,\r\nfirst of all, thanks a lot for building this awesome library!\r\n\r\nI have checked the docs and could not find a clear answer to my question, so asking here.\r\nI am currently using a `mask_rcnn` model and I am not sure whether `MODEL.ROI_HEADS.NUM_CLASSES` should include _background_ or not (e.g. if my dataset includes only `dogs`, NUM_CLASSES should be `2`).\r\n\r\nThis is not specified in the relevant [class docstring](https://github.com/facebookresearch/detectron2/blob/9bfa212f68daf47b42e9bb1314652cfce5882d13/detectron2/modeling/roi_heads/mask_head.py#L220) and, given `torchvision` [makes it explicit](https://github.com/pytorch/vision/blob/4d3a309379f2df748922a610c5dd648ae7248bae/torchvision/models/detection/mask_rcnn.py#L315), I am a bit confused.\r\n\r\nCan you please provide some guidance?\r\nThanks ",
    "comments": [
      {
        "user": "huangfeng95",
        "body": "I have the same doubt"
      },
      {
        "user": "ppwwyyxx",
        "body": "The config reference https://detectron2.readthedocs.io/modules/config.html#config-references has answered this: \"Number of foreground classes\"\r\n\r\nWe will add it to the class docstring as well."
      },
      {
        "user": "FraPochetti",
        "body": "I am more than happy to open a PR for this!\r\n\r\n@ppwwyyxx thanks a lot for the prompt reply.\r\nI just want to make sure I get this right.\r\n\r\n_\"Number of foreground classes\"_ means that it should include `background`, so in my example above \"if my dataset includes only `dogs`, NUM_CLASSES should be `2`\".\r\nIs my understanding correct?"
      }
    ]
  },
  {
    "issue_number": 4882,
    "title": "Dockerfile build failed with unsupported python version",
    "author": "zerollzeng",
    "state": "open",
    "created_at": "2023-03-28T10:18:47Z",
    "updated_at": "2025-05-06T19:25:14Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n[+] Building 631.5s (15/16)\r\n => [internal] load .dockerignore                                                                                                                                                                                                                                   0.0s\r\n => => transferring context: 2B                                                                                                                                                                                                                                     0.0s\r\n => [internal] load build definition from Dockerfile                                                                                                                                                                                                                0.0s\r\n => => transferring dockerfile: 2.13kB                                                                                                                                                                                                                              0.0s\r\n => [internal] load metadata for docker.io/nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04                                                                                                                                                                              1.0s\r\n => [ 1/13] FROM docker.io/nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04@sha256:1f181384de58303eb71b70854033fa0774a3212ac6824ad07859c96f91e98fac                                                                                                                    280.8s\r\n => => resolve docker.io/nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04@sha256:1f181384de58303eb71b70854033fa0774a3212ac6824ad07859c96f91e98fac                                                                                                                        0.0s\r\n => => sha256:a404e54162968593b8d92b571f3cdd673e4c9eab5d9be28d7c494595c0aa6682 26.71MB / 26.71MB                                                                                                                                                                    0.3s\r\n => => sha256:391d07dd0009f93d13fb7b13dab2078ad0686953b6b398f66688c7204466df48 7.22MB / 7.22MB                                                                                                                                                                      0.8s\r\n => => sha256:cb7a4dc5cae35387c4323a9d9855171616e61cd95711ce2b411ce03a03f349e6 10.79MB / 10.79MB                                                                                                                                                                    0.5s\r\n => => sha256:1f181384de58303eb71b70854033fa0774a3212ac6824ad07859c96f91e98fac 1.05kB / 1.05kB                                                                                                                                                                      0.0s\r\n => => sha256:26f27dedabe94a7aa56e1683be4595f56993ba42db50ecb54db1d92a73be7be8 2.43kB / 2.43kB                                                                                                                                                                      0.0s\r\n => => sha256:d91fe8dffe66931f4f2def08c2163dd2c0afc536e21d133c8352eb8978483f5a 15.21kB / 15.21kB                                                                                                                                                                    0.0s\r\n => => sha256:3f77a3e2807d8cb8690b749c26d19e6e462743141b750330d311916f3c4857e9 186B / 186B                                                                                                                                                                          0.5s\r\n => => extracting sha256:a404e54162968593b8d92b571f3cdd673e4c9eab5d9be28d7c494595c0aa6682                                                                                                                                                                           1.8s\r\n => => sha256:0f0ed9680ff1f69ce856414b2c9cd4482d37b24147c07821faba7ae51d862a6d 6.43kB / 6.43kB                                                                                                                                                                      0.6s\r\n => => sha256:e2250e4b9e6414e7df5d1f97abaa9fdfb5b5a97cef526f9bdf91b6623b076b6a 1.51GB / 1.51GB                                                                                                                                                                     14.5s\r\n => => sha256:9cf40c59065f805dd01d0a204a6817daa6acf7034abaf92e9d950c73d7b4cb11 63.42kB / 63.42kB                                                                                                                                                                    0.7s\r\n => => sha256:2948bd655f12ed243a171bd23359dc90cd0be5fed8da758a99997c092a2e4618 1.25GB / 1.25GB                                                                                                                                                                     11.4s\r\n => => sha256:c27dc09446dd9f1ec89a8a74c1371779e699eedbf6e2e9cd833c884ff1628f08 87.61kB / 87.61kB                                                                                                                                                                    0.9s\r\n => => sha256:2ada995899f12968272da2be7985d70c2b61eae023b7526afc41757f98536259 1.57GB / 1.57GB                                                                                                                                                                     18.0s\r\n => => extracting sha256:391d07dd0009f93d13fb7b13dab2078ad0686953b6b398f66688c7204466df48                                                                                                                                                                           0.5s\r\n => => extracting sha256:cb7a4dc5cae35387c4323a9d9855171616e61cd95711ce2b411ce03a03f349e6                                                                                                                                                                           0.6s\r\n => => extracting sha256:3f77a3e2807d8cb8690b749c26d19e6e462743141b750330d311916f3c4857e9                                                                                                                                                                           0.0s\r\n => => extracting sha256:0f0ed9680ff1f69ce856414b2c9cd4482d37b24147c07821faba7ae51d862a6d                                                                                                                                                                           0.0s\r\n => => extracting sha256:e2250e4b9e6414e7df5d1f97abaa9fdfb5b5a97cef526f9bdf91b6623b076b6a                                                                                                                                                                          84.6s\r\n => => extracting sha256:9cf40c59065f805dd01d0a204a6817daa6acf7034abaf92e9d950c73d7b4cb11                                                                                                                                                                           0.1s\r\n => => extracting sha256:2948bd655f12ed243a171bd23359dc90cd0be5fed8da758a99997c092a2e4618                                                                                                                                                                          71.5s\r\n => => extracting sha256:c27dc09446dd9f1ec89a8a74c1371779e699eedbf6e2e9cd833c884ff1628f08                                                                                                                                                                           0.1s\r\n => => extracting sha256:2ada995899f12968272da2be7985d70c2b61eae023b7526afc41757f98536259                                                                                                                                                                         109.6s\r\n => [ 2/13] RUN apt-get update && apt-get install -y  python3-opencv ca-certificates python3-dev git wget sudo ninja-build                                                                                                                                        181.5s\r\n => [ 3/13] RUN ln -sv /usr/bin/python3 /usr/bin/python                                                                                                                                                                                                             0.4s\r\n => [ 4/13] RUN useradd -m --no-log-init --system  --uid 42189 appuser -g sudo                                                                                                                                                                                      0.4s\r\n => [ 5/13] RUN echo '%sudo ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers                                                                                                                                                                                                 0.5s\r\n => [ 6/13] WORKDIR /home/appuser                                                                                                                                                                                                                                   0.0s\r\n => [ 7/13] RUN wget https://bootstrap.pypa.io/pip/3.6/get-pip.py &&  python3 get-pip.py --user &&  rm get-pip.py                                                                                                                                                   4.2s\r\n => [ 8/13] RUN pip install --user tensorboard cmake onnx   # cmake from apt-get is too old                                                                                                                                                                        24.9s\r\n => [ 9/13] RUN pip install --user torch==1.10 torchvision==0.11.1 -f https://download.pytorch.org/whl/cu111/torch_stable.html                                                                                                                                    119.7s\r\n => [10/13] RUN pip install --user 'git+https://github.com/facebookresearch/fvcore'                                                                                                                                                                                 5.1s\r\n => [11/13] RUN git clone https://github.com/facebookresearch/detectron2 detectron2_repo                                                                                                                                                                            1.7s\r\n => ERROR [12/13] RUN pip install --user -e detectron2_repo                                                                                                                                                                                                        11.0s\r\n------\r\n > [12/13] RUN pip install --user -e detectron2_repo:\r\n#0 0.903 Obtaining file:///home/appuser/detectron2_repo\r\n#0 0.903   Preparing metadata (setup.py): started\r\n#0 2.654   Preparing metadata (setup.py): finished with status 'done'\r\n#0 2.695 Requirement already satisfied: Pillow>=7.1 in ./.local/lib/python3.6/site-packages (from detectron2==0.6) (8.4.0)\r\n#0 3.251 Collecting matplotlib\r\n#0 3.282   Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\r\n#0 3.654 Collecting pycocotools>=2.0.2\r\n#0 3.660   Downloading pycocotools-2.0.6.tar.gz (24 kB)\r\n#0 3.673   Installing build dependencies: started\r\n#0 9.152   Installing build dependencies: finished with status 'done'\r\n#0 9.154   Getting requirements to build wheel: started\r\n#0 9.531   Getting requirements to build wheel: finished with status 'done'\r\n#0 9.537   Preparing metadata (pyproject.toml): started\r\n#0 9.932   Preparing metadata (pyproject.toml): finished with status 'done'\r\n#0 9.934 Requirement already satisfied: termcolor>=1.1 in ./.local/lib/python3.6/site-packages (from detectron2==0.6) (1.1.0)\r\n#0 9.935 Requirement already satisfied: yacs>=0.1.8 in ./.local/lib/python3.6/site-packages (from detectron2==0.6) (0.1.8)\r\n#0 9.935 Requirement already satisfied: tabulate in ./.local/lib/python3.6/site-packages (from detectron2==0.6) (0.8.10)\r\n#0 9.981 Collecting cloudpickle\r\n#0 9.988   Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\r\n#0 9.991 Requirement already satisfied: tqdm>4.29.0 in ./.local/lib/python3.6/site-packages (from detectron2==0.6) (4.64.1)\r\n#0 9.991 Requirement already satisfied: tensorboard in ./.local/lib/python3.6/site-packages (from detectron2==0.6) (2.10.1)\r\n#0 10.08 Collecting fvcore<0.1.6,>=0.1.5\r\n#0 10.09   Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\r\n#0 10.10   Preparing metadata (setup.py): started\r\n#0 10.37   Preparing metadata (setup.py): finished with status 'done'\r\n#0 10.40 Collecting iopath<0.1.10,>=0.1.7\r\n#0 10.41   Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\r\n#0 10.55 Collecting omegaconf>=2.1\r\n#0 10.55   Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\r\n#0 10.60 Collecting hydra-core>=1.1\r\n#0 10.60   Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\r\n#0 10.71 Collecting black\r\n#0 10.72   Downloading black-22.8.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\r\n#0 10.80 Collecting packaging\r\n#0 10.81   Downloading packaging-21.3-py3-none-any.whl (40 kB)\r\n#0 10.81 Requirement already satisfied: dataclasses in ./.local/lib/python3.6/site-packages (from detectron2==0.6) (0.8)\r\n#0 10.81 ERROR: Package 'detectron2' requires a different Python: 3.6.9 not in '>=3.7'\r\n------\r\nDockerfile:36\r\n--------------------\r\n  34 |     ENV TORCH_CUDA_ARCH_LIST=\"${TORCH_CUDA_ARCH_LIST}\"\r\n  35 |\r\n  36 | >>> RUN pip install --user -e detectron2_repo\r\n  37 |\r\n  38 |     # Set a fixed model cache directory.\r\n--------------------\r\nERROR: failed to solve: process \"/bin/sh -c pip install --user -e detectron2_repo\" did not complete successfully: exit code: 1\r\n```\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\n```\r\ndocker build --build-arg USER_ID=$UID -t detectron2:v0 .\r\n```\r\n\r\n",
    "comments": [
      {
        "user": "mabushey",
        "body": "Anyone have the solution? The whole point of docker is to encapsulate this insanely fragile mess. Does reverting to an older commit fix this?"
      },
      {
        "user": "mabushey",
        "body": "The reason you couldn't find the solution is it was resolved a year ago, but with over 24K stars there's apparently no one that cares. \r\nI got the docker container to build by changing ubuntu18 to ubuntu20, but the demo errors. \r\n\r\nI wish these AI libraries were available for Rust so I could actually use them."
      },
      {
        "user": "sxyxs",
        "body": "> The reason you couldn't find the solution is it was resolved a year ago, but with over 24K stars there's apparently no one that cares. I got the docker container to build by changing ubuntu18 to ubuntu20, but the demo errors.\r\n> \r\n> I wish these AI libraries were available for Rust so I could actually use them.\r\n\r\nI switch the ubuntu 18 to 20  and it works for me :D"
      }
    ]
  },
  {
    "issue_number": 5368,
    "title": "Fix for running panoptic segmentation on video in the Detectron2 Tutorial.ipynb",
    "author": "Reka-Berci-Hajnovics",
    "state": "open",
    "created_at": "2024-09-25T08:41:00Z",
    "updated_at": "2025-04-25T01:49:18Z",
    "labels": [
      "documentation"
    ],
    "body": "## üìö Documentation Issue\r\n\r\nIn the Detectron2 Tutorial.ipynb Google Colab notebook the segmentation on a video is broken.\r\n[Detectron2 Tutorial.ipynb](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=cyA4VmKcF61k)\r\n\r\nThis issue can be fixed by installing another youtube-dl and setting the locale to UTF-8:\r\n```\r\n# Install dependencies, download the video, and crop 5 seconds for processing\r\nimport locale\r\nlocale.getpreferredencoding = lambda: \"UTF-8\"\r\n\r\n#ERROR: Unable to extract uploader id\r\n#!pip install youtube-dl\r\n#!youtube-dl https://www.youtube.com/watch?v=ll8TgCZ0plk -f 22 -o video.mp4\r\n!pip install https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\r\n!yt-dlp https://www.youtube.com/watch?v=ll8TgCZ0plk -f 269 -o video.mp4\r\n!ffmpeg -i video.mp4 -t 00:00:06 -c:v copy video-clip.mp4\r\n```\r\n\r\nThe next code block returns an error as well, because of the relative paths used in the demo.py script:\r\n```\r\n# Run frame-by-frame inference demo on this video (takes 3-4 minutes) with the \"demo.py\" tool we provided in the repo.\r\n#!git clone https://github.com/facebookresearch/detectron2\r\n# Note: this is currently BROKEN due to missing codec. See https://github.com/facebookresearch/detectron2/issues/2901 for workaround.\r\n#%run detectron2/demo/demo.py --config-file detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml --video-input video-clip.mp4 --confidence-threshold 0.6 --output video-output.mkv \\\r\n#  --opts MODEL.WEIGHTS detectron2://COCO-PanopticSegmentation/panoptic_fpn_R_101_3x/139514519/model_final_cafdb1.pkl\r\n\r\n#Fix:\r\n#Set the path to the parent 'detectron2' folder\r\nsys.path.insert(0, os.path.abspath('detectron2'))\r\n#Open the detectron2 folder in the left side panel of Google Colab. In the demo folder you can find the demo.py script.\r\n#Now you can modify the demo.py script. Comment or delete the import of VisualizationDemo, and add the following import:\r\n#from predictor import VisualizationDemo\r\n#When the pull request will be accepted, the manual modification of demo.py script will no longer be needed.\r\n\r\n%run detectron2/demo/demo.py --config-file detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml --video-input video-clip.mp4 --confidence-threshold 0.6 --output video-output.mkv \\\r\n  --opts MODEL.WEIGHTS detectron2://COCO-PanopticSegmentation/panoptic_fpn_R_101_3x/139514519/model_final_cafdb1.pkl\r\n```\r\n\r\n",
    "comments": [
      {
        "user": "tantan39",
        "body": "Great fix! Thanks @Reka-Berci-Hajnovics "
      }
    ]
  },
  {
    "issue_number": 5443,
    "title": "Google Colab Tutorial as a Python script does not give expected results",
    "author": "moritzw01",
    "state": "closed",
    "created_at": "2025-02-27T21:34:40Z",
    "updated_at": "2025-04-24T14:46:54Z",
    "labels": [],
    "body": null,
    "comments": []
  },
  {
    "issue_number": 5309,
    "title": "Please read & provide the following",
    "author": "Mandymoe32",
    "state": "closed",
    "created_at": "2024-06-15T07:29:51Z",
    "updated_at": "2025-04-21T02:18:55Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "If you do not know the root cause of the problem, please post according to this template:\n\n## Instructions To Reproduce the Issue:\n\nCheck https://stackoverflow.com/help/minimal-reproducible-example for how to ask good questions.\nSimplify the steps to reproduce the issue using suggestions from the above link, and provide them below:\n\n1. Full runnable code or full changes you made:\n```\nIf making changes to the project itself, please use output of the following command:\ngit rev-parse HEAD; git diff\n\n<put code or diff here>\n```\n2. What exact command you run:\n3. __Full logs__ or other relevant observations:\n```\n<put logs here>\n```\n\n## Expected behavior:\n\nIf there are no obvious crash in \"full logs\" provided above,\nplease tell us the expected behavior.\n\nIf you expect a model to converge / work better, we do not help with such issues, unless\na model fails to reproduce the results in detectron2 model zoo, or proves existence of bugs.\n\n## Environment:\n\nPaste the output of the following command:\n```\nwget -nc -nv https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\n```\n\nIf your issue looks like an installation issue / environment issue,\nplease first check common issues in https://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "Programmer-RD-AI",
        "body": "Hi,\r\nCould you please provide the issue your facing?\r\nThank you"
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5461,
    "title": "Stitching of image features",
    "author": "wangjinpo",
    "state": "open",
    "created_at": "2025-04-18T07:36:14Z",
    "updated_at": "2025-04-18T07:36:14Z",
    "labels": [
      "enhancement"
    ],
    "body": "Can it be used for image feature stitching fusion?",
    "comments": []
  },
  {
    "issue_number": 5458,
    "title": "Hi @Scttmrx123!",
    "author": "Scttmrx123",
    "state": "closed",
    "created_at": "2025-04-09T04:17:33Z",
    "updated_at": "2025-04-17T02:15:35Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "              Hi @Scttmrx123! \r\n\r\nThank you for your pull request and welcome to our community. \r\n\r\n# Action Required\r\n\r\nIn order to merge **any pull request** (code, docs, etc.), we **require** contributors to sign our **Contributor License Agreement**, and we don't seem to have one on file for you.\r\n\r\n# Process\r\n\r\nIn order for us to review and merge your suggested changes, please sign at <https://code.facebook.com/cla>. **If you are contributing on behalf of someone else (eg your employer)**, the individual CLA may not be sufficient and your employer may need to sign the corporate CLA.\r\n\r\nOnce the CLA is signed, our tooling will perform checks and validations. Afterwards, the **pull request will be tagged** with `CLA signed`. The tagging process may take up to 1 hour after signing. Please give it that time before contacting us about it.\r\n\r\nIf you have received this in error or have any questions, please contact us at [cla@meta.com](mailto:cla@meta.com?subject=CLA%20for%20facebookresearch%2Fvggt%20%2329). Thanks!\r\n\r\n_Originally posted by @facebook-github-bot in https://github.com/facebookresearch/vggt/issues/29#issuecomment-2734862887_\r\n            ",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5009,
    "title": "RuntimeError: Error compiling objects for extension (installation issue - without CUDA)",
    "author": "Ambuj-Choudha",
    "state": "closed",
    "created_at": "2023-06-26T08:12:55Z",
    "updated_at": "2025-04-16T02:16:31Z",
    "labels": [],
    "body": "1. Terminal Output:\r\n```\r\nObtaining file:///home/ambuj/Myprojects/detectron2\r\n  Preparing metadata (setup.py) ... done\r\nRequirement already satisfied: Pillow>=7.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (9.4.0)\r\nRequirement already satisfied: matplotlib in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (3.7.1)\r\nRequirement already satisfied: pycocotools>=2.0.2 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (2.0.6)\r\nRequirement already satisfied: termcolor>=1.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (2.3.0)\r\nRequirement already satisfied: yacs>=0.1.8 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (0.1.8)\r\nRequirement already satisfied: tabulate in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (0.9.0)\r\nRequirement already satisfied: cloudpickle in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (2.2.1)\r\nRequirement already satisfied: tqdm>4.29.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (4.65.0)\r\nRequirement already satisfied: tensorboard in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (2.13.0)\r\nRequirement already satisfied: fvcore<0.1.6,>=0.1.5 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (0.1.5.post20221221)\r\nRequirement already satisfied: iopath<0.1.10,>=0.1.7 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (0.1.9)\r\nRequirement already satisfied: omegaconf>=2.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (2.3.0)\r\nRequirement already satisfied: hydra-core>=1.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (1.3.2)\r\nRequirement already satisfied: black in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (23.3.0)\r\nRequirement already satisfied: packaging in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from detectron2==0.6) (23.1)\r\nRequirement already satisfied: numpy in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.25.0)\r\nRequirement already satisfied: pyyaml>=5.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0)\r\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\r\nRequirement already satisfied: portalocker in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.7.0)\r\nRequirement already satisfied: contourpy>=1.0.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (1.1.0)\r\nRequirement already satisfied: cycler>=0.10 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (0.11.0)\r\nRequirement already satisfied: fonttools>=4.22.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (4.40.0)\r\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (1.4.4)\r\nRequirement already satisfied: pyparsing>=2.3.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (3.1.0)\r\nRequirement already satisfied: python-dateutil>=2.7 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (2.8.2)\r\nRequirement already satisfied: click>=8.0.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from black->detectron2==0.6) (8.1.3)\r\nRequirement already satisfied: mypy-extensions>=0.4.3 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from black->detectron2==0.6) (1.0.0)\r\nRequirement already satisfied: pathspec>=0.9.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from black->detectron2==0.6) (0.11.1)\r\nRequirement already satisfied: platformdirs>=2 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from black->detectron2==0.6) (3.8.0)\r\nRequirement already satisfied: absl-py>=0.4 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (1.4.0)\r\nRequirement already satisfied: grpcio>=1.48.2 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (1.56.0)\r\nRequirement already satisfied: google-auth<3,>=1.6.3 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (2.20.0)\r\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (1.0.0)\r\nRequirement already satisfied: markdown>=2.6.8 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (3.4.3)\r\nRequirement already satisfied: protobuf>=3.19.6 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (4.23.3)\r\nRequirement already satisfied: requests<3,>=2.21.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (2.29.0)\r\nRequirement already satisfied: setuptools>=41.0.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (67.8.0)\r\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (0.7.1)\r\nRequirement already satisfied: werkzeug>=1.0.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (2.3.6)\r\nRequirement already satisfied: wheel>=0.26 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (0.38.4)\r\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.1)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\r\nRequirement already satisfied: rsa<5,>=3.1.4 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\r\nRequirement already satisfied: six>=1.9.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.16.0)\r\nRequirement already satisfied: urllib3<2.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.26.16)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.4)\r\nRequirement already satisfied: idna<4,>=2.5 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.5.7)\r\nRequirement already satisfied: MarkupSafe>=2.1.1 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.1)\r\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.0)\r\nRequirement already satisfied: oauthlib>=3.0.0 in /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\r\nInstalling collected packages: detectron2\r\n  Running setup.py develop for detectron2\r\n    error: subprocess-exited-with-error\r\n    \r\n    √ó python setup.py develop did not run successfully.\r\n    ‚îÇ exit code: 1\r\n    ‚ï∞‚îÄ> [119 lines of output]\r\n        running develop\r\n        /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\r\n        !!\r\n        \r\n                ********************************************************************************\r\n                Please avoid running ``setup.py`` and ``easy_install``.\r\n                Instead, use pypa/build, pypa/installer, pypa/build or\r\n                other standards-based tools.\r\n        \r\n                See https://github.com/pypa/setuptools/issues/917 for details.\r\n                ********************************************************************************\r\n        \r\n        !!\r\n          easy_install.initialize_options(self)\r\n        /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\r\n        !!\r\n        \r\n                ********************************************************************************\r\n                Please avoid running ``setup.py`` directly.\r\n                Instead, use pypa/build, pypa/installer, pypa/build or\r\n                other standards-based tools.\r\n        \r\n                See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\r\n                ********************************************************************************\r\n        \r\n        !!\r\n          self.initialize_options()\r\n        running egg_info\r\n        writing detectron2.egg-info/PKG-INFO\r\n        writing dependency_links to detectron2.egg-info/dependency_links.txt\r\n        writing requirements to detectron2.egg-info/requires.txt\r\n        writing top-level names to detectron2.egg-info/top_level.txt\r\n        reading manifest file 'detectron2.egg-info/SOURCES.txt'\r\n        adding license file 'LICENSE'\r\n        writing manifest file 'detectron2.egg-info/SOURCES.txt'\r\n        running build_ext\r\n        building 'detectron2._C' extension\r\n        Emitting ninja build file /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/build.ninja...\r\n        Compiling objects...\r\n        Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n        [1/2] c++ -MMD -MF /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o.d -pthread -B /home/ambuj/anaconda3/envs/percepTree/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -I/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/TH -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/THC -I/home/ambuj/anaconda3/envs/percepTree/include/python3.11 -c -c /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp -o /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\r\n        FAILED: /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o\r\n        c++ -MMD -MF /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o.d -pthread -B /home/ambuj/anaconda3/envs/percepTree/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -I/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/TH -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/THC -I/home/ambuj/anaconda3/envs/percepTree/include/python3.11 -c -c /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp -o /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\r\n        In file included from /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp:2:0:\r\n        /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.h:4:10: fatal error: pybind11/numpy.h: No such file or directory\r\n         #include <pybind11/numpy.h>\r\n                  ^~~~~~~~~~~~~~~~~~\r\n        compilation terminated.\r\n        [2/2] c++ -MMD -MF /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.o.d -pthread -B /home/ambuj/anaconda3/envs/percepTree/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -I/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/TH -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/THC -I/home/ambuj/anaconda3/envs/percepTree/include/python3.11 -c -c /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.cpp -o /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\r\n        FAILED: /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.o\r\n        c++ -MMD -MF /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.o.d -pthread -B /home/ambuj/anaconda3/envs/percepTree/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -I/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/TH -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/THC -I/home/ambuj/anaconda3/envs/percepTree/include/python3.11 -c -c /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.cpp -o /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\r\n        In file included from /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/python.h:11:0,\r\n                         from /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/extension.h:6,\r\n                         from /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.cpp:3:\r\n        /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/Exceptions.h:14:10: fatal error: pybind11/pybind11.h: No such file or directory\r\n         #include <pybind11/pybind11.h>\r\n                  ^~~~~~~~~~~~~~~~~~~~~\r\n        compilation terminated.\r\n        ninja: build stopped: subcommand failed.\r\n        Traceback (most recent call last):\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1893, in _run_ninja_build\r\n            subprocess.run(\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/subprocess.py\", line 571, in run\r\n            raise CalledProcessError(retcode, process.args,\r\n        subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\r\n        \r\n        The above exception was the direct cause of the following exception:\r\n        \r\n        Traceback (most recent call last):\r\n          File \"<string>\", line 2, in <module>\r\n          File \"<pip-setuptools-caller>\", line 34, in <module>\r\n          File \"/home/ambuj/Myprojects/detectron2/setup.py\", line 151, in <module>\r\n            setup(\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/__init__.py\", line 107, in setup\r\n            return distutils.core.setup(**attrs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 185, in setup\r\n            return run_commands(dist)\r\n                   ^^^^^^^^^^^^^^^^^^\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\r\n            dist.run_commands()\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\r\n            self.run_command(cmd)\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/dist.py\", line 1244, in run_command\r\n            super().run_command(command)\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n            cmd_obj.run()\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/command/develop.py\", line 34, in run\r\n            self.install_for_development()\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/command/develop.py\", line 115, in install_for_development\r\n            self.run_command('build_ext')\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\r\n            self.distribution.run_command(command)\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/dist.py\", line 1244, in run_command\r\n            super().run_command(command)\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n            cmd_obj.run()\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/command/build_ext.py\", line 84, in run\r\n            _build_ext.run(self)\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 345, in run\r\n            self.build_extensions()\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 843, in build_extensions\r\n            build_ext.build_extensions(self)\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 467, in build_extensions\r\n            self._build_extensions_serial()\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 493, in _build_extensions_serial\r\n            self.build_extension(ext)\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/command/build_ext.py\", line 246, in build_extension\r\n            _build_ext.build_extension(self, ext)\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 548, in build_extension\r\n            objects = self.compiler.compile(\r\n                      ^^^^^^^^^^^^^^^^^^^^^^\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 658, in unix_wrap_ninja_compile\r\n            _write_ninja_file_and_compile_objects(\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1574, in _write_ninja_file_and_compile_objects\r\n            _run_ninja_build(\r\n          File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1909, in _run_ninja_build\r\n            raise RuntimeError(message) from e\r\n        RuntimeError: Error compiling objects for extension\r\n        [end of output]\r\n    \r\n    note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n√ó python setup.py develop did not run successfully.\r\n‚îÇ exit code: 1\r\n‚ï∞‚îÄ> [119 lines of output]\r\n    running develop\r\n    /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\r\n    !!\r\n    \r\n            ********************************************************************************\r\n            Please avoid running ``setup.py`` and ``easy_install``.\r\n            Instead, use pypa/build, pypa/installer, pypa/build or\r\n            other standards-based tools.\r\n    \r\n            See https://github.com/pypa/setuptools/issues/917 for details.\r\n            ********************************************************************************\r\n    \r\n    !!\r\n      easy_install.initialize_options(self)\r\n    /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\r\n    !!\r\n    \r\n            ********************************************************************************\r\n            Please avoid running ``setup.py`` directly.\r\n            Instead, use pypa/build, pypa/installer, pypa/build or\r\n            other standards-based tools.\r\n    \r\n            See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\r\n            ********************************************************************************\r\n    \r\n    !!\r\n      self.initialize_options()\r\n    running egg_info\r\n    writing detectron2.egg-info/PKG-INFO\r\n    writing dependency_links to detectron2.egg-info/dependency_links.txt\r\n    writing requirements to detectron2.egg-info/requires.txt\r\n    writing top-level names to detectron2.egg-info/top_level.txt\r\n    reading manifest file 'detectron2.egg-info/SOURCES.txt'\r\n    adding license file 'LICENSE'\r\n    writing manifest file 'detectron2.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    building 'detectron2._C' extension\r\n    Emitting ninja build file /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/build.ninja...\r\n    Compiling objects...\r\n    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n    [1/2] c++ -MMD -MF /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o.d -pthread -B /home/ambuj/anaconda3/envs/percepTree/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -I/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/TH -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/THC -I/home/ambuj/anaconda3/envs/percepTree/include/python3.11 -c -c /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp -o /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\r\n    FAILED: /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o\r\n    c++ -MMD -MF /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o.d -pthread -B /home/ambuj/anaconda3/envs/percepTree/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -I/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/TH -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/THC -I/home/ambuj/anaconda3/envs/percepTree/include/python3.11 -c -c /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp -o /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\r\n    In file included from /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp:2:0:\r\n    /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.h:4:10: fatal error: pybind11/numpy.h: No such file or directory\r\n     #include <pybind11/numpy.h>\r\n              ^~~~~~~~~~~~~~~~~~\r\n    compilation terminated.\r\n    [2/2] c++ -MMD -MF /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.o.d -pthread -B /home/ambuj/anaconda3/envs/percepTree/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -I/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/TH -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/THC -I/home/ambuj/anaconda3/envs/percepTree/include/python3.11 -c -c /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.cpp -o /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\r\n    FAILED: /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.o\r\n    c++ -MMD -MF /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.o.d -pthread -B /home/ambuj/anaconda3/envs/percepTree/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -O2 -isystem /home/ambuj/anaconda3/envs/percepTree/include -fPIC -I/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/TH -I/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/THC -I/home/ambuj/anaconda3/envs/percepTree/include/python3.11 -c -c /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.cpp -o /home/ambuj/Myprojects/detectron2/build/temp.linux-x86_64-cpython-311/home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\r\n    In file included from /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/python.h:11:0,\r\n                     from /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/extension.h:6,\r\n                     from /home/ambuj/Myprojects/detectron2/detectron2/layers/csrc/vision.cpp:3:\r\n    /home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/include/torch/csrc/Exceptions.h:14:10: fatal error: pybind11/pybind11.h: No such file or directory\r\n     #include <pybind11/pybind11.h>\r\n              ^~~~~~~~~~~~~~~~~~~~~\r\n    compilation terminated.\r\n    ninja: build stopped: subcommand failed.\r\n    Traceback (most recent call last):\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1893, in _run_ninja_build\r\n        subprocess.run(\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/subprocess.py\", line 571, in run\r\n        raise CalledProcessError(retcode, process.args,\r\n    subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\r\n    \r\n    The above exception was the direct cause of the following exception:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 2, in <module>\r\n      File \"<pip-setuptools-caller>\", line 34, in <module>\r\n      File \"/home/ambuj/Myprojects/detectron2/setup.py\", line 151, in <module>\r\n        setup(\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/__init__.py\", line 107, in setup\r\n        return distutils.core.setup(**attrs)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 185, in setup\r\n        return run_commands(dist)\r\n               ^^^^^^^^^^^^^^^^^^\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\r\n        dist.run_commands()\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/dist.py\", line 1244, in run_command\r\n        super().run_command(command)\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n        cmd_obj.run()\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/command/develop.py\", line 34, in run\r\n        self.install_for_development()\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/command/develop.py\", line 115, in install_for_development\r\n        self.run_command('build_ext')\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/dist.py\", line 1244, in run_command\r\n        super().run_command(command)\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n        cmd_obj.run()\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/command/build_ext.py\", line 84, in run\r\n        _build_ext.run(self)\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 345, in run\r\n        self.build_extensions()\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 843, in build_extensions\r\n        build_ext.build_extensions(self)\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 467, in build_extensions\r\n        self._build_extensions_serial()\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 493, in _build_extensions_serial\r\n        self.build_extension(ext)\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/command/build_ext.py\", line 246, in build_extension\r\n        _build_ext.build_extension(self, ext)\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/setuptools/_distutils/command/build_ext.py\", line 548, in build_extension\r\n        objects = self.compiler.compile(\r\n                  ^^^^^^^^^^^^^^^^^^^^^^\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 658, in unix_wrap_ninja_compile\r\n        _write_ninja_file_and_compile_objects(\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1574, in _write_ninja_file_and_compile_objects\r\n        _run_ninja_build(\r\n      File \"/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1909, in _run_ninja_build\r\n        raise RuntimeError(message) from e\r\n    RuntimeError: Error compiling objects for extension\r\n    [end of output]\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n```\r\n2. What exact command you run:\r\n\r\nafter installing pyTorch and openCV. I cloned the git repo for detectron2 and then ran the following command. \r\nFollowed all the instructions for installing the dependencies correctly. \r\n `python -m pip install -e detectron2`\r\n\r\n## Expected behavior: \r\nthe package should get installed \r\n\r\n## Environment:\r\n```\r\n2023-06-26 10:02:15 URL:https://raw.githubusercontent.com/facebookresearch/detectron2/main/detectron2/utils/collect_env.py [8525/8525] -> \"collect_env.py\" [1]\r\n/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\r\n  warn(\r\n-------------------------------  --------------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.11.3 (main, May 15 2023, 15:45:52) [GCC 11.2.0]\r\nnumpy                            1.25.0\r\ndetectron2                       imported a wrong installation\r\ndetectron2._C                    not built correctly: No module named 'detectron2._C'\r\nCompiler ($CXX)                  c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.0.1 @/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  True\r\nGPU available                    No: torch.cuda.is_available() == False\r\nPillow                           9.4.0\r\ntorchvision                      0.15.2 @/home/ambuj/anaconda3/envs/percepTree/lib/python3.11/site-packages/torchvision\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.6.0\r\n-------------------------------  --------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 11.2\r\n  - C++ Version: 201703\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - Build settings: BLAS_INFO=open, BUILD_TYPE=Release, CXX_COMPILER=/croot/pytorch_1686931851744/_build_env/bin/x86_64-conda-linux-gnu-c++, CXX_FLAGS=-fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /croot/pytorch_1686931851744/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/include -fdebug-prefix-map=/croot/pytorch_1686931851744/work=/usr/local/src/conda/pytorch-2.0.1 -fdebug-prefix-map=/croot/pytorch_1686931851744/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold=/usr/local/src/conda-prefix -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=open, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n```\r\n",
    "comments": [
      {
        "user": "satishjasthi",
        "body": "Hi @Ambuj-Choudha \r\n\r\nThere seems to be an issue with your PyTorch installation. You can follow these steps to install detectron2 within your environment constraints(like python 3.11.3 and linux platform). Within same Environment as yours I was able to install detectron2 successfully. I have shared my Environment at the end of this comment. I hope this resolves your issue, if you face any further issue even after following these steps, let me know.\r\n\r\n- Install pyenv from their [repository](https://github.com/pyenv/pyenv). Its a great tool to maintain different python versions\r\n- Install python 3.11.3 version using pyenv\r\n```bash\r\npyenv install 3.11.3\r\n```\r\n- Set python 3.11.3 as python version for current terminal session using \r\n```bash\r\npyenv shell 3.11.3\r\n```\r\n- create a new virtual env using and activate it \r\n```bash\r\npython -m venv env && source ./env/bin/activate\r\n```\r\n- check your python version and path using \r\n```bash\r\npython --version && which python\r\n```\r\n- Now install torch and torch vision using pip\r\n```bash\r\npython -m pip install torch torchvision\r\n```\r\n- I see that you already have GCC and G++ installed on your system and they are above v5 so you need not install them again\r\n- Next clone detectron repo using \r\n```bash\r\ngit clone https://github.com/facebookresearch/detectron2.git\r\n```\r\n- Install detectron2 using \r\n```bash\r\npython -m pip install -e detectron2\r\n```\r\n\r\n## My Environment \r\n```\r\n-------------------------------  ---------------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.11.3 (main, Jun 27 2023, 16:19:35) [GCC 11.3.0]\r\nnumpy                            1.25.0\r\ndetectron2                       0.6 @/home/***/Projects/OSP/detectron2/detectron2\r\nCompiler                         GCC 11.3\r\nCUDA compiler                    not available\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.0.1+cu117 @/home/***/Projects/OSP/env/lib/python3.11/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    No: torch.cuda.is_available() == False\r\nPillow                           9.5.0\r\ntorchvision                      0.15.2+cu117 @/home/***/Projects/OSP/env/lib/python3.11/site-packages/torchvision\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.7.0\r\n-------------------------------  ---------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201703\r\n  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,\r\n```"
      },
      {
        "user": "Ambuj-Choudha",
        "body": "Thanks a lot! @satishjasthi \r\n\r\nMore importantly, I see you have directly installed detectron2 on your system after pytorch installation, as openCV is an optional dependency. \r\n\r\nBut I would like to highlight the fact that the reason why my pytorch version got messed up was because that I installed openCV right after installing torch, and the openCV package has different version requirement than detectron2, and it kinda SUPERSEDED, and a different version of pytorch (particularly torchvision) got installed. \r\n\r\nThank you very much for the help!"
      },
      {
        "user": "goodstudent9",
        "body": "I have the same problems. Have you solved yet?"
      }
    ]
  },
  {
    "issue_number": 5308,
    "title": "Convert detectron2 to other frameworks - different outputs",
    "author": "lwenaeven",
    "state": "closed",
    "created_at": "2024-06-13T14:29:04Z",
    "updated_at": "2025-04-14T02:17:23Z",
    "labels": [
      "needs-more-info"
    ],
    "body": "I have a custom trained detectron2 model for instance segmentation that I load and use for inference as below:\r\n```python\r\ncfg = get_cfg()\r\ncfg.merge_from_file(config_path)\r\ncfg.MODEL.WEIGHTS = weights_path\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\r\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\r\ncfg.MODEL.DEVICE='cpu'\r\n\r\npredictor = DefaultPredictor(cfg)\r\noutputs = predictor(im)\r\n```\r\n\r\nI have followed [this tutorial][1] from OpenVino in order to convert it to an OV model:\r\n```python\r\nmodel = build_model(cfg)\r\nDetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\r\nmodel.eval()\r\n\r\nov_model = convert_detectron2_model(model, im)\r\n\r\ncore = ov.Core()\r\nov_model = core.read_model(\"../model/model.xml\")\r\ncompiled_model = ov.compile_model(ov_model)\r\nresults = compiled_model(sample_input[0][\"image\"])\r\n```\r\n\r\nHowever, I don't obtain the expected result from the complied ov model, ie. I normally should obtain one instance in the outputs and this is the case when using the classic detectron2 model, but when using the complied ov model, I don't get any instance detected.\r\n```python\r\nInstances(num_instances=0, image_height=3024, image_width=4032, fields=[pred_boxes: Boxes(tensor([], size=(0, 4))), scores: [], pred_classes: [], pred_masks: tensor([], size=(0, 3024, 4032), dtype=torch.bool)])\r\n```\r\n\r\nHere is the information about the OV model:\r\n```python\r\n<Model: 'Model4'\r\ninputs[\r\n<ConstOutput: names[args] shape[?,?,?] type: u8>\r\n]\r\noutputs[\r\n<ConstOutput: names[tensor, 2193, 2195, 2190, 2188, 2172, 2167] shape[..100,4] type: f32>,\r\n<ConstOutput: names[] shape[..100] type: i64>,\r\n<ConstOutput: names[] shape[?,1,28,28] type: f32>,\r\n<ConstOutput: names[] shape[..100] type: f32>,\r\n<ConstOutput: names[image_size] shape[2] type: i64>\r\n]>\r\n```\r\n\r\n\r\nUPDATE:\r\nAs I really need to convert it to another framework in order to use model serving tools, I also tried to convert it to Torchscript. However, here again I have an empty output.\r\n\r\nThis time I followed the tutorial in [this issue][2]:\r\n```python\r\ndef inference_func(model, image):\r\n    inputs= [{\"image\": image}]\r\n    return model.inference(inputs, do_postprocess=False)[0]\r\n\r\nwrapper= TracingAdapter(model, sample_input[0][\"image\"], inference_func)\r\nwrapper.eval()\r\n```\r\n\r\n```python\r\ntraced_script_module= torch.jit.trace(wrapper, (sample_input[0][\"image\"],))\r\ntraced_script_module.save(\"torchscript.pt\")\r\n```\r\n\r\nThe conversion is then done after a LOT of warnings, and here is a snippet of the resulting model:\r\n```python\r\nRecursiveScriptModule(\r\n  original_name=TracingAdapter\r\n  (model): RecursiveScriptModule(\r\n    original_name=GeneralizedRCNN\r\n    (backbone): RecursiveScriptModule(\r\n      original_name=FPN\r\n      (fpn_lateral2): RecursiveScriptModule(original_name=Conv2d)\r\n      (fpn_output2): RecursiveScriptModule(original_name=Conv2d)\r\n      (fpn_lateral3): RecursiveScriptModule(original_name=Conv2d)\r\n      (fpn_output3): RecursiveScriptModule(original_name=Conv2d)\r\n      (fpn_lateral4): RecursiveScriptModule(original_name=Conv2d)\r\n      (fpn_output4): RecursiveScriptModule(original_name=Conv2d)\r\n      (fpn_lateral5): RecursiveScriptModule(original_name=Conv2d)\r\n      (fpn_output5): RecursiveScriptModule(original_name=Conv2d)\r\n      (top_block): RecursiveScriptModule(original_name=LastLevelMaxPool)\r\n      (bottom_up): RecursiveScriptModule(\r\n        original_name=ResNet\r\n        (stem): RecursiveScriptModule(\r\n          original_name=BasicStem\r\n          (conv1): RecursiveScriptModule(\r\n            original_name=Conv2d\r\n            (norm): RecursiveScriptModule(original_name=FrozenBatchNorm2d)\r\n          )\r\n...\r\n```\r\n\r\nI then proceed the inference:\r\n```python\r\noutputs = torchscript_model(sample_input[0][\"image\"])\r\n```\r\n\r\nAnd the resulting outputs are empty:\r\n```python\r\n(tensor([], size=(0, 4), grad_fn=<ViewBackward0>),\r\n tensor([], dtype=torch.int64),\r\n tensor([], size=(0, 1, 28, 28), grad_fn=<SplitWithSizesBackward0>),\r\n tensor([], grad_fn=<IndexBackward0>),\r\n tensor([3024, 4032]))\r\n```\r\n\r\nI also have tried to export the model directly using the detectron2 functions [documented here][3], but again I have the same issue in the resulting model's inference.\r\n\r\n```terminal\r\npython ../detectron2-main/tools/deploy/export_model.py  --config-file ../detectron2-main/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml --output torchscript_model --format torchscript --sample-image ../data/test.JPG --export-method tracing MODEL.DEVICE cpu MODEL.WEIGHTS ../model/custom_trained_model.pth\r\n```\r\n\r\nI'll take any idea!\r\n\r\n  [1]: https://docs.openvino.ai/2023.3/notebooks/123-detectron2-to-openvino-with-output.html\r\n  [2]: https://github.com/triton-inference-server/server/issues/2025\r\n  [3]: https://detectron2.readthedocs.io/en/latest/tutorials/deployment.html",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "Programmer-RD-AI",
        "body": "Hi,\r\nThe most probable cause of this is the conversion and inference processes, and ensuring that the input pre-processing and output post-processing match the original model's expectations...\r\nThis is something you could look into :)\r\n\r\nHope this helps\r\n\r\nBest regards,\r\nRanuga Disansa"
      }
    ]
  },
  {
    "issue_number": 5457,
    "title": "‰øùÂ≠òÊúÄ‰Ω≥ÁªìÊûú",
    "author": "sjdch",
    "state": "closed",
    "created_at": "2025-04-04T01:27:01Z",
    "updated_at": "2025-04-11T02:14:29Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "ÊàëÊòØÂ∞èÁôΩÔºåÊÉ≥‰øùÂ≠òÊúÄ‰Ω≥ÁöÑap,ap50,ap75Á≠â‰ø°ÊÅØÔºåÊ†πÊçÆ‰πãÂâçÁöÑÂ∑≤ÁªèÂÖ≥Èó≠ÁöÑÈóÆÈ¢ò‰øÆÊîπÂêé‰πüÊ≤°ÊúâÂÆûÁé∞Ëøô‰∏™ÊïàÊûúÔºåÂ∫îËØ•‰øÆÊîπÂì™‰∫õÊñá‰ª∂ÔºåÂ¶Ç‰Ωï‰øÆÊîπÔºüË∞¢Ë∞¢ÊÇ®ÁöÑÂõûÂ§ç",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5459,
    "title": "The problem of slow GPU inference speed in exporting onnx models",
    "author": "Doctor-bun",
    "state": "open",
    "created_at": "2025-04-10T15:29:24Z",
    "updated_at": "2025-04-10T15:29:24Z",
    "labels": [
      "enhancement"
    ],
    "body": "Dear Facebook Development Team\nI saw this description in the guide: The converted model is able to run in either Python or C++ without detectron2/torchvision dependency, on CPU or GPUs. It has a runtime optimized for CPU & mobile inference, but not optimized for GPU inference.  After actual testing, I found that the CPU time is only one-third of the GPU time. Accelerated optimization will significantly improve inference speed. Therefore, I am wondering if it is possible to add optimization to the exported onnx GPU inference, as this is also a fundamental feature that is universal in the project.\n\n![Image](https://github.com/user-attachments/assets/cccf054a-c50b-4b42-8e0f-fb2eebed77ca)",
    "comments": []
  },
  {
    "issue_number": 5227,
    "title": "Error while running setup.py",
    "author": "JiaoSiyi",
    "state": "closed",
    "created_at": "2024-02-28T13:20:39Z",
    "updated_at": "2025-04-10T02:14:13Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "I am trying to run setup.py, and this is my error traceback:\r\n\r\n```\r\n\r\n> Running setup.py develop for detectron2\r\n>     error: subprocess-exited-with-error\r\n>     \r\n>     √ó python setup.py develop did not run successfully.\r\n>     ‚îÇ exit code: 1\r\n>     ‚ï∞‚îÄ> [53 lines of output]\r\n>         running develop\r\n>         running egg_info\r\n>         writing detectron2.egg-info/PKG-INFO\r\n>         writing dependency_links to detectron2.egg-info/dependency_links.txt\r\n>         writing requirements to detectron2.egg-info/requires.txt\r\n>         writing top-level names to detectron2.egg-info/top_level.txt\r\n>         reading manifest file 'detectron2.egg-info/SOURCES.txt'\r\n>         adding license file 'LICENSE'\r\n>         writing manifest file 'detectron2.egg-info/SOURCES.txt'\r\n>         running build_ext\r\n>         raise RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))\r\n>         building 'detectron2._C' extension\r\n>         Emitting ninja build file /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/build.ninja...\r\n>         Compiling objects...\r\n>         Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n>         /opt/conda/envs/DatasetDM/lib/python3.8/site-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\r\n>         !!\r\n>         \r\n>                 ********************************************************************************\r\n>                 Please avoid running ``setup.py`` and ``easy_install``.\r\n>                 Instead, use pypa/build, pypa/installer or other\r\n>                 standards-based tools.\r\n>         \r\n>                 See https://github.com/pypa/setuptools/issues/917 for details.\r\n>                 ********************************************************************************\r\n>         \r\n>         !!\r\n>           easy_install.initialize_options(self)\r\n>         /opt/conda/envs/DatasetDM/lib/python3.8/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\r\n>         !!\r\n>         \r\n>                 ********************************************************************************\r\n>                 Please avoid running ``setup.py`` directly.\r\n>                 Instead, use pypa/build, pypa/installer or other\r\n>                 standards-based tools.\r\n>         \r\n>                 See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\r\n>                 ********************************************************************************\r\n>         \r\n>         !!\r\n>           self.initialize_options()\r\n>         /opt/conda/envs/DatasetDM/lib/python3.8/site-packages/torch/utils/cpp_extension.py:782: UserWarning: The detected CUDA version (11.7) has a minor version mismatch with the version that was used to compile PyTorch (10.2). Most likely this shouldn't be a problem.\r\n>           warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\r\n>         /opt/conda/envs/DatasetDM/lib/python3.8/site-packages/torch/cuda/__init__.py:143: UserWarning:\r\n>         NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\r\n>         The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\r\n>         If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\r\n>         \r\n>           warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\r\n>         1.10.2.git.kitware.jobserver-1\r\n>         /opt/conda/envs/DatasetDM/bin/x86_64-conda-linux-gnu-c++ -shared -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,-rpath,/opt/conda/envs/DatasetDM/lib -L/opt/conda/envs/DatasetDM/lib -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,-rpath,/opt/conda/envs/DatasetDM/lib -L/opt/conda/envs/DatasetDM/lib -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -march -DNDEBUG -D_FORTIFY_SOURCE /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/cuda_version.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/vision.o -L/opt/conda/envs/DatasetDM/lib/python3.8/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-38/detectron2/_C.cpython-38-x86_64-linux-gnu.so\r\n>         x86_64-conda-linux-gnu-c++: error: unrecognized command-line option '-march'\r\n>         error: command '/opt/conda/envs/DatasetDM/bin/x86_64-conda-linux-gnu-c++' failed with exit code 1\r\n>         [end of output]\r\n>     \r\n>     note: This error originates from a subprocess, and is likely not a problem with pip.\r\n> error: subprocess-exited-with-error\r\n> \r\n> √ó python setup.py develop did not run successfully.\r\n> ‚îÇ exit code: 1\r\n> ‚ï∞‚îÄ> [53 lines of output]\r\n>     running develop\r\n>     running egg_info\r\n>     writing detectron2.egg-info/PKG-INFO\r\n>     writing dependency_links to detectron2.egg-info/dependency_links.txt\r\n>     writing requirements to detectron2.egg-info/requires.txt\r\n>     writing top-level names to detectron2.egg-info/top_level.txt\r\n>     reading manifest file 'detectron2.egg-info/SOURCES.txt'\r\n>     adding license file 'LICENSE'\r\n>     writing manifest file 'detectron2.egg-info/SOURCES.txt'\r\n>     running build_ext\r\n>     raise RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))\r\n>     building 'detectron2._C' extension\r\n>     Emitting ninja build file /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/build.ninja...\r\n>     Compiling objects...\r\n>     Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n>     /opt/conda/envs/DatasetDM/lib/python3.8/site-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\r\n>     !!\r\n>     \r\n>             ********************************************************************************\r\n>             Please avoid running ``setup.py`` and ``easy_install``.\r\n>             Instead, use pypa/build, pypa/installer or other\r\n>             standards-based tools.\r\n>     \r\n>             See https://github.com/pypa/setuptools/issues/917 for details.\r\n>             ********************************************************************************\r\n>     \r\n>     !!\r\n>       easy_install.initialize_options(self)\r\n>     /opt/conda/envs/DatasetDM/lib/python3.8/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\r\n>     !!\r\n>     \r\n>             ********************************************************************************\r\n>             Please avoid running ``setup.py`` directly.\r\n>             Instead, use pypa/build, pypa/installer or other\r\n>             standards-based tools.\r\n>     \r\n>             See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\r\n>             ********************************************************************************\r\n>     \r\n>     !!\r\n>       self.initialize_options()\r\n>     /opt/conda/envs/DatasetDM/lib/python3.8/site-packages/torch/utils/cpp_extension.py:782: UserWarning: The detected CUDA version (11.7) has a minor version mismatch with the version that was used to compile PyTorch (10.2). Most likely this shouldn't be a problem.\r\n>       warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\r\n>     /opt/conda/envs/DatasetDM/lib/python3.8/site-packages/torch/cuda/__init__.py:143: UserWarning:\r\n>     NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\r\n>     The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\r\n>     If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\r\n>     \r\n>       warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\r\n>     1.10.2.git.kitware.jobserver-1\r\n>     /opt/conda/envs/DatasetDM/bin/x86_64-conda-linux-gnu-c++ -shared -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,-rpath,/opt/conda/envs/DatasetDM/lib -L/opt/conda/envs/DatasetDM/lib -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,-rpath,/opt/conda/envs/DatasetDM/lib -L/opt/conda/envs/DatasetDM/lib -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -march -DNDEBUG -D_FORTIFY_SOURCE /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/cuda_version.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o /home/dancer/DatasetDM/src/detectron2/build/temp.linux-x86_64-cpython-38/home/dancer/DatasetDM/src/detectron2/detectron2/layers/csrc/vision.o -L/opt/conda/envs/DatasetDM/lib/python3.8/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-38/detectron2/_C.cpython-38-x86_64-linux-gnu.so\r\n>     x86_64-conda-linux-gnu-c++: error: unrecognized command-line option '-march'\r\n>     error: command '/opt/conda/envs/DatasetDM/bin/x86_64-conda-linux-gnu-c++' failed with exit code 1\r\n>     [end of output]\r\n> \r\n> note: This error originates from a subprocess, and is likely not a problem with pip.\r\n\r\n```",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "RajUpadhyay",
        "body": "Your pytorch version does not match the cuda version.\r\nThat is why it is raising the error.\r\nInstall the pytorch version compatible with your cuda version.\r\n"
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5450,
    "title": "new VERSION!",
    "author": "hellobo2802",
    "state": "open",
    "created_at": "2025-03-13T03:15:59Z",
    "updated_at": "2025-04-08T14:54:33Z",
    "labels": [
      "enhancement"
    ],
    "body": "The latest version is 4 years old, has it stopped updating?\n\ncuda has been updated to 12.x and torch has been updated to 2.x.\n\ncuda11.3 and torch1.10 are the latest support for this project!\n\n\n\nIt's annoying.",
    "comments": [
      {
        "user": "hellosenthil",
        "body": "Agree. We have Linux RHEL9 which does not support CUDA 11.3. "
      },
      {
        "user": "bhomaidan1990",
        "body": "current version doesn't run on Ubuntu 24.04 due to torch compatibility issues"
      },
      {
        "user": "ExtReMLapin",
        "body": "What are you guys even talking about, just build the project yourself instead of using the prebuilt package\n\n![Image](https://github.com/user-attachments/assets/87682b1b-1a2d-45a8-a076-bca953d6f3d1)"
      }
    ]
  },
  {
    "issue_number": 5103,
    "title": "AssertionError: A prediction has class=10, but the dataset only has 10 classes and predicted class id should be in [0, 9].",
    "author": "mahilaMoghadami",
    "state": "open",
    "created_at": "2023-10-04T13:26:13Z",
    "updated_at": "2025-04-07T22:33:53Z",
    "labels": [
      "documentation"
    ],
    "body": " File \"train_fcos.py\", line 89, in <module>\r\n    launch(\r\n  File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/launch.py\", line 82, in launch\r\n    main_func(*args)\r\n  File \"train_fcos.py\", line 80, in main\r\n    return trainer.train()\r\n  File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/defaults.py\", line 484, in train\r\n    super().train(self.start_iter, self.max_iter)\r\n  File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/train_loop.py\", line 150, in train\r\n    self.after_step()\r\n  File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/train_loop.py\", line 180, in after_step\r\n    h.after_step()\r\n  File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/hooks.py\", line 552, in after_step\r\n    self._do_eval()\r\n  File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/hooks.py\", line 525, in _do_eval\r\n    results = self._func()\r\n  File \"/home/mahilamoghadami.mut/CZDet/DroneDetectron2/croptrain/engine/trainer_fcos.py\", line 234, in test_and_save_results\r\n    self._last_eval_results = self.test_crop(self.cfg, self.model, self.iter)\r\n  File \"/home/mahilamoghadami.mut/CZDet/DroneDetectron2/croptrain/engine/trainer_fcos.py\", line 278, in test_crop\r\n    results_i = inference_fcos.inference_with_crops(model, data_loader, evaluator, cfg, iter)\r\n  File \"/home/mahilamoghadami.mut/CZDet/DroneDetectron2/croptrain/engine/inference_fcos.py\", line 124, in inference_with_crops\r\n    results = evaluator.evaluate()\r\n  File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/evaluation/coco_evaluation.py\", line 194, in evaluate\r\n    self._eval_predictions(predictions, img_ids=img_ids)\r\n  File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/evaluation/coco_evaluation.py\", line 228, in _eval_predictions\r\n    assert category_id < num_classes, (\r\n**AssertionError: A prediction has class=10, but the dataset only has 10 classes and predicted class id should be in [0, 9].\r\n\r\nAssertionError: A prediction has class=10, but the dataset only has 10 classes and predicted class id should be in [0, 9].**",
    "comments": [
      {
        "user": "olivia632",
        "body": "how can i contribute to this \r\n"
      },
      {
        "user": "pevers",
        "body": "@mahilaMoghadami make sure you have set `cfg.MODEL.ROI_HEADS.NUM_CLASSES` correctly. If your model predicts too many classes then there are categories available in your COCO dataset, it will fail with this error. "
      },
      {
        "user": "weirgmat",
        "body": "> File \"train_fcos.py\", line 89, in launch( File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/launch.py\", line 82, in launch main_func(*args) File \"train_fcos.py\", line 80, in main return trainer.train() File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/defaults.py\", line 484, in train super().train(self.start_iter, self.max_iter) File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/train_loop.py\", line 150, in train self.after_step() File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/train_loop.py\", line 180, in after_step h.after_step() File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/hooks.py\", line 552, in after_step self._do_eval() File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/engine/hooks.py\", line 525, in _do_eval results = self._func() File \"/home/mahilamoghadami.mut/CZDet/DroneDetectron2/croptrain/engine/trainer_fcos.py\", line 234, in test_and_save_results self._last_eval_results = self.test_crop(self.cfg, self.model, self.iter) File \"/home/mahilamoghadami.mut/CZDet/DroneDetectron2/croptrain/engine/trainer_fcos.py\", line 278, in test_crop results_i = inference_fcos.inference_with_crops(model, data_loader, evaluator, cfg, iter) File \"/home/mahilamoghadami.mut/CZDet/DroneDetectron2/croptrain/engine/inference_fcos.py\", line 124, in inference_with_crops results = evaluator.evaluate() File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/evaluation/coco_evaluation.py\", line 194, in evaluate self._eval_predictions(predictions, img_ids=img_ids) File \"/home/mahilamoghadami.mut/miniconda3/envs/CZDET/lib/python3.8/site-packages/detectron2/evaluation/coco_evaluation.py\", line 228, in _eval_predictions assert category_id < num_classes, ( **AssertionError: A prediction has class=10, but the dataset only has 10 classes and predicted class id should be in [0, 9].\r\n> \r\n> AssertionError: A prediction has class=10, but the dataset only has 10 classes and predicted class id should be in [0, 9].**\r\n\r\n\r\nHello, have you resolved this issue? How to solve it? thanks"
      }
    ]
  },
  {
    "issue_number": 5255,
    "title": "export_model.py crashes with keypoints",
    "author": "Huxwell",
    "state": "closed",
    "created_at": "2024-04-12T10:30:49Z",
    "updated_at": "2025-04-07T02:16:39Z",
    "labels": [],
    "body": "EDIT: I am discussing export_model.py issues with keypoints in : https://github.com/facebookresearch/detectron2/issues/5143 since it receives more attention.\r\n\r\n\r\n## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\n2. What exact command you run:\r\n```\r\npython detectron2/tools/deploy/export_model.py \\\r\n    --sample-image 1344x1344.jpg \\\r\n    --config-file detectron2/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml \\\r\n    --export-method tracing \\\r\n    --format onnx \\\r\n    --output ./keypoints_onnx \\\r\n    MODEL.WEIGHTS model_final_a6e10b.pkl \r\n    MODEL.DEVICE cuda\r\n```\r\n3. __Full logs__ or other relevant observations:\r\n```\r\npython detectron2/tools/deploy/export_model.py --sample-image 1344x1344.jpg --config-file detectron2/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml --export-method tracing --format onnx --output ./keypoints_onnx MODEL.WEIGHTS /home/ubuntu/onnx_trtmodel_final_a6e10b.pkl MODEL.DEVICE cuda\r\n[04/12 12:18:05 detectron2]: Command line arguments: Namespace(config_file='detectron2/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml', export_method='tracing', format='onnx', opts=['MODEL.WEIGHTS', '/home/ubuntu/onnx_trtmodel_final_a6e10b.pkl', 'MODEL.DEVICE', 'cuda'], output='./keypoints_onnx', run_eval=False, sample_image='1344x1344.jpg')\r\n[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 1) (function operator())\r\n/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\r\n  warnings.warn(\"Can't initialize NVML\")\r\n[04/12 12:18:07 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /home/ubuntu/onnx_trtmodel_final_a6e10b.pkl ...\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/image_list.py:85: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert t.shape[:-2] == tensors[0].shape[:-2], t.shape\r\n/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\r\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if tensor.numel() == 0:\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if tensor.numel() == 0:\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\r\n/home/ubuntu/detectron2/detectron2/detectron2/modeling/proposal_generator/proposal_utils.py:106: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if not valid_mask.all():\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/boxes.py:192: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\r\n  h, w = box_size\r\n/home/ubuntu/detectron2/detectron2/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert boxes.shape[-1] == 4\r\n/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert condition, message\r\n/home/ubuntu/detectron2/detectron2/detectron2/layers/roi_align.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert rois.dim() == 2 and rois.size(1) == 5\r\n/home/ubuntu/detectron2/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if not valid_mask.all():\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if tensor.numel() == 0:\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\r\n/home/ubuntu/detectron2/detectron2/detectron2/structures/boxes.py:192: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\r\n  h, w = box_size\r\n/home/ubuntu/detectron2/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if num_bbox_reg_classes == 1:\r\n/home/ubuntu/detectron2/detectron2/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert boxes.shape[-1] == 4\r\n/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert condition, message\r\n/home/ubuntu/detectron2/detectron2/detectron2/layers/roi_align.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert rois.dim() == 2 and rois.size(1) == 5\r\n/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/jit/_trace.py:1223: UserWarning: operator() sees varying value in profiling, ignoring and this should be handled by GUARD logic (Triggered internally at ../third_party/nvfuser/csrc/parser.cpp:3777.)\r\n  return compiled_fn(*args, **kwargs)\r\n/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:5589: UserWarning: Exporting aten::index operator of advanced indexing in opset 11 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\r\n  warnings.warn(\r\n/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torchvision/ops/_register_onnx_ops.py:59: UserWarning: ROIAlign with aligned=True is only supported in opset >= 16. Please export with opset 16 or higher, or use aligned=False.\r\n  warnings.warn(\r\n============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\r\nverbose: False, log level: Level.ERROR\r\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\r\n\r\nTraceback (most recent call last):\r\n  File \"detectron2/tools/deploy/export_model.py\", line 225, in <module>\r\n    exported_model = export_tracing(torch_model, sample_inputs)\r\n  File \"detectron2/tools/deploy/export_model.py\", line 132, in export_tracing\r\n    torch.onnx.export(traceable_model, (image,), f, opset_version=STABLE_ONNX_OPSET_VERSION)\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/utils.py\", line 506, in export\r\n    _export(\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1548, in _export\r\n    graph, params_dict, torch_out = _model_to_graph(\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1117, in _model_to_graph\r\n    graph = _optimize_graph(\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/utils.py\", line 665, in _optimize_graph\r\n    graph = _C._jit_pass_onnx(graph, operator_export_type)\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1891, in _run_symbolic_function\r\n    return symbolic_fn(graph_context, *inputs, **attrs)\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py\", line 6709, in prim_loop\r\n    torch._C._jit_pass_onnx_block(\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1891, in _run_symbolic_function\r\n    return symbolic_fn(graph_context, *inputs, **attrs)\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/symbolic_opset11.py\", line 1063, in index\r\n    return opset9.index(g, self, index)\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py\", line 5580, in index\r\n    return symbolic_helper._unimplemented(\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py\", line 607, in _unimplemented\r\n    _onnx_unsupported(f\"{op}, {msg}\", value)\r\n  File \"/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py\", line 618, in _onnx_unsupported\r\n    raise errors.SymbolicValueError(\r\ntorch.onnx.errors.SymbolicValueError: Unsupported: ONNX export of operator aten::index, operator of advanced indexing on tensor of unknown rank. Try turning on shape inference during export: torch.onnx._export(..., onnx_shape_inference=True).. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues  [Caused by the value 'roi_map.3 defined in (%roi_map.3 : Tensor = onnx::Reshape(%roi_map, %2727) # /home/ubuntu/detectron2/detectron2/detectron2/structures/keypoints.py:205:18\r\n)' (type 'Tensor') in the TorchScript graph. The containing node has kind 'onnx::Reshape'.] \r\n    (node defined in   File \"/home/ubuntu/detectron2/detectron2/detectron2/structures/keypoints.py\", line 205\r\n        # Although semantically equivalent, `reshape` is used instead of `squeeze` due\r\n        # to limitation during ONNX export of `squeeze` in scripting mode\r\n        roi_map = roi_map.reshape(roi_map.shape[1:])  # keypoints x H x W\r\n                  ~~~~~~~~~~~~~~~ <--- HERE\r\n\r\n        # softmax over the spatial region\r\n)\r\n\r\n    Inputs:\r\n        #0: roi_map defined in (%roi_map : Tensor = onnx::Resize[coordinate_transformation_mode=\"half_pixel\", cubic_coeff_a=-0.75, mode=\"cubic\", nearest_mode=\"floor\"](%2710, %2719, %2720, %2718) # /home/ubuntu/detectron2/detectron2/detectron2/structures/keypoints.py:201:18\r\n    )  (type 'Tensor')\r\n        #1: 2727 defined in (%2727 : LongTensor(device=cpu)[] = onnx::Slice(%2722, %2724, %2725, %2723, %2726) # /home/ubuntu/detectron2/detectron2/detectron2/structures/keypoints.py:205:34\r\n    )  (type 'List[Tensor]')\r\n    Outputs:\r\n        #0: roi_map.3 defined in (%roi_map.3 : Tensor = onnx::Reshape(%roi_map, %2727) # /home/ubuntu/detectron2/detectron2/detectron2/structures/keypoints.py:205:18\r\n    )  (type 'Tensor')\r\n```\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\n## Expected behavior:\r\n\r\nAn onnx file generated that I can :\r\n1) run with onnxruntime to verify correctness\r\n2) export to TensorRT, but this is probably beyond the scope of detectron2 maintenance\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n\r\n/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\r\n  warnings.warn(\"Can't initialize NVML\")\r\n-------------------------------  ------------------------------------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.8.10 (default, Nov 22 2023, 10:22:35) [GCC 9.4.0]\r\nnumpy                            1.24.4\r\ndetectron2                       0.6 @/home/ubuntu/detectron2/detectron2/detectron2\r\ndetectron2._C                    not built correctly: No module named 'detectron2._C'\r\nCompiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.0.0+cu117 @/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0                            NVIDIA T600 Laptop GPU (arch=7.5)\r\nDriver version\r\nCUDA_HOME                        None - invalid!\r\nPillow                           10.0.0\r\ntorchvision                      0.15.1+cu117 @/home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags           /home/ubuntu/detectron2/env_perception/lib/python3.8/site-packages/torchvision/_C.so\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.10\r\ncv2                              4.7.0\r\n-------------------------------  ------------------------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201703\r\n  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 11.7\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\r\n  - CuDNN 8.5\r\n  - Magma 2.6.1\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n```",
    "comments": [
      {
        "user": "RajUpadhyay",
        "body": "@Huxwell I see, it really is weird. It hasn't been long since I ran a keypoint onnx with onnxruntime-gpu.\r\nThe error mentioned above is due to the code in the onnx package, you can try using one of the following\r\n1. ONNX_FALLTHROUGH \r\n2. ONNX_ATEN\r\n3. ONNX_ATEN_FALLBACK\r\n\r\nI do not remember much but I think I got success with aten_fallback."
      },
      {
        "user": "Huxwell",
        "body": "No luck so far, with ONNX_ATEN_FALLBACK not changing anything for me and ONNX_ATEN resulting in export crash\r\n\r\n```\r\naten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a):\r\nExpected a value of type 'Tensor' for argument 'self' but instead found type 'List[Tensor]'.\r\nEmpty lists default to List[Tensor]. Add a variable annotation to the assignment to create an empty list of another type (torch.jit.annotate(List[T, []]) where T is the type of elements in the list for Python 2)\r\n```\r\nI will read comment section of my '/Apr2024Detectron_venv/lib/python3.8/site-packages/torch/onnx/utils.py', run the unit tests from detectron2 for export and analyze the logs and hope I will find some clue there.\r\n\r\nIn the meantime, do you happen to have a converted .onnx file from vanilla keypoints detector, that you could share? It would allow me to verify if my problem is with the exporter (Loops in keypoints related code) or rather with my onnxruntime usage/version."
      },
      {
        "user": "Huxwell",
        "body": "Just to clarify: ONNX_FALLTHROUGH successfully generates an onnx file, but onnxruntime crushes when reading such file with\r\n```\r\nType parameter (T) of Optype (SequenceConstruct) bound to different types (tensor(int64) and tensor(float) in node (SequenceConstruct_2862)\r\n```"
      }
    ]
  },
  {
    "issue_number": 5456,
    "title": "Make Detectron2 Work Better with Torch 2.6.0 torch.load semantics",
    "author": "mritterfigma",
    "state": "open",
    "created_at": "2025-04-03T14:23:51Z",
    "updated_at": "2025-04-06T12:11:55Z",
    "labels": [
      "enhancement"
    ],
    "body": "## üöÄ Feature\nTorch 2.6.0 makes a change to `torch.load` where `weights_only=True` by default (https://pytorch.org/docs/stable/notes/serialization.html#torch-load-with-weights-only-true). This causes any `torch.load` calls to fail if they don't either (a) set `weights_only=False` or (b) call `torch.serialization.add_safe_globals([{__name__}])` for all of the classes that they want to allowlist in torch.\n\nUnfortunately Detectron2 wraps the call to `torch.load` inside [DetectronCheckpointer.load](https://github.com/facebookresearch/detectron2/blob/9604f5995cc628619f0e4fd913453b4d7d61db3f/detectron2/checkpoint/detection_checkpoint.py#L34). So, there is no easy way to pass `weights_only=True`. You can workaround this by getting all of the globals in the checkpoint and manually adding them, but it's annoying and takes some fiddling.\n\nInstead, Detectron should support this `weights_only` param and pass it through to torch.\n\nHere is an example of the workaround code:\n\n```\n  safe_globals = torch.serialization.get_unsafe_globals_in_checkpoint(path_to_checkpoint)\n\n  imported_objects = []\n  for item in safe_globals:\n      module_name, _, class_name = item.rpartition('.')\n      module = importlib.import_module(module_name)\n      imported_object = getattr(module, class_name)\n      imported_objects.append(imported_object)\n\n  torch.serialization.add_safe_globals(imported_objects)\n```\n\n",
    "comments": [
      {
        "user": "dgcnz",
        "body": "Another workaround is setting`TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD=1` :)"
      }
    ]
  },
  {
    "issue_number": 2114,
    "title": "Feature: a hook to automatically save the best model during training",
    "author": "xjinai",
    "state": "closed",
    "created_at": "2020-10-07T18:26:26Z",
    "updated_at": "2025-04-04T02:02:42Z",
    "labels": [
      "enhancement",
      "contributions welcome"
    ],
    "body": "## üöÄ Feature\r\nI'm using train_net.py to train model using custom dataset. It worked well, especially with multiple GPUs. Thank you for your great work!\r\n\r\nI set SOLVER.CHECKPOINT_PERIOD (e.g. 1000) to save the model every 1000 iterations. I want Detectron2 to automatically save the best model as the training goes, so that I can use the best model later for inference and evaluation. Currently this feature is missing in Detectron2. \r\n\r\n## Motivation & Examples\r\n\r\nI want Detectron2 to save the best model as the training goes, so that I can use the best model later for inference and evaluation. This feature exists in other object detection frameworks, for example, Darknet. I found that it is very useful since the model may overfit with the specified number of iterations. Therefore, the model_final.pth saved by Detectron2 is typically not the best model. If the best model is saved automatically during training, I can read it later and apply it for inference and evaluation.\r\n\r\nA possible implementation:\r\n1) Save the model at the first evaluation period to a file named model_best.pth.\r\n2) At every following evaluation period, compare AP value (on the validation set) with the AP value of the last evaluation period. If AP is better, then automatically update the saved best model (model_best.pth). \r\n\r\n## Note\r\n\r\nI believe that this feature is relevant to and would be highly appreciated by many users since saving and applying best model is a common practice for object detection. \r\n",
    "comments": [
      {
        "user": "ppwwyyxx",
        "body": "Duplicate of #645 "
      },
      {
        "user": "xjinai",
        "body": "Thank you for your response. \r\n\r\nI looked at #645 before. It is not exactly what I want. What I want is saving the best model during training as the default behavior, no matter if I run training from train_net.py or tutorial in Colab notebook. Please consider to add this feature. \r\n\r\nRegarding #645, can you please elaborate on how to add the logic \"using the return value of do_test\" in plain_train_net.py? Does it work with custom dataset?"
      },
      {
        "user": "ppwwyyxx",
        "body": "I think it is not reasonable to make it automatically a default because \r\n* there is no definition of \"best\" model unless users first choose a metric somehow. So it will require a new user input somewhere\r\n* these example training scripts are examples, as written on the top of those files. They are not meant to support every nice features\r\n* in research, using the best model is not a common thing to do (and sometimes not the right thing to do)\r\n\r\nIt's still a good idea though to implement a reusable hook that can be manually added by users to a trainer. For users using custom training loop, it should only take a few lines of code to implement it from scratch anyway.\r\n\r\n`do_test` in `plain_train_net` returns the metrics. So it works for any dataset as long as there are some metrics."
      }
    ]
  },
  {
    "issue_number": 5452,
    "title": "Please read & provide the following",
    "author": "boligrafo45",
    "state": "closed",
    "created_at": "2025-03-24T10:56:49Z",
    "updated_at": "2025-04-01T02:21:52Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Hello!\nI tried to pass an image to DensePose model like this: \n\n```\ndensepose_rgb = load_densepose_model()\nvisual_img = transform(cv2.imread(rgb_path))\ndensepose_rgb_output = densepose_rgb(visual_img) \n\ndef load_densepose_model():\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    return DefaultPredictor(cfg)\n```\n\nbut I got this error: \n\n```\n    densepose_rgb_output = densepose_rgb(visual_img)  # Extract features from RGB\n  File \"/home/celia/Documentos/DensePose/detectron2/detectron2/engine/defaults.py\", line 345, in __call__\n    image = self.aug.get_transform(original_image).apply_image(original_image)\n  File \"/home/celia/Documentos/DensePose/detectron2/detectron2/data/transforms/transform.py\", line 128, in apply_image\n    if any(x < 0 for x in img.strides):\nAttributeError: 'Tensor' object has no attribute 'strides'\n```\n\nIt is because DensePose can not work with tensors? It is compulsory to transform the image to numpy? If I do so I won't be able to train the model because gradients will be lost. \nThank you in advance!\n\n\n\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5027,
    "title": "No usable annotations with COCO format, problem with \"iscrowd\" attribute",
    "author": "matejfric",
    "state": "open",
    "created_at": "2023-07-12T15:06:50Z",
    "updated_at": "2025-03-31T04:49:00Z",
    "labels": [],
    "body": "I'm trying to apply instance segmentation to images of the wood piles:\r\n\r\n![Screenshot from 2023-07-11 12-54-19](https://github.com/facebookresearch/detectron2/assets/95862670/74580de7-a8a1-400c-b63f-c1afb6c63ec9)\r\n\r\nThe dataset I'm using was annotated in CVAT and then exported to COCO 1.0 format. The problem is that in most cases the \"iscrowd\" parameter is set to 1 (true), and when there are no cases with the \"iscrowd\" parameter set to 0, the training fails with an error. Please see *Logs* and *Google Colab notebook* in sections below.\r\n\r\nNote that when there are some \"iscrowd\": 0 attributes in the exported annotations, the training successfuly finishes, but the number of instances in the training log is equal to the number of instances with \"iscrowd\" attribute set to zero.\r\n\r\nSo the question is: Is this a desirable behaviour? Can I do something about it? I would be grateful for any suggestions. Given the nature of my data and the difficulty of annotating it, I would like to train the model on as many instances as possible.\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nPlease see this notebook on [Google Colab](https://colab.research.google.com/drive/1scxQo_Ra5oWNGxNAwyaKk6vENB9vt0hw?usp=sharing)\r\n\r\n## Logs or other relevant observations:\r\n\r\nThis is the output when there are no cases with the \"iscrowd\" parameter set to 0.\r\n\r\n```\r\n[07/12 14:25:31 d2.data.datasets.coco]: Loaded 1 images in COCO format from annotations/sample_annotation.json\r\n[07/12 14:25:31 d2.data.build]: Removed 1 images with no usable annotations. 0 images left.\r\n[07/12 14:25:31 d2.data.build]: Distribution of instances among all 1 categories:\r\n|  category  | #instances   |\r\n|:----------:|:-------------|\r\n|    log     | 0            |\r\n|            |              |\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n[<ipython-input-8-a39d262f9c11>](https://localhost:8080/#) in <cell line: 25>()\r\n     23 \r\n     24 os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n---> 25 trainer = DefaultTrainer(cfg)\r\n     26 trainer.resume_or_load(resume=False)\r\n     27 trainer.train()\r\n\r\n5 frames\r\n[/content/detectron2/detectron2/data/build.py](https://localhost:8080/#) in get_detection_dataset_dicts(names, filter_empty, min_keypoints, proposal_files, check_consistency)\r\n    277             pass\r\n    278 \r\n--> 279     assert len(dataset_dicts), \"No valid data found in {}.\".format(\",\".join(names))\r\n    280     return dataset_dicts\r\n    281 \r\n\r\nAssertionError: No valid data found in oli_train.\r\n```\r\n\r\nIf I manually change at least one of the \"iscrowd\" attributes to 0 (false), another error is raised:\r\n\r\n```\r\n[07/12 14:30:49 d2.data.datasets.coco]: Loaded 1 images in COCO format from annotations/sample_annotation.json\r\n[07/12 14:30:49 d2.data.build]: Removed 0 images with no usable annotations. 1 images left.\r\n[07/12 14:30:49 d2.data.build]: Distribution of instances among all 1 categories:\r\n|  category  | #instances   |\r\n|:----------:|:-------------|\r\n|    log     | 1            |\r\n|            |              |\r\n[07/12 14:30:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\r\n[07/12 14:30:49 d2.data.build]: Using training sampler TrainingSampler\r\n[07/12 14:30:49 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\r\n[07/12 14:30:49 d2.data.common]: Serializing 1 elements to byte tensors and concatenating them all ...\r\n[07/12 14:30:49 d2.data.common]: Serialized dataset takes 0.06 MiB\r\n[07/12 14:30:49 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\r\nmodel_final_f10217.pkl: 178MB [00:00, 209MB/s]                           \r\nWARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\r\nWARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\r\nWARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\r\nWARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\r\nWARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\r\nWARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\r\nWARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\nroi_heads.mask_head.predictor.{bias, weight}\r\n[07/12 14:30:50 d2.engine.train_loop]: Starting training from iteration 0\r\nERROR [07/12 14:30:51 d2.engine.train_loop]: Exception during training:\r\nTraceback (most recent call last):\r\n  File \"/content/detectron2/detectron2/engine/train_loop.py\", line 155, in train\r\n    self.run_step()\r\n  File \"/content/detectron2/detectron2/engine/defaults.py\", line 494, in run_step\r\n    self._trainer.run_step()\r\n  File \"/content/detectron2/detectron2/engine/train_loop.py\", line 297, in run_step\r\n    data = next(self._data_loader_iter)\r\n  File \"/content/detectron2/detectron2/data/common.py\", line 291, in __iter__\r\n    for d in self.dataset:\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\r\n    data = self._next_data()\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1345, in _next_data\r\n    return self._process_data(data)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\r\n    data.reraise()\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 644, in reraise\r\n    raise exception\r\nValueError: Caught ValueError in DataLoader worker process 0.\r\nOriginal Traceback (most recent call last):\r\n  File \"/content/detectron2/detectron2/data/detection_utils.py\", line 416, in annotations_to_instances\r\n    masks = PolygonMasks(segms)\r\n  File \"/content/detectron2/detectron2/structures/masks.py\", line 309, in __init__\r\n    self.polygons: List[List[np.ndarray]] = [\r\n  File \"/content/detectron2/detectron2/structures/masks.py\", line 310, in <listcomp>\r\n    process_polygons(polygons_per_instance) for polygons_per_instance in polygons\r\n  File \"/content/detectron2/detectron2/structures/masks.py\", line 298, in process_polygons\r\n    raise ValueError(\r\nValueError: Cannot create polygons: Expect a list of polygons per instance. Got '<class 'numpy.ndarray'>' instead.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\r\n    data = fetcher.fetch(index)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\r\n    data.append(next(self.dataset_iter))\r\n  File \"/content/detectron2/detectron2/data/common.py\", line 258, in __iter__\r\n    yield self.dataset[idx]\r\n  File \"/content/detectron2/detectron2/data/common.py\", line 95, in __getitem__\r\n    data = self._map_func(self._dataset[cur_idx])\r\n  File \"/content/detectron2/detectron2/utils/serialize.py\", line 26, in __call__\r\n    return self._obj(*args, **kwargs)\r\n  File \"/content/detectron2/detectron2/data/dataset_mapper.py\", line 189, in __call__\r\n    self._transform_annotations(dataset_dict, transforms, image_shape)\r\n  File \"/content/detectron2/detectron2/data/dataset_mapper.py\", line 131, in _transform_annotations\r\n    instances = utils.annotations_to_instances(\r\n  File \"/content/detectron2/detectron2/data/detection_utils.py\", line 418, in annotations_to_instances\r\n    raise ValueError(\r\nValueError: Failed to use mask_format=='polygon' from the given annotations!\r\n\r\n[07/12 14:30:51 d2.engine.hooks]: Total training time: 0:00:01 (0:00:00 on hooks)\r\n[07/12 14:30:51 d2.utils.events]:  iter: 0       lr: N/A  max_mem: 345M\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n[<ipython-input-10-a39d262f9c11>](https://localhost:8080/#) in <cell line: 27>()\r\n     25 trainer = DefaultTrainer(cfg)\r\n     26 trainer.resume_or_load(resume=False)\r\n---> 27 trainer.train()\r\n\r\n8 frames\r\n[/usr/local/lib/python3.10/dist-packages/torch/_utils.py](https://localhost:8080/#) in reraise(self)\r\n    642             # instantiate since we don't know how to\r\n    643             raise RuntimeError(msg) from None\r\n--> 644         raise exception\r\n    645 \r\n    646 \r\n\r\nValueError: Caught ValueError in DataLoader worker process 0.\r\nOriginal Traceback (most recent call last):\r\n  File \"/content/detectron2/detectron2/data/detection_utils.py\", line 416, in annotations_to_instances\r\n    masks = PolygonMasks(segms)\r\n  File \"/content/detectron2/detectron2/structures/masks.py\", line 309, in __init__\r\n    self.polygons: List[List[np.ndarray]] = [\r\n  File \"/content/detectron2/detectron2/structures/masks.py\", line 310, in <listcomp>\r\n    process_polygons(polygons_per_instance) for polygons_per_instance in polygons\r\n  File \"/content/detectron2/detectron2/structures/masks.py\", line 298, in process_polygons\r\n    raise ValueError(\r\nValueError: Cannot create polygons: Expect a list of polygons per instance. Got '<class 'numpy.ndarray'>' instead.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\r\n    data = fetcher.fetch(index)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\r\n    data.append(next(self.dataset_iter))\r\n  File \"/content/detectron2/detectron2/data/common.py\", line 258, in __iter__\r\n    yield self.dataset[idx]\r\n  File \"/content/detectron2/detectron2/data/common.py\", line 95, in __getitem__\r\n    data = self._map_func(self._dataset[cur_idx])\r\n  File \"/content/detectron2/detectron2/utils/serialize.py\", line 26, in __call__\r\n    return self._obj(*args, **kwargs)\r\n  File \"/content/detectron2/detectron2/data/dataset_mapper.py\", line 189, in __call__\r\n    self._transform_annotations(dataset_dict, transforms, image_shape)\r\n  File \"/content/detectron2/detectron2/data/dataset_mapper.py\", line 131, in _transform_annotations\r\n    instances = utils.annotations_to_instances(\r\n  File \"/content/detectron2/detectron2/data/detection_utils.py\", line 418, in annotations_to_instances\r\n    raise ValueError(\r\nValueError: Failed to use mask_format=='polygon' from the given annotations!\r\n```\r\n\r\n## Environment:\r\n\r\n```\r\n-------------------------------  -----------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]\r\nnumpy                            1.22.4\r\ndetectron2                       0.6 @/content/detectron2/detectron2\r\ndetectron2._C                    not built correctly: No module named 'detectron2._C'\r\nCompiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\r\nCUDA compiler                    Build cuda_11.8.r11.8/compiler.31833905_0\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.0.1+cu118 @/usr/local/lib/python3.10/dist-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0                            Tesla T4 (arch=7.5)\r\nDriver version                   525.85.12\r\nCUDA_HOME                        /usr/local/cuda\r\nPillow                           8.4.0\r\ntorchvision                      0.15.2+cu118 @/usr/local/lib/python3.10/dist-packages/torchvision\r\ntorchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.7.0\r\n-------------------------------  -----------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201703\r\n  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 11.8\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n  - CuDNN 8.7\r\n  - Magma 2.6.1\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n```",
    "comments": [
      {
        "user": "alecGraves",
        "body": "Similarly, I am unable to load CVAT-exported \"COCO 1.0\"-formatted  datasets with detectron2's COCO data loader. There is no indication of _why_ the annotations are unusable; the images are just dropped without explanation. The data \r\nlooks fine when loading it manually using pycocotools.\r\n\r\n>  [12/05 01:13:47 d2.data.datasets.coco]: Loaded 100 images in COCO format from dataset/annotations/instances_default.json\r\n> [12/05 01:13:47 d2.data.build]: Removed 100 images with no usable annotations. 0 images left.\r\n\r\n"
      },
      {
        "user": "Pragalbhv",
        "body": "I am facing the same issue; has there been a resolution yet?"
      },
      {
        "user": "annaszczuka",
        "body": "Same here"
      }
    ]
  },
  {
    "issue_number": 5276,
    "title": "AttributeError: Cannot find field 'gt_masks' in the given Instances! ",
    "author": "stoic-signs",
    "state": "closed",
    "created_at": "2024-05-03T15:37:03Z",
    "updated_at": "2025-03-27T07:58:45Z",
    "labels": [],
    "body": "If you do not know the root cause of the problem, please post according to this template:\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nCheck https://stackoverflow.com/help/minimal-reproducible-example for how to ask good questions.\r\nSimplify the steps to reproduce the issue using suggestions from the above link, and provide them below:\r\n\r\n1. Full runnable code or full changes you made:\r\nHere's my model config, based on the mask rcnn config provided, with the mask heads removed:\r\n```\r\nmodel = L(GeneralizedRCNN)(\r\n    backbone=L(FPN)(\r\n        bottom_up=L(ResNet)(\r\n            stem=L(BasicStem)(in_channels=3, out_channels=64, norm=\"FrozenBN\"),\r\n            stages=L(ResNet.make_default_stages)(\r\n                depth=50,\r\n                stride_in_1x1=True,\r\n                norm=\"FrozenBN\",\r\n            ),\r\n            out_features=[\"res2\", \"res3\", \"res4\", \"res5\"],\r\n        ),\r\n        in_features=\"${.bottom_up.out_features}\",\r\n        out_channels=256,\r\n        top_block=L(LastLevelMaxPool)(),\r\n    ),\r\n    proposal_generator=L(RPN)(\r\n        in_features=[\"p2\", \"p3\", \"p4\", \"p5\", \"p6\"],\r\n        head=L(StandardRPNHead)(in_channels=256, num_anchors=3),\r\n        anchor_generator=L(DefaultAnchorGenerator)(\r\n            sizes=[[32], [64], [128], [256], [512]],\r\n            aspect_ratios=[0.5, 1.0, 2.0],\r\n            strides=[4, 8, 16, 32, 64],\r\n            offset=0.0,\r\n        ),\r\n        anchor_matcher=L(Matcher)(\r\n            thresholds=[0.3, 0.7], labels=[0, -1, 1], allow_low_quality_matches=True\r\n        ),\r\n        box2box_transform=L(Box2BoxTransform)(weights=[1.0, 1.0, 1.0, 1.0]),\r\n        batch_size_per_image=256,\r\n        positive_fraction=0.5,\r\n        pre_nms_topk=(2000, 1000),\r\n        post_nms_topk=(1000, 1000),\r\n        nms_thresh=0.7,\r\n    ),\r\n    roi_heads=L(StandardROIHeads)(\r\n        num_classes=80,\r\n        batch_size_per_image=512,\r\n        positive_fraction=0.25,\r\n        proposal_matcher=L(Matcher)(\r\n            thresholds=[0.5], labels=[0, 1], allow_low_quality_matches=False\r\n        ),\r\n        box_in_features=[\"p2\", \"p3\", \"p4\", \"p5\"],\r\n        box_pooler=L(ROIPooler)(\r\n            output_size=7,\r\n            scales=(1.0 / 4, 1.0 / 8, 1.0 / 16, 1.0 / 32),\r\n            sampling_ratio=0,\r\n            pooler_type=\"ROIAlignV2\",\r\n        ),\r\n        box_head=L(FastRCNNConvFCHead)(\r\n            input_shape=ShapeSpec(channels=256, height=7, width=7),\r\n            conv_dims=[],\r\n            fc_dims=[1024, 1024],\r\n        ),\r\n        box_predictor=L(FastRCNNOutputLayers)(\r\n            input_shape=ShapeSpec(channels=1024),\r\n            test_score_thresh=0.05,\r\n            box2box_transform=L(Box2BoxTransform)(weights=(10, 10, 5, 5)),\r\n            num_classes=\"${..num_classes}\",\r\n        ),\r\n    ),\r\n    pixel_mean=constants.imagenet_bgr256_mean,\r\n    pixel_std=constants.imagenet_bgr256_std,\r\n    input_format=\"BGR\",\r\n)\r\nmodel.pixel_mean = [123.675, 116.28, 103.53]\r\nmodel.pixel_std = [58.395, 57.12, 57.375]\r\nmodel.input_format = \"RGB\"\r\n\r\nmodel.roi_heads.num_classes = len(model_classes)\r\n\r\ntrain = model_zoo.get_config(\"common/train.py\").train\r\ntrain.amp.enabled = True\r\ntrain.ddp.fp16_compression = True\r\ntrain.init_checkpoint = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\r\ndataloader = model_zoo.get_config(\"common/data/coco.py\").dataloader\r\ndataloader.train.mapper.augmentations = [\r\n\tL(T.RandomFlip)(horizontal=True),  # flip first\r\n\tL(T.RandomApply)(tfm_or_aug=L(T.RandomBrightness)(intensity_min=0.5,intensity_max=1.5),prob=0.3),\r\n\tL(T.RandomApply)(tfm_or_aug=L(T.RandomCrop)(crop_type='relative_range',crop_size=[0.7,0.7]),prob=0.4),\r\n\tL(T.ResizeShortestEdge)(short_edge_length=min_edge_range, sample_style=\"range\",max_size=max_size)\r\n]\r\ndataloader.train.mapper.image_format = \"RGB\"\r\n# recompute boxes due to cropping\r\ndataloader.train.mapper.recompute_boxes = True\r\n\r\ndataloader.test.mapper.augmentations = [\r\n\tL(T.ResizeShortestEdge)(short_edge_length=min_edge_range[1], max_size=max_size),\r\n]\r\ndataloader.test.mapper.recompute_boxes = True\r\n```\r\nHere's the model output during runtime:\r\n```\r\n[05/03 14:14:25 detectron2]: Model:\r\nGeneralizedRCNN(\r\n  (backbone): FPN(\r\n    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (top_block): LastLevelMaxPool()\r\n    (bottom_up): ResNet(\r\n      (stem): BasicStem(\r\n        (conv1): Conv2d(\r\n          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\r\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n        )\r\n      )\r\n      (res2): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res3): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res4): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (4): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (5): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res5): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n    )\r\n  )\r\n  (proposal_generator): RPN(\r\n    (rpn_head): StandardRPNHead(\r\n      (conv): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n    (anchor_generator): DefaultAnchorGenerator(\r\n      (cell_anchors): BufferList()\r\n    )\r\n  )\r\n  (roi_heads): StandardROIHeads(\r\n    (box_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (box_head): FastRCNNConvFCHead(\r\n      (flatten): Flatten(start_dim=1, end_dim=-1)\r\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\r\n      (fc_relu1): ReLU()\r\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\r\n      (fc_relu2): ReLU()\r\n    )\r\n    (box_predictor): FastRCNNOutputLayers(\r\n      (cls_score): Linear(in_features=1024, out_features=8, bias=True)\r\n      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\r\n    )\r\n  )\r\n)\r\n```\r\n\r\n2. What exact command you run:\r\n```\r\npython lazyconfig_train_net.py --config-file config.py\r\n```\r\n3. __Full logs__ or other relevant observations:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/Trainer/detectron2/detectron2/engine/train_loop.py\", line 149, in train\r\n    self.run_step()\r\n  File \"/home/ubuntu/Trainer/detectron2/detectron2/engine/train_loop.py\", line 404, in run_step\r\n    data = next(self._data_loader_iter)\r\n  File \"/home/ubuntu/Trainer/detectron2/detectron2/data/common.py\", line 234, in __iter__\r\n    for d in self.dataset:\r\n  File \"/home/ubuntu/miniconda3/envs/detectron/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 517, in __next__\r\n    data = self._next_data()\r\n  File \"/home/ubuntu/miniconda3/envs/detectron/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1199, in _next_data\r\n    return self._process_data(data)\r\n  File \"/home/ubuntu/miniconda3/envs/detectron/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1225, in _process_data\r\n    data.reraise()\r\n  File \"/home/ubuntu/miniconda3/envs/detectron/lib/python3.8/site-packages/torch/_utils.py\", line 429, in reraise\r\n    raise self.exc_type(msg)\r\nAttributeError: Caught AttributeError in DataLoader worker process 0.\r\nOriginal Traceback (most recent call last):\r\n  File \"/home/ubuntu/miniconda3/envs/detectron/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\r\n    data = fetcher.fetch(index)\r\n  File \"/home/ubuntu/miniconda3/envs/detectron/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 28, in fetch\r\n    data.append(next(self.dataset_iter))\r\n  File \"/home/ubuntu/Trainer/detectron2/detectron2/data/common.py\", line 201, in __iter__\r\n    yield self.dataset[idx]\r\n  File \"/home/ubuntu/Trainer/detectron2/detectron2/data/common.py\", line 90, in __getitem__\r\n    data = self._map_func(self._dataset[cur_idx])\r\n  File \"/home/ubuntu/Trainer/detectron2/detectron2/utils/serialize.py\", line 26, in __call__\r\n    return self._obj(*args, **kwargs)\r\n  File \"/home/ubuntu/Trainer/detectron2/detectron2/data/dataset_mapper.py\", line 189, in __call__\r\n    self._transform_annotations(dataset_dict, transforms, image_shape)\r\n  File \"/home/ubuntu/Trainer/detectron2/detectron2/data/dataset_mapper.py\", line 141, in _transform_annotations\r\n    instances.gt_boxes = instances.gt_masks.get_bounding_boxes()\r\n  File \"/home/ubuntu/Trainer/detectron2/detectron2/structures/instances.py\", line 68, in __getattr__\r\n    raise AttributeError(\"Cannot find field '{}' in the given Instances!\".format(name))\r\nAttributeError: Cannot find field 'gt_masks' in the given Instances!\r\n```\r\n\r\n## Expected behavior:\r\n\r\nThe model should start training without issue. I referred to #485 , but I'm using a detection model with bbox annotations. \r\nNot sure what is going on. The model weights from \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\" load fine, too.\r\nA sample of my dataset:\r\n```\r\n{'file_name': '1713252303077.jpg', 'image_id': 71, 'height': 3000, 'width': 4000, 'annotations': [{'bbox': [61, 820, 3982, 2080], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 3}]}\r\n```\r\n\r\n## Environment:\r\n\r\nThe detectron2 is locally built from a fork without any changes.\r\n\r\n```\r\n----------------------  -------------------------------------------------------------------------------------------\r\nsys.platform            linux\r\nPython                  3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]\r\nnumpy                   1.24.4\r\ndetectron2              0.6 @/home/ubuntu/Trainer/detectron2/detectron2\r\nCompiler                GCC 11.4\r\nCUDA compiler           not available\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.8.2+cu102 @/home/ubuntu/miniconda3/envs/detectron/lib/python3.8/site-packages/torch\r\nPyTorch debug build     False\r\nGPU available           Yes\r\nGPU 0                   Tesla T4 (arch=7.5)\r\nDriver version          535.171.04\r\nCUDA_HOME               None - invalid!\r\nPillow                  10.3.0\r\ntorchvision             0.9.2+cu102 @/home/ubuntu/miniconda3/envs/detectron/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags  /home/ubuntu/miniconda3/envs/detectron/lib/python3.8/site-packages/torchvision/_C.so\r\nfvcore                  0.1.5.post20221221\r\niopath                  0.1.9\r\ncv2                     4.9.0\r\n----------------------  -------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 10.2\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\r\n  - CuDNN 7.6.5\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,\r\n```",
    "comments": [
      {
        "user": "stoic-signs",
        "body": "Okay, looks like I found the issue: `recompute_boxes` requires `gt_masks` to get tighter bounding boxes when cropping.\r\nI removed that and it seems to work fine now. \r\nFollow-up question: when using the `ResizeShortestEdge` augmentation, I assume the bounding boxes are automatically scaled. Is this true? And is there any way to use cropping and recomputing bboxes when gt_mask isn't available?"
      },
      {
        "user": "function2-llx",
        "body": "> when using the `ResizeShortestEdge` augmentation, I assume the bounding boxes are automatically scaled. Is this true?\r\n\r\nThis seems to be true, annotations are applied with the same set of transforms: \r\n\r\nhttps://github.com/facebookresearch/detectron2/blob/2a420edb307c9bdf640f036d3b196bed474b8593/detectron2/data/dataset_mapper.py#L124-L130\r\n\r\n> And is there any way to use cropping and recomputing bboxes when gt_mask isn't available?\r\n\r\nSo, I think annotations should also be automatically transformed in these cases."
      },
      {
        "user": "ExtReMLapin",
        "body": "As for future people meeting this issue.\n\nI don't get this error with default trained but as soon as I use my aug trainer\n\n```python\nclass AugTrainer(DefaultTrainer):\n        @classmethod\n        def build_train_loader(cls, cfg):\n            mapper = DatasetMapper(\n                cfg,\n                is_train=True,\n                use_instance_mask=True,\n                recompute_boxes=True,\n                augmentations=[\n                    T.ResizeShortestEdge(\n                        short_edge_length=cfg.INPUT.MIN_SIZE_TRAIN, \n                        max_size=cfg.INPUT.MAX_SIZE_TRAIN,\n                        sample_style=cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING,\n                    ),\n                T.RandomApply(T.RandomFlip(vertical=True, horizontal=False), prob=0.5),\n                T.RandomApply(T.RandomFlip(vertical=False, horizontal=True), prob=0.5),\n                T.RandomRotation([0, 360]),\n                T.RandomApply(T.RandomContrast(0.3, 1.4), prob=0.7),\n                T.RandomApply(T.RandomBrightness(0.3, 1.4), prob=0.7),\n                T.RandomApply(T.RandomLighting(scale=0.5), prob=0.5),\n                ],\n            )\n            return build_detection_train_loader(cfg, mapper=mapper)\n\n        @classmethod\n        def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n            if output_folder is None:\n                output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n            return COCOEvaluator(dataset_name, output_dir=output_folder)\n\n\n```\n\nWIth `cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False` it errors as soon as it tries to train on a background image"
      }
    ]
  },
  {
    "issue_number": 655,
    "title": "Pre-defined color for dataset in COCO format",
    "author": "wiamadaya",
    "state": "closed",
    "created_at": "2020-01-09T07:59:56Z",
    "updated_at": "2025-03-25T13:07:15Z",
    "labels": [
      "documentation"
    ],
    "body": "How to use `stuff_colors` to pre-defined color for each stuff category for dataset in COCO format?",
    "comments": [
      {
        "user": "ppwwyyxx",
        "body": "I'm not sure I understand what you're trying to do, but `stuff_colors` is explained in docs: https://detectron2.readthedocs.io/tutorials/datasets.html#metadata-for-datasets"
      },
      {
        "user": "wiamadaya",
        "body": "I register my dataset as COCO and has set the `stuff_colors ` but the visualizer still give me random color, i did the following at the inference stage, or should it be done from the training stage?\r\n\r\n```\r\nregister_coco_instances(\"my_dataset\", {}, \"./training.json\", \"./images\")\r\ndataset_metadata = MetadataCatalog.get(\"my_dataset\")\r\nMetadataCatalog.get(\"my_dataset\").stuff_colors = [(102,255,102), (102,255,255), (102,102,255)]\r\n```"
      },
      {
        "user": "ppwwyyxx",
        "body": "You should use \"thing_colors\" which is missing in documentation. \"Stuff\" means it's not for instances."
      }
    ]
  },
  {
    "issue_number": 5054,
    "title": "Precision and recall values per class (Not AP and AR)",
    "author": "khodabakhshih",
    "state": "open",
    "created_at": "2023-08-11T00:47:18Z",
    "updated_at": "2025-03-22T19:02:36Z",
    "labels": [
      "enhancement"
    ],
    "body": "Hi\r\nWould you please show me a way to calculate the precision and recall values (not AP and AR) for a validation dataset.\r\nI need it to compare mask rcnn with other models in a research paper.\r\nBest regards\r\nHossein",
    "comments": [
      {
        "user": "JoyeZLearning",
        "body": "Hello, do you now have the code to  calculate the precision and recall values (not AP and AR) for a validation dataset? Could you please share with us?"
      },
      {
        "user": "ajzhai",
        "body": "In case anyone still needs help with this, here is a small repo I made for getting those precision and recall values:\nhttps://github.com/ajzhai/detectron2-precision-recall\n"
      }
    ]
  },
  {
    "issue_number": 5447,
    "title": "module 'PIL.Image' has no attribute 'LINEAR'. Did you mean: 'BILINEAR'",
    "author": "TeslaZY",
    "state": "open",
    "created_at": "2025-03-07T06:13:42Z",
    "updated_at": "2025-03-17T23:37:44Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\n1. Full runnable code or full changes you made:\n```\n# detectron2/detectron2/data/transforms/transform.py  line 46\nbeforeÔºödef __init__(self, src_rect, output_size, interp=Image.LINEAR, fill=0):\nafterÔºö   def __init__(self, src_rect, output_size, interp=Image.BILINEAR, fill=0):\n\n```\n2. What exact command you run:\nmagic-pdf -p demo1.pdf -o . -m auto \n3. __Full logs__ or other relevant observations:```\nTraceback (most recent call last):\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/bin/magic-pdf\", line 4, in <module>\n    from magic_pdf.tools.cli import cli\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/magic_pdf/tools/cli.py\", line 12, in <module>\n    from magic_pdf.tools.common import do_parse, parse_pdf_methods\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/magic_pdf/tools/common.py\", line 13, in <module>\n    from magic_pdf.model.doc_analyze_by_custom_model import doc_analyze\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/magic_pdf/model/doc_analyze_by_custom_model.py\", line 15, in <module>\n    from magic_pdf.model.batch_analyze import BatchAnalyze\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/magic_pdf/model/batch_analyze.py\", line 15, in <module>\n    from magic_pdf.model.pdf_extract_kit import CustomPEKModel\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/magic_pdf/model/pdf_extract_kit.py\", line 24, in <module>\n    from magic_pdf.model.sub_modules.model_init import AtomModelSingleton\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/magic_pdf/model/sub_modules/model_init.py\", line 8, in <module>\n    from magic_pdf.model.sub_modules.layout.layoutlmv3.model_init import Layoutlmv3_Predictor\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/magic_pdf/model/sub_modules/layout/layoutlmv3/model_init.py\", line 1, in <module>\n    from .visualizer import Visualizer\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/magic_pdf/model/sub_modules/layout/layoutlmv3/visualizer.py\", line 16, in <module>\n    from detectron2.data import MetadataCatalog\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/detectron2/data/__init__.py\", line 2, in <module>\n    from . import transforms  # isort:skip\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/detectron2/data/transforms/__init__.py\", line 4, in <module>\n    from .transform import *\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/detectron2/data/transforms/transform.py\", line 36, in <module>\n    class ExtentTransform(Transform):\n  File \"/Users/zyy/Documents/dev_project/mineru_service/.venv/lib/python3.10/site-packages/detectron2/data/transforms/transform.py\", line 46, in ExtentTransform\n    def __init__(self, src_rect, output_size, interp=Image.LINEAR, fill=0):\nAttributeError: module 'PIL.Image' has no attribute 'LINEAR'. Did you mean: 'BILINEAR'?\n```\n4. please simplify the steps as much as possible so they do not require additional resources to\n   run, such as a private dataset.\n\n## Expected behavior:\n\n\n## Environment:\n\nmacOS 15.3.1 (24D70)\npython 3.10\n\npillow==11.1.0\n\n",
    "comments": [
      {
        "user": "Nodemana",
        "body": "Hi, without looking into this too much. I have had issues with Pillow in the past with detectron2 due to detectron2 being old. The easiest fixes is to just downgrade Pillow. Pillow==9.5.0 has worked for me in the past."
      }
    ]
  },
  {
    "issue_number": 4141,
    "title": "Missing 3D meshes used in DensePose",
    "author": "statho",
    "state": "open",
    "created_at": "2022-04-08T18:47:01Z",
    "updated_at": "2025-03-17T06:30:17Z",
    "labels": [
      "enhancement"
    ],
    "body": "Hi,\r\n\r\nCould you please release the 3D meshes used in ```projects/DensePose```?\r\nThe 3D meshes released right now are just placeholders with all vertices and faces being equal to 0.\r\nAn example illustrating that follows:\r\n```\r\nimport pickle\r\nfrom detectron2.utils.file_io import PathManager\r\nwith PathManager.open(\"https://dl.fbaipublicfiles.com/densepose/meshes/cat_7466.pkl\", \"rb\") as hFile:\r\n    data = pickle.load(hFile)\r\n    print(data)\r\n```\r\n\r\nReleasing the 3D meshes can facilitate further research in this field and is fairly easy to do (just upload some .pkl files).\r\n\r\nThank you in advance!\r\n",
    "comments": [
      {
        "user": "statho",
        "body": "@MarcSzafraniec @vkhalidov\r\n\r\nI found you on the [history of DensePose](https://github.com/facebookresearch/detectron2/commits/main?before=2a1cec4c647dbe8a05f2d5b599d7d4c7cf9f04ad+35&branch=main&path%5B%5D=projects&path%5B%5D=DensePose) and you are also co-authors of the [CSE paper](https://arxiv.org/pdf/2011.12438.pdf).\r\n\r\nI would be really grateful if any of you can help me with this issue.\r\n\r\nThanks you :)"
      },
      {
        "user": "sunflower110",
        "body": "Hello, do you now have a way to generate meshes data or other alternatives now? @statho @"
      }
    ]
  },
  {
    "issue_number": 3457,
    "title": "Only Blue CSE vertex on Cat Image",
    "author": "kingsj0405",
    "state": "open",
    "created_at": "2021-09-07T12:15:09Z",
    "updated_at": "2025-03-11T09:49:58Z",
    "labels": [
      "densepose"
    ],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\nNo Change\r\n2. What exact command you run:\r\n\r\n```\r\npython apply_net.py show \\\r\n    configs/cse/densepose_rcnn_R_50_FPN_soft_animals_I0_finetune_m2m_16k.yaml \\\r\n    https://dl.fbaipublicfiles.com/densepose/cse/densepose_rcnn_R_50_FPN_soft_animals_finetune_maskonly_24k/267687159/model_final_354e61.pkl \\\r\n    image_examples \\\r\n    dp_vertex,bbox \\\r\n    -v \\\r\n    --output outputs/cse_animal2_test.png\r\n```\r\n3. __Full logs__ or other relevant observations:\r\nOnly blue vertex on animal\r\n![cse_animal2_test 0005](https://user-images.githubusercontent.com/13496612/132341505-fe62617b-374b-461f-91f6-d68581b0c42d.png)\r\n![cse_animal2_test 0006](https://user-images.githubusercontent.com/13496612/132341569-ce1feb5b-0f40-4348-a2b5-fa8f16cbb96b.png)\r\n![cse_animal2_test 0002](https://user-images.githubusercontent.com/13496612/132341584-258bd4cb-fd6b-409e-891c-40b99169d742.png)\r\n![cse_animal2_test 0004](https://user-images.githubusercontent.com/13496612/132341596-fce6c9b0-7ff3-4cad-8a0d-06f134290862.png)\r\n\r\n\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\nRun the above command with the following input examples\r\n[image_examples.zip](https://github.com/facebookresearch/detectron2/files/7121341/image_examples.zip)\r\n## Expected behavior:\r\nRainbox CSE Vertex on Cat\r\n![csv_example](https://camo.githubusercontent.com/b471c8c622057e33c6855c5694533d4d21e3c4a787c20689a7b8f485f4766403/68747470733a2f2f646c2e666261697075626c696366696c65732e636f6d2f64656e7365706f73652f7765622f64656e7365706f73655f6373655f7465617365722e706e67)\r\n\r\n## Environment:\r\n\r\n```\r\n----------------------  --------------------------------------------------------------------------------------\r\nsys.platform            linux\r\nPython                  3.9.6 (default, Aug 18 2021, 19:38:01) [GCC 7.5.0]\r\nnumpy                   1.20.3\r\ndetectron2              0.5 @/host/media/sejongyang/AnimalFaceReenactment/3dmm_stylegan2/detectron2/detectron2\r\nCompiler                GCC 7.5\r\nCUDA compiler           CUDA 10.0\r\ndetectron2 arch flags   6.1\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.9.0 @/root/miniconda3/envs/detectron2/lib/python3.9/site-packages/torch\r\nPyTorch debug build     False\r\nGPU available           Yes\r\nGPU 0,1                 GeForce GTX 1080 Ti (arch=6.1)\r\nCUDA_HOME               /usr/local/cuda\r\nPillow                  8.3.1\r\ntorchvision             0.10.0 @/root/miniconda3/envs/detectron2/lib/python3.9/site-packages/torchvision\r\ntorchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5\r\nfvcore                  0.1.5.post20210825\r\niopath                  0.1.9\r\ncv2                     4.5.3\r\n----------------------  --------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 10.2\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 7.6.5\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \r\n```",
    "comments": [
      {
        "user": "kingsj0405",
        "body": "It turns out every mesh file provided from DensePose has **zero vertices**.\r\n\r\nThis python code loads cat meshes for Continuous Surface Embedding.\r\n\r\n```python\r\nimport pickle\r\n\r\nfrom detectron2.utils.file_io import PathManager\r\n\r\nwith PathManager.open(\"https://dl.fbaipublicfiles.com/densepose/meshes/cat_7466.pkl\", \"rb\") as hFile:\r\n    data = pickle.load(hFile)\r\n    print(data)\r\n```\r\n\r\nBut every vertex has zero values\r\n\r\n```\r\n{'vertices': array([[ 0.,  0.,  0.],\r\n       [ 0.,  0.,  0.],\r\n       [ 0.,  0.,  0.],\r\n       ...,\r\n       [-0.,  0.,  0.],\r\n       [-0.,  0.,  0.],\r\n       [-0.,  0.,  0.]]), 'faces': array([[0, 0, 0],\r\n       [0, 0, 0],\r\n       [0, 0, 0],\r\n       ...,\r\n       [0, 0, 0],\r\n       [0, 0, 0],\r\n       [0, 0, 0]])}\r\n```\r\n\r\nIs there a proper URL for each animal meshes?\r\n\r\nOr should [`load_mesh_data` on DensePose/densepose/structures/mesh.py](https://github.com/facebookresearch/detectron2/blob/main/projects/DensePose/densepose/structures/mesh.py#L134) be updated?\r\n\r\nThis is called on [`get_xyz_vertex_embedding` on DensePose/densepose/vis/densepose_outputs_vertex.py](https://github.com/facebookresearch/detectron2/blob/main/projects/DensePose/densepose/vis/densepose_outputs_vertex.py#L31)"
      },
      {
        "user": "kingsj0405",
        "body": "(+) My builtin mesh catalog on `DensePose/build/lib/densepose/data/meshes/builtin.py` has the content as followings\r\n\r\n```python\r\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\r\n\r\nfrom .catalog import MeshInfo, register_meshes\r\n\r\nDENSEPOSE_MESHES_DIR = \"https://dl.fbaipublicfiles.com/densepose/meshes/\"\r\n\r\nMESHES = [\r\n    MeshInfo(\r\n        name=\"smpl_27554\",\r\n        data=\"smpl_27554.pkl\",\r\n        geodists=\"geodists/geodists_smpl_27554.pkl\",\r\n        symmetry=\"symmetry/symmetry_smpl_27554.pkl\",\r\n        texcoords=\"texcoords/texcoords_smpl_27554.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"chimp_5029\",\r\n        data=\"chimp_5029.pkl\",\r\n        geodists=\"geodists/geodists_chimp_5029.pkl\",\r\n        symmetry=\"symmetry/symmetry_chimp_5029.pkl\",\r\n        texcoords=\"texcoords/texcoords_chimp_5029.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"cat_5001\",\r\n        data=\"cat_5001.pkl\",\r\n        geodists=\"geodists/geodists_cat_5001.pkl\",\r\n        symmetry=\"symmetry/symmetry_cat_5001.pkl\",\r\n        texcoords=\"texcoords/texcoords_cat_5001.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"cat_7466\",\r\n        data=\"cat_7466.pkl\",\r\n        geodists=\"geodists/geodists_cat_7466.pkl\",\r\n        symmetry=\"symmetry/symmetry_cat_7466.pkl\",\r\n        texcoords=\"texcoords/texcoords_cat_7466.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"sheep_5004\",\r\n        data=\"sheep_5004.pkl\",\r\n        geodists=\"geodists/geodists_sheep_5004.pkl\",\r\n        symmetry=\"symmetry/symmetry_sheep_5004.pkl\",\r\n        texcoords=\"texcoords/texcoords_sheep_5004.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"zebra_5002\",\r\n        data=\"zebra_5002.pkl\",\r\n        geodists=\"geodists/geodists_zebra_5002.pkl\",\r\n        symmetry=\"symmetry/symmetry_zebra_5002.pkl\",\r\n        texcoords=\"texcoords/texcoords_zebra_5002.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"horse_5004\",\r\n        data=\"horse_5004.pkl\",\r\n        geodists=\"geodists/geodists_horse_5004.pkl\",\r\n        symmetry=\"symmetry/symmetry_horse_5004.pkl\",\r\n        texcoords=\"texcoords/texcoords_zebra_5002.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"giraffe_5002\",\r\n        data=\"giraffe_5002.pkl\",\r\n        geodists=\"geodists/geodists_giraffe_5002.pkl\",\r\n        symmetry=\"symmetry/symmetry_giraffe_5002.pkl\",\r\n        texcoords=\"texcoords/texcoords_giraffe_5002.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"elephant_5002\",\r\n        data=\"elephant_5002.pkl\",\r\n        geodists=\"geodists/geodists_elephant_5002.pkl\",\r\n        symmetry=\"symmetry/symmetry_elephant_5002.pkl\",\r\n        texcoords=\"texcoords/texcoords_elephant_5002.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"dog_5002\",\r\n        data=\"dog_5002.pkl\",\r\n        geodists=\"geodists/geodists_dog_5002.pkl\",\r\n        symmetry=\"symmetry/symmetry_dog_5002.pkl\",\r\n        texcoords=\"texcoords/texcoords_dog_5002.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"dog_7466\",\r\n        data=\"dog_7466.pkl\",\r\n        geodists=\"geodists/geodists_dog_7466.pkl\",\r\n        symmetry=\"symmetry/symmetry_dog_7466.pkl\",\r\n        texcoords=\"texcoords/texcoords_dog_7466.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"cow_5002\",\r\n        data=\"cow_5002.pkl\",\r\n        geodists=\"geodists/geodists_cow_5002.pkl\",\r\n        symmetry=\"symmetry/symmetry_cow_5002.pkl\",\r\n        texcoords=\"texcoords/texcoords_cow_5002.pkl\",\r\n    ),\r\n    MeshInfo(\r\n        name=\"bear_4936\",\r\n        data=\"bear_4936.pkl\",\r\n        geodists=\"geodists/geodists_bear_4936.pkl\",\r\n        symmetry=\"symmetry/symmetry_bear_4936.pkl\",\r\n        texcoords=\"texcoords/texcoords_bear_4936.pkl\",\r\n    ),\r\n]\r\n\r\nregister_meshes(MESHES, DENSEPOSE_MESHES_DIR)\r\n```"
      },
      {
        "user": "kingsj0405",
        "body": "@vkhalidov @MarcSzafraniec \r\nI found you on [history of DensePose](https://github.com/facebookresearch/detectron2/commits/main?before=2a1cec4c647dbe8a05f2d5b599d7d4c7cf9f04ad+35&branch=main&path%5B%5D=projects&path%5B%5D=DensePose).\r\nIt could be helpful any kind of tips to solve the problem.\r\nThank you :)"
      }
    ]
  },
  {
    "issue_number": 1795,
    "title": "Improve Densepose inference time when single person in the image",
    "author": "zhangy76",
    "state": "closed",
    "created_at": "2020-07-19T20:13:21Z",
    "updated_at": "2025-03-09T02:02:26Z",
    "labels": [
      "densepose"
    ],
    "body": "## ‚ùì How to do something using detectron2\r\n\r\nFor the Densepose project, besides using simpler Densepose head, is that possible to reduce the inference time if we know there is only single person is in the image?\r\n\r\nThanks,\r\nYufei",
    "comments": []
  },
  {
    "issue_number": 3964,
    "title": "TypeError: add(): argument 'alpha' must be Number, not NoneType #35",
    "author": "reubenwenisch",
    "state": "open",
    "created_at": "2022-02-15T15:43:29Z",
    "updated_at": "2025-03-08T10:02:40Z",
    "labels": [],
    "body": "I was trying to run the repo [DynamicHead](https://github.com/microsoft/DynamicHead) and trying to run the model with a custom dataset and have the following error. In the repo the launch function is called and I get these errors.\r\n\r\nThe command I run was \r\n```\r\nDETECTRON2_DATASETS=$DATASET python train_net.py --config configs/dyhead_r50_retina_fpn_1x.yaml --num-gpus 8\r\n```\r\n## Logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"train_net_custom.py\", line 222, in <module>\r\n    launch(\r\n  File \"/home/xxx/anaconda3/envs/detectron/lib/python3.8/site-packages/detectron2/engine/launch.py\", line 82, in launch\r\n    main_func(*args)\r\n  File \"train_net_custom.py\", line 216, in main\r\n    return trainer.train()\r\n  File \"/home/xxx/anaconda3/envs/detectron/lib/python3.8/site-packages/detectron2/engine/defaults.py\", line 484, in train\r\n    super().train(self.start_iter, self.max_iter)\r\n  File \"/home/xxx/anaconda3/envs/detectron/lib/python3.8/site-packages/detectron2/engine/train_loop.py\", line 149, in train\r\n    self.run_step()\r\n  File \"/home/xxx/anaconda3/envs/detectron/lib/python3.8/site-packages/detectron2/engine/defaults.py\", line 494, in run_step\r\n    self._trainer.run_step()\r\n  File \"/home/xxx/anaconda3/envs/detectron/lib/python3.8/site-packages/detectron2/engine/train_loop.py\", line 294, in run_step\r\n    self.optimizer.step()\r\n  File \"/home/xxx/anaconda3/envs/detectron/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\r\n    return wrapped(*args, **kwargs)\r\n  File \"/home/xxx/anaconda3/envs/detectron/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/xxx/anaconda3/envs/detectron/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/home/xxx/anaconda3/envs/detectron/lib/python3.8/site-packages/torch/optim/sgd.py\", line 110, in step\r\n    F.sgd(params_with_grad,\r\n  File \"/home/xxx/anaconda3/envs/detectron/lib/python3.8/site-packages/torch/optim/_functional.py\", line 160, in sgd\r\n    d_p = d_p.add(param, alpha=weight_decay)\r\nTypeError: add(): argument 'alpha' must be Number, not NoneType\r\n```\r\nDetectron2 version: 0.6\r\n\r\n## Expected behaviour is the training loop runs without error.",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "dedoogong",
        "body": "I got the same error!"
      },
      {
        "user": "reubenwenisch",
        "body": "@dedoogong This error had come with using detectron2 latest version I moved it to previous version and the code started working. Hope this helps."
      }
    ]
  },
  {
    "issue_number": 5445,
    "title": "Failing to build the wheel",
    "author": "Ansh-Gandhi",
    "state": "open",
    "created_at": "2025-03-01T19:05:05Z",
    "updated_at": "2025-03-06T14:38:06Z",
    "labels": [],
    "body": "1. Full runnable code or full changes you made:\n```\nconda create -n two-stage-weed-test python=3.10.12\n\n%conda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia\n!python -m pip install cython pyyaml\n!python -m pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n```\n2. __Full logs__ or other relevant observations:\n```\nChannels:\n - pytorch\n - nvidia\n - defaults\n - conda-forge\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /home/agandh04/miniconda3/envs/two-stage-weed-test\n\n  added / updated specs:\n    - pytorch-cuda=11.6\n    - pytorch==1.13.1\n    -  torchaudio==0.13.1\n    - torchvision==0.14.1\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    blas-1.0                   |              mkl           6 KB\n...\n  ERROR: Failed building wheel for detectron2\n  Running setup.py clean for detectron2\nFailed to build detectron2\nERROR: Failed to build installable wheels for some pyproject.toml based projects (detectron2)\n```\n\n",
    "comments": [
      {
        "user": "PrinceAlmeida",
        "body": "Hey Ansh,\n\nEven I was facing the same problem I have python 3.10 got the same wheel error.\n\n\"Check your python version. If you have Python version as 3.10 or higher you will face this issue. This is because detectron2 library has only wheels for <= Python 3.9.\"\n\nSource stack overflow\n\nhttps://stackoverflow.com/questions/75357936/how-to-install-detectron2\n\nThanks\n"
      }
    ]
  },
  {
    "issue_number": 5440,
    "title": "PointRend Model Outputs Incorrect Bounding Box: Bottom-Right Coordinates Are Incorrect",
    "author": "LAlongago",
    "state": "closed",
    "created_at": "2025-02-26T16:32:40Z",
    "updated_at": "2025-03-06T02:11:05Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "I have trained a PointRend model using my custom dataset, and during inference, I noticed that the predicted bounding boxes have incorrect bottom-right coordinates. Specifically, the output format that should be `[x1, y1, x2, y2]` is being output as `[x1, y1, x2+w, y2+h]` . This means the model is adding the width w and height h to the correct x2 and y2 coordinates, which results in incorrect bounding box values.\n\nThe mask and class predictions are correct, but the bounding box coordinates are incorrect. Below is the inference code I am using:\n```import torch\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.modeling import build_model\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog\nfrom detectron2 import model_zoo\nfrom detectron2.projects import point_rend\nimport cv2\n\nMetadataCatalog.get(\"my_train_dataset\").thing_classes = [\"0-1\", \"1-2\", \"2-3\", \"3-4\", \"4-5\", \"5-6\", \"6-7\", \"7-8\", \"1-11\", \"1-12\", \"11-111\", \"11-112\", \"11-113\", \"111-1111\", \"111-1112\", \"111-1113\", \"112-1121\", \"112-1122\", \"113-1131\", \"113-1132\", \"2-21\", \"2-22\", \"22-221\", \"22-222\", \"22-223\", \"3-31\", \"4-41\", \"41-411\", \"41-412\", \"5-51\", \"51-511\", \"51-512\", \"6-61\", \"7-71\", \"8-81\", \"8-82\"] \nMetadataCatalog.get(\"my_val_dataset\").thing_classes = [\"0-1\", \"1-2\", \"2-3\", \"3-4\", \"4-5\", \"5-6\", \"6-7\", \"7-8\", \"1-11\", \"1-12\", \"11-111\", \"11-112\", \"11-113\", \"111-1111\", \"111-1112\", \"111-1113\", \"112-1121\", \"112-1122\", \"113-1131\", \"113-1132\", \"2-21\", \"2-22\", \"22-221\", \"22-222\", \"22-223\", \"3-31\", \"4-41\", \"41-411\", \"41-412\", \"5-51\", \"51-511\", \"51-512\", \"6-61\", \"7-71\", \"8-81\", \"8-82\"]\n\ncfg = get_cfg()\npoint_rend.add_pointrend_config(cfg)\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/pointrend_rcnn_R_50_FPN_1x_coco.yaml\"))\n\ncfg.DATASETS.TRAIN = (\"my_train_dataset\",)\ncfg.DATASETS.TEST = (\"my_val_dataset\",)\ncfg.DATALOADER.NUM_WORKERS = 4\n\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 36\ncfg.MODEL.POINT_HEAD.NUM_CLASSES = 36 \ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\ncfg.SOLVER.IMS_PER_BATCH = 4 \n\ncfg.MODEL.DEVICE = \"cuda\" \n\ncfg.MODEL.WEIGHTS = \"model_final.pth\" \n\nmodel = build_model(cfg)\ncheckpoint = torch.load(cfg.MODEL.WEIGHTS)\nmodel.load_state_dict(checkpoint['model'], strict=False)\n\nmodel.eval()\npredictor = DefaultPredictor(cfg)\n\nimage = cv2.imread(\"WireInstanceDataset101/test/images/IMG20241018152403.jpg\") \n\noutputs = predictor(image)\nprint(outputs)\n\nv = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=0.8)\nv = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n\ncv2.imshow(\"Inference Result\", v.get_image()[:, :, ::-1])\ncv2.imwrite(\"interface_output.jpg\", v.get_image()[:, :, ::-1])\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n```\nCould you please guide me on how to fix this issue with the bounding box coordinates? Is there any specific handling required in the code?\n\nThank you for your help!",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5320,
    "title": "Does it possible to install detectron2 on the device with cuda version>11.3 in the future",
    "author": "HarisIqbal89",
    "state": "open",
    "created_at": "2024-07-02T07:52:07Z",
    "updated_at": "2025-03-03T20:18:42Z",
    "labels": [
      "documentation"
    ],
    "body": "Hi , my previous code is based on cuda 11.7. So I want to know if you have planned to explore detectron2 in a new version. I will be appreciate for this :)",
    "comments": [
      {
        "user": "Programmer-RD-AI",
        "body": "Hi,\r\nThis seems to have been brought up in issue #5058 but It seems that there are no plans as for right...\r\nBut I am not 100% sure as I am not an official contributor to detectron2...\r\n"
      },
      {
        "user": "lattebyte",
        "body": "I've been running Detectron2 on a CUDA 11.8 and Windows 11 platform for over a year. While I did encounter some strange errors during installation, they were easy to fix. Feel free to reach out if you run into any issues!"
      },
      {
        "user": "whb007",
        "body": "> I've been running Detectron2 on a CUDA 11.8 and Windows 11 platform for over a year. While I did encounter some strange errors during installation, they were easy to fix. Feel free to reach out if you run into any issues!\n\n\nHello, Could you please tell me how to install Detectron2 on the CUDA 11.8 platform. I use the command \n```bash\npip install detectron2\n```\nor \n```bash\npython -m pip install detectron2\n```\nand it turn out\n\n![Image](https://github.com/user-attachments/assets/df3ca0ad-2df0-4610-ad87-61f0e728e58e)"
      }
    ]
  },
  {
    "issue_number": 4964,
    "title": "RuntimeError:  Module 'ResNet' has no attribute 'stages_and_names' ",
    "author": "lix19937",
    "state": "open",
    "created_at": "2023-05-19T08:09:36Z",
    "updated_at": "2025-03-03T06:50:24Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n\r\n1. Full runnable code or full changes you made:\r\n\r\n```\r\n  File \"/opt/conda/envs/alpha_env/lib/python3.8/site-packages/torch/jit/_recursive.py\", line 368, in create_methods_and_properties_from_stubs\r\n    concrete_type._create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)\r\n\r\nRuntimeError: \r\nModule 'ResNet' has no attribute 'stages_and_names' (This attribute exists on the Python module, but we failed to convert Python type: 'list' to a TorchScript type. Could not infer type of list element: Cannot infer concrete type of torch.nn.Module. Its type was inferred; try adding a type annotation for the attribute.):\r\n\r\n  File \"/root/code/modeling/backbone/res2net.py\", line 632\r\n\r\n        if \"stem\" in self._out_features:\r\n            outputs[\"stem\"] = x\r\n        for stage, name in self.stages_and_names:\r\n                           ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n\r\n            x = stage(x)\r\n            if name in self._out_features:\r\n\r\n```\r\nref  https://github.com/facebookresearch/detectron2/issues/2734   Ôºå \r\n https://detectron2.readthedocs.io/en/latest/tutorials/deployment.html#deployment-with-tracing-or-scripting    **not work !!!**  \r\n\r\n## Environment:     \r\ntorch                              1.10.2+cu113      \r\ndetectron2                     0.6        \r\n",
    "comments": [
      {
        "user": "fumin",
        "body": "Hitting against this bug, too:\r\n\r\n```\r\nRuntimeError: \r\nModule 'ResNet' has no attribute 'stages' (This attribute exists on the Python module, but we failed to convert Python type: 'list' to a TorchScript type. Could not infer type of list element: Cannot infer concrete type of torch.nn.Module. Its type was inferred; try adding a type annotation for the attribute.):\r\n  File \"/usr/local/detectron2/detectron2/modeling/backbone/resnet.py\", line 448\r\n        if \"stem\" in self._out_features:\r\n            outputs[\"stem\"] = x\r\n        for name, stage in zip(self.stage_names, self.stages):\r\n                                                 ~~~~~~~~~~~ <--- HERE\r\n            x = stage(x)\r\n            if name in self._out_features:\r\n\r\n\r\n```"
      },
      {
        "user": "lodgegao",
        "body": "Hitting the same bug, anyone knows how to fix it ?"
      }
    ]
  },
  {
    "issue_number": 5444,
    "title": "Instance-Segmentation Predictions to COCO JSON Format",
    "author": "daksh47",
    "state": "open",
    "created_at": "2025-03-01T12:46:43Z",
    "updated_at": "2025-03-01T12:48:00Z",
    "labels": [
      "enhancement"
    ],
    "body": "## üöÄ Feature\nTaking the detailed output of instance segmentation, which provides masks that highlight individual objects, we transform this into a COCO JSON format. This process involves examining the spatial relationships between the segmented objects within each image. The resulting COCO JSON data is offering a structured representation of the predictions, which can be used as an BASE input for further annotations/labellings\n\n## Motivation & Examples\n\n- Lesion Detection\n- Urban Planning and Monitoring\n- Organ Segmentation\n- Disaster Management\n- Many More\n\nin the above mentioned uses of image segmentation and deep learning, where the training dataset contains many images, where each image contains many multiple objects of similar or different classes, which requires manually annotating all the images\n\nPros\n- More accurate annotations\n\nCons\n- Time consuming\n- Prone To Human Error\n- Reduces Efficiency\n\nbut if a small subset of the same dataset is feed as the training dataset and a BASE model is trained, then you can use this feature or piece of code to convert the predictions made by the BASE model to annotations for the remaining images present in the dataset, which reduces the time taken significantly \n\nLets say you have 100 images, each containing 10-50 objects to be annotated, total objects an avg to be annotated is 3,000 objects.\n\nnow lets say you can annotated around 200-300 objects a day without affecting the accuracy and efficiency in the annotations, resulting in \n\n- 10-12 days of only annotating the training dataset\n- 3,000+ objects annotated\n\nwhich can still contain human error\n\nBut if you train the BASE model with 10 images, and then perform predications on the remaining images with a minimum of 80% overall accuracy including 10% false positives and 10% false negatives, then on avg the changes to be made or new annotation to be marked per image will be reduced from 30 -> 6, therefore on avg resulting in\n\n- 2 days of training the model ( 1-1.5 days of annotating the images and the rest for training the BASE model )\n- 2 days for manually correcting the inaccuracies and missing data on the remaining images\n\non avg time taken is around 3-5days, when compared with manual annotations, this feature is 2-3 times ( 150-200% ) faster than the manual, traditional method\n\n# Simple Example\n\n### Input Image\n\n![Image](https://github.com/user-attachments/assets/2e1ba8ef-055d-4d34-9a6c-29ef5839e9b8)\n\n### Model\n\nthe pre-trained already available Instance-Segmentation Model ( COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml )\n\n### Output Image\n\n![Image](https://github.com/user-attachments/assets/3d34771b-2b07-4c2d-a4eb-ac67533c37b5)\n\nthese COCO annotations are made using above mentioned feature/piece of code ",
    "comments": []
  },
  {
    "issue_number": 5269,
    "title": "missing config key error",
    "author": "yanchuqiao",
    "state": "closed",
    "created_at": "2024-04-26T09:16:59Z",
    "updated_at": "2025-02-28T02:10:19Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "I am facing this error: Saving features to: /home/ubuntu/feature_extraction/Char_summ_image_features/features/features_test_boxes36.h5\r\nConfig '/home/ubuntu/feature_extraction/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\r\nTraceback (most recent call last):\r\n  File \"vistext_proposal.py\", line 84, in <module>\r\n    extract(output_fname, dataloader, desc)\r\n  File \"/home/ubuntu/feature_extraction/detectron2_proposal_maxnms.py\", line 164, in extract\r\n    detector = build_model()\r\n  File \"/home/ubuntu/feature_extraction/detectron2_proposal_maxnms.py\", line 140, in build_model\r\n    cfg.merge_from_file(os.path.join(\r\n  File \"/home/ubuntu/miniconda3/envs/feature_extractor/lib/python3.8/site-packages/detectron2/config/config.py\", line 54, in merge_from_file\r\n    self.merge_from_other_cfg(loaded_cfg)\r\n  File \"/home/ubuntu/miniconda3/envs/feature_extractor/lib/python3.8/site-packages/fvcore/common/config.py\", line 123, in merge_from_other_cfg\r\n    return super().merge_from_other_cfg(cfg_other)\r\n  File \"/home/ubuntu/miniconda3/envs/feature_extractor/lib/python3.8/site-packages/yacs/config.py\", line 217, in merge_from_other_cfg\r\n    _merge_a_into_b(cfg_other, self, self, [])\r\n  File \"/home/ubuntu/miniconda3/envs/feature_extractor/lib/python3.8/site-packages/yacs/config.py\", line 478, in _merge_a_into_b\r\n    _merge_a_into_b(v, b[k], root, key_list + [k])\r\n  File \"/home/ubuntu/miniconda3/envs/feature_extractor/lib/python3.8/site-packages/yacs/config.py\", line 491, in _merge_a_into_b\r\n    raise KeyError(\"Non-existent config key: {}\".format(full_key))\r\nKeyError: 'Non-existent config key: MODEL.CAFFE_MAXPOOL' \r\n\r\nI tried with all of detectron2-0.4 future-1.0.0 fvcore-0.1.3.post20210317 pydot-2.0.0 / detectron2-0.5 / detectron2-0.6",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5436,
    "title": "ModuleNotFoundError: No module named 'deeplearning' when running evaluation on cityscapes dataset",
    "author": "mudit-soni",
    "state": "open",
    "created_at": "2025-02-18T17:23:20Z",
    "updated_at": "2025-02-21T11:08:46Z",
    "labels": [],
    "body": "I am trying to evaluate a pretrained mask2former model on cityscapes using the mask2former repository here https://github.com/facebookresearch/Mask2Former. It uses detectron2 for evaluation, and I have made no changes to either of the repositories from my side.\n\n```\nTraceback (most recent call last):\nFile \"train_net.py\", line 321, in <module>\n    launch(\nFile \"/raid/scripts/mudit/detectron2/detectron2/engine/launch.py\", line 84, in launch\n    main_func(*args)\nFile \"train_net.py\", line 306, in main\n    res = Trainer.test(cfg, model)\nFile \"/raid/scripts/mudit/detectron2/detectron2/engine/defaults.py\", line 653, in test\n   results_i = inference_on_dataset(model, data_loader, evaluator)\nFile \"/raid/scripts/mudit/detectron2/detectron2/evaluation/evaluator.py\", line 172, in inference_on_dataset\n   evaluator.process(inputs, outputs)\nFile \"/raid/scripts/mudit/detectron2/detectron2/evaluation/cityscapes_evaluation.py\", line 143, in process\n    from deeplearning.projects.cityscapesApi.cityscapesscripts.helpers.labels import trainId2label\nModuleNotFoundError: No module named 'deeplearning'\n```\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "mudit-soni",
        "body": "I don't think additional details are required as the error is due to a missing module \"deeplearning\". It doesn't seem to be included in the detectron2 repository and I can't find any other instructions to install it."
      },
      {
        "user": "Sta8is",
        "body": "I have also encountered  this issue. Seems that a recent commit changed some lines at detectron/data/datasets/cityscapes.py and detectron2/evaluation/cityscapes_evaluation.py as you can see here https://github.com/facebookresearch/detectron2/commit/4823082af157bbc0231091b4b22e1faf72058d46. Removing the \"deeplearning.projects.cityscapesApi\" prefix seems to work for me. For example change\n```python\nfrom deeplearning.projects.cityscapesApi.cityscapesscripts.helpers.labels import labels\n```\nto \n```python\nfrom cityscapesscripts.helpers.labels import labels\n```"
      }
    ]
  },
  {
    "issue_number": 5437,
    "title": "Created Dockerfile & Python Script to Run all Models for Images and Videos",
    "author": "michaelslice",
    "state": "open",
    "created_at": "2025-02-20T06:57:14Z",
    "updated_at": "2025-02-20T06:57:14Z",
    "labels": [
      "documentation"
    ],
    "body": "## üìö Documentation Issue\n\nI know... the documentation is hard to follow, and there are a million dependencies to get this project to work. Well no worries, because I have created a Dockerfile and a Python Script to run and process all your images/videos in a GPU accelerated environment!\n\nThe Dockerfile and Repo is available here [michaelslice Github Link](https://github.com/michaelslice/detectron2_dockerfile)\n\nI was able to do so with these commands below in a Dockerfile, and a Python Script available on my Github.\n```\n# Base image with CUDA 11.3.1 and cuDNN 8\nFROM nvidia/cuda:11.3.1-cudnn8-runtime-ubuntu20.04\n\n# Install system dependencies\nRUN apt-get update && \\\n    DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n    git \\\n    python3.8 \\\n    python3.8-dev \\\n    python3.8-distutils \\\n    python3-pip \\\n    libgl1 \\\n    ffmpeg \\\n    wget \\\n    libglib2.0-0 \\\n    libsm6 \\\n    libxext6 \\\n    libxrender-dev \\\n    libqt5x11extras5 \\\n    g++ \\ \n    gcc \\ \n    cmake \\\n    libgtk2.0-dev \\\n    pkg-config \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set Python 3.8 as the default Python version\nRUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n\n# Upgrade pip and install Python dependencies\nRUN python3 -m pip install --upgrade pip && \\\n    pip3 install opencv-python-headless && \\\n    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu113 && \\\n    python3 -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n\n# Create data directory\nRUN mkdir -p data\nCOPY ./data data\n\n# Download the model file and set permissions\nRUN wget https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl -O model_final_cafdb1.pkl && \\\n    chmod 644 model_final_cafdb1.pkl\n\n# Copy the rest of the application code\nCOPY . .\n\n# Set proper permissions for the data directory\nRUN chmod -R 755 data\n\n```",
    "comments": []
  },
  {
    "issue_number": 5260,
    "title": "Very slow training on Apple M1 Pro",
    "author": "andreivicol",
    "state": "closed",
    "created_at": "2024-04-17T10:44:57Z",
    "updated_at": "2025-02-19T02:07:53Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "I'm trying to train detectron2 for object detection on a custom dataset consisting of 2000 480 x 352 plant images. The dataset is in COCO format. I've run object detection training on YOLOv8 using the same dataset with a time of 7 minutes per epoch on CPU and about 2 minutes per epoch using MPS. \r\n\r\nHowever, on detectron2 I'm seeing incredibly long training times on CPU and cannot get it to work on GPU. Any advice would be welcome. I'd really like to not have to switch to a Windows machine for this, if possible.\r\n\r\nI suspect this might be a configuration issue. \r\n\r\n1. Full runnable code or full changes you made:\r\n```\r\nif __name__ == \"__main__\":\r\n\r\n    setup_logger()\r\n    register_coco_instances(\"train\", {},\r\n                            \"train.json\",\r\n                            \"pTrain_images\")\r\n    register_coco_instances(\"valid\", {},\r\n                            \"val.json\",\r\n                            \"pVal_images\")\r\n\r\n    cfg = get_cfg()\r\n    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"))\r\n    cfg.DATASETS.TRAIN = (\"train\",)\r\n    cfg.DATASETS.TEST = (\"valid\",)\r\n    cfg.OUTPUT_DIR = \"det2Out\"\r\n\r\n    cfg.DATALOADER.NUM_WORKERS = 8\r\n    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\r\n        \"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")\r\n    cfg.SOLVER.IMS_PER_BATCH = 4\r\n    cfg.SOLVER.BASE_LR = 0.0001\r\n\r\n    cfg.SOLVER.WARMUP_ITERS = 500\r\n    # cfg.SOLVER.MAX_ITER = 1500\r\n    # cfg.SOLVER.STEPS = (1000, 1500)\r\n    cfg.SOLVER.STEPS = (30000,)\r\n    cfg.SOLVER.GAMMA = 0.1\r\n\r\n    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\r\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\r\n    cfg.MODEL.DEVICE = \"cpu\"\r\n    cfg.TEST.EVAL_PERIOD = 500\r\n\r\n\r\n    class CocoTrainer(DefaultTrainer):\r\n\r\n        @classmethod\r\n        def build_evaluator(cls, cfg, dataset_name, output_folder=None):\r\n            if output_folder is None:\r\n                os.makedirs(\"coco_eval\", exist_ok=True)\r\n                output_folder = \"coco_eval\"\r\n\r\n            return COCOEvaluator(dataset_name, cfg, False, output_folder)\r\n\r\n\r\n    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n    trainer = CocoTrainer(cfg)\r\n    trainer.resume_or_load(resume=False)\r\n    trainer.train()\r\n```\r\n2. What exact command you run:\r\n\r\nI'm training in PyCharm.\r\n\r\n4. __Full logs__ or other relevant observations:\r\n```\r\n[04/17 13:20:38 d2.data.datasets.coco]: Loaded 2952 images in COCO format from /Users/andreivicol/Doctorat/An1/YOLO/scripts/dataset/input/pTrain_masks/train.json\r\n[04/17 13:20:38 d2.engine.defaults]: Model:\r\nGeneralizedRCNN(\r\n  (backbone): FPN(\r\n    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (top_block): LastLevelMaxPool()\r\n    (bottom_up): ResNet(\r\n      (stem): BasicStem(\r\n        (conv1): Conv2d(\r\n          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\r\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n        )\r\n      )\r\n      (res2): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res3): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res4): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (4): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (5): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res5): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n    )\r\n  )\r\n  (proposal_generator): RPN(\r\n    (rpn_head): StandardRPNHead(\r\n      (conv): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n    (anchor_generator): DefaultAnchorGenerator(\r\n      (cell_anchors): BufferList()\r\n    )\r\n  )\r\n  (roi_heads): StandardROIHeads(\r\n    (box_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (box_head): FastRCNNConvFCHead(\r\n      (flatten): Flatten(start_dim=1, end_dim=-1)\r\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\r\n      (fc_relu1): ReLU()\r\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\r\n      (fc_relu2): ReLU()\r\n    )\r\n    (box_predictor): FastRCNNOutputLayers(\r\n      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\r\n      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\r\n    )\r\n  )\r\n)\r\n[04/17 13:20:38 d2.data.datasets.coco]: Loaded 2952 images in COCO format from /Users/andreivicol/Doctorat/An1/YOLO/scripts/dataset/input/pTrain_masks/train.json\r\n[04/17 13:20:38 d2.data.build]: Removed 8 images with no usable annotations. 2944 images left.\r\n[04/17 13:20:38 d2.data.build]: Distribution of instances among all 1 categories:\r\n|  category  | #instances   |\r\n|:----------:|:-------------|\r\n|  tobacco   | 12463        |\r\n|            |              |\r\n[04/17 13:20:38 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\r\n[04/17 13:20:38 d2.data.build]: Using training sampler TrainingSampler\r\n[04/17 13:20:38 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\r\n[04/17 13:20:38 d2.data.common]: Serializing 2944 elements to byte tensors and concatenating them all ...\r\n[04/17 13:20:38 d2.data.common]: Serialized dataset takes 3.89 MiB\r\n[04/17 13:20:38 d2.data.build]: Making batched data loader with batch_size=4\r\n[04/17 13:20:38 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl ...\r\nSkip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\r\nSkip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\r\nSkip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\r\nSkip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\r\nSome model parameters or buffers are not found in the checkpoint:\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\n[04/17 13:20:38 d2.engine.train_loop]: Starting training from iteration 0\r\n/Users/andreivicol/miniconda3/envs/detectron2/lib/python3.12/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403226120/work/aten/src/ATen/native/TensorShape.cpp:3550.)\r\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n\r\n[04/17 13:23:04 d2.utils.events]:  eta: 7 days, 6:13:20  iter: 19  total_loss: 1.87  loss_cls: 0.7303  loss_box_reg: 0.8469  loss_rpn_cls: 0.2471  loss_rpn_loc: 0.03693    time: 7.0937  last_time: 6.1614  data_time: 0.1178  last_data_time: 0.0017   lr: 3.8962e-06  \r\n[04/17 13:25:31 d2.utils.events]:  eta: 7 days, 22:27:45  iter: 39  total_loss: 1.832  loss_cls: 0.6939  loss_box_reg: 0.8942  loss_rpn_cls: 0.2154  loss_rpn_loc: 0.03777    time: 7.2422  last_time: 8.3476  data_time: 0.0015  last_data_time: 0.0014   lr: 7.8922e-06  \r\n\r\n```\r\n\r\n## Expected behavior:\r\n\r\nI would expect training to take a significantly shorter time. I'm getting an estimate of 7 days.\r\n\r\n## Environment:\r\n\r\nPaste the output of the following command:\r\n```\r\n# Name                    Version                   Build  Channel\r\nabsl-py                   2.1.0                    pypi_0    pypi\r\nantlr4-python3-runtime    4.9.3                    pypi_0    pypi\r\nblack                     24.4.0                   pypi_0    pypi\r\nblas                      1.0                    openblas  \r\nbrotli-python             1.0.9           py312h313beb8_7  \r\nbzip2                     1.0.8                h80987f9_5  \r\nca-certificates           2024.3.11            hca03da5_0  \r\ncertifi                   2024.2.2        py312hca03da5_0  \r\ncharset-normalizer        2.0.4              pyhd3eb1b0_0  \r\nclick                     8.1.7                    pypi_0    pypi\r\ncloudpickle               3.0.0                    pypi_0    pypi\r\ncontourpy                 1.2.1                    pypi_0    pypi\r\ncycler                    0.12.1                   pypi_0    pypi\r\ndetectron2                0.6                      pypi_0    pypi\r\nexpat                     2.5.0                h313beb8_0  \r\nfilelock                  3.13.1          py312hca03da5_0  \r\nfonttools                 4.51.0                   pypi_0    pypi\r\nfreetype                  2.12.1               h1192e45_0  \r\nfvcore                    0.1.5.post20221221          pypi_0    pypi\r\ngrpcio                    1.62.1                   pypi_0    pypi\r\nhydra-core                1.3.2                    pypi_0    pypi\r\nidna                      3.4             py312hca03da5_0  \r\niopath                    0.1.9                    pypi_0    pypi\r\njinja2                    3.1.3           py312hca03da5_0  \r\njpeg                      9e                   h80987f9_1  \r\nkiwisolver                1.4.5                    pypi_0    pypi\r\nlcms2                     2.12                 hba8e193_0  \r\nlerc                      3.0                  hc377ac9_0  \r\nlibcxx                    14.0.6               h848a8c0_0  \r\nlibdeflate                1.17                 h80987f9_1  \r\nlibffi                    3.4.4                hca03da5_0  \r\nlibgfortran               5.0.0           11_3_0_hca03da5_28  \r\nlibgfortran5              11.3.0              h009349e_28  \r\nlibjpeg-turbo             2.0.0                h1a28f6b_0  \r\nlibopenblas               0.3.21               h269037a_0  \r\nlibpng                    1.6.39               h80987f9_0  \r\nlibtiff                   4.5.1                h313beb8_0  \r\nlibwebp-base              1.3.2                h80987f9_0  \r\nllvm-openmp               14.0.6               hc6e5704_0  \r\nlz4-c                     1.9.4                h313beb8_0  \r\nmarkdown                  3.6                      pypi_0    pypi\r\nmarkupsafe                2.1.3           py312h80987f9_0  \r\nmatplotlib                3.8.4                    pypi_0    pypi\r\nmpmath                    1.3.0           py312hca03da5_0  \r\nmypy-extensions           1.0.0                    pypi_0    pypi\r\nncurses                   6.4                  h313beb8_0  \r\nnetworkx                  3.1             py312hca03da5_0  \r\nnumpy                     1.26.4          py312h7f4fdc5_0  \r\nnumpy-base                1.26.4          py312he047099_0  \r\nomegaconf                 2.3.0                    pypi_0    pypi\r\nopencv-python             4.9.0.80                 pypi_0    pypi\r\nopenjpeg                  2.3.0                h7a6adac_2  \r\nopenssl                   3.0.13               h1a28f6b_0  \r\npackaging                 24.0                     pypi_0    pypi\r\npathspec                  0.12.1                   pypi_0    pypi\r\npillow                    10.2.0          py312h80987f9_0  \r\npip                       23.3.1          py312hca03da5_0  \r\nplatformdirs              4.2.0                    pypi_0    pypi\r\nportalocker               2.8.2                    pypi_0    pypi\r\nprotobuf                  5.26.1                   pypi_0    pypi\r\npycocotools               2.0.7                    pypi_0    pypi\r\npyparsing                 3.1.2                    pypi_0    pypi\r\npysocks                   1.7.1           py312hca03da5_0  \r\npython                    3.12.2               h99e199e_0  \r\npython-dateutil           2.9.0.post0              pypi_0    pypi\r\npytorch                   2.2.2                  py3.12_0    pytorch\r\npyyaml                    6.0.1           py312h80987f9_0  \r\nreadline                  8.2                  h1a28f6b_0  \r\nrequests                  2.31.0          py312hca03da5_1  \r\nsetuptools                68.2.2          py312hca03da5_0  \r\nsix                       1.16.0                   pypi_0    pypi\r\nsqlite                    3.41.2               h80987f9_0  \r\nsympy                     1.12            py312hca03da5_0  \r\ntabulate                  0.9.0                    pypi_0    pypi\r\ntensorboard               2.16.2                   pypi_0    pypi\r\ntensorboard-data-server   0.7.2                    pypi_0    pypi\r\ntermcolor                 2.4.0                    pypi_0    pypi\r\ntk                        8.6.12               hb8d0fd4_0  \r\ntorchaudio                2.2.2                 py312_cpu    pytorch\r\ntorchvision               0.17.2                py312_cpu    pytorch\r\ntqdm                      4.66.2                   pypi_0    pypi\r\ntyping_extensions         4.9.0           py312hca03da5_1  \r\ntzdata                    2024a                h04d1e81_0  \r\nurllib3                   2.1.0           py312hca03da5_1  \r\nwerkzeug                  3.0.2                    pypi_0    pypi\r\nwheel                     0.41.2          py312hca03da5_0  \r\nxz                        5.4.6                h80987f9_0  \r\nyacs                      0.1.8                    pypi_0    pypi\r\nyaml                      0.2.5                h1a28f6b_0  \r\nzlib                      1.2.13               h5a0b063_0  \r\nzstd                      1.5.5                hd90d995_0  \r\n```",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5267,
    "title": "The comits you are making are breaking the code!!!",
    "author": "sebastianfernandezgarcia",
    "state": "closed",
    "created_at": "2024-04-23T06:37:39Z",
    "updated_at": "2025-02-18T02:07:02Z",
    "labels": [
      "needs-more-info"
    ],
    "body": ".0 pathspec-0.12.1 platformdirs-4.2.0 portalocker-2.8.2 pycocotools-2.0.7 tabulate-0.9.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 termcolor-2.4.0 tomli-2.0.1 werkzeug-3.0.2 yacs-0.1.8\r\n\r\n[notice] A new release of pip available: 22.3.1 -> 24.0\r\n[notice] To update, run: python -m pip install --upgrade pip\r\nCloning into 'unilm'...\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n\r\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r\n100   500  100   500    0     0   1477      0 --:--:-- --:--:-- --:--:--  1479\r\nTraceback (most recent call last):\r\n  File \"/home/user/app/app.py\", line 39, in <module>\r\n    predictor = DefaultPredictor(cfg)\r\n  File \"/home/user/app/detectron2/detectron2/engine/defaults.py\", line 288, in __init__\r\n    checkpointer.load(cfg.MODEL.WEIGHTS)\r\n  File \"/home/user/app/detectron2/detectron2/checkpoint/detection_checkpoint.py\", line 62, in load\r\n    ret = super().load(path, *args, **kwargs)\r\n  File \"/home/user/.local/lib/python3.10/site-packages/fvcore/common/checkpoint.py\", line 155, in load\r\n    checkpoint = self._load_file(path)\r\n  File \"/home/user/app/detectron2/detectron2/checkpoint/detection_checkpoint.py\", line 99, in _load_file\r\n    loaded = self._torch_load(filename)\r\n  File \"/home/user/app/detectron2/detectron2/checkpoint/detection_checkpoint.py\", line 114, in _torch_load\r\n    return super()._load_file(f)\r\n  File \"/home/user/.local/lib/python3.10/site-packages/fvcore/common/checkpoint.py\", line 252, in _load_file\r\n    return torch.load(f, map_location=torch.device(\"cpu\"))\r\n  File \"/home/user/.local/lib/python3.10/site-packages/torch/serialization.py\", line 713, in load\r\n    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\r\n  File \"/home/user/.local/lib/python3.10/site-packages/torch/serialization.py\", line 920, in _legacy_load\r\n    magic_number = pickle_module.load(f, **pickle_load_args)\r\n_pickle.UnpicklingError: invalid load key, '\\xef'.",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      }
    ]
  },
  {
    "issue_number": 3745,
    "title": "How to distinguish between front of the head and back of the head from Densepose output",
    "author": "abhaydoke09",
    "state": "open",
    "created_at": "2021-12-01T19:02:11Z",
    "updated_at": "2025-02-17T05:11:23Z",
    "labels": [
      "documentation",
      "densepose"
    ],
    "body": "## üìö Documentation Issue\r\n\r\nFrom the Densepose output, is there a way to know which head pixel belong the front of the head and which one belongs to back of the head? Especially, segmentation values 23 and 24 represent head segmentation, but I am not clear on which one is the front part of the head and which is the back part of the head. https://github.com/facebookresearch/DensePose/issues/64\r\n\r\nOn the similar track, is there a way to map UV values to identify eyes, nose of the human head in the original RGB input image?\r\n\r\n\r\n\r\n",
    "comments": [
      {
        "user": "dStanhill",
        "body": "Hi Abhay Doke,  did you find a solution to your issue, that is, how to identify coordinates of eyes and nose in RGB image using the UV map?"
      },
      {
        "user": "abhaydoke09",
        "body": "@dStanhill No. I haven't been able to find the solution."
      },
      {
        "user": "bharatsingh430",
        "body": "23 is front and 24 is back"
      }
    ]
  },
  {
    "issue_number": 5410,
    "title": "Troubleshooting Memory Leaks in Video Detection Models",
    "author": "micedevai",
    "state": "open",
    "created_at": "2024-12-19T16:33:18Z",
    "updated_at": "2025-02-16T19:06:47Z",
    "labels": [],
    "body": "### Troubleshooting Memory Leaks in Video Detection Models\r\n\r\nWhile performing detection inference on a video, a memory leak is observed even after resource cleanup. During the inference process, memory usage increases over time, eventually causing the process to slow down, while the memory usage should ideally remain stable.\r\n\r\n#### Installations\r\nTo set up the necessary environment, run the following installation commands:\r\n\r\n```bash\r\n!python -m pip install pyyaml\r\n!pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\n!pip install opencv-python\r\n!pip install torch\r\n```\r\n\r\nThen, import the required libraries:\r\n```python\r\nimport cv2, os, numpy as np, tqdm, time, math, psutil, torch\r\nfrom collections import defaultdict\r\nfrom google.colab.patches import cv2_imshow\r\nfrom tqdm import tqdm\r\nfrom detectron2.utils.logger import setup_logger\r\nsetup_logger()\r\nfrom detectron2 import model_zoo\r\nfrom detectron2.engine import DefaultPredictor\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.utils.video_visualizer import VideoVisualizer\r\nfrom detectron2.utils.visualizer import ColorMode, Visualizer\r\nfrom detectron2.data import MetadataCatalog\r\n```\r\n\r\n#### Set Up Configuration and Initialize the Predictor\r\nConfigure the Detectron2 model for object detection:\r\n```python\r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\r\ncfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\npredictor = DefaultPredictor(cfg)\r\n```\r\n\r\n#### Open the Video and Initialize Video Writer\r\nSet up the video capture and writer for processing:\r\n```python\r\ncap = cv2.VideoCapture(\"/content/Input_Video.mp4\")\r\nfps = int(cap.get(cv2.CAP_PROP_FPS))\r\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\r\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\r\nvideo_writer = cv2.VideoWriter(\"/content/Output_Video.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\r\n```\r\n\r\n#### Process the Video\r\nProcess each frame of the video, run object detection, and draw bounding boxes:\r\n```python\r\nstart_time = time.time()\r\nframe_idx = 0\r\n\r\nwhile cap.isOpened():\r\n    success, frame = cap.read()\r\n    if not success: break\r\n\r\n    outputs = predictor(frame)\r\n    boxes = outputs[\"instances\"].to(\"cpu\").pred_boxes if outputs[\"instances\"].has(\"pred_boxes\") else None\r\n    if boxes:\r\n        for box in boxes:\r\n            x1, y1, x2, y2 = map(int, box.tolist())\r\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\r\n    video_writer.write(frame)\r\n    frame_idx += 1\r\n```\r\n\r\n#### Resource Cleanup\r\nEnsure proper cleanup after processing:\r\n```python\r\ncap.release()\r\nvideo_writer.release()\r\ncv2.destroyAllWindows()\r\n```\r\n\r\n#### Observed Behavior\r\nMemory usage is monitored before and after inference:\r\n```python\r\nmemory_before = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\r\n\r\n# Video Inference\r\n\r\nmemory_after = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\r\nprint(f\"Memory difference: {memory_after - memory_before:.2f} MB\")\r\n```\r\n\r\n**Output:**\r\n```\r\nMemory difference: 621.10 MB\r\n```\r\n\r\n#### Expected Behavior:\r\nFor a video detection task, memory usage should remain stable across frames of similar resolution. However, in this case, the memory usage steadily increases, which is indicative of a potential memory leak.\r\n\r\n#### Environment:\r\n- **Detectron2 version**: 0.6\r\n- **Python version**: 3.10.12\r\n- **OS**: Ubuntu 22.04\r\n- **GPU**: NVIDIA-SMI 535.104.05, CUDA 12.2",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "nikky4D",
        "body": "did you get this solved?"
      }
    ]
  },
  {
    "issue_number": 5435,
    "title": "Installation issue with 3080 Ti, GCC 9.3, CUDA 11.6",
    "author": "koren-v",
    "state": "open",
    "created_at": "2025-02-14T18:20:24Z",
    "updated_at": "2025-02-14T18:25:21Z",
    "labels": [],
    "body": "Hi, could you please help me to understand what is wrong with my environment? I spent a few days trying to install detectron2, and still facing this issue... üôèüôèüôè\n \n2. What exact command you run:\n```\npip install numpy==1.23.0\n\npip install torch==1.13.0+cu116 torchvision==0.14.0+cu116 -f https://download.pytorch.org/whl/torch_stable.html\n\npip install git+https://github.com/facebookresearch/detectron2.git\n```\n3. __Full logs__ or other relevant observations:\n```\nCollecting git+https://github.com/facebookresearch/detectron2.git\n  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-da2tsxr7\n  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-da2tsxr7\n  Resolved https://github.com/facebookresearch/detectron2.git to commit 9604f5995cc628619f0e4fd913453b4d7d61db3f\n  Preparing metadata (setup.py) ... done\nRequirement already satisfied: Pillow>=7.1 in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (11.1.0)\nRequirement already satisfied: black in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (25.1.0)\nRequirement already satisfied: cloudpickle in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (3.1.1)\nRequirement already satisfied: fvcore<0.1.6,>=0.1.5 in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (0.1.5.post20221221)\nRequirement already satisfied: hydra-core>=1.1 in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (1.3.2)\nRequirement already satisfied: iopath<0.1.10,>=0.1.7 in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (0.1.9)\nRequirement already satisfied: matplotlib in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (3.10.0)\nRequirement already satisfied: omegaconf<2.4,>=2.1 in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (2.3.0)\nRequirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (24.2)\nRequirement already satisfied: pycocotools>=2.0.2 in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (2.0.8)\nRequirement already satisfied: tabulate in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (0.9.0)\nRequirement already satisfied: tensorboard in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (2.19.0)\nRequirement already satisfied: termcolor>=1.1 in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (2.5.0)\nRequirement already satisfied: tqdm>4.29.0 in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (4.67.1)\nRequirement already satisfied: yacs>=0.1.8 in ./venv/lib/python3.10/site-packages (from detectron2==0.6) (0.1.8)\nRequirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\nRequirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.23.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in ./venv/lib/python3.10/site-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\nRequirement already satisfied: portalocker in ./venv/lib/python3.10/site-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (3.1.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.4.8)\nRequirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.3.1)\nRequirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\nRequirement already satisfied: cycler>=0.10 in ./venv/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (4.56.0)\nRequirement already satisfied: click>=8.0.0 in ./venv/lib/python3.10/site-packages (from black->detectron2==0.6) (8.1.8)\nRequirement already satisfied: platformdirs>=2 in ./venv/lib/python3.10/site-packages (from black->detectron2==0.6) (4.3.6)\nRequirement already satisfied: tomli>=1.1.0 in ./venv/lib/python3.10/site-packages (from black->detectron2==0.6) (2.2.1)\nRequirement already satisfied: mypy-extensions>=0.4.3 in ./venv/lib/python3.10/site-packages (from black->detectron2==0.6) (1.0.0)\nRequirement already satisfied: typing-extensions>=4.0.1 in ./venv/lib/python3.10/site-packages (from black->detectron2==0.6) (4.12.2)\nRequirement already satisfied: pathspec>=0.9.0 in ./venv/lib/python3.10/site-packages (from black->detectron2==0.6) (0.12.1)\nRequirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.1.3)\nRequirement already satisfied: absl-py>=0.4 in ./venv/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.1.0)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./venv/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (5.29.3)\nRequirement already satisfied: grpcio>=1.48.2 in ./venv/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.70.0)\nRequirement already satisfied: six>1.9 in ./venv/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.17.0)\nRequirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (59.6.0)\nRequirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (0.7.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\nBuilding wheels for collected packages: detectron2\n  Building wheel for detectron2 (setup.py) ... error\n  error: subprocess-exited-with-error\n  \n  √ó python setup.py bdist_wheel did not run successfully.\n  ‚îÇ exit code: 1\n  ‚ï∞‚îÄ> [508 lines of output]\n      running bdist_wheel\n      running build\n      running build_py\n      creating build\n      creating build/lib.linux-x86_64-3.10\n      creating build/lib.linux-x86_64-3.10/detectron2\n      copying detectron2/__init__.py -> build/lib.linux-x86_64-3.10/detectron2\n      creating build/lib.linux-x86_64-3.10/tools\n      copying tools/train_net.py -> build/lib.linux-x86_64-3.10/tools\n...\n      creating build/lib.linux-x86_64-3.10/detectron2/model_zoo/configs/common/data\n      copying detectron2/model_zoo/configs/common/data/coco_panoptic_separated.py -> build/lib.linux-x86_64-3.10/detectron2/model_zoo/configs/common/data\n      copying detectron2/model_zoo/configs/common/data/coco_keypoint.py -> build/lib.linux-x86_64-3.10/detectron2/model_zoo/configs/common/data\n      copying detectron2/model_zoo/configs/common/data/constants.py -> build/lib.linux-x86_64-3.10/detectron2/model_zoo/configs/common/data\n      copying detectron2/model_zoo/configs/common/data/coco.py -> build/lib.linux-x86_64-3.10/detectron2/model_zoo/configs/common/data\n      running build_ext\n      building 'detectron2._C' extension\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/ROIAlignRotated\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/box_iou_rotated\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/cocoeval\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable\n      creating /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/nms_rotated\n      Emitting ninja build file /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/build.ninja...\n      Compiling objects...\n      Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n      [1/11] /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/cuda_version.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/cuda_version.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      [2/11] c++ -MMD -MF /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/cocoeval/cocoeval.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/cocoeval/cocoeval.cpp -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/cocoeval/cocoeval.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n      [3/11] c++ -MMD -MF /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.cpp -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n      [4/11] c++ -MMD -MF /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n      [5/11] c++ -MMD -MF /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n      [6/11] /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      FAILED: /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o\n      /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      /usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‚Äò...‚Äô:\n        435 |         function(_Functor&& __f)\n            |                                                                                                                                                 ^\n      /usr/include/c++/11/bits/std_function.h:435:145: note:         ‚Äò_ArgTypes‚Äô\n      /usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‚Äò...‚Äô:\n        530 |         operator=(_Functor&& __f)\n            |                                                                                                                                                  ^\n      /usr/include/c++/11/bits/std_function.h:530:146: note:         ‚Äò_ArgTypes‚Äô\n      [7/11] /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      FAILED: /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o\n      /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      /usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‚Äò...‚Äô:\n        435 |         function(_Functor&& __f)\n            |                                                                                                                                                 ^\n      /usr/include/c++/11/bits/std_function.h:435:145: note:         ‚Äò_ArgTypes‚Äô\n      /usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‚Äò...‚Äô:\n        530 |         operator=(_Functor&& __f)\n            |                                                                                                                                                  ^\n      /usr/include/c++/11/bits/std_function.h:530:146: note:         ‚Äò_ArgTypes‚Äô\n      [8/11] /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      FAILED: /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o\n      /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      /usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‚Äò...‚Äô:\n        435 |         function(_Functor&& __f)\n            |                                                                                                                                                 ^\n      /usr/include/c++/11/bits/std_function.h:435:145: note:         ‚Äò_ArgTypes‚Äô\n      /usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‚Äò...‚Äô:\n        530 |         operator=(_Functor&& __f)\n            |                                                                                                                                                  ^\n      /usr/include/c++/11/bits/std_function.h:530:146: note:         ‚Äò_ArgTypes‚Äô\n      [9/11] /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable/deform_conv_cuda.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable/deform_conv_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      FAILED: /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable/deform_conv_cuda.o\n      /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable/deform_conv_cuda.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/deformable/deform_conv_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      /usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‚Äò...‚Äô:\n        435 |         function(_Functor&& __f)\n            |                                                                                                                                                 ^\n      /usr/include/c++/11/bits/std_function.h:435:145: note:         ‚Äò_ArgTypes‚Äô\n      /usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‚Äò...‚Äô:\n        530 |         operator=(_Functor&& __f)\n            |                                                                                                                                                  ^\n      /usr/include/c++/11/bits/std_function.h:530:146: note:         ‚Äò_ArgTypes‚Äô\n      [10/11] /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      FAILED: /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o\n      /usr/local/cuda-11.6/bin/nvcc  -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++14\n      /usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‚Äò...‚Äô:\n        435 |         function(_Functor&& __f)\n            |                                                                                                                                                 ^\n      /usr/include/c++/11/bits/std_function.h:435:145: note:         ‚Äò_ArgTypes‚Äô\n      /usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‚Äò...‚Äô:\n        530 |         operator=(_Functor&& __f)\n            |                                                                                                                                                  ^\n      /usr/include/c++/11/bits/std_function.h:530:146: note:         ‚Äò_ArgTypes‚Äô\n      [11/11] c++ -MMD -MF /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/vision.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/TH -I/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/home/vitaliy/learning/the-exceptional-trajectories/venv/include -I/usr/include/python3.10 -c -c /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/vision.cpp -o /tmp/pip-req-build-da2tsxr7/build/temp.linux-x86_64-3.10/tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n      In file included from /home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/Exceptions.h:13,\n                       from /home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/python.h:11,\n                       from /home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/torch/extension.h:6,\n                       from /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/vision.cpp:3:\n      /home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/pybind11/pybind11.h: In instantiation of ‚Äòclass pybind11::class_<detectron2::COCOeval::InstanceAnnotation>‚Äô:\n      /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/vision.cpp:105:73:   required from here\n      /home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/pybind11/pybind11.h:1479:7: warning: ‚Äòpybind11::class_<detectron2::COCOeval::InstanceAnnotation>‚Äô declared with greater visibility than its base ‚Äòpybind11::detail::generic_type‚Äô [-Wattributes]\n       1479 | class class_ : public detail::generic_type {\n            |       ^~~~~~\n      /home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/pybind11/pybind11.h: In instantiation of ‚Äòclass pybind11::class_<detectron2::COCOeval::ImageEvaluation>‚Äô:\n      /tmp/pip-req-build-da2tsxr7/detectron2/layers/csrc/vision.cpp:107:67:   required from here\n      /home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/include/pybind11/pybind11.h:1479:7: warning: ‚Äòpybind11::class_<detectron2::COCOeval::ImageEvaluation>‚Äô declared with greater visibility than its base ‚Äòpybind11::detail::generic_type‚Äô [-Wattributes]\n      ninja: build stopped: subcommand failed.\n      Traceback (most recent call last):\n        File \"/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1900, in _run_ninja_build\n          subprocess.run(\n        File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\n          raise CalledProcessError(retcode, process.args,\n      subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n      \n      The above exception was the direct cause of the following exception:\n      \n      Traceback (most recent call last):\n        File \"<string>\", line 2, in <module>\n        File \"<pip-setuptools-caller>\", line 34, in <module>\n        File \"/tmp/pip-req-build-da2tsxr7/setup.py\", line 151, in <module>\n          setup(\n        File \"/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/setuptools/__init__.py\", line 153, in setup\n          return distutils.core.setup(**attrs)\n        File \"/usr/lib/python3.10/distutils/core.py\", line 148, in setup\n          dist.run_commands()\n        File \"/usr/lib/python3.10/distutils/dist.py\", line 966, in run_commands\n          self.run_command(cmd)\n        File \"/usr/lib/python3.10/distutils/dist.py\", line 985, in run_command\n          cmd_obj.run()\n        File \"/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/wheel/_bdist_wheel.py\", line 387, in run\n          self.run_command(\"build\")\n        File \"/usr/lib/python3.10/distutils/cmd.py\", line 313, in run_command\n          self.distribution.run_command(command)\n        File \"/usr/lib/python3.10/distutils/dist.py\", line 985, in run_command\n          cmd_obj.run()\n        File \"/usr/lib/python3.10/distutils/command/build.py\", line 135, in run\n          self.run_command(cmd_name)\n        File \"/usr/lib/python3.10/distutils/cmd.py\", line 313, in run_command\n          self.distribution.run_command(command)\n        File \"/usr/lib/python3.10/distutils/dist.py\", line 985, in run_command\n          cmd_obj.run()\n        File \"/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/setuptools/command/build_ext.py\", line 79, in run\n          _build_ext.run(self)\n        File \"/usr/lib/python3.10/distutils/command/build_ext.py\", line 340, in run\n          self.build_extensions()\n        File \"/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 843, in build_extensions\n          build_ext.build_extensions(self)\n        File \"/usr/lib/python3.10/distutils/command/build_ext.py\", line 449, in build_extensions\n          self._build_extensions_serial()\n        File \"/usr/lib/python3.10/distutils/command/build_ext.py\", line 474, in _build_extensions_serial\n          self.build_extension(ext)\n        File \"/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/setuptools/command/build_ext.py\", line 202, in build_extension\n          _build_ext.build_extension(self, ext)\n        File \"/usr/lib/python3.10/distutils/command/build_ext.py\", line 529, in build_extension\n          objects = self.compiler.compile(sources,\n        File \"/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 658, in unix_wrap_ninja_compile\n          _write_ninja_file_and_compile_objects(\n        File \"/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1573, in _write_ninja_file_and_compile_objects\n          _run_ninja_build(\n        File \"/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1916, in _run_ninja_build\n          raise RuntimeError(message) from e\n      RuntimeError: Error compiling objects for extension\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\n  ERROR: Failed building wheel for detectron2\n  Running setup.py clean for detectron2\nFailed to build detectron2\nInstalling collected packages: detectron2\n  Running setup.py install for detectron2 ... error\n\n```\n\n## Expected behavior:\n\nSuccessful installation\n\n## Environment:\n\n```\n-------------------------------  ---------------------------------------------------------------------------------------------------------------\nsys.platform                     linux\nPython                           3.10.12 (main, Jan 17 2025, 14:35:34) [GCC 11.4.0]\nnumpy                            1.23.0\ndetectron2                       failed to import\ndetectron2._C                    not built correctly: No module named 'detectron2'\nCompiler ($CXX)                  c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\nCUDA compiler                    Build cuda_11.6.r11.6/compiler.30794723_0\nDETECTRON2_ENV_MODULE            <not set>\nPyTorch                          1.13.0+cu116 @/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torch\nPyTorch debug build              False\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\nGPU available                    Yes\nGPU 0                            NVIDIA GeForce RTX 3080 Ti (arch=8.6)\nDriver version                   535.183.01\nCUDA_HOME                        /usr/local/cuda-11.6\nPillow                           11.1.0\ntorchvision                      0.14.0+cu116 @/home/vitaliy/learning/the-exceptional-trajectories/venv/lib/python3.10/site-packages/torchvision\ntorchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\nfvcore                           0.1.5.post20221221\niopath                           0.1.9\ncv2                              Not found\n-------------------------------  ---------------------------------------------------------------------------------------------------------------\nPyTorch built with:\n  - GCC 9.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.6\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.3.2  (built against CUDA 11.5)\n  - Magma 2.6.1\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,\n```\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "koren-v",
        "body": "I have provided all commands to reproduce and Full Logs (I cut the huge part of `copying detectron2/ ... -> build/ ...` from traceback)"
      }
    ]
  },
  {
    "issue_number": 5010,
    "title": "`PIL.Image.LINEAR` no longer exists",
    "author": "ydshieh",
    "state": "closed",
    "created_at": "2023-07-03T07:35:48Z",
    "updated_at": "2025-02-14T02:07:15Z",
    "labels": [],
    "body": "`Pillow 10.0.0` is released on July 1. \r\n\r\nThe previous warning\r\n```\r\n`LINEAR` is deprecated and will be removed in Pillow 10 (2023-07-01). Use BILINEAR or Resampling.BILINEAR instead. \r\n```\r\nis now an exception.\r\n\r\nIn `detectron2`, there are still usage of `PIL.Image.LINEAR`, fro example, \r\n\r\n(https://github.com/facebookresearch/detectron2/blob/67ac149947124670f6678e1bdd75f89dbf0dd5e7/detectron2/data/transforms/transform.py#L46)\r\n\r\nIt would be great if such usage could be updated to avoid failure. Thank you üôè ",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "ydshieh",
        "body": "cc @ppwwyyxx\r\n"
      },
      {
        "user": "rayryeng",
        "body": "The latest commit to `master` (as of July 10, 2023) has now fixed this error and has corrected it to `Image.BILINEAR`. This should no longer be an issue now: https://github.com/facebookresearch/detectron2/commit/ff53992b1985b63bd3262b5a36167098e3dada02"
      }
    ]
  },
  {
    "issue_number": 4912,
    "title": "Is there any support for Swin Transformer based backbone for MaskRCNN? If anyone could help me out.",
    "author": "sushilkhadkaanon",
    "state": "open",
    "created_at": "2023-04-13T06:46:56Z",
    "updated_at": "2025-02-11T13:27:23Z",
    "labels": [
      "enhancement"
    ],
    "body": "I want to try Swin Backbone for MaskRCNN instance segmentation. If anyone has any article or blog, please drop the link.",
    "comments": [
      {
        "user": "GeorgePearse",
        "body": "This is implemented in MMDetection, but I've not managed to find it anywhere else, it's been my go to model for months. \n\nBut I'm now trying to leave MMDetection because all of the dependencies are getting very out of date."
      }
    ]
  },
  {
    "issue_number": 5432,
    "title": "About .onnx Detectron2 => executionProviders: ['wasm'] (Box: Ok, Masks: OK), executionProviders: ['webgpu'] (Box: Ok, Masks: NOK)",
    "author": "Greg7000",
    "state": "open",
    "created_at": "2025-02-07T13:54:51Z",
    "updated_at": "2025-02-07T20:19:40Z",
    "labels": [],
    "body": "When using a model based on  mask_rcnn_X_101_32x8d_FPN_3x.yaml converted to .onnx.\n _(I think it was that one, please note that I am facing the same issue with good old mask_rcnn_R_50_FPN_3x.yaml)_ \n\n- I can use it as expected in a onnxruntime-web/webgpu 'wasm' provider context. (All boxes OK, All masks OK)\n- I can partially use it in a onnxruntime-web/webgpu 'webgpu' provider context. (All boxes OK, **Only 1 mask OK**)\n\n## Instructions To Reproduce the Issue:\n\nThe .onnx model was generated  using commit (c69939aa85460e8135f40bce908a6cddaa73065f 21 Nov 2024)\n```\n        \"tools/deploy/export_model.py\",\n        \"--config-file\", \"my_conf.yml\",\n        \"--sample-image\", \"my_image.jpg\",\n        \"--output\", \"weight\",\n        \"--export-method\", \"tracing\",\n        \"--format\", \"onnx\",\n        \"MODEL.WEIGHTS\", \"my_model.pth\",\n        \"MODEL.DEVICE\", \"cuda\"\n```\n\nThen I used it with success (Boxes: ALL OK, Masks: All OK) on the FE with 'wasm':\n```\n\timport * as ort from 'onnxruntime-web/webgpu';\n\t...\n\tconst session = await ort.InferenceSession.create(MODEL_PATH, {\n\t\t\t\texecutionProviders: ['wasm'],\n\n\t});\n\t...\n\tconst feeds = { 'x.1': inputTensor };\n\tconst results = await session.run(feeds);\n\t...\n\tconst boxes = results['boxes.35'].data as Float32Array;\t\t\t\t//OK\n\tconst classes = results['value.3'].data as BigInt64Array;\t\t\t//OK\n\tconst masks = results['value.7'].data as Float32Array;\t\t\t\t//OK (36,1,28,28) \n\tconst scores = results['value'].data as Float32Array;\t\t\t\t//OK\n\t...\n```\n\nThen I used it with partial success   (Boxes: ALL OK, Masks: **Only 1 mask OK**) on the FE with 'webgpu':\n```\n\timport * as ort from 'onnxruntime-web/webgpu';\n\t...\n\tconst session = await ort.InferenceSession.create(MODEL_PATH, {\n\t\t\t\texecutionProviders: ['webgpu'],                           // <<<< THE ONLY CHANGE, SAME IMAGE, SAME CODE\n\n\t});\n\t...\n\tconst feeds = { 'x.1': inputTensor };\n\tconst results = await session.run(feeds);\n\t...\n\tconst boxes = results['boxes.35'].data as Float32Array;\t\t\t\t//OK\n\tconst classes = results['value.3'].data as BigInt64Array;\t\t\t//OK\n\tconst masks = results['value.7'].data as Float32Array;\t\t\t\t//Shape ok (36,1,28,28) but ONLY 1 MASK WORKS\n\tconst scores = results['value'].data as Float32Array;\t\t\t\t//OK\n\t...\n```\n\n\n3. __Full logs__ or other relevant observations:\n**CPU Validrun logs**\n```\nNohting clean log\n```\nMasks (reorganized output of results['value.7']) ALL GOOD: \n\n![Image](https://github.com/user-attachments/assets/9c105705-519c-460a-bf99-3a3e5e082ae1)\n\n**GPU problematic run logs**\n```\n2025-02-07 14:53:45.258599 [V:onnxruntime:Default, js_execution_provider.cc:735 JsExecutionProvider] Graph capture enable: 0\n2025-02-07 14:53:45.676399 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: ReduceProd_1505\n2025-02-07 14:53:45.677099 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/Gather_6\n2025-02-07 14:53:45.677500 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: Gather_1596\n2025-02-07 14:53:45.677799 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/Slice\n2025-02-07 14:53:45.678399 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/level_poolers.0/Gather_1\n2025-02-07 14:53:45.678899 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/Slice_1\n2025-02-07 14:53:45.679599 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/level_poolers.1/Gather_1\n2025-02-07 14:53:45.680399 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/Slice_2\n2025-02-07 14:53:45.681699 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/level_poolers.2/Gather_1\n2025-02-07 14:53:45.682699 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/Slice_3\n2025-02-07 14:53:45.683699 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/level_poolers.3/Gather_1\n2025-02-07 14:53:45.684699 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/Gather_5\n2025-02-07 14:53:45.685000 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/Gather_4\n2025-02-07 14:53:45.685699 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/Gather_7\n2025-02-07 14:53:45.686199 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: ReduceProd_1892\n2025-02-07 14:53:45.687000 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/Gather\n2025-02-07 14:53:45.687599 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: Gather_1993\n2025-02-07 14:53:45.688000 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/Slice\n2025-02-07 14:53:45.688500 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/level_poolers.0/Gather_1\n2025-02-07 14:53:45.688899 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/Slice_1\n2025-02-07 14:53:45.689199 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/level_poolers.1/Gather_1\n2025-02-07 14:53:45.689500 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/Slice_2\n2025-02-07 14:53:45.690699 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/level_poolers.2/Gather_1\n2025-02-07 14:53:45.691000 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/Slice_3\n2025-02-07 14:53:45.691500 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/level_poolers.3/Gather_1\n2025-02-07 14:53:45.692099 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_head/Gather_3\n2025-02-07 14:53:45.692599 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_head/Gather_1\n2025-02-07 14:53:45.692899 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_head/Gather_2\n2025-02-07 14:53:45.693299 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_head/Gather\n2025-02-07 14:53:45.693799 [I:onnxruntime:Default, fallback_cpu_capability.cc:162 GetCpuPreferredNodes] ORT optimization- Force fallback to CPU execution for node: /roi_heads/box_pooler/Shape_2 because the CPU execution path is deemed faster than overhead involved with execution on other EPs  capable of executing this node\n2025-02-07 14:53:45.694199 [I:onnxruntime:Default, fallback_cpu_capability.cc:162 GetCpuPreferredNodes] ORT optimization- Force fallback to CPU execution for node: /roi_heads/box_pooler/Shape_4 because the CPU execution path is deemed faster than overhead involved with execution on other EPs  capable of executing this node\n2025-02-07 14:53:45.694599 [I:onnxruntime:Default, fallback_cpu_capability.cc:162 GetCpuPreferredNodes] ORT optimization- Force fallback to CPU execution for node: /roi_heads/box_pooler/Shape_6 because the CPU execution path is deemed faster than overhead involved with execution on other EPs  capable of executing this node\n2025-02-07 14:53:45.695099 [I:onnxruntime:Default, fallback_cpu_capability.cc:162 GetCpuPreferredNodes] ORT optimization- Force fallback to CPU execution for node: /roi_heads/box_pooler/Shape_8 because the CPU execution path is deemed faster than overhead involved with execution on other EPs  capable of executing this node\n2025-02-07 14:53:45.695399 [I:onnxruntime:Default, fallback_cpu_capability.cc:162 GetCpuPreferredNodes] ORT optimization- Force fallback to CPU execution for node: /roi_heads/box_head/flatten/Flatten because the CPU execution path is deemed faster than overhead involved with execution on other EPs  capable of executing this node\n2025-02-07 14:53:45.695899 [I:onnxruntime:Default, fallback_cpu_capability.cc:162 GetCpuPreferredNodes] ORT optimization- Force fallback to CPU execution for node: /roi_heads/mask_pooler/Shape_2 because the CPU execution path is deemed faster than overhead involved with execution on other EPs  capable of executing this node\n2025-02-07 14:53:45.696299 [I:onnxruntime:Default, fallback_cpu_capability.cc:162 GetCpuPreferredNodes] ORT optimization- Force fallback to CPU execution for node: /roi_heads/mask_pooler/Shape_4 because the CPU execution path is deemed faster than overhead involved with execution on other EPs  capable of executing this node\n2025-02-07 14:53:45.696799 [I:onnxruntime:Default, fallback_cpu_capability.cc:162 GetCpuPreferredNodes] ORT optimization- Force fallback to CPU execution for node: /roi_heads/mask_pooler/Shape_6 because the CPU execution path is deemed faster than overhead involved with execution on other EPs  capable of executing this node\n2025-02-07 14:53:45.697099 [I:onnxruntime:Default, fallback_cpu_capability.cc:162 GetCpuPreferredNodes] ORT optimization- Force fallback to CPU execution for node: /roi_heads/mask_pooler/Shape_8 because the CPU execution path is deemed faster than overhead involved with execution on other EPs  capable of executing this node\n2025-02-07 14:53:45.726099 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/Slice\n2025-02-07 14:53:45.726699 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/Slice_1\n2025-02-07 14:53:45.730799 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/Slice_2\n2025-02-07 14:53:45.731199 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/box_pooler/Slice_3\n2025-02-07 14:53:45.731599 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/Slice\n2025-02-07 14:53:45.732099 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/Slice_1\n2025-02-07 14:53:45.732500 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/Slice_2\n2025-02-07 14:53:45.732899 [I:onnxruntime:Default, fallback_cpu_capability.cc:86 operator()] Candidate for fallback CPU execution: /roi_heads/mask_pooler/Slice_3\n2025-02-07 14:53:45.845099 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n2025-02-07 14:53:45.845699 [W:onnxruntime:, session_state.cc:1170 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n2025-02-07 14:53:46.198599 [V:onnxruntime:Default, conv_transpose.h:97 ConvTranspose] output_shape = {}\n\n2025-02-07 14:53:46.199399 [V:onnxruntime:Default, conv_transpose.h:98 ConvTranspose] output_padding = {}\n\n2025-02-07 14:53:46.237399 [V:onnxruntime:Default, js_export.cc:17 JsepOutput] JsepOutput(0, {3,1130,2260})\n2025-02-07 14:53:46.239399 [V:onnxruntime:Default, js_export.cc:22 JsepOutput] JsepOutput -- data=284\n2025-02-07 14:53:46.241799 [V:onnxruntime:Default, js_kernel.h:206 ComputeInternal] outputs = 1. Y.data=284.\n2025-02-07 14:53:46.242899 [V:onnxruntime:Default, js_export.cc:17 JsepOutput] JsepOutput(0, {3,1130,2260})\n2025-02-07 14:53:46.243599 [V:onnxruntime:Default, js_export.cc:22 JsepOutput] JsepOutput -- data=286\n2025-02-07 14:53:46.245000 [V:onnxruntime:Default, js_kernel.h:206 ComputeInternal] outputs = 1. Y.data=286.\n2025-02-07 14:53:46.246500 [V:onnxruntime:Default, js_export.cc:17 JsepOutput] JsepOutput(0, {3,1152,2272})\n2025-02-07 14:53:46.247399 [V:onnxruntime:Default, js_export.cc:22 JsepOutput] JsepOutput -- data=288\n2025-02-07 14:53:46.248500 [V:onnxruntime:Default, js_kernel.h:206 ComputeInternal] outputs = 1. Y.data=288.\n2025-02-07 14:53:46.250099 [V:onnxruntime:Default, js_export.cc:17 JsepOutput] JsepOutput(0, {1,1152,2272,3})\n...\n```\nMASKS NOK  (reorganized output of results['value.7']) , only 1 mask works (same code except executionProviders)\n![Image](https://github.com/user-attachments/assets/d2baf2dd-5a2e-4d32-a683-936f5ec384be)\n\n## Expected behavior:\n\nI expect to be able to get all masks when using the 'webgpu' execution provider\n\n## Environment:\n\n\n```\n-------------------------------  --------------------------------------------------------------------------------------------------------------------\nPyTorch built with:\n  - C++ Version: 199711\n  - MSVC 193431937\n  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n  - OpenMP 2019\n  - LAPACK is enabled (usually provided by MKL)\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.7\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 8.5\n  - Magma 2.5.4\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF,\n```\n\n\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      }
    ]
  },
  {
    "issue_number": 5152,
    "title": "Install error: ld: failed to set dynamic section sizes: bad value",
    "author": "fumin",
    "state": "closed",
    "created_at": "2023-11-16T11:00:04Z",
    "updated_at": "2025-02-02T09:03:37Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\nAbsolutely no changes, just a vanilla install.\r\n\r\n2. What exact command you run: `python -m pip install -e detectron2`\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n/usr/lib/python3/dist-packages/pythran/tables.py:4553: FutureWarning: In the future `np.bytes` will be defined as the corresponding NumPy scalar.\r\n      obj = getattr(themodule, elem)\r\n    error: Command \"x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/cuda_version.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/vision.o -L/home/topunion/.local/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.10/detectron2/_C.cpython-310-x86_64-linux-gnu.so\" failed with exit status 1\r\n    [end of output]\r\n```\r\nRunning the specific command above gives:\r\n```\r\n$ x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -fPIC -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/cuda_version.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/vision.o -L/home/topunion/.local/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.10/detectron2/_C.cpython-310-x86_64-linux-gnu.so\r\n/usr/bin/ld: build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o: relocation R_X86_64_TPOFF32 against hidden symbol `_ZZN8pybind116handle15inc_ref_counterEmE7counter' can not be used when making a shared object\r\n/usr/bin/ld: failed to set dynamic section sizes: bad value\r\ncollect2: error: ld returned 1 exit status\r\n```\r\n\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\nJust a simple clone of detectron2, change to the directory and run\r\n\r\n```\r\n86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -fPIC -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/cuda_version.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o build/temp.linux-x86_64-3.10/home/topunion/.local/lib/python3.10/site-packages/detectron2/detectron2/layers/csrc/vision.o -L/home/topunion/.local/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.10/detectron2/_C.cpython-310-x86_64-linux-gnu.so\r\n```\r\n\r\n## Expected behavior:\r\n\r\nExpecting the installation to succeed.\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\n$ wget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n-------------------------------  ----------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\r\nnumpy                            1.26.2\r\ndetectron2                       imported a wrong installation\r\ndetectron2._C                    not built correctly: No module named 'detectron2._C'\r\nCompiler ($CXX)                  c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\r\nCUDA compiler                    Build cuda_11.8.r11.8/compiler.31833905_0\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.1.1+cu118 @/home/topunion/.local/lib/python3.10/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0                            NVIDIA GeForce RTX 3060 (arch=8.6)\r\nDriver version                   545.23.06\r\nCUDA_HOME                        /usr/local/cuda\r\nPillow                           9.0.1\r\ntorchvision                      0.16.1+cu118 @/home/topunion/.local/lib/python3.10/site-packages/torchvision\r\ntorchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.8.1\r\n-------------------------------  ----------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201703\r\n  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 11.8\r\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90\r\n  - CuDNN 8.7\r\n  - Magma 2.6.1\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n\r\n\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first try to solve it yourself with the instructions in\r\nhttps://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n",
    "comments": []
  },
  {
    "issue_number": 4505,
    "title": "How can you use a Transformer model as a backbone? No documentation available",
    "author": "deshwalmahesh",
    "state": "open",
    "created_at": "2022-08-28T05:45:11Z",
    "updated_at": "2025-02-01T19:09:20Z",
    "labels": [
      "enhancement"
    ],
    "body": "Hey,\r\nJust wanted to know that how could you use a pre-trained Transformer model for object detection? I want to use [Microsoft's DiT](https://github.com/microsoft/unilm/tree/master/dit/object_detection). Seems like they have used it with `Detectron2` but no clear steps have been described. Can you please let me know about where can I find the blog / tutorial / documentation on how to fine tune that transformer architecture to use it as a detection backbone with `Faster RCNN` / `Cascade RCNN`.\r\n\r\nThanks in advance :)",
    "comments": [
      {
        "user": "ZawarK7",
        "body": "Hey, \r\nit has been a long time. Have you implemented the transformer backbone? I am currently using ViT with Faster R-CNN. Let me know if you have implemented it or if you need any help."
      },
      {
        "user": "ae1028",
        "body": "> Hey, it has been a long time. Have you implemented the transformer backbone? I am currently using ViT with Faster R-CNN. Let me know if you have implemented it or if you need any help.\n\nHey. Have you completed your code? I couldn't find anything related to using ViT with Fast RCNN in your account."
      },
      {
        "user": "ZawarK7",
        "body": "Yeah,  I have completed the code. Drop your email, and I will share it with you."
      }
    ]
  },
  {
    "issue_number": 5247,
    "title": "Detectron2 Keypoints detection slowness issue",
    "author": "AswinkumarGitHub",
    "state": "closed",
    "created_at": "2024-03-29T06:33:32Z",
    "updated_at": "2025-01-31T02:05:52Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Hey ,\r\nI have been using Detectron2 keypoints detection for 2 months , I got some promising results but it takes upto 70% - 90% of my 8 GB Nvidia P4000 GPU. And when I incorporated with other models like yolov8 along with the detectron2 and while loading the model all together it takes up 100% of my GPU. I have gone through online still am facing same issue.\r\n\r\nI was using R50-FPN - 1x for Detectron2 keypoints detection the lowest model.\r\n\r\nHow to make the detectron2 use less GPU ?\r\n\r\nPlease provide a support .Advice if any config or feature available to reduce this slowness.\r\n\r\nAlso share if anyone gone through the same issue.\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5431,
    "title": "export_model.py ONNX gives a model that does not work",
    "author": "enislalmi",
    "state": "open",
    "created_at": "2025-01-30T13:32:47Z",
    "updated_at": "2025-01-30T13:48:32Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\n1. Full runnable code or full changes you made:\nNo changes.\n\n2. What exact command you run:\npython detectron2/tools/deploy/export_model.py --config-file Detectron2/detectron2/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml --output ./output --export-method tracing  --format onnx --sample-image image_1.bmp MODEL.DEVICE cuda MODEL.WEIGHTS Detectron2/output_object_detection/model_final.pth\n3. __Full logs__ or other relevant observations:```\nTracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[01/30 14:29:26 detectron2]: Inputs schema: TupleSchema(schemas=[ListSchema(schemas=[DictSchema(schemas=[IdentitySchema()], sizes=[1], keys=['image'])], sizes=[1])], sizes=[1])\n[01/30 14:29:26 detectron2]: Outputs schema: ListSchema(schemas=[DictSchema(schemas=[InstancesSchema(schemas=[TensorWrapSchema(class_name='detectron2.structures.Boxes'), IdentitySchema(), IdentitySchema()], sizes=[1, 1, 1], keys=['pred_boxes', 'pred_classes', 'scores'])], sizes=[4], keys=['instances'])], sizes=[4])\n[01/30 14:29:26 detectron2]: Success.\n\n4. please simplify the steps as much as possible so they do not require additional resources to\n\n\n## Expected behavior:\nAfter running the conversion command to ONNX, to have a ONNX that is able to find the same boxes as the .pt does per the same image. The ONNX does not find any boxes.\n\n\n## Environment:\nEverything has been done following this:\nhttps://colab.research.google.com/github/mashyko/object_detection/blob/master/Detectron2_Tutorial.ipynb ",
    "comments": [
      {
        "user": "enislalmi",
        "body": "@thiagocrepaldi I also followed your tutorial, pr and open issues, any idea?"
      }
    ]
  },
  {
    "issue_number": 4260,
    "title": "Repeated training not deterministic despite identical setup and reproducibility flags",
    "author": "j-rausch",
    "state": "open",
    "created_at": "2022-05-23T14:28:34Z",
    "updated_at": "2025-01-22T18:47:49Z",
    "labels": [],
    "body": "Hi, I'm working on an experiment where I noticed large differences between models trained with identical configs and random seeds. I'm trying to understand the causes for this.\r\n\r\nI've upgraded to a more recent PyTorch version that introduced flags for deterministic training between multiple executions:\r\nhttps://pytorch.org/docs/1.11/notes/randomness.html?highlight=reproducibility\r\n\r\nHowever, despite using these flags and the most recent detectron2 sources, the final trained models and their validation accuracies can differ greatly on a custom dataset set of mine (~2 AP).\r\nThese differences occur in multiple runs on the same machine (identical device, code, config, random seed).\r\n\r\nI've been looking into reproducing this problem and also observe this for the unaltered detectron2 demo training code. I've added a minimal script to reproduce the training and observe rather big differences between the first logged losses of three subsequent runs.\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\n1. Full runnable code or full changes you made:\r\nscript to reproduce the experiment (`deterministic_example.py`)\r\n```\r\nimport os\r\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\r\nimport torch\r\ntorch.backends.cudnn.deterministic = True\r\ntorch.backends.cudnn.benchmark = False\r\ntorch.use_deterministic_algorithms(True)\r\n\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.engine import DefaultTrainer, default_argument_parser, default_setup, launch\r\n\r\n\r\n\r\ndef setup(args):\r\n    \"\"\"\r\n    Create configs and perform basic setups.\r\n    \"\"\"\r\n    cfg = get_cfg()\r\n    cfg.merge_from_file(args.config_file)\r\n    cfg.merge_from_list(args.opts)\r\n    cfg.freeze()\r\n    default_setup(cfg, args)\r\n    return cfg\r\n\r\ndef main(args):\r\n\r\n    cfg = setup(args)\r\n\r\n    trainer = DefaultTrainer(cfg)\r\n    trainer.resume_or_load(resume=False)\r\n    return trainer.train()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    args = default_argument_parser().parse_args()\r\n    print(\"Command Line Args:\", args)\r\n    launch(\r\n        main,\r\n        args.num_gpus,\r\n        num_machines=args.num_machines,\r\n        machine_rank=args.machine_rank,\r\n        dist_url=args.dist_url,\r\n        args=(args,),\r\n    )\r\n```\r\n```\r\ngit rev-parse HEAD; git diff\r\ne091a07ef573915056f8c2191b774aad0e38d09c\r\n```\r\n2. What exact command you run:\r\n```\r\nCUDA_VISIBLE_DEVICES=0 python deterministic_example.py --num-gpus 1 --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml SOLVER.IMS_PER_BATCH 1 SEED 42 DATALOADER.NUM_WORKERS 1\r\n```\r\n\r\n3. __Full logs__ or other relevant observations:\r\n```\r\nCommand Line Args: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:53650', opts=['SOLVER.IMS_PER_BATCH', '1', 'SEED', '42', 'DATALOADER.NUM_WORKERS', '1'])\r\n[05/23 15:49:06 detectron2]: Rank of current process: 0. World size: 1\r\n[05/23 15:49:08 detectron2]: Environment info:\r\n----------------------  --------------------------------------------------------------------------------------------------------------------------\r\nsys.platform            linux\r\nPython                  3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:39:04) [GCC 10.3.0]\r\nnumpy                   1.22.3\r\ndetectron2              0.6 @/rootpath/git/detectron2/detectron2\r\nCompiler                GCC 9.3\r\nCUDA compiler           CUDA 11.5\r\ndetectron2 arch flags   6.1\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.11.0+cu115 @/rootpath/anaconda3/envs/sgg_torch111_detectron06/lib/python3.10/site-packages/torch\r\nPyTorch debug build     False\r\nGPU available           Yes\r\nGPU 0                   NVIDIA TITAN Xp (arch=6.1)\r\nDriver version          510.47.03\r\nCUDA_HOME               /usr/local/cuda-11.5\r\nPillow                  9.1.0\r\ntorchvision             0.12.0+cu115 @/rootpath/anaconda3/envs/sgg_torch111_detectron06/lib/python3.10/site-packages/torchvision\r\ntorchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\r\nfvcore                  0.1.5.post20220504\r\niopath                  0.1.9\r\ncv2                     4.5.5\r\n----------------------  --------------------------------------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 11.5\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\r\n  - CuDNN 8.3.2\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.5, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,\r\n\r\n[05/23 15:49:08 detectron2]: Command line arguments: Namespace(config_file='./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:53650', opts=['SOLVER.IMS_PER_BATCH', '1', 'SEED', '42', 'DATALOADER.NUM_WORKERS', '1'])\r\n[05/23 15:49:08 detectron2]: Contents of args.config_file=./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:\r\n_BASE_: \"../Base-RCNN-FPN.yaml\"\r\nMODEL:\r\n  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\r\n  MASK_ON: True\r\n  RESNETS:\r\n    DEPTH: 50\r\n\r\n\r\n  FILTER_EMPTY_ANNOTATIONS: true\r\n  NUM_WORKERS: 1\r\n  REPEAT_THRESHOLD: 0.0\r\n  SAMPLER_TRAIN: TrainingSampler\r\nDATASETS:\r\n  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\r\n  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\r\n  PROPOSAL_FILES_TEST: []\r\n  PROPOSAL_FILES_TRAIN: []\r\n  TEST:\r\n  - coco_2017_val\r\n  TRAIN:\r\n  - coco_2017_train\r\nGLOBAL:\r\n  HACK: 1.0\r\nINPUT:\r\n  CROP:\r\n    ENABLED: false\r\n    SIZE:\r\n    - 0.9\r\n    - 0.9\r\n    TYPE: relative_range\r\n  FORMAT: BGR\r\n  MASK_FORMAT: polygon\r\n  MAX_SIZE_TEST: 1333\r\n  MAX_SIZE_TRAIN: 1333\r\n  MIN_SIZE_TEST: 800\r\n  MIN_SIZE_TRAIN:\r\n  - 640\r\n  - 672\r\n  - 704\r\n  - 736\r\n  - 768\r\n  - 800\r\n  MIN_SIZE_TRAIN_SAMPLING: choice\r\n  RANDOM_FLIP: horizontal\r\nMODEL:\r\n  ANCHOR_GENERATOR:\r\n    ANGLES:\r\n    - - -90\r\n      - 0\r\n      - 90\r\n    ASPECT_RATIOS:\r\n    - - 0.5\r\n      - 1.0\r\n      - 2.0\r\n    NAME\r\n    OFFSET: 0.0\r\n    SIZES:\r\n    - - 32\r\n    - - 64\r\n    - - 128\r\n    - - 256\r\n    - - 512\r\n  BACKBONE:\r\n    FREEZE_AT: 2\r\n    NAME: build_resnet_fpn_backbone\r\n  DEVICE: cuda\r\n  FPN:\r\n    FUSE_TYPE: sum\r\n    IN_FEATURES:\r\n    - res2\r\n    - res3\r\n    - res4\r\n    - res5\r\n    NORM: ''\r\n    OUT_CHANNELS: 256\r\n  KEYPOINT_ON: false\r\n  LOAD_PROPOSALS: false\r\n  MASK_ON: true\r\n  META_ARCHITECTURE: GeneralizedRCNN\r\n  PANOPTIC_FPN:\r\n    COMBINE:\r\n      ENABLED: true\r\n      INSTANCES_CONFIDENCE_THRESH: 0.5\r\n      OVERLAP_THRESH: 0.5\r\n      STUFF_AREA_LIMIT: 4096\r\n    INSTANCE_LOSS_WEIGHT: 1.0\r\n  PIXEL_MEAN:\r\n  - 103.53\r\n  - 116.28\r\n  - 123.675\r\n  PIXEL_STD:\r\n  - 1.0\r\n  - 1.0\r\n  - 1.0\r\n  PROPOSAL_GENERATOR:\r\n    MIN_SIZE: 0\r\n    NAME: RPN\r\n  RESNETS:\r\n    DEFORM_MODULATED: false\r\n    DEFORM_NUM_GROUPS: 1\r\n    DEFORM_ON_PER_STAGE:\r\n    -\r\n    - false\r\n    DEPTH: 50\r\n    NORM: FrozenBN\r\n    NUM_GROUPS: 1\r\n    OUT_FEATURES:\r\n    - res2\r\n    - res3\r\n    - res4\r\n    - res5\r\n    RES2_OUT_CHANNELS: 256\r\n    RES5_DILATION: 1\r\n    STEM_OUT_CHANNELS: 64\r\n    STRIDE_IN_1X1: true\r\n    WIDTH_PER_GROUP: 64\r\n  RETINANET:\r\n    BBOX_REG_LOSS_TYPE: smooth_l1\r\n    BBOX_REG_WEIGHTS: &id002\r\n    - 1.0\r\n    - 1.0\r\n    - 1.0\r\n    - 1.0\r\n    FOCAL_LOSS_ALPHA: 0.25\r\n    FOCAL_LOSS_GAMMA: 2.0\r\n    IN_FEATURES:\r\n    - p3\r\n    - p4\r\n    - p5\r\n    - p6\r\n    - p7\r\n    IOU_LABELS:\r\n    - 0\r\n    - -1\r\n    - 1\r\n    IOU_THRESHOLDS:\r\n    - 0.4\r\n    - 0.5\r\n    NMS_THRESH_TEST: 0.5\r\n    NORM: ''\r\n    NUM_CLASSES: 80\r\n    NUM_CONVS: 4\r\n    PRIOR_PROB: 0.01\r\n    SCORE_THRESH_TEST: 0.05\r\n    SMOOTH_L1_LOSS_BETA: 0.1\r\n    TOPK_CANDIDATES_TEST: 1000\r\n  ROI_BOX_CASCADE_HEAD:\r\n    BBOX_REG_WEIGHTS:\r\n    - &id\r\n      - 10.0\r\n      - 5.0\r\n      - 5.0\r\n    - - 20.0\r\n      - 20.0\r\n      - 10.0\r\n      - 10.0\r\n    - - 30.0\r\n      - 30.0\r\n      - 15.0\r\n      - 15.0\r\n    IOUS:\r\n    - 0.5\r\n    - 0.6\r\n    - 0.7\r\n  ROI_BOX_HEAD:\r\n    BBOX_REG_LOSS_TYPE: smooth_l1\r\n    BBOX_REG_LOSS_WEIGHT: 1.0\r\n    BBOX_REG_WEIGHTS: *id001\r\n    CLS_AGNOSTIC_BBOX_REG: false\r\n    CONV_DIM: 256\r\n    FC_DIM: 1024\r\n    FED_LOSS_FREQ_WEIGHT_POWER: 0.5\r\n    FED_LOSS_NUM_CLASSES: 50\r\n    NAME: FastRCNNConvFCHead\r\n    NORM: ''\r\n    NUM_CONV: 0\r\n    NUM_FC: 2\r\n    POOLER_RESOLUTION: 7\r\n    POOLER_SAMPLING_RATIO: 0\r\n    POOLER_TYPE: ROIAlignV2\r\n    SMOOTH_L1_BETA: 0.0\r\n    TRAIN_ON_PRED_BOXES: false\r\n    USE_FED_LOSS: false\r\n    USE_SIGMOID_CE: false\r\n  ROI_HEADS:\r\n    BATCH_SIZE_PER_IMAGE: 512\r\n    IN_FEATURES:\r\n    - p2\r\n    - p3\r\n    - p4\r\n    - p5\r\n    IOU_LABELS:\r\n    - 0\r\n    - 1\r\n    IOU_THRESHOLDS:\r\n    - 0.5\r\n    NAME: StandardROIHeads\r\n    NMS_THRESH_TEST: 0.5\r\n    NUM_CLASSES: 80\r\n    POSITIVE_FRACTION: 0.25\r\n    PROPOSAL_APPEND_GT: true\r\n    SCORE_THRESH_TEST: 0.05\r\n  ROI_KEYPOINT_HEAD:\r\n    CONV_DIMS:\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    LOSS_WEIGHT: 1.0\r\n    MIN_KEYPOINTS_PER_IMAGE: 1\r\n    NAME: KRCNNConvDeconvUpsampleHead\r\n    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true\r\n    NUM_KEYPOINTS: 17\r\n    POOLER_RESOLUTION: 14\r\n    POOLER_SAMPLING_RATIO: 0\r\n    POOLER_TYPE: ROIAlignV2\r\n  ROI_MASK_HEAD:\r\n    CLS_AGNOSTIC_MASK: false\r\n    CONV_DIM: 256\r\n    NAME: MaskRCNNConvUpsampleHead\r\n    NORM: ''\r\n    NUM_CONV: 4\r\n    POOLER_RESOLUTION: 14\r\n    POOLER_SAMPLING_RATIO: 0\r\n    POOLER_TYPE: ROIAlignV2\r\n  RPN:\r\n    BATCH_SIZE_PER_IMAGE: 256\r\n    BBOX_REG_LOSS_TYPE: smooth_l1\r\n    BBOX_REG_LOSS_WEIGHT: 1.0\r\n    BBOX_REG_WEIGHTS: *id002\r\n    BOUNDARY_THRESH: -1\r\n    CONV_DIMS:\r\n    - -1\r\n    HEAD_NAME: StandardRPNHead\r\n    IN_FEATURES:\r\n    -\r\n    - p4\r\n    - p5\r\n    - p6\r\n    IOU_LABELS:\r\n    - 0\r\n    - -1\r\n    - 1\r\n    IOU_THRESHOLDS:\r\n    - 0.3\r\n    - 0.7\r\n    LOSS_WEIGHT: 1.0\r\n    NMS_THRESH: 0.7\r\n    POSITIVE_FRACTION: 0.5\r\n    POST_NMS_TOPK_TEST: 1000\r\n    POST_NMS_TOPK_TRAIN: 1000\r\n    PRE_NMS_TOPK_TEST: 1000\r\n    PRE_NMS_TOPK_TRAIN: 2000\r\n    SMOOTH_L1_BETA: 0.0\r\n  SEM_SEG_HEAD:\r\n    COMMON_STRIDE: 4\r\n    CONVS_DIM: 128\r\n    IGNORE_VALUE: 255\r\n    IN_FEATURES:\r\n    - p2\r\n    - p3\r\n    - p4\r\n    - p5\r\n    LOSS_WEIGHT: 1.0\r\n    NAME: SemSegFPNHead\r\n    NORM: GN\r\n    NUM_CLASSES: 54\r\n  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl\r\nOUTPUT_DIR: ./output\r\nSEED: 42\r\nSOLVER:\r\n  AMP:\r\n    ENABLED: false\r\n  BASE_LR: 0.02\r\n  BASE_LR_END: 0.0\r\n  BIAS_LR_FACTOR: 1.0\r\n  CHECKPOINT_PERIOD: 5000\r\n  CLIP_GRADIENTS:\r\n    CLIP_TYPE: value\r\n    CLIP_VALUE: 1.0\r\n    ENABLED: false\r\n    NORM_TYPE: 2.0\r\n  GAMMA: 0.1\r\n  IMS_PER_BATCH: 1\r\n  LR_SCHEDULER_NAME: WarmupMultiStepLR\r\n  MAX_ITER: 90000\r\n  MOMENTUM: 0.9\r\n  NESTEROV: false\r\n  REFERENCE_WORLD_SIZE: 0\r\n  STEPS:\r\n  - 60000\r\n  - 80000\r\n  WARMUP_FACTOR: 0.001\r\n  WARMUP_ITERS: 1000\r\n  WARMUP_METHOD: linear\r\n  WEIGHT_DECAY: 0.0001\r\n  WEIGHT_DECAY_BIAS: null\r\n  WEIGHT_DECAY_NORM: 0.0\r\nTEST:\r\n  AUG:\r\n    ENABLED: false\r\n    FLIP: true\r\n    MAX_SIZE: 4000\r\n    MIN_SIZES:\r\n    - 400\r\n    - 500\r\n    - 600\r\n    - 700\r\n    - 800\r\n    - 900\r\n    - 1000\r\n    - 1100\r\n    - 1200\r\n  DETECTIONS_PER_IMAGE: 100\r\n  EVAL_PERIOD: 0\r\n  EXPECTED_RESULTS: []\r\n  KEYPOINT_OKS_SIGMAS: []\r\n  PRECISE_BN:\r\n    ENABLED: false\r\n    NUM_ITER: 200\r\nVERSION: 2\r\nVIS_PERIOD: 0\r\n\r\n[05/23 15:49:08 detectron2]: Full config saved to ./output/config.yaml\r\n\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res3): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (4): BottleneckBl\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n    )\r\n  )\r\n  (proposal_generator): RPN(\r\n    (rpn_head): StandardRPNHead(\r\n      (conv): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n    (anchor_generator): DefaultAnchorGenerator(\r\n      (cell_anchors): BufferList()\r\n    )\r\n  )\r\n  (roi_heads): StandardROIHeads(\r\n    (box_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (box_head): FastRCNNConvFCHead(\r\n      (flatten): Flatten(start_dim=1, end_dim=-1)\r\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\r\n      (fc_relu1): ReLU()\r\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\r\n      (fc_relu2): ReLU()\r\n    )\r\n    (box_predictor): FastRCNNOutputLayers(\r\n      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\r\n      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\r\n    )\r\n    (mask_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (mask_head): MaskRCNNConvUpsampleHead(\r\n      (mask_fcn1): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn2): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn3): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn4): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\r\n      (deconv_relu): ReLU()\r\n      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n  )\r\n)\r\n[05/23 15:49:30 d2.data.datasets.coco]: Loading datasets/coco/annotations/instances_train2017.json takes 18.03 seconds.\r\n[05/23 15:49:31 d2.data.datasets.coco]: Loaded 118287 images in COCO format from datasets/coco/annotations/instances_train2017.json\r\n[05/23 15:49:37 d2.data.build]: Removed 1021 images with no usable annotations. 117266 images left.\r\n[05/23 15:49:43 d2.data.build]: Distribution of instances among all 80 categories:\r\n|   category    | #instances   |   category   | #instances   |   category    | #instances   |\r\n|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\r\n|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |\r\n|  motorcycle   | 8654         |   airplane   | 5129         |      bus      | 6061         |\r\n|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |\r\n| traffic light | 12842        | fire hydrant | 1865         |   stop sign   | 1983         |\r\n| parking meter | 1283         |    bench     | 9820         |     bird      | 10542        |\r\n|      cat      | 4766         |     dog      | 5500         |     horse     | 6567         |\r\n|     sheep     | 9223         |     cow      | 8014         |   elephant    | 5484         |\r\n|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |\r\n|   backpack    | 8714         |   umbrella   | 11265        |    handbag    | 12342        |\r\n|      tie      | 6448         |   suitcase   | 6112         |    frisbee    | 2681         |\r\n|     skis      | 6623         |  snowboard   | 2681         |  sports ball  | 6299         |\r\n|     kite      | 8802         | baseball bat | 3273         | baseball gl.. | 3747         |\r\n|  skateboard   | 5536         |  surfboard   | 6095         | tennis racket | 4807         |\r\n|    bottle     | 24070        |  wine glass  | 7839         |      cup      | 20574        |\r\n|     fork      | 5474         |    knife     | 7760         |     spoon     | 6159         |\r\n|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |\r\n|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |\r\n|    carrot     | 7758         |   hot dog    | 2884         |     pizza     | 5807         |\r\n|     donut     | 7005         |     cake     | 6296         |     chair     | 38073        |\r\n|     couch     | 5779         | potted plant | 8631         |      bed      | 4192         |\r\n| dining table  | 15695        |    toilet    | 4149         |      tv       | 5803         |\r\n|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |\r\n|   keyboard    | 2854         |  cell phone  | 6422         |   microwave   | 1672         |\r\n|     oven      | 3334         |   toaster    | 225          |     sink      | 5609         |\r\n| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |\r\n|     vase      | 6577         |   scissors   | 1464         |  teddy bear   | 4729         |\r\n|  hair drier   | 198          |  toothbrush  | 1945         |               |              |\r\n|     total     | 849949       |              |              |               |              |\r\n[05/23 15:49:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\r\n[05/23 15:49:43 d2.data.build]: Using training sampler TrainingSampler\r\n[05/23 15:49:43 d2.data.common]: Serializing 117266 elements to byte tensors and concatenating them all ...\r\n[05/23 15:49:47 d2.data.common]: Serialized dataset takes 451.21 MiB\r\n[05/23 15:50:04 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...\r\n[05/23 15:50:04 d2.checkpoint.c2_model_loading]: Renaming Caffe2 weights ......\r\n[05/23 15:50:04 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.bottom_up:\r\n| Names in Model    | Names in Checkpoint      | Shapes                                          |\r\n|:------------------|:-------------------------|:------------------------------------------------|\r\n| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |\r\n| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\r\n| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\r\n| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\r\n| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\r\n| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\r\n| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |\r\n| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |\r\n| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\r\n| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\r\n| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\r\n| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |\r\n| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\r\n| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\nproposal_generator.rpn_head.anchor_deltas.{bias, weight}\r\nproposal_generator.rpn_head.conv.{bias, weight}\r\nproposal_generator.rpn_head.objectness_logits.{bias, weight}\r\nroi_heads.box_head.fc1.{bias, weight}\r\nroi_heads.box_head.fc2.{bias, weight}\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\nroi_heads.mask_head.deconv.{bias, weight}\r\nroi_heads.mask_head.mask_fcn1.{bias, weight}\r\nroi_heads.mask_head.mask_fcn2.{bias, weight}\r\nroi_heads.mask_head.mask_fcn3.{bias, weight}\r\nroi_heads.mask_head.mask_fcn4.{bias, weight}\r\nroi_heads.mask_head.predictor.{bias, weight}\r\nWARNING [05/23 15:50:04 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:\r\n  fc1000.{bias, weight}\r\n  stem.conv1.bias\r\n[05/23 15:50:04 d2.engine.train_loop]: Starting training from iteration 0\r\n/rootpath/anaconda3/envs/sgg_torch111_detectron06/lib/python3.10/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the index\r\nbackbone.fpn_output2.{bias, weight}\r\nbackbone.fpn_output3.{bias, weight}\r\nbackbone.fpn_output4.{bias, weight}\r\nbackbone.fpn_output5.{bias, weight}\r\nproposal_generator.rpn_head.anchor_deltas.{bias, weight}\r\nproposal_generator.rpn_head.conv.{bias, weight}\r\nproposal_generator.rpn_head.objectness_logits.{bias, weight}\r\nroi_heads.box_head.fc1.{bias, weight}\r\nroi_heads.box_head.fc2.{bias, weight}\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\nroi_heads.mask_head.deconv.{bias, weight}\r\nroi_heads.mask_head.mask_fcn1.{bias, weight}\r\nroi_heads.mask_head.mask_fcn2.{bias, weight}\r\nroi_heads.mask_head.mask_fcn3.{bias, weight}\r\nroi_heads.mask_head.mask_fcn4.{bias, weight}\r\nroi_heads.mask_head.predictor.{bias, weight}\r\nWARNING [05/23 15:50:04 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:\r\n  fc1000.{bias, weight}\r\n  stem.conv1.bias\r\n[05/23 15:50:04 d2.engine.train_loop]: Starting training from iteration 0\r\n/rootpath/anaconda3/envs/sgg_torch111_detectron06/lib/python3.10/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\r\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n[05/23 15:50:12 d2.utils.events]:  eta: 7:44:48  iter: 19  total_loss: 2.345  loss_cls: 0.5814  loss_box_reg: 0.01275  loss_mask: 0.6936  loss_rpn_cls: 0.6719  loss_rpn_loc: 0.0908  time: 0.3151  data_time: 0.0139  lr: 0.00039962  max_mem: 1481M\r\n[05/23 15:50:19 d2.utils.events]:  eta: 8:08:10  iter: 39  total_loss: 1.601  loss_cls: 0.4312  loss_box_reg: 0.04747  loss_mask: 0.6906  loss_rpn_cls: 0.4376  loss_rpn_loc: 0.0764  time: 0.3254  data_time: 0.0026  lr: 0.00079922  max_mem: 1481M\r\n[05/23 15:50:26 d2.utils.events]:  eta: 8:17:54  iter: 59  total_loss: 1.641  loss_cls: 0.4153  loss_box_reg: 0.09799  loss_mask: 0.691  loss_rpn_cls: 0.3649  loss_rpn_loc: 0.1253  time: 0.3259  data_time: 0.0028  lr: 0.0011988  max_mem: 1481M\r\n[05/23 15:50:32 d2.utils.events]:  eta: 8:20:12  iter: 79  total_loss: 1.439  loss_cls: 0.3282  loss_box_reg: 0.09175  loss_mask: 0.6924  loss_rpn_cls: 0.2477  loss_rpn_loc: 0.05234  time: 0.3288  data_time: 0.0027  lr: 0.0015984  max_mem: 1481M\r\n[05/23 15:50:39 d2.utils.events]:  eta: 8:20:06  iter: 99  total_loss: 1.285  loss_cls: 0.2667  loss_box_reg: 0.1191  loss_mask: 0.6891  loss_rpn_cls: 0.154  loss_rpn_loc: 0.05424  time: 0.3274  data_time: 0.0025  lr: 0.001998  max_mem: 1481M\r\n[05/23 15:50:45 d2.utils.events]:  eta: 8:15:39  iter: 119  total_loss: 1.52  loss_cls: 0.346  loss_box_reg: 0.1504  loss_mask: 0.6818  loss_rpn_cls: 0.2181  loss_rpn_loc: 0.09391  time: 0.3256  data_time: 0.0025  lr: 0.0023976  max_mem: 1481M\r\n[05/23 15:50:51 d2.utils.events]:  eta: 8:12:57  iter: 139  total_loss: 1.546  loss_cls: 0.2511  loss_box_reg: 0.1242  loss_mask: 0.6869  loss_rpn_cls: 0.2738  loss_rpn_loc: 0.04643  time: 0.3242  data_time: 0.0027  lr: 0.0027972  max_mem: 1481M\r\n[05/23 15:50:58 d2.utils.events]:  eta: 8:12:51  iter: 159  total_loss: 1.687  loss_cls: 0.3452  loss_box_reg: 0.09927  loss_mask: 0.6778  loss_rpn_cls: 0.2546  loss_rpn_loc: 0.1271  time: 0.3253  data_time: 0.0028  lr: 0.0031968  max_mem: 1481M\r\n[05/23 15:51:05 d2.utils.events]:  eta: 8:15:19  iter: 179  total_loss: 1.557  loss_cls: 0.4099  loss_box_reg: 0.1837  loss_mask: 0.6872  loss_rpn_cls: 0.1388  loss_rpn_loc: 0.06568  time: 0.3271  data_time: 0.0027  lr: 0.0035964  max_mem: 1481M\r\n[05/23 15:51:12 d2.utils.events]:  eta: 8:16:06  iter: 199  total_loss: 1.931  loss_cls: 0.5021  loss_box_reg: 0.2378  loss_mask: 0.6843  loss_rpn_cls: 0.2495  loss_rpn_loc: 0.1568  time: 0.3284  data_time: 0.0035  lr: 0.003996  max_mem: 1481M\r\n```\r\n\r\nrun2:\r\n```\r\n[05/23 15:52:57 d2.utils.events]:  eta: 7:49:54  iter: 19  total_loss: 2.349  loss_cls: 0.5801  loss_box_reg: 0.01275  loss_mask: 0.6936  loss_rpn_cls: 0.6719  loss_rpn_loc: 0.09081  time: 0.3190  data_time: 0.0176  lr: 0.00039962  max_mem: 1481M\r\n[05/23 15:53:04 d2.utils.events]:  eta: 8:10:18  iter: 39  total_loss: 1.603  loss_cls: 0.4004  loss_box_reg: 0.04758  loss_mask: 0.6906  loss_rpn_cls: 0.4404  loss_rpn_loc: 0.07629  time: 0.3276  data_time: 0.0025  lr: 0.00079922  max_mem: 1481M\r\n[05/23 15:53:10 d2.utils.events]:  eta: 8:19:58  iter: 59  total_loss: 1.646  loss_cls: 0.4176  loss_box_reg: 0.1167  loss_mask: 0.6912  loss_rpn_cls: 0.3633  loss_rpn_loc: 0.1252  time: 0.3274  data_time: 0.0026  lr: 0.0011988  max_mem: 1481M\r\n[05/23 15:53:17 d2.utils.events]:  eta: 8:21:51  iter: 79  total_loss: 1.428  loss_cls: 0.299  loss_box_reg: 0.0902  loss_mask: 0.6921  loss_rpn_cls: 0.2449  loss_rpn_loc: 0.05256  time: 0.3296  data_time: 0.0026  lr: 0.0015984  max_mem: 1481M\r\n[05/23 15:53:23 d2.utils.events]:  eta: 8:21:44  iter: 99  total_loss: 1.319  loss_cls: 0.2876  loss_box_reg: 0.1062  loss_mask: 0.6898  loss_rpn_cls: 0.1512  loss_rpn_loc: 0.05531  time: 0.3289  data_time: 0.0027  lr: 0.001998  max_mem: 1481M\r\n[05/23 15:53:30 d2.utils.events]:  eta: 8:17:13  iter: 119  total_loss: 1.441  loss_cls: 0.28  loss_box_reg: 0.1317  loss_mask: 0.6835  loss_rpn_cls: 0.2149  loss_rpn_loc: 0.09209  time: 0.3274  data_time: 0.0025  lr: 0.0023976  max_mem: 1481M\r\n[05/23 15:53:36 d2.utils.events]:  eta: 8:15:03  iter: 139  total_loss: 1.496  loss_cls: 0.272  loss_box_reg: 0.1103  loss_mask: 0.6876  loss_rpn_cls: 0.2564  loss_rpn_loc: 0.04832  time: 0.3262  data_time: 0.0025  lr: 0.0027972  max_mem: 1481M\r\n[05/23 15:53:43 d2.utils.events]:  eta: 8:14:56  iter: 159  total_loss: 1.737  loss_cls: 0.3486  loss_box_reg: 0.06897  loss_mask: 0.678  loss_rpn_cls: 0.2603  loss_rpn_loc: 0.1359  time: 0.3266  data_time: 0.0025  lr: 0.0031968  max_mem: 1481M\r\n[05/23 15:53:49 d2.utils.events]:  eta: 8:16:21  iter: 179  total_loss: 1.525  loss_cls: 0.3834  loss_box_reg: 0.1672  loss_mask: 0.6877  loss_rpn_cls: 0.1623  loss_rpn_loc: 0.08118  time: 0.3272  data_time: 0.0026  lr: 0.0035964  max_mem: 1481M\r\n[05/23 15:53:56 d2.utils.events]:  eta: 8:16:14  iter: 199  total_loss: 1.598  loss_cls: 0.3331  loss_box_reg: 0.1141  loss_mask: 0.6792  loss_rpn_cls: 0.2563  loss_rpn_loc: 0.1831  time: 0.3270  data_time: 0.0026  lr: 0.003996  max_mem: 1481M\r\n```\r\n\r\nrun3:\r\n```\r\n[05/23 15:56:10 d2.utils.events]:  eta: 7:45:39  iter: 19  total_loss: 2.348  loss_cls: 0.5763  loss_box_reg: 0.01275  loss_mask: 0.6936  loss_rpn_cls: 0.6719  loss_rpn_loc: 0.0908  time: 0.3167  data_time: 0.0122  lr: 0.00039962  max_mem: 1481M\r\n[05/23 15:56:16 d2.utils.events]:  eta: 8:10:26  iter: 39  total_loss: 1.605  loss_cls: 0.3891  loss_box_reg: 0.04755  loss_mask: 0.6906  loss_rpn_cls: 0.4403  loss_rpn_loc: 0.07635  time: 0.3277  data_time: 0.0027  lr: 0.00079922  max_mem: 1481M\r\n[05/23 15:56:23 d2.utils.events]:  eta: 8:23:04  iter: 59  total_loss: 1.679  loss_cls: 0.4163  loss_box_reg: 0.1102  loss_mask: 0.6912  loss_rpn_cls: 0.3563  loss_rpn_loc: 0.1251  time: 0.3293  data_time: 0.0031  lr: 0.0011988  max_mem: 1481M\r\n[05/23 15:56:30 d2.utils.events]:  eta: 8:21:28  iter: 79  total_loss: 1.433  loss_cls: 0.3133  loss_box_reg: 0.07978  loss_mask: 0.6921  loss_rpn_cls: 0.2468  loss_rpn_loc: 0.05257  time: 0.3303  data_time: 0.0028  lr: 0.0015984  max_mem: 1481M\r\n[05/23 15:56:36 d2.utils.events]:  eta: 8:22:50  iter: 99  total_loss: 1.317  loss_cls: 0.2764  loss_box_reg: 0.1469  loss_mask: 0.6895  loss_rpn_cls: 0.1487  loss_rpn_loc: 0.05474  time: 0.3291  data_time: 0.0027  lr: 0.001998  max_mem: 1481M\r\n[05/23 15:56:43 d2.utils.events]:  eta: 8:20:03  iter: 119  total_loss: 1.455  loss_cls: 0.3264  loss_box_reg: 0.1456  loss_mask: 0.6827  loss_rpn_cls: 0.209  loss_rpn_loc: 0.09486  time: 0.3281  data_time: 0.0030  lr: 0.0023976  max_mem: 1481M\r\n[05/23 15:56:49 d2.utils.events]:  eta: 8:16:57  iter: 139  total_loss: 1.475  loss_cls: 0.2835  loss_box_reg: 0.09706  loss_mask: 0.6861  loss_rpn_cls: 0.2541  loss_rpn_loc: 0.04725  time: 0.3260  data_time: 0.0027  lr: 0.0027972  max_mem: 1481M\r\n[05/23 15:56:56 d2.utils.events]:  eta: 8:18:19  iter: 159  total_loss: 1.675  loss_cls: 0.3287  loss_box_reg: 0.1219  loss_mask: 0.6776  loss_rpn_cls: 0.2344  loss_rpn_loc: 0.1299  time: 0.3269  data_time: 0.0028  lr: 0.0031968  max_mem: 1481M\r\n[05/23 15:57:02 d2.utils.events]:  eta: 8:19:43  iter: 179  total_loss: 1.568  loss_cls: 0.4459  loss_box_reg: 0.1866  loss_mask: 0.6875  loss_rpn_cls: 0.124  loss_rpn_loc: 0.06825  time: 0.3279  data_time: 0.0027  lr: 0.0035964  max_mem: 1481M\r\n[05/23 15:57:09 d2.utils.events]:  eta: 8:19:37  iter: 199  total_loss: 1.803  loss_cls: 0.4938  loss_box_reg: 0.1835  loss_mask: 0.6884  loss_rpn_cls: 0.2585  loss_rpn_loc: 0.1701  time: 0.3281  data_time: 0.0029  lr: 0.003996  max_mem: 1481M\r\n```\r\n## Expected behavior:\r\n\r\nI would expect the losses to be (largely) identical in the default training setup, when using identical machine/code/random seed/config and PyTorch flags for deterministic training.\r\n\r\n\r\n\r\n",
    "comments": [
      {
        "user": "jhindel",
        "body": "I am facing a very similar issue. Did you find a reason for this behaviour and have any suggestions how to fix it?"
      },
      {
        "user": "j-rausch",
        "body": "I'm still facing the issue. Without having debugged this in more detail and just looking at the losses of the three runs, `loss_cls` appears to differ the most at the beginning of the training.\r\n\r\nThere have been other issues that have been closed in the past (e.g. https://github.com/facebookresearch/detectron2/issues/2480\r\n), pointing to PyTorch's non-determinism. Perhaps revisiting them with the new deterministic training flags in PyTorch could give new pointers.\r\n"
      },
      {
        "user": "j-rausch",
        "body": "Are there any news or advice on possible reasons for this issue?"
      }
    ]
  },
  {
    "issue_number": 5425,
    "title": "Concerns in Pascal Context GT Visualization.",
    "author": "loveyou143j",
    "state": "closed",
    "created_at": "2025-01-09T14:23:27Z",
    "updated_at": "2025-01-17T02:05:18Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": " it‚Äôs important to first clarify what \"Pascal Context GT\" refers to, as this could be related to a specific software tool, context, or implementation. Assuming you're dealing with some form of graphical visualization within a Pascal programming environment or using a specific visualization tool (like a GUI or graphics library), I can help you troubleshoot general visualization issues.\r\n\r\nHere are a few common problems and solutions when it comes to visualization tools in Pascal (or Pascal-like environments) and possible approaches to fixing them:\r\n\r\n### 1. **Incorrect Rendering or Clipping Issues**\r\n   - **Cause:** This could happen if the rendering window or canvas is not being properly updated or if objects are drawn outside the bounds of the visible area.\r\n   - **Solution:** Make sure that your canvas or drawing area is initialized properly. If you're working with custom coordinates or scaling factors, double-check that your drawing logic respects the window or viewport boundaries. Additionally, ensure that objects are rendered in the correct order, especially in cases of overlapping elements.\r\n   - **Example Fix:**\r\n     ```pascal\r\n     procedure DrawGraphics;\r\n     begin\r\n         // Set up drawing area bounds\r\n         SetViewport(0, 0, 640, 480, Clip);\r\n         // Redraw content properly, ensuring everything fits in the window\r\n         DrawSomeObject;\r\n     end;\r\n     ```\r\n\r\n### 2. **Color and Pixel Rendering Problems**\r\n   - **Cause:** Sometimes the wrong color settings or pixel formats can cause rendering to appear incorrect. This could be due to incorrect color palette settings, incorrect use of `RGB` or `BGR` values, or improper handling of pixel formats in image buffers.\r\n   - **Solution:** Ensure that you're using the right color formats for your output device. For example, if you're working with an image or pixel buffer, make sure the pixel format matches the expected one for the display context.\r\n   - **Example Fix:**\r\n     ```pascal\r\n     procedure SetPixelColor(X, Y: Integer; Color: TColor);\r\n     begin\r\n         // Ensure you are setting the pixel correctly in the right format\r\n         PutPixel(X, Y, Color);\r\n     end;\r\n     ```\r\n\r\n### 3. **Performance Issues in Visualization**\r\n   - **Cause:** High computational cost or inefficient rendering methods could lead to lag or poor performance.\r\n   - **Solution:** Optimize the code to minimize unnecessary redraws or use double buffering if your environment supports it. This can reduce flickering and improve responsiveness.\r\n   - **Example Fix:**\r\n     ```pascal\r\n     procedure DrawGraphics;\r\n     begin\r\n         // Use double buffering to optimize rendering\r\n         StartDrawingOnOffscreenBuffer;\r\n         DrawScene;\r\n         EndDrawingOnOffscreenBuffer;\r\n         DisplayBufferOnScreen;\r\n     end;\r\n     ```\r\n\r\n### 4. **Memory Leaks or Resource Management Problems**\r\n   - **Cause:** Improper resource handling or failing to release memory after usage may lead to memory leaks.\r\n   - **Solution:** Always release resources like images, buffers, and contexts when they are no longer needed.\r\n   - **Example Fix:**\r\n     ```pascal\r\n     procedure CleanupResources;\r\n     begin\r\n         FreeMem(GraphicBuffer);\r\n         ReleaseDrawingContext;\r\n     end;\r\n     ```\r\n\r\n### 5. **Incorrect Handling of Input or Interactivity**\r\n   - **Cause:** If the program is interactive (such as handling user input like mouse clicks or key presses for visualization), incorrect event handling or failure to capture events could cause issues.\r\n   - **Solution:** Ensure proper event handling and make sure that input events are being processed correctly. If working with libraries like `SDL` or `OpenGL`, ensure that input events are captured and managed in the event loop.\r\n   - **Example Fix:**\r\n     ```pascal\r\n     procedure HandleUserInput;\r\n     begin\r\n         if MouseClicked then\r\n         begin\r\n             ProcessClickAt(MouseX, MouseY);\r\n         end;\r\n     end;\r\n     ```\r\n\r\n### 6. **Misconfigured Libraries or Dependencies**\r\n   - **Cause:** If you're using third-party libraries (e.g., for graphics or GUI) and they are misconfigured, you may encounter rendering issues, crashes, or errors.\r\n   - **Solution:** Double-check that you‚Äôve correctly linked the libraries and configured any environment-specific settings. Sometimes, an incorrect path or missing dependencies can cause unexpected behavior. If using a GUI library like **Lazarus**, verify your project settings and dependencies.\r\n   \r\n### 7. **Debugging Tools:**\r\n   - Use debugging tools like **Pascal debuggers** (e.g., `GDB` for Free Pascal, or built-in debugging tools in IDEs like Lazarus) to check for any runtime issues.\r\n   - Use logging to track down errors:\r\n     ```pascal\r\n     procedure LogError(Message: string);\r\n     begin\r\n         WriteLn('Error: ', Message);\r\n     end;\r\n     ```\r\n\r\n### Key Tips for Effective Debugging:\r\n\r\n- **Isolate the Issue:** Break down your code and test each component (e.g., rendering, event handling, resource management) individually.\r\n- **Logging and Debugging:** Use print statements or logging to output variables and track execution flow, helping you identify where things go wrong.\r\n- **Check Memory Management:** Ensure that memory and resources are being allocated and freed properly.\r\n- **Test on Different Platforms/Compilers:** If you‚Äôre working in an IDE like Lazarus, test your application on different environments or with different compiler settings to isolate platform-specific issues.\r\n\r\n### Conclusion\r\nFor issues with **Pascal Context GT Visualization**, it's crucial to check the following areas:\r\n- **Rendering Logic:** Ensure everything is drawn within the bounds and in the correct order.\r\n- **Color and Pixel Handling:** Use proper color formats and palettes.\r\n- **Performance and Optimization:** Implement techniques like double buffering to improve performance.\r\n- **Event Handling and Input:** Ensure user input is processed correctly.\r\n\r\nIf you're using a specific tool or framework (e.g., **Lazarus**, **SDL**, **OpenGL**), knowing more about the context and libraries in use will help refine the troubleshooting steps further.",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5237,
    "title": "Adjusting Model Confidence Level",
    "author": "Rahul6903",
    "state": "closed",
    "created_at": "2024-03-12T04:27:17Z",
    "updated_at": "2025-01-14T02:05:06Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "import sys\r\nsys.path.append(\"unilm\")\r\nsys.path.append(\"detectron2\")\r\nimport cv2\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom unilm.dit.object_detection.ditod import add_vit_config\r\nimport torch\r\n\r\nfrom detectron2.config import CfgNode as CN\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.utils.visualizer import ColorMode, Visualizer\r\nfrom detectron2.data import MetadataCatalog\r\nfrom detectron2.engine import DefaultPredictor\r\n\r\nimport gradio as gr\r\n# Step 1: instantiate config\r\ncfg = get_cfg()\r\nadd_vit_config(cfg)\r\ncfg.merge_from_file(\"cascade_dit_base.yml\")\r\n# Step 2: add model weights URL to config\r\ncfg.MODEL.WEIGHTS = \"publaynet_dit-b_cascade.pth\"\r\n# Step 3: set device\r\ncfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n# Step 4: define model\r\npredictor = DefaultPredictor(cfg)\r\n\r\n\r\nimport json\r\nimport pdfplumber\r\n\r\ndef extract_text_from_pdf_with_coordinates(pdf_path, page_number, x_min, y_min, x_max, y_max):\r\n    with pdfplumber.open(pdf_path) as pdf:\r\n        page = pdf.pages[page_number - 1]  # Adjust for 0-based indexing\r\n        content = \"\"\r\n        page_width = page.width\r\n        page_height = page.height\r\n        \r\n        # Check if the coordinates fall within the page bounds\r\n        if x_min < 0 or y_min < 0 or x_max > page_width or y_max > page_height:\r\n            raise ValueError(\"Coordinates are outside the page bounds\")\r\n            \r\n        # Extract text from the specified coordinates\r\n        text = page.crop((x_min, y_min, x_max, y_max)).extract_text()\r\n        content += text.strip() + \"\\n\"\r\n    return content\r\n\r\n\r\npdf_path = \"/Users/infx012941/Desktop/AI/pdf/AIM_chest-imaging.pdf\"\r\npage_number = 6\r\n\r\n\r\ndef analyze_image(img):\r\n    md = MetadataCatalog.get(cfg.DATASETS.TEST[0])\r\n    if cfg.DATASETS.TEST[0] == 'icdar2019_test':\r\n        md.set(thing_classes=[\"table\"])\r\n    else:\r\n        md.set(thing_classes=[\"text\", \"title\", \"list\", \"table\", \"figure\"])\r\n\r\n    output = predictor(img)[\"instances\"]\r\n    v = Visualizer(img[:, :, ::-1],\r\n                   md,\r\n                   scale=1.0,\r\n                   instance_mode=ColorMode.SEGMENTATION)\r\n    result = v.draw_instance_predictions(output.to(\"cpu\"))\r\n    result_image = result.get_image()[:, :, ::-1]\r\n\r\n    bbox_data = []\r\n\r\n    # Plot each bounding box\r\n    for i, bbox in enumerate(output.pred_boxes.tensor):\r\n        x_min, y_min, x_max, y_max = bbox.cpu().numpy().tolist()  # Convert float32 to Python float\r\n        width = x_max - x_min\r\n        height = y_max - y_min\r\n        class_label = md.thing_classes[output.pred_classes[i]]\r\n        bbox_data.append({\r\n            \"class_name\": class_label,\r\n            \"coordinates\": {\r\n                \"x_min\": x_min,\r\n                \"y_min\": y_min,\r\n                \"x_max\": x_max,\r\n                \"y_max\": y_max\r\n            },\r\n            \"contents\": extract_text_from_pdf_with_coordinates(pdf_path, page_number, x_min, y_min, x_max, y_max)\r\n        })\r\n\r\n    # Convert bounding box data to JSON\r\n    json_data = json.dumps(bbox_data, indent=4)\r\n    file_path = \"pdf_output.json\"\r\n    with open(file_path, \"w\") as json_file:\r\n        json_file.write(json_data)\r\n\r\n    # Plot the image\r\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\r\n\r\n    # Plot each bounding box\r\n    for bbox in bbox_data:\r\n        coordinates = bbox[\"coordinates\"]\r\n        class_label = bbox[\"class_name\"]\r\n        x_min, y_min, x_max, y_max = coordinates[\"x_min\"], coordinates[\"y_min\"], coordinates[\"x_max\"], coordinates[\"y_max\"]\r\n        plt.text(x_min, y_min - 2, class_label, fontsize=8, color='r')\r\n        rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\r\n        plt.gca().add_patch(rect)\r\n\r\n    plt.axis('off')  # Turn off axis\r\n    plt.show()\r\n    # Close the plot to prevent the warning\r\n    plt.close()\r\n    return result_image\r\n\r\n\r\n    \r\ntitle = \"Interactive demo: Document Layout Analysis with DiT\"\r\n# description = \"Demo for Microsoft's DiT, the Document Image Transformer for state-of-the-art document understanding tasks. This particular model is fine-tuned on PubLayNet, a large dataset for document layout analysis (read more at the links below). To use it, simply upload an image or use the example image below and click 'Submit'. Results will show up in a few seconds. If you want to make the output bigger, right-click on it and select 'Open image in new tab'.\"\r\n# article = \"<p style='text-align: center'><a href='https://arxiv.org/abs/2203.02378' target='_blank'>Paper</a> | <a href='https://github.com/microsoft/unilm/tree/master/dit' target='_blank'>Github Repo</a></p> | <a href='https://huggingface.co/docs/transformers/master/en/model_doc/dit' target='_blank'>HuggingFace doc</a></p>\"\r\n# examples =[['publaynet_example.jpeg']]\r\ncss = \".output-image, .input-image, .image-preview {height: 600px !important}\"\r\n\r\niface = gr.Interface(fn=analyze_image, \r\n                     inputs=gr.Image(type=\"numpy\", label=\"document image\"), \r\n                     outputs=gr.Image(type=\"numpy\", label=\"annotated document\"),\r\n                     title=title,\r\n                     css=css)\r\nobj=iface.launch(debug=True)\r\n\r\n\r\n\r\n\r\n\r\n\r\nit's possible to adjust a model's confidence level because i unable to obtain the complete labeled coordinates along with the corresponding text",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 4940,
    "title": "when I run export_model.py  get  KeyError: 'Non-existent config key: MODEL.FCOS', why?",
    "author": "fxooooooooo",
    "state": "closed",
    "created_at": "2023-05-09T13:03:36Z",
    "updated_at": "2025-01-09T02:25:01Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\n```\r\nIf making changes to the project itself, please use output of the following command:\r\ngit rev-parse HEAD; git diff\r\n\r\n<put code or diff here>\r\n```\r\n2. What exact command you run:\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n<put logs here>\r\n```\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\n## Expected behavior:\r\n\r\nIf there are no obvious error in \"full logs\" provided above,\r\nplease tell us the expected behavior.\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first try to solve it yourself with the instructions in\r\nhttps://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      },
      {
        "user": "anthonyweidai",
        "body": "Same problem"
      }
    ]
  },
  {
    "issue_number": 5422,
    "title": "Issues in Pascal Context GT Visualization",
    "author": "russellward2025",
    "state": "open",
    "created_at": "2025-01-08T11:18:03Z",
    "updated_at": "2025-01-08T11:18:03Z",
    "labels": [],
    "body": "Steps to Reproduce the Bug:\r\n\r\n1. Full runnable code or changes made:  \r\n   Refer to the failed pull request: #5391\r\n\r\n2. Exact command run:  \r\n   I executed `tools/visualize_data` and noticed that `visualize.py` in the `utils` folder uses an outdated numpy dtype.\r\n\r\n3. Logs or relevant observations:  \r\n   The image should correspond to train(id: 359), but there is an overflow issue, referencing fly(id: 359-256 = 103) instead.\r\n\r\n**Expected Behavior:**  \r\nIt should handle classes greater than 256, but Pascal Context 459 results in an overflow.\r\n\r\n**Environment:**  \r\n- Python 3.10  \r\n- NumPy 1.22.4  \r\n- PyTorch 1.13.1",
    "comments": []
  },
  {
    "issue_number": 5420,
    "title": "Panoptic Quality Metrics (PQ): Unexpected PQ value during model evaluation.",
    "author": "Skywalker83",
    "state": "open",
    "created_at": "2025-01-06T02:57:02Z",
    "updated_at": "2025-01-06T06:11:34Z",
    "labels": [],
    "body": "I'm using a custom dataset (fine-tuning) for the panoptic task using R101-FPN as COCO Panoptic Segmentation baseline (Panoptic FPN).\r\n\r\nBoth training and inferencing are able to obtain good result. However, when I perform model evaluation I got the following result:\r\n\r\nPanoptic Evaluation Results:\r\n| | PQ | SQ | RQ | #categories |\r\n|:------:|:-------:|:-------:|:------:|:-------------:|\r\n| All | 669.439 | 785.069 | 68.472 | 71 |\r\n| Things | 51.593 | 75.233 | 66.680 | 2 |\r\n| Stuff | 687.348 | 805.644 | 68.524 | 69 |\r\n\r\nEvaluation metrics: \r\n{\r\n'PQ': np.float64(669.4392318591345), \r\n'SQ': np.float64(785.0691309166493), \r\n'RQ': 68.47162219667933,\r\n'PQ_th': np.float64(51.592946379865104), \r\n'SQ_th': np.float64(75.23326285684394), \r\n'RQ_th': 66.68010678527925,\r\n'PQ_st': np.float64(687.3478198440408), \r\n'SQ_st': np.float64(805.6440836140348), \r\n'RQ_st': 68.52355017961847\r\n}\r\n\r\nI'm not sure why SQ_st is in the hundreds range which I believe it causes PQ to be in hundreds range too. Would appreciate help if anyone could point out any possible issues. Thanks.\r\n\r\n## Instructions To Reproduce the Issue:\r\nUnable to provide data to reproduce the issue.\r\n\r\n## Source code:\r\n\r\nself._cfg.merge_from_file(self._trained_config_path)\r\nself._predictor = DefaultPredictor(self._cfg)\r\nself._initialize_datasets()\r\n\r\nevaluator = COCOPanopticEvaluator(\r\n    dataset_name=eval_dataset_name,\r\n    output_dir=self._output_dir,\r\n)\r\nval_loader = build_detection_test_loader(self._cfg, eval_dataset_name)\r\n\r\nresults = inference_on_dataset(self._predictor.model, val_loader, evaluator)\r\n\r\n\r\n## Environment:\r\n-------------------------------  ---------------------------------------------------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.12.7 (main, Oct 16 2024, 04:37:19) [Clang 18.1.8 ]\r\nnumpy                            1.26.4\r\ndetectron2                       0.6 @/pvc-data/workspaces/xxx/xxx/.venv/lib/python3.12/site-packages/detectron2\r\nCompiler                         clang 18.1.3\r\nCUDA compiler                    not available\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.5.1+cu124 @/pvc-data/workspaces/xxx/xxx/.venv/lib/python3.12/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    No: torch.cuda.is_available() == False\r\nPillow                           11.0.0\r\ntorchvision                      0.20.1+cu124 @/pvc-data/workspaces/xxx/xxx/.venv/lib/python3.12/site-packages/torchvision\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.10.0\r\n-------------------------------  ---------------------------------------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201703\r\n  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      }
    ]
  },
  {
    "issue_number": 5417,
    "title": "My code has an issue identifying the search space in grid search.",
    "author": "jobmart",
    "state": "closed",
    "created_at": "2024-12-27T08:54:31Z",
    "updated_at": "2025-01-04T02:06:23Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "\"I am working on the backend code of my Jupyter Notebook, and I'm encountering an issue when running the model. Here's the code:\r\n`# Imports\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom scipy import stats\r\n\r\n# Sklearn\r\nfrom sklearn.metrics import r2_score\r\nfrom ML.ml_utils import *\r\nfrom sklearn.model_selection import train_test_split\r\n\r\n# FNN\r\nimport tensorflow as tf\r\nimport keras_tuner as kt\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\r\nfrom tensorflow.keras.optimizers import SGD, Adam\r\nfrom tensorflow.keras.callbacks import EarlyStopping\r\nfrom keras_tuner import HyperParameters\r\nfrom keras_tuner import Objective\r\nfrom keras_tuner.tuners import GridSearch, RandomSearch\r\nfrom your_module import create_model\r\n\r\n# FeedForwardNN and related classes\r\nclass FeedForwardNN(tf.keras.Model):\r\n    def __init__(self, input_dim=None, random_seed=42):\r\n        super(FeedForwardNN, self).__init__()\r\n        self.seed = random_seed\r\n        self.input_dim = 2048\r\n        self.model = self.build_model()\r\n\r\n    def build_model(self, hp=None):\r\n        if hp is None:\r\n            hp = kt.HyperParameters()\r\n        tf.random.set_seed(self.seed)\r\n\r\n        # Define hyperparameters\r\n        optimizer_c = hp.Choice(\"optimizer\", ['SGD', 'Adam'])\r\n        learning_rate = hp.Float(\"learning_rate\", min_value=0.00001, max_value=0.1, sampling='log')\r\n        l2_reg = hp.Float(\"l2_reg\", min_value=0.0001, max_value=0.1, sampling='log')\r\n        dropout_rate = hp.Float(\"dropout_rate\", min_value=0, max_value=0.5, step=0.1)\r\n        output_dim = hp.Fixed(\"output_dim\", value=1)\r\n\r\n        model = tf.keras.Sequential()\r\n        model.add(tf.keras.layers.Input(shape=(self.input_dim,)))\r\n        model.add(tf.keras.layers.Dense(units=hp.Int(\"units_1\", min_value=32, max_value=256, step=32),\r\n                                        activation='relu',\r\n                                        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)))\r\n\r\n        for i in range(hp.Int(\"num_layers\", 1, 3)):\r\n            model.add(tf.keras.layers.Dense(units=hp.Int(f\"units_{i}\", min_value=32, max_value=256, step=32),\r\n                                            activation='relu',\r\n                                            kernel_regularizer=tf.keras.regularizers.l2(l2_reg)))\r\n\r\n        if optimizer_c == \"SGD\":\r\n            optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\r\n        elif optimizer_c == \"Adam\":\r\n            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\r\n        else:\r\n            raise ValueError(\"Unsupported optimizer\")\r\n\r\n        model.add(tf.keras.layers.Dropout(dropout_rate))\r\n        model.add(tf.keras.layers.Dense(output_dim, activation='linear'))\r\n\r\n        model.compile(loss=tf.keras.losses.mean_squared_error,\r\n                      optimizer=optimizer,\r\n                      metrics=['mean_absolute_error'])\r\n        return model\r\n\r\n    def call(self, inputs, training=False):\r\n        return self.model(inputs, training=training)\r\n\r\n    def fit(self, X, y, *args, **kwargs):\r\n        return self.model.fit(X, y, *args, shuffle=True, **kwargs)\r\n`\r\nWhen I attempt to run the hyperparameter search with this setup, the search_space_summary() displays the following output:\r\n`Search space summary\r\nDefault search space size: 0\r\n`\r\nAs a result, the hyperparameter search doesn't execute. I suspect the issue is related to the hp=kt.HyperParameters configuration, but I have tried multiple approaches without success.\r\n\r\nDoes anyone have suggestions for how to correct this and enable proper hyperparameter tuning?\"\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5225,
    "title": "AttributeError: Cannot find field 'gt_masks' in the given Instances! for mask2former with coco-format dataset",
    "author": "jetsonwork",
    "state": "closed",
    "created_at": "2024-02-27T19:12:59Z",
    "updated_at": "2025-01-03T02:08:01Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Hello,\r\nI want to fine tune a swin-based mask2former model, and I register my coco format dataset as below:\r\n\r\nfrom detectron2.data.datasets import register_coco_instances\r\nregister_coco_instances(\"my_dataset_train\", {}, \"/content/drive/MyDrive/ColabNotebooks/data/3D-EM-Platelet/train/3D-EM-platelet-train.json\", \"/content/drive/MyDrive/ColabNotebooks/data/3D-EM-Platelet/train\")\r\nregister_coco_instances(\"my_dataset_val\", {}, \"/content/drive/MyDrive/ColabNotebooks/data/3D-EM-Platelet/val/3D-EM-platelet-val.json\", \"/content/drive/MyDrive/ColabNotebooks/data/3D-EM-Platelet/val\")\r\n\r\ntrain_metadata = MetadataCatalog.get(\"my_dataset_train\")\r\ntrain_dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\r\n\r\nval_metadata = MetadataCatalog.get(\"my_dataset_val\")\r\nval_dataset_dicts = DatasetCatalog.get(\"my_dataset_val\")\r\n\r\n\r\nbut when I want to train the model I am facing to the below error. Could you please advise how can I solve the issue?\r\n\r\nAttributeError: Cannot find field 'gt_masks' in the given Instances!\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "DimbyTa",
        "body": "Hello @jetsonwork,\r\n\r\nYour issue relates not to how you register your dataset but to the data itself or the model you use. Indeed, after reading the docs: https://detectron2.readthedocs.io/en/latest/_modules/detectron2/structures/instances.html?highlight=AttributeError#, you can see that the AttributeError is raised when: name == \"_fields\" or name not in self._fields, as stated in the docs of Instances.\r\n\r\nIf it was related to how you registered your dataset, the error would have stated that it could not find my_dataset_train or my_dataset_val.\r\n\r\nIf you read the docs on gt_masks, you can see that it is related to Model Input (https://detectron2.readthedocs.io/en/latest/tutorials/models.html?highlight=gt_masks#model-input-format), the docs talk about custom models and what they expect as input and the correct format.\r\n\r\nAs stated in https://detectron2.readthedocs.io/en/latest/tutorials/models.html?highlight=gt_masks#use-a-model, each model takes as inputs a list[dict] with each dict corresponding to one image. It is also stated that the required keys depend on the model. \r\n\r\nThat means the mask2former model probably requires the gt_masks field in the inputs (e.g.: [{\"image\": Tensor, \"height\": some_value, \"width\": some_value, ..., \"gt_masks\": PolygonMasks or BitMasks},{\"image\": Tensor, \"height\": some_value, \"width\": some_value, ..., \"gt_masks\": PolygonMasks or BitMasks},... ]).\r\n\r\nCan you confirm that you do have gt_masks in the inputs? Try: print(train_dataset_dicts[0].keys())\r\n\r\nFor more information on Instances: https://detectron2.readthedocs.io/en/latest/modules/structures.html#detectron2.structures.Instances\r\n\r\nThese might help you but I'm not sure: \r\nhttps://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/MaskFormer/Fine-tuning/Fine_tuning_MaskFormerForInstanceSegmentation_on_semantic_sidewalk.ipynb\r\n\r\nhttps://detectron2.readthedocs.io/en/latest/tutorials/datasets.html"
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5419,
    "title": "Challenges in Visualizing Pascal Context Ground Truth",
    "author": "khangii222",
    "state": "open",
    "created_at": "2024-12-31T17:24:18Z",
    "updated_at": "2024-12-31T17:24:18Z",
    "labels": [],
    "body": "ChatGPT\r\n\r\nYou said:\r\nGenerate pic of person for github profile in jpg , png file\r\nChatGPT said:\r\nChatGPT\r\n\r\nA professional yet approachable person suitable for a GitHub profile picture. The individual is in their mid-20s to early 30s, with a warm smile, wearing casual business attire (such as a button-down shirt or blazer). The background is minimalistic and blurred, emphasizing the person's face. The image should have natural lighting and a soft focus effect to give a professional yet modern feel.\r\nThe image has been generated. Let me know if you need any further adjustments or assistance.\r\n\r\n\r\n\r\n\r\n\r\nYou said:\r\nIn JPG\r\nChatGPT said:\r\nChatGPT\r\nThe image has been converted to JPG format. You can download it here. Let me know if you need further assistance! ‚Äã‚Äã\r\n\r\n\r\n\r\n\r\n\r\n\r\nYou said:\r\nrewrite (Could not find a version that satisfies the requirement torch (from versions: none)\r\nChatGPT said:\r\nChatGPT\r\nNo version of the package torch could be found that satisfies the specified requirement (available versions: none).\r\n\r\n\r\n\r\n\r\n\r\n\r\nYou said:\r\nrewrite ( Issues in Pascal Context GT Visualization\r\nChatGPT said:\r\nChatGPT\r\nProblems with Pascal Context Ground Truth Visualization\r\n\r\n\r\n2/2\r\n\r\n\r\n\r\n\r\n\r\n\r\nYou said:\r\nrewrite ( Issues in Pascal Context GT Visualization\r\nChatGPT said:\r\nChatGPT\r\nChallenges in Visualizing Pascal Context Ground Truth\r\n\r\n\r\n\r\n\r\n\r\n\r\nYou said:\r\nrewrite ( Bug Report: Issues with Pascal Context GT Visualization\r\n\r\nSteps to Reproduce the Bug:\r\n\r\nRun the command tools/visualize_data.\r\nObserve that visualize.py in the utils folder uses an outdated numpy dtype, leading to overflow issues.\r\nCode and Changes:\r\nRefer to the details in the failed pull request: #5391.\r\n\r\nObservation:\r\n\r\nThe visualization incorrectly displays the image. For instance:\r\nThe class ID should be train (359) but overflows and maps to fly (103) due to the calculation 359 - 256 = 103.\r\nExpected Behavior:\r\nHandle more than 256 classes correctly without overflow.\r\n(Note: Pascal Context contains 459 classes, causing the overflow issue.)\r\n\r\nEnvironment:\r\n\r\nPython: 3.10\r\nNumpy: 1.22.4\r\nPyTorch: 1.13.1\r\nAdditional Notes:\r\nSimplify the reproduction steps to avoid dependencies on private datasets. Ensure the d type supports the required range of class IDs.\r\nChatGPT said:\r\nChatGPT\r\nBug Report: Issues with Pascal Context Ground Truth (GT) Visualization\r\n\r\nSteps to Reproduce:\r\n\r\nRun the command tools/visualize_data.\r\nObserve that visualize.py in the utils folder uses an outdated NumPy dtype, resulting in overflow issues.\r\nCode and Changes:\r\nDetails can be found in the failed pull request: #5391.\r\n\r\nObservation:\r\nThe visualization outputs incorrect results due to overflow. For example:\r\n\r\nThe class ID should be train (359), but it overflows and maps to fly (103) because of the calculation 359 - 256 = 103.\r\nExpected Behavior:\r\nThe visualization should correctly handle more than 256 classes without overflow.\r\n(Note: Pascal Context contains 459 classes, which exceeds the current handling capacity.)\r\n\r\nEnvironment:\r\n\r\nPython: 3.10\r\nNumPy: 1.22.4\r\nPyTorch: 1.13.1\r\nAdditional Notes:\r\n\r\nSimplify reproduction steps to remove dependencies on private datasets.\r\nEnsure the dtype supports the full range of class IDs to avoid similar issues in the future.",
    "comments": []
  },
  {
    "issue_number": 4971,
    "title": "errors when training pointsup",
    "author": "muses0229",
    "state": "open",
    "created_at": "2023-05-24T07:11:40Z",
    "updated_at": "2024-12-30T09:14:50Z",
    "labels": [],
    "body": null,
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "zqy1",
        "body": "I'm having the same problem."
      },
      {
        "user": "Khola-naseem",
        "body": "I resolved this issue by passing keypoint_hflip_indices as a keyword argument  line 85  in point_sup/detection_utils.py file\r\nReplace this \r\nannotation = base_transform_instance_annotations(annotation, transforms, image_size, keypoint_hflip_indices) \r\nwith this:\r\nannotation = base_transform_instance_annotations( annotation, transforms, image_size, keypoint_hflip_indices=keypoint_hflip_indices)"
      }
    ]
  },
  {
    "issue_number": 5407,
    "title": "Issues in Pascal Context GT Visualization",
    "author": "unknownpersonai",
    "state": "open",
    "created_at": "2024-12-17T19:40:36Z",
    "updated_at": "2024-12-30T08:29:51Z",
    "labels": [],
    "body": "Bug Report: Issues with Pascal Context GT Visualization\r\n\r\nSteps to Reproduce the Bug:\r\n\r\nRun the command tools/visualize_data.\r\nObserve that visualize.py in the utils folder uses an outdated numpy dtype, leading to overflow issues.\r\nCode and Changes:\r\nRefer to the details in the failed pull request: #5391.\r\n\r\nObservation:\r\n\r\nThe visualization incorrectly displays the image. For instance:\r\nThe class ID should be train (359) but overflows and maps to fly (103) due to the calculation 359 - 256 = 103.\r\nExpected Behavior:\r\nHandle more than 256 classes correctly without overflow.\r\n(Note: Pascal Context contains 459 classes, causing the overflow issue.)\r\n\r\nEnvironment:\r\n\r\nPython: 3.10\r\nNumpy: 1.22.4\r\nPyTorch: 1.13.1\r\nAdditional Notes:\r\nSimplify the reproduction steps to avoid dependencies on private datasets. Ensure the d type supports the required range of class IDs.",
    "comments": [
      {
        "user": "shivvamm",
        "body": "I'd like to work on this issue. Is anyone else actively working on it?"
      }
    ]
  },
  {
    "issue_number": 5413,
    "title": "Issues with Visualizing Ground Truth Data in Pascal Context",
    "author": "Faris468",
    "state": "closed",
    "created_at": "2024-12-22T18:43:27Z",
    "updated_at": "2024-12-30T02:09:36Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Run the following command:\r\nbash\r\nCopy code\r\npython tools/visualize_data.py\r\nThe script uses visualize.py in the utils folder. The issue lies in the outdated numpy dtype configuration.\r\nDetailed Issue:\r\n\r\nThe visualization assigns an incorrect class due to overflow:\r\nExpected: train (id: 359)\r\nResult: fly (id: 103) from the calculation 359 - 256 = 103.\r\nThe tool fails to handle datasets with more than 256 classes, such as Pascal Context with 459 classes.\r\nExpected Behavior:\r\nThe tool should handle datasets with more than 256 classes without encountering overflow issues.\r\n\r\nEnvironment:\r\n\r\nPython Version: 3.10\r\nNumpy Version: 1.22.4\r\nTorch Version: 1.13.1\r\nFix Proposal:\r\nUpdate the numpy dtype in visualize.py to support a higher class range, such as int32 or a compatible type.\r\nEnsure compatibility with all class ranges in Pascal _Context.****_",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5411,
    "title": "AssertionError in Detectron2 PanopticFPN with Custom Mapper",
    "author": "duckling800",
    "state": "closed",
    "created_at": "2024-12-20T05:43:17Z",
    "updated_at": "2024-12-28T02:05:54Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "I'm encountering an AssertionError: assert \"sem_seg\" in batched_inputs[0] while training a Detectron2 model with PanopticFPN and a custom mapper for data augmentation.\r\nCustom Mapper:\r\nBriefly explain the purpose of your custom mapper (e.g., increase data augmentation).\r\nInclude the relevant code snippet for custom_mapper. Remove sensitive information if necessary. Consider linking to a Gist or repository if the code is lengthy.\r\nFull Error Traceback:\r\nProvide a complete copy of the error traceback, including line numbers and any associated error messages. You can paste this into a code block using triple backticks (`````) on GitHub.\r\nExpected Behavior:\r\nDescribe how you expected the code to work (e.g., model to train with augmentations applied).\r\nTroubleshooting Steps:\r\nMention any steps you've already tried to resolve the issue (e.g., reviewed similar examples, double-checked code for assumptions about data format).\r\nEnvironment:\r\nList key components (OS, Python version, Detectron2 version, GPU details).\r\nAdditional Context (Optional):\r\nInclude any relevant information not covered above, such as configuration files or specific datasets.\r\nIf you have specific questions or areas where you need guidance, feel free to mention them.\r\nExample Code Snippet:\r\n\r\nPython\r\n\r\ndef custom_mapper(dataset_dict):\r\n    # ... (Your custom data augmentation logic here) ...\r\n    return dataset_dict\r\nAdditional Considerations:\r\n\r\nDouble-check potential typos or errors in your custom_mapper function.\r\nVerify if any assumptions about input data formats or image dimensions might be causing problems.\r\nConsider simplifying your custom mapping logic temporarily to isolate the root cause.\r\nReview Detectron2 documentation or search for similar issues in the community forums.",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5401,
    "title": "Olny want the segm",
    "author": "mo230761",
    "state": "open",
    "created_at": "2024-11-28T09:06:39Z",
    "updated_at": "2024-12-27T07:09:47Z",
    "labels": [
      "enhancement"
    ],
    "body": "![image](https://github.com/user-attachments/assets/aa216c74-2117-436a-a759-8700279a4ee9)\r\nI olny want the segm and do not need the source image.How can I do this?",
    "comments": []
  },
  {
    "issue_number": 5219,
    "title": "RuntimeError: Not compiled with GPU support (ROIAlign_forward at",
    "author": "zhanghx66",
    "state": "closed",
    "created_at": "2024-02-20T06:23:39Z",
    "updated_at": "2024-12-24T02:08:08Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "If you do not know the root cause of the problem, please post according to this template:\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nCheck https://stackoverflow.com/help/minimal-reproducible-example for how to ask good questions.\r\nSimplify the steps to reproduce the issue using suggestions from the above link, and provide them below:\r\n\r\n1. Full runnable code or full changes you made:\r\n```\r\nIf making changes to the project itself, please use output of the following command:\r\ngit rev-parse HEAD; git diff\r\n\r\n<put code or diff here>\r\n```\r\n2. What exact command you run:\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n<put logs here>\r\n```\r\n\r\n## Expected behavior:\r\n\r\nIf there are no obvious crash in \"full logs\" provided above,\r\nplease tell us the expected behavior.\r\n\r\nIf you expect a model to converge / work better, we do not help with such issues, unless\r\na model fails to reproduce the results in detectron2 model zoo, or proves existence of bugs.\r\n\r\n## Environment:\r\n\r\nPaste the output of the following command:\r\n```\r\nwget -nc -nv https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first check common issues in https://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5380,
    "title": "‰∏∫‰ªÄ‰πà‰∏çÊûÑÂª∫win10ÁéØÂ¢ÉÁöÑÂÆâË£ÖÂåÖ",
    "author": "Metasymbols",
    "state": "closed",
    "created_at": "2024-10-12T22:11:13Z",
    "updated_at": "2024-12-23T01:33:51Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "\r\nrunning build\r\nrunning build_py\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\r\ncopying detectron2\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\r\ncreating build\\lib.win-amd64-cpython-312\\tools\r\ncopying tools\\analyze_model.py -> build\\lib.win-amd64-cpython-312\\tools\r\ncopying tools\\benchmark.py -> build\\lib.win-amd64-cpython-312\\tools\r\ncopying tools\\convert-torchvision-to-d2.py -> build\\lib.win-amd64-cpython-312\\tools\r\ncopying tools\\lazyconfig_train_net.py -> build\\lib.win-amd64-cpython-312\\tools     \r\ncopying tools\\lightning_train_net.py -> build\\lib.win-amd64-cpython-312\\tools      \r\ncopying tools\\plain_train_net.py -> build\\lib.win-amd64-cpython-312\\tools\r\ncopying tools\\train_net.py -> build\\lib.win-amd64-cpython-312\\tools\r\ncopying tools\\visualize_data.py -> build\\lib.win-amd64-cpython-312\\tools\r\ncopying tools\\visualize_json_results.py -> build\\lib.win-amd64-cpython-312\\tools\r\ncopying tools\\__init__.py -> build\\lib.win-amd64-cpython-312\\tools\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\checkpoint\r\ncopying detectron2\\checkpoint\\c2_model_loading.py -> build\\lib.win-amd64-cpython-312\\detectron2\\checkpoint\r\ncopying detectron2\\checkpoint\\catalog.py -> build\\lib.win-amd64-cpython-312\\detectron2\\checkpoint        \r\ncopying detectron2\\checkpoint\\detection_checkpoint.py -> build\\lib.win-amd64-cpython-312\\detectron2\\checkpoint\r\ncopying detectron2\\checkpoint\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\checkpoint       \r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\config\r\ncopying detectron2\\config\\compat.py -> build\\lib.win-amd64-cpython-312\\detectron2\\config\r\ncopying detectron2\\config\\config.py -> build\\lib.win-amd64-cpython-312\\detectron2\\config\r\ncopying detectron2\\config\\defaults.py -> build\\lib.win-amd64-cpython-312\\detectron2\\config\r\ncopying detectron2\\config\\instantiate.py -> build\\lib.win-amd64-cpython-312\\detectron2\\config\r\ncopying detectron2\\config\\lazy.py -> build\\lib.win-amd64-cpython-312\\detectron2\\config\r\ncopying detectron2\\config\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\config\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\data\r\ncopying detectron2\\data\\benchmark.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\r\ncopying detectron2\\data\\build.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\r\ncopying detectron2\\data\\catalog.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\r\ncopying detectron2\\data\\common.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\r\ncopying detectron2\\data\\dataset_mapper.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\r\ncopying detectron2\\data\\detection_utils.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\r\ncopying detectron2\\data\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\engine\r\ncopying detectron2\\engine\\defaults.py -> build\\lib.win-amd64-cpython-312\\detectron2\\engine\r\ncopying detectron2\\engine\\hooks.py -> build\\lib.win-amd64-cpython-312\\detectron2\\engine\r\ncopying detectron2\\engine\\launch.py -> build\\lib.win-amd64-cpython-312\\detectron2\\engine\r\ncopying detectron2\\engine\\train_loop.py -> build\\lib.win-amd64-cpython-312\\detectron2\\engine\r\ncopying detectron2\\engine\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\engine\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\evaluation\r\ncopying detectron2\\evaluation\\cityscapes_evaluation.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluation\r\ncopying detectron2\\evaluation\\coco_evaluation.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluationcopying detectron2\\evaluation\\evaluator.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluation      \r\ncopying detectron2\\evaluation\\fast_eval_api.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluation  \r\ncopying detectron2\\evaluation\\lvis_evaluation.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluationcopying detectron2\\evaluation\\panoptic_evaluation.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluation\r\ncopying detectron2\\evaluation\\pascal_voc_evaluation.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluation\r\ncopying detectron2\\evaluation\\rotated_coco_evaluation.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluation\r\ncopying detectron2\\evaluation\\sem_seg_evaluation.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluation\r\ncopying detectron2\\evaluation\\testing.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluation        \r\ncopying detectron2\\evaluation\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\evaluation       \r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\export\r\ncopying detectron2\\export\\api.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export\r\ncopying detectron2\\export\\c10.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export\r\ncopying detectron2\\export\\caffe2_export.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export\r\ncopying detectron2\\export\\caffe2_inference.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export       \r\ncopying detectron2\\export\\caffe2_modeling.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export        \r\ncopying detectron2\\export\\caffe2_patch.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export\r\ncopying detectron2\\export\\flatten.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export\r\ncopying detectron2\\export\\shared.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export\r\ncopying detectron2\\export\\torchscript.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export\r\ncopying detectron2\\export\\torchscript_patch.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export      \r\ncopying detectron2\\export\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\export\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\aspp.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\batch_norm.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\blocks.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\deform_conv.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\losses.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\mask_ops.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\nms.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\roi_align.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\roi_align_rotated.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers      \r\ncopying detectron2\\layers\\rotated_boxes.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\shape_spec.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\wrappers.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncopying detectron2\\layers\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\layers\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\modeling\r\ncopying detectron2\\modeling\\anchor_generator.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling   \r\ncopying detectron2\\modeling\\box_regression.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling     \r\ncopying detectron2\\modeling\\matcher.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\r\ncopying detectron2\\modeling\\mmdet_wrapper.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling      \r\ncopying detectron2\\modeling\\poolers.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\r\ncopying detectron2\\modeling\\postprocessing.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling     \r\ncopying detectron2\\modeling\\sampling.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\r\ncopying detectron2\\modeling\\test_time_augmentation.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\r\ncopying detectron2\\modeling\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\r\ncopying detectron2\\model_zoo\\model_zoo.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo        \r\ncopying detectron2\\model_zoo\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\projects\r\ncopying detectron2\\projects\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\solver\r\ncopying detectron2\\solver\\build.py -> build\\lib.win-amd64-cpython-312\\detectron2\\solver\r\ncopying detectron2\\solver\\lr_scheduler.py -> build\\lib.win-amd64-cpython-312\\detectron2\\solver\r\ncopying detectron2\\solver\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\solver\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\structures\r\ncopying detectron2\\structures\\boxes.py -> build\\lib.win-amd64-cpython-312\\detectron2\\structures\r\ncopying detectron2\\structures\\image_list.py -> build\\lib.win-amd64-cpython-312\\detectron2\\structures     \r\ncopying detectron2\\structures\\instances.py -> build\\lib.win-amd64-cpython-312\\detectron2\\structures      \r\ncopying detectron2\\structures\\keypoints.py -> build\\lib.win-amd64-cpython-312\\detectron2\\structures      \r\ncopying detectron2\\structures\\masks.py -> build\\lib.win-amd64-cpython-312\\detectron2\\structures\r\ncopying detectron2\\structures\\rotated_boxes.py -> build\\lib.win-amd64-cpython-312\\detectron2\\structures  \r\ncopying detectron2\\structures\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\structures       \r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\tracking\r\ncopying detectron2\\tracking\\base_tracker.py -> build\\lib.win-amd64-cpython-312\\detectron2\\tracking       \r\ncopying detectron2\\tracking\\bbox_iou_tracker.py -> build\\lib.win-amd64-cpython-312\\detectron2\\tracking   \r\ncopying detectron2\\tracking\\hungarian_tracker.py -> build\\lib.win-amd64-cpython-312\\detectron2\\tracking  \r\ncopying detectron2\\tracking\\iou_weighted_hungarian_bbox_iou_tracker.py -> build\\lib.win-amd64-cpython-312\\detectron2\\tracking\r\ncopying detectron2\\tracking\\utils.py -> build\\lib.win-amd64-cpython-312\\detectron2\\tracking\r\ncopying detectron2\\tracking\\vanilla_hungarian_bbox_iou_tracker.py -> build\\lib.win-amd64-cpython-312\\detectron2\\tracking\r\ncopying detectron2\\tracking\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\tracking\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\analysis.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\collect_env.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\colormap.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\comm.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\develop.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\env.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\events.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\file_io.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\logger.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\memory.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\registry.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\serialize.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\testing.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\tracing.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\video_visualizer.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\visualizer.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncopying detectron2\\utils\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\utils\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets\r\ncopying detectron2\\data\\datasets\\builtin.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets  \r\ncopying detectron2\\data\\datasets\\builtin_meta.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets\r\ncopying detectron2\\data\\datasets\\cityscapes.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets\r\ncopying detectron2\\data\\datasets\\cityscapes_panoptic.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets\r\ncopying detectron2\\data\\datasets\\coco.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets     \r\ncopying detectron2\\data\\datasets\\coco_panoptic.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets\r\ncopying detectron2\\data\\datasets\\lvis.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets     \r\ncopying detectron2\\data\\datasets\\lvis_v0_5_categories.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets\r\ncopying detectron2\\data\\datasets\\lvis_v1_categories.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets\r\ncopying detectron2\\data\\datasets\\lvis_v1_category_image_count.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets\r\ncopying detectron2\\data\\datasets\\pascal_voc.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets\r\ncopying detectron2\\data\\datasets\\register_coco.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets\r\ncopying detectron2\\data\\datasets\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\datasets \r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\data\\samplers\r\ncopying detectron2\\data\\samplers\\distributed_sampler.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\samplers\r\ncopying detectron2\\data\\samplers\\grouped_batch_sampler.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\samplers\r\ncopying detectron2\\data\\samplers\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\samplers \r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\data\\transforms\r\ncopying detectron2\\data\\transforms\\augmentation.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\transforms\r\ncopying detectron2\\data\\transforms\\augmentation_impl.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\transforms\r\ncopying detectron2\\data\\transforms\\transform.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\transforms\r\ncopying detectron2\\data\\transforms\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\data\\transforms\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncopying detectron2\\modeling\\backbone\\backbone.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncopying detectron2\\modeling\\backbone\\build.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncopying detectron2\\modeling\\backbone\\fpn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncopying detectron2\\modeling\\backbone\\mvit.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncopying detectron2\\modeling\\backbone\\regnet.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncopying detectron2\\modeling\\backbone\\resnet.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncopying detectron2\\modeling\\backbone\\swin.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncopying detectron2\\modeling\\backbone\\utils.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncopying detectron2\\modeling\\backbone\\vit.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncopying detectron2\\modeling\\backbone\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\backbone\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\meta_arch\r\ncopying detectron2\\modeling\\meta_arch\\build.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\meta_arch\r\ncopying detectron2\\modeling\\meta_arch\\dense_detector.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\meta_arch\r\ncopying detectron2\\modeling\\meta_arch\\fcos.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\meta_arch\r\ncopying detectron2\\modeling\\meta_arch\\panoptic_fpn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\meta_arch\r\ncopying detectron2\\modeling\\meta_arch\\rcnn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\meta_arch\r\ncopying detectron2\\modeling\\meta_arch\\retinanet.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\meta_arch\r\ncopying detectron2\\modeling\\meta_arch\\semantic_seg.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\meta_arch\r\ncopying detectron2\\modeling\\meta_arch\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\meta_arch\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\proposal_generator\r\ncopying detectron2\\modeling\\proposal_generator\\build.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\proposal_generator\r\ncopying detectron2\\modeling\\proposal_generator\\proposal_utils.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\proposal_generator\r\ncopying detectron2\\modeling\\proposal_generator\\rpn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\proposal_generator\r\ncopying detectron2\\modeling\\proposal_generator\\rrpn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\proposal_generator\r\ncopying detectron2\\modeling\\proposal_generator\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\proposal_generator\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\roi_heads\r\ncopying detectron2\\modeling\\roi_heads\\box_head.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\roi_heads\r\ncopying detectron2\\modeling\\roi_heads\\cascade_rcnn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\roi_heads\r\ncopying detectron2\\modeling\\roi_heads\\fast_rcnn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\roi_heads\r\ncopying detectron2\\modeling\\roi_heads\\keypoint_head.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\roi_heads\r\ncopying detectron2\\modeling\\roi_heads\\mask_head.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\roi_heads\r\ncopying detectron2\\modeling\\roi_heads\\roi_heads.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\roi_heads\r\ncopying detectron2\\modeling\\roi_heads\\rotated_fast_rcnn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\roi_heads\r\ncopying detectron2\\modeling\\roi_heads\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\modeling\\roi_heads\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\projects\\point_rend\r\ncopying projects\\PointRend\\point_rend\\color_augmentation.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\point_rend\r\ncopying projects\\PointRend\\point_rend\\config.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\point_rend\r\ncopying projects\\PointRend\\point_rend\\mask_head.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\point_rend\r\ncopying projects\\PointRend\\point_rend\\point_features.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\point_rend\r\ncopying projects\\PointRend\\point_rend\\point_head.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\point_rend\r\ncopying projects\\PointRend\\point_rend\\roi_heads.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\point_rend\r\ncopying projects\\PointRend\\point_rend\\semantic_seg.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\point_rend\r\ncopying projects\\PointRend\\point_rend\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\point_rend\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\projects\\deeplab\r\ncopying projects\\DeepLab\\deeplab\\build_solver.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\deeplab\r\ncopying projects\\DeepLab\\deeplab\\config.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\deeplabcopying projects\\DeepLab\\deeplab\\loss.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\deeplab  \r\ncopying projects\\DeepLab\\deeplab\\lr_scheduler.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\deeplab\r\ncopying projects\\DeepLab\\deeplab\\resnet.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\deeplabcopying projects\\DeepLab\\deeplab\\semantic_seg.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\deeplab\r\ncopying projects\\DeepLab\\deeplab\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\deeplab\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\projects\\panoptic_deeplab\r\ncopying projects\\Panoptic-DeepLab\\panoptic_deeplab\\config.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\panoptic_deeplab\r\ncopying projects\\Panoptic-DeepLab\\panoptic_deeplab\\dataset_mapper.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\panoptic_deeplab\r\ncopying projects\\Panoptic-DeepLab\\panoptic_deeplab\\panoptic_seg.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\panoptic_deeplab\r\ncopying projects\\Panoptic-DeepLab\\panoptic_deeplab\\post_processing.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\panoptic_deeplab\r\ncopying projects\\Panoptic-DeepLab\\panoptic_deeplab\\target_generator.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\panoptic_deeplab\r\ncopying projects\\Panoptic-DeepLab\\panoptic_deeplab\\__init__.py -> build\\lib.win-amd64-cpython-312\\detectron2\\projects\\panoptic_deeplab\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\r\ncopying detectron2\\model_zoo\\configs\\Base-RCNN-C4.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\r\ncopying detectron2\\model_zoo\\configs\\Base-RCNN-DilatedC5.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\r\ncopying detectron2\\model_zoo\\configs\\Base-RCNN-FPN.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\r\ncopying detectron2\\model_zoo\\configs\\Base-RetinaNet.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Cityscapes\r\ncopying detectron2\\model_zoo\\configs\\Cityscapes\\mask_rcnn_R_50_FPN.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Cityscapes\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\faster_rcnn_R_101_C4_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\faster_rcnn_R_101_DC5_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\faster_rcnn_R_101_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\faster_rcnn_R_50_C4_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\faster_rcnn_R_50_C4_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\faster_rcnn_R_50_DC5_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\faster_rcnn_R_50_DC5_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\faster_rcnn_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\faster_rcnn_R_50_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\faster_rcnn_X_101_32x8d_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\fast_rcnn_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\retinanet_R_101_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\retinanet_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\retinanet_R_50_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\rpn_R_50_C4_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\rpn_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_101_C4_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_101_DC5_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_101_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_50_C4_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_50_C4_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_50_DC5_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_50_DC5_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_50_FPN_1x_giou.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_50_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_X_101_32x8d_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Keypoints\r\ncopying detectron2\\model_zoo\\configs\\COCO-Keypoints\\Base-Keypoint-RCNN-FPN.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Keypoints\r\ncopying detectron2\\model_zoo\\configs\\COCO-Keypoints\\keypoint_rcnn_R_101_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Keypoints\r\ncopying detectron2\\model_zoo\\configs\\COCO-Keypoints\\keypoint_rcnn_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Keypoints\r\ncopying detectron2\\model_zoo\\configs\\COCO-Keypoints\\keypoint_rcnn_R_50_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Keypoints\r\ncopying detectron2\\model_zoo\\configs\\COCO-Keypoints\\keypoint_rcnn_X_101_32x8d_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Keypoints\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\\Base-Panoptic-FPN.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\\panoptic_fpn_R_101_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\\panoptic_fpn_R_50_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\\panoptic_fpn_R_50_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Detectron1-Comparisons\r\ncopying detectron2\\model_zoo\\configs\\Detectron1-Comparisons\\faster_rcnn_R_50_FPN_noaug_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Detectron1-Comparisons\r\ncopying detectron2\\model_zoo\\configs\\Detectron1-Comparisons\\keypoint_rcnn_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Detectron1-Comparisons\r\ncopying detectron2\\model_zoo\\configs\\Detectron1-Comparisons\\mask_rcnn_R_50_FPN_noaug_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Detectron1-Comparisons\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\LVISv0.5-InstanceSegmentation      \r\ncopying detectron2\\model_zoo\\configs\\LVISv0.5-InstanceSegmentation\\mask_rcnn_R_101_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\LVISv0.5-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\LVISv0.5-InstanceSegmentation\\mask_rcnn_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\LVISv0.5-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\LVISv0.5-InstanceSegmentation\\mask_rcnn_X_101_32x8d_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\LVISv0.5-InstanceSegmentation\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\LVISv1-InstanceSegmentation        \r\ncopying detectron2\\model_zoo\\configs\\LVISv1-InstanceSegmentation\\mask_rcnn_R_101_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\LVISv1-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\LVISv1-InstanceSegmentation\\mask_rcnn_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\LVISv1-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\LVISv1-InstanceSegmentation\\mask_rcnn_X_101_32x8d_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\LVISv1-InstanceSegmentation\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\cascade_mask_rcnn_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\cascade_mask_rcnn_R_50_FPN_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\mask_rcnn_R_50_FPN_1x_cls_agnostic.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\mask_rcnn_R_50_FPN_1x_dconv_c3-c5.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\mask_rcnn_R_50_FPN_3x_gn.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\mask_rcnn_R_50_FPN_3x_syncbn.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\panoptic_fpn_R_101_dconv_cascade_gn_3x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\scratch_mask_rcnn_R_50_FPN_3x_gn.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\scratch_mask_rcnn_R_50_FPN_9x_gn.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\scratch_mask_rcnn_R_50_FPN_9x_syncbn.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\semantic_R_50_FPN_1x.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\PascalVOC-Detection\r\ncopying detectron2\\model_zoo\\configs\\PascalVOC-Detection\\faster_rcnn_R_50_C4.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\PascalVOC-Detection\r\ncopying detectron2\\model_zoo\\configs\\PascalVOC-Detection\\faster_rcnn_R_50_FPN.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\PascalVOC-Detection\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\cascade_mask_rcnn_R_50_FPN_inference_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\cascade_mask_rcnn_R_50_FPN_instant_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\fast_rcnn_R_50_FPN_inference_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\fast_rcnn_R_50_FPN_instant_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\keypoint_rcnn_R_50_FPN_inference_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\keypoint_rcnn_R_50_FPN_instant_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\keypoint_rcnn_R_50_FPN_normalized_training_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\keypoint_rcnn_R_50_FPN_training_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\mask_rcnn_R_50_C4_GCV_instant_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\mask_rcnn_R_50_C4_inference_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\mask_rcnn_R_50_C4_instant_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\mask_rcnn_R_50_C4_training_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\mask_rcnn_R_50_DC5_inference_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\mask_rcnn_R_50_FPN_inference_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\mask_rcnn_R_50_FPN_instant_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\mask_rcnn_R_50_FPN_pred_boxes_training_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\mask_rcnn_R_50_FPN_training_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\panoptic_fpn_R_50_inference_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\panoptic_fpn_R_50_instant_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\panoptic_fpn_R_50_training_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\retinanet_R_50_FPN_inference_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\retinanet_R_50_FPN_instant_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\rpn_R_50_FPN_inference_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\rpn_R_50_FPN_instant_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\semantic_R_50_FPN_inference_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\semantic_R_50_FPN_instant_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\quick_schedules\\semantic_R_50_FPN_training_acc_test.yaml -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\quick_schedules\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\fcos_R_50_FPN_1x.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-Detection\\retinanet_R_50_FPN_1x.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Detection\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_regnetx_4gf_dds_fpn_1x.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_regnety_4gf_dds_fpn_1x.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_50_C4_1x.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\\mask_rcnn_R_50_FPN_1x.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-InstanceSegmentation\r\ncopying detectron2\\model_zoo\\configs\\COCO-Keypoints\\keypoint_rcnn_R_50_FPN_1x.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-Keypoints\r\ncopying detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\\panoptic_fpn_R_50_1x.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\COCO-PanopticSegmentation\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\r\ncopying detectron2\\model_zoo\\configs\\common\\coco_schedule.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\r\ncopying detectron2\\model_zoo\\configs\\common\\optim.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\r\ncopying detectron2\\model_zoo\\configs\\common\\train.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\data\r\ncopying detectron2\\model_zoo\\configs\\common\\data\\coco.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\data\r\ncopying detectron2\\model_zoo\\configs\\common\\data\\coco_keypoint.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\data\r\ncopying detectron2\\model_zoo\\configs\\common\\data\\coco_panoptic_separated.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\data\r\ncopying detectron2\\model_zoo\\configs\\common\\data\\constants.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\data\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\models\r\ncopying detectron2\\model_zoo\\configs\\common\\models\\cascade_rcnn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\models\r\ncopying detectron2\\model_zoo\\configs\\common\\models\\fcos.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\models\r\ncopying detectron2\\model_zoo\\configs\\common\\models\\keypoint_rcnn_fpn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\models\r\ncopying detectron2\\model_zoo\\configs\\common\\models\\mask_rcnn_c4.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\models\r\ncopying detectron2\\model_zoo\\configs\\common\\models\\mask_rcnn_fpn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\models\r\ncopying detectron2\\model_zoo\\configs\\common\\models\\mask_rcnn_vitdet.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\models\r\ncopying detectron2\\model_zoo\\configs\\common\\models\\panoptic_fpn.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\models\r\ncopying detectron2\\model_zoo\\configs\\common\\models\\retinanet.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\common\\models\r\ncopying detectron2\\model_zoo\\configs\\Misc\\mmdet_mask_rcnn_R_50_FPN_1x.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncopying detectron2\\model_zoo\\configs\\Misc\\torchvision_imagenet_R_50.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\Misc\r\ncreating build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\ncopying detectron2\\model_zoo\\configs\\new_baselines\\mask_rcnn_regnetx_4gf_dds_FPN_100ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\ncopying detectron2\\model_zoo\\configs\\new_baselines\\mask_rcnn_regnetx_4gf_dds_FPN_200ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\ncopying detectron2\\model_zoo\\configs\\new_baselines\\mask_rcnn_regnetx_4gf_dds_FPN_400ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\ncopying detectron2\\model_zoo\\configs\\new_baselines\\mask_rcnn_regnety_4gf_dds_FPN_100ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\ncopying detectron2\\model_zoo\\configs\\new_baselines\\mask_rcnn_regnety_4gf_dds_FPN_200ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\ncopying detectron2\\model_zoo\\configs\\new_baselines\\mask_rcnn_regnety_4gf_dds_FPN_400ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\ncopying detectron2\\model_zoo\\configs\\new_baselines\\mask_rcnn_R_101_FPN_100ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\ncopying detectron2\\model_zoo\\configs\\new_baselines\\mask_rcnn_R_101_FPN_200ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\ncopying detectron2\\model_zoo\\configs\\new_baselines\\mask_rcnn_R_101_FPN_400ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\ncopying detectron2\\model_zoo\\configs\\new_baselines\\mask_rcnn_R_50_FPN_100ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\nrunning build_ext                                 \\mask_rcnn_R_50_FPN_200ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new_baselines\r\nD:\\Program Files\\anaconda3\\envs\\py_code_env\\Lib\\si                                                                                                   w_baselineste-packages\\torch\\utils\\cpp_extension.py:384: User\\mask_rcnn_R_50_FPN_400ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\ne_baselinesWarning: Error checking compiler version for cl: [WinError 2] Á≥ªÁªüÊâæ‰∏çÂà∞ÊåáÂÆöÁöÑÊñá‰ª∂„ÄÇ                \\mask_rcnn_R_50_FPN_50ep_LSJ.py -> build\\lib.win-amd64-cpython-312\\detectron2\\model_zoo\\configs\\new[WinError 2] Á≥ªÁªüÊâæ  Âà∞ÊåáÂÆöÁöÑÊñá‰ª∂„ÄÇ\r\n  warnings.warn(f'Error checking compiler version \r\nfor {compiler}: {error}')\r\nbuilding 'detectron2._C' extension                te-packages\\torch\\utils\\cpp_extension.py:384: UserWarning: Error checking compiler version for cl: \r\nb'\\x93\\x8feQL\\x88*Y\\x7f\\x95\\x020\\r\\x00\\n\\x00}T\\xe4N\\xed\\x8b\\xd5l\\rNcknx\\x020\\r\\x00\\n\\x00'           for {compiler}: {error}')\r\nerror: Error executing cmd /u /c \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\N\\xed\\x8b\\xd5l\\rNcknx\\x020\\r\\x00\\n\\x00'Auxiliary\\Build\\vcvarsall.bat\" x86_amd64 && set",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      },
      {
        "user": "laizheng521",
        "body": "ËØ∑ÈóÆËß£ÂÜ≥‰∫Ü‰πàÔºü"
      }
    ]
  },
  {
    "issue_number": 4748,
    "title": "Detectron2 installation error on Python 3.9",
    "author": "EdibHamzaArslan",
    "state": "open",
    "created_at": "2023-01-18T22:46:17Z",
    "updated_at": "2024-12-20T19:08:20Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\nI didn't change anything. **_I have another conda enviroment in my machine, and I successfully installed detectron2 on this enviroment, the only difference is that this enviroment is using python 3.8._** \r\n2. What exact command you run: python -m pip install -e detectron2 or python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\n3. __Full logs__ or other relevant observations:\r\n```\r\nInstalling collected packages: detectron2\r\n  Running setup.py develop for detectron2\r\n    error: subprocess-exited-with-error\r\n    \r\n    √ó python setup.py develop did not run successfully.\r\n    ‚îÇ exit code: 1\r\n    ‚ï∞‚îÄ> [94 lines of output]\r\n        running develop\r\n        /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\r\n          warnings.warn(\r\n        /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n          warnings.warn(\r\n        running egg_info\r\n        writing detectron2.egg-info/PKG-INFO\r\n        writing dependency_links to detectron2.egg-info/dependency_links.txt\r\n        writing requirements to detectron2.egg-info/requires.txt\r\n        writing top-level names to detectron2.egg-info/top_level.txt\r\n        reading manifest file 'detectron2.egg-info/SOURCES.txt'\r\n        adding license file 'LICENSE'\r\n        writing manifest file 'detectron2.egg-info/SOURCES.txt'\r\n        running build_ext\r\n        building 'detectron2._C' extension\r\n        Emitting ninja build file /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/build.ninja...\r\n        Compiling objects...\r\n        Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n        [1/2] c++ -MMD -MF /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o.d -pthread -B /home/edib_hamza/anaconda3/envs/pytorch3d/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -DWITH_CUDA -I/home/edib_hamza/projects/detectron2/detectron2/layers/csrc -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/TH -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.3/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include/python3.9 -c -c /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp -o /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14\r\n        FAILED: /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o\r\n        c++ -MMD -MF /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o.d -pthread -B /home/edib_hamza/anaconda3/envs/pytorch3d/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -DWITH_CUDA -I/home/edib_hamza/projects/detectron2/detectron2/layers/csrc -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/TH -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.3/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include/python3.9 -c -c /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp -o /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14\r\n        In file included from /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp:2:\r\n        /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.h:4:10: fatal error: pybind11/numpy.h: No such file or directory\r\n            4 | #include <pybind11/numpy.h>\r\n              |          ^~~~~~~~~~~~~~~~~~\r\n        compilation terminated.\r\n        [2/2] c++ -MMD -MF /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.o.d -pthread -B /home/edib_hamza/anaconda3/envs/pytorch3d/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -DWITH_CUDA -I/home/edib_hamza/projects/detectron2/detectron2/layers/csrc -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/TH -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.3/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include/python3.9 -c -c /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.cpp -o /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14\r\n        FAILED: /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.o\r\n        c++ -MMD -MF /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.o.d -pthread -B /home/edib_hamza/anaconda3/envs/pytorch3d/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -DWITH_CUDA -I/home/edib_hamza/projects/detectron2/detectron2/layers/csrc -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/TH -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.3/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include/python3.9 -c -c /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.cpp -o /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14\r\n        In file included from /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/python.h:12,\r\n                         from /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/extension.h:6,\r\n                         from /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.cpp:3:\r\n        /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/utils/pybind.h:7:10: fatal error: pybind11/pybind11.h: No such file or directory\r\n            7 | #include <pybind11/pybind11.h>\r\n              |          ^~~~~~~~~~~~~~~~~~~~~\r\n        compilation terminated.\r\n        ninja: build stopped: subcommand failed.\r\n        Traceback (most recent call last):\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1813, in _run_ninja_build\r\n            subprocess.run(\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/subprocess.py\", line 528, in run\r\n            raise CalledProcessError(retcode, process.args,\r\n        subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\r\n        \r\n        The above exception was the direct cause of the following exception:\r\n        \r\n        Traceback (most recent call last):\r\n          File \"<string>\", line 2, in <module>\r\n          File \"<pip-setuptools-caller>\", line 34, in <module>\r\n          File \"/home/edib_hamza/projects/detectron2/setup.py\", line 148, in <module>\r\n            setup(\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/__init__.py\", line 87, in setup\r\n            return distutils.core.setup(**attrs)\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 185, in setup\r\n            return run_commands(dist)\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\r\n            dist.run_commands()\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\r\n            self.run_command(cmd)\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/dist.py\", line 1208, in run_command\r\n            super().run_command(command)\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n            cmd_obj.run()\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/develop.py\", line 34, in run\r\n            self.install_for_development()\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/develop.py\", line 114, in install_for_development\r\n            self.run_command('build_ext')\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\r\n            self.distribution.run_command(command)\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/dist.py\", line 1208, in run_command\r\n            super().run_command(command)\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n            cmd_obj.run()\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 84, in run\r\n            _build_ext.run(self)\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 346, in run\r\n            self.build_extensions()\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 770, in build_extensions\r\n            build_ext.build_extensions(self)\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 468, in build_extensions\r\n            self._build_extensions_serial()\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 494, in _build_extensions_serial\r\n            self.build_extension(ext)\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 246, in build_extension\r\n            _build_ext.build_extension(self, ext)\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 549, in build_extension\r\n            objects = self.compiler.compile(\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 591, in unix_wrap_ninja_compile\r\n            _write_ninja_file_and_compile_objects(\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1492, in _write_ninja_file_and_compile_objects\r\n            _run_ninja_build(\r\n          File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1829, in _run_ninja_build\r\n            raise RuntimeError(message) from e\r\n        RuntimeError: Error compiling objects for extension\r\n        [end of output]\r\n    \r\n    note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n√ó python setup.py develop did not run successfully.\r\n‚îÇ exit code: 1\r\n‚ï∞‚îÄ> [94 lines of output]\r\n    running develop\r\n    /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\r\n      warnings.warn(\r\n    /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n      warnings.warn(\r\n    running egg_info\r\n    writing detectron2.egg-info/PKG-INFO\r\n    writing dependency_links to detectron2.egg-info/dependency_links.txt\r\n    writing requirements to detectron2.egg-info/requires.txt\r\n    writing top-level names to detectron2.egg-info/top_level.txt\r\n    reading manifest file 'detectron2.egg-info/SOURCES.txt'\r\n    adding license file 'LICENSE'\r\n    writing manifest file 'detectron2.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    building 'detectron2._C' extension\r\n    Emitting ninja build file /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/build.ninja...\r\n    Compiling objects...\r\n    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n    [1/2] c++ -MMD -MF /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o.d -pthread -B /home/edib_hamza/anaconda3/envs/pytorch3d/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -DWITH_CUDA -I/home/edib_hamza/projects/detectron2/detectron2/layers/csrc -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/TH -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.3/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include/python3.9 -c -c /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp -o /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14\r\n    FAILED: /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o\r\n    c++ -MMD -MF /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o.d -pthread -B /home/edib_hamza/anaconda3/envs/pytorch3d/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -DWITH_CUDA -I/home/edib_hamza/projects/detectron2/detectron2/layers/csrc -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/TH -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.3/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include/python3.9 -c -c /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp -o /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14\r\n    In file included from /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.cpp:2:\r\n    /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/cocoeval/cocoeval.h:4:10: fatal error: pybind11/numpy.h: No such file or directory\r\n        4 | #include <pybind11/numpy.h>\r\n          |          ^~~~~~~~~~~~~~~~~~\r\n    compilation terminated.\r\n    [2/2] c++ -MMD -MF /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.o.d -pthread -B /home/edib_hamza/anaconda3/envs/pytorch3d/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -DWITH_CUDA -I/home/edib_hamza/projects/detectron2/detectron2/layers/csrc -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/TH -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.3/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include/python3.9 -c -c /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.cpp -o /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14\r\n    FAILED: /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.o\r\n    c++ -MMD -MF /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.o.d -pthread -B /home/edib_hamza/anaconda3/envs/pytorch3d/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -O2 -isystem /home/edib_hamza/anaconda3/envs/pytorch3d/include -fPIC -DWITH_CUDA -I/home/edib_hamza/projects/detectron2/detectron2/layers/csrc -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/TH -I/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.3/include -I/home/edib_hamza/anaconda3/envs/pytorch3d/include/python3.9 -c -c /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.cpp -o /home/edib_hamza/projects/detectron2/build/temp.linux-x86_64-cpython-39/home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1013\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14\r\n    In file included from /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/python.h:12,\r\n                     from /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/extension.h:6,\r\n                     from /home/edib_hamza/projects/detectron2/detectron2/layers/csrc/vision.cpp:3:\r\n    /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/include/torch/csrc/utils/pybind.h:7:10: fatal error: pybind11/pybind11.h: No such file or directory\r\n        7 | #include <pybind11/pybind11.h>\r\n          |          ^~~~~~~~~~~~~~~~~~~~~\r\n    compilation terminated.\r\n    ninja: build stopped: subcommand failed.\r\n    Traceback (most recent call last):\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1813, in _run_ninja_build\r\n        subprocess.run(\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/subprocess.py\", line 528, in run\r\n        raise CalledProcessError(retcode, process.args,\r\n    subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\r\n    \r\n    The above exception was the direct cause of the following exception:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 2, in <module>\r\n      File \"<pip-setuptools-caller>\", line 34, in <module>\r\n      File \"/home/edib_hamza/projects/detectron2/setup.py\", line 148, in <module>\r\n        setup(\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/__init__.py\", line 87, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 185, in setup\r\n        return run_commands(dist)\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\r\n        dist.run_commands()\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/dist.py\", line 1208, in run_command\r\n        super().run_command(command)\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n        cmd_obj.run()\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/develop.py\", line 34, in run\r\n        self.install_for_development()\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/develop.py\", line 114, in install_for_development\r\n        self.run_command('build_ext')\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/dist.py\", line 1208, in run_command\r\n        super().run_command(command)\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\r\n        cmd_obj.run()\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 84, in run\r\n        _build_ext.run(self)\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 346, in run\r\n        self.build_extensions()\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 770, in build_extensions\r\n        build_ext.build_extensions(self)\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 468, in build_extensions\r\n        self._build_extensions_serial()\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 494, in _build_extensions_serial\r\n        self.build_extension(ext)\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 246, in build_extension\r\n        _build_ext.build_extension(self, ext)\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 549, in build_extension\r\n        objects = self.compiler.compile(\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 591, in unix_wrap_ninja_compile\r\n        _write_ninja_file_and_compile_objects(\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1492, in _write_ninja_file_and_compile_objects\r\n        _run_ninja_build(\r\n      File \"/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1829, in _run_ninja_build\r\n        raise RuntimeError(message) from e\r\n    RuntimeError: Error compiling objects for extension\r\n    [end of output]\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n```\r\n\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\ncuobjdump info    : File '/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torchvision/_C.so' does not contain device code\r\n----------------------  -------------------------------------------------------------------------------------------\r\nsys.platform            linux\r\nPython                  3.9.16 (main, Jan 11 2023, 16:05:54) [GCC 11.2.0]\r\nnumpy                   1.23.5\r\ndetectron2              imported a wrong installation\r\ndetectron2._C           not built correctly: No module named 'detectron2._C'\r\nCompiler ($CXX)         c++ (Ubuntu 10.3.0-1ubuntu1~20.04) 10.3.0\r\nCUDA compiler           Build cuda_11.3.r11.3/compiler.29745058_0\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.12.1 @/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch\r\nPyTorch debug build     False\r\nGPU available           Yes\r\nGPU 0                   NVIDIA GeForce GTX 1050 Ti (arch=6.1)\r\nDriver version          510.85.02\r\nCUDA_HOME               /usr/local/cuda-11.3\r\nPillow                  9.3.0\r\ntorchvision             0.13.1a0 @/home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torchvision\r\ntorchvision arch flags  /home/edib_hamza/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torchvision/_C.so\r\nfvcore                  0.1.5.post20221221\r\niopath                  0.1.9\r\ncv2                     4.7.0\r\n----------------------  -------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201402\r\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.6.0 (Git Hash N/A)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 11.3\r\n  - NVCC architecture flags: -gencode;arch=compute_35,code=sm_35;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_86,code=compute_86\r\n  - CuDNN 8.2.1\r\n  - Magma 2.7.0\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.1, CXX_COMPILER=/home/builder/mc3/envs/pytorch-build/envs/pytorch-build/conda-bld/pytorch_1673601922403/_build_env/bin/x86_64-conda-linux-gnu-c++, CXX_FLAGS=-fvisibility-inlines-hidden  -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/builder/mc3/envs/pytorch-build/envs/pytorch-build/conda-bld/pytorch_1673601922403/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_/include -fdebug-prefix-map=/home/builder/mc3/envs/pytorch-build/envs/pytorch-build/conda-bld/pytorch_1673601922403/work=/usr/local/src/conda/pytorch-1.12.1 -fdebug-prefix-map=/home/builder/mc3/envs/pytorch-build/envs/pytorch-build/conda-bld/pytorch_1673601922403/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_=/usr/local/src/conda-prefix -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=1, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,\r\n```",
    "comments": [
      {
        "user": "EdibHamzaArslan",
        "body": "Hey, I created new env with python=3.8.5 but I didn't fix it. Before install detectron2, I installed this packages:\r\n```\r\nconda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch\r\nconda install -c fvcore -c iopath -c conda-forge fvcore iopath\r\nconda install -c bottler nvidiacub\r\nconda install jupyter\r\npip install scikit-image matplotlib imageio plotly opencv-python\r\npip install black usort flake8 flake8-bugbear flake8-comprehensions\r\nconda install pytorch3d -c pytorch3d\r\n```\r\nAfter that I am running this command \"python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' \"\r\nI get same error."
      },
      {
        "user": "nikhilaravi",
        "body": "`apt-get update && apt-get -y install pybind11-dev` this fixed the issue for me. "
      },
      {
        "user": "arthurgervais",
        "body": "Thank you, pybind was the culprit üëç "
      }
    ]
  },
  {
    "issue_number": 5412,
    "title": "Some model parameters or buffers are not found in the checkpoint",
    "author": "iholy19",
    "state": "open",
    "created_at": "2024-12-20T13:22:35Z",
    "updated_at": "2024-12-20T13:38:34Z",
    "labels": [],
    "body": "## Issue\r\nWhen I try to load the model, it says that \r\n```\r\nSome model parameters or buffers are not found in the checkpoint:\r\nbackbone.fpn_lateral2.{bias, weight}\r\nbackbone.fpn_lateral3.{bias, weight}\r\n.\r\n.\r\n.\r\nroi_heads.mask_head.mask_fcn4.{bias, weight}\r\nroi_heads.mask_head.predictor.{bias, weight}\r\nThe checkpoint state_dict contains keys that are not used by the model:\r\n  fc1000.{bias, weight}\r\n  stem.conv1.bias\r\n```\r\n\r\n## Instructions To Reproduce the Issue:\r\n### Installation\r\nI created conda env with torch v1.10.0 and CUDA 11.3\r\n`conda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch -c conda-forge`\r\n\r\nI installed detectronv0.6 from the instruction [here](https://detectron2.readthedocs.io/en/latest/tutorials/install.html)\r\n`python -m pip install detectron2 -f \\\r\n  https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html`\r\n\r\n### Code for training\r\n#### Dataset and config\r\nThis part works fine\r\n```\r\nTRAIN_IMAGES = \"../../train/images\"\r\nTRAIN_JSON = \"../../train/annotations/train.json\"\r\nVAL_IMAGES = \"../../val/images\"\r\nVAL_JSON = \"../../val/annotations/val.json\"\r\n\r\nregister_coco_instances(\"train\", {}, TRAIN_JSON, TRAIN_IMAGES)\r\nregister_coco_instances(\"val\", {}, VAL_JSON, VAL_IMAGES)\r\n\r\ncfg = get_cfg()\r\ncfg.merge_from_file(r\"detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\")\r\ncfg.DATASETS.TRAIN = (\"train\",)\r\ncfg.DATASETS.TEST = (\"val\",)\r\ncfg.OUTPUT_DIR = \"./output1\"\r\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n```\r\n#### Training\r\n```\r\ntrainer = DefaultTrainer(cfg)\r\ntrainer.resume_or_load(resume=False)\r\n```\r\nThe above part throws warning like this\r\n```\r\nSome model parameters or buffers are not found in the checkpoint:\r\nbackbone.fpn_lateral2.{bias, weight}\r\nbackbone.fpn_lateral3.{bias, weight}\r\nbackbone.fpn_lateral4.{bias, weight}\r\nbackbone.fpn_lateral5.{bias, weight}\r\nbackbone.fpn_output2.{bias, weight}\r\nbackbone.fpn_output3.{bias, weight}\r\nbackbone.fpn_output4.{bias, weight}\r\nbackbone.fpn_output5.{bias, weight}\r\nproposal_generator.rpn_head.anchor_deltas.{bias, weight}\r\nproposal_generator.rpn_head.conv.{bias, weight}\r\nproposal_generator.rpn_head.objectness_logits.{bias, weight}\r\nroi_heads.box_head.fc1.{bias, weight}\r\nroi_heads.box_head.fc2.{bias, weight}\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\nroi_heads.mask_head.deconv.{bias, weight}\r\nroi_heads.mask_head.mask_fcn1.{bias, weight}\r\nroi_heads.mask_head.mask_fcn2.{bias, weight}\r\nroi_heads.mask_head.mask_fcn3.{bias, weight}\r\nroi_heads.mask_head.mask_fcn4.{bias, weight}\r\nroi_heads.mask_head.predictor.{bias, weight}\r\nThe checkpoint state_dict contains keys that are not used by the model:\r\n  fc1000.{bias, weight}\r\n  stem.conv1.bias\r\n```\r\n\r\n## Full log \r\n```\r\nTrue\r\n[12/20 11:21:47 d2.engine.defaults]: Model:\r\nGeneralizedRCNN(\r\n  (backbone): FPN(\r\n    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (top_block): LastLevelMaxPool()\r\n    (bottom_up): ResNet(\r\n      (stem): BasicStem(\r\n        (conv1): Conv2d(\r\n          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\r\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n        )\r\n      )\r\n      (res2): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res3): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res4): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (4): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (5): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res5): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n    )\r\n  )\r\n  (proposal_generator): RPN(\r\n    (rpn_head): StandardRPNHead(\r\n      (conv): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n    (anchor_generator): DefaultAnchorGenerator(\r\n      (cell_anchors): BufferList()\r\n    )\r\n  )\r\n  (roi_heads): StandardROIHeads(\r\n    (box_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (box_head): FastRCNNConvFCHead(\r\n      (flatten): Flatten(start_dim=1, end_dim=-1)\r\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\r\n      (fc_relu1): ReLU()\r\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\r\n      (fc_relu2): ReLU()\r\n    )\r\n    (box_predictor): FastRCNNOutputLayers(\r\n      (cls_score): Linear(in_features=1024, out_features=42, bias=True)\r\n      (bbox_pred): Linear(in_features=1024, out_features=164, bias=True)\r\n    )\r\n    (mask_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (mask_head): MaskRCNNConvUpsampleHead(\r\n      (mask_fcn1): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn2): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn3): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn4): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\r\n      (deconv_relu): ReLU()\r\n      (predictor): Conv2d(256, 41, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n  )\r\n)\r\n[12/20 11:21:47 d2.data.datasets.coco]: Loaded 906 images in COCO format from ../../rcshv1.1/train/annotations/train.json\r\n[12/20 11:21:47 d2.data.build]: Removed 0 images with no usable annotations. 906 images left.\r\n[12/20 11:21:47 d2.data.build]: Distribution of instances among all 41 categories:\r\n|   category    | #instances   |   category    | #instances   |   category    | #instances   |\r\n|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\r\n|  ligne_mixte  | 117          | dents_de_re.. | 37           | cedez_passage | 26           |\r\n| passage_pie.. | 443          |     zebra     | 61           |    zigzag     | 108          |\r\n| fleche_droit  | 160          | fleche_droi.. | 62           | fleche_droi.. | 36           |\r\n| fleche_droite | 21           | fleche_raba.. | 0            | fleche_raba.. | 7            |\r\n|    damier     | 29           |  ligne_feux   | 210          | ligne_sens_.. | 87           |\r\n|    panneau    | 69           |    pic_pmr    | 45           |   pic_velo    | 620          |\r\n|   txt_autre   | 36           |    txt_bus    | 32           |   txt_ecole   | 11           |\r\n| txt_livraison | 51           |  txt_payant   | 186          | fleche_gauche | 93           |\r\n|  ligne_stop   | 21           |   txt_velo    | 5            |  ligne_autre  | 151          |\r\n|   sas_velo    | 0            | piste_cycla.. | 0            | ligne_conti.. | 244          |\r\n| ligne_conti.. | 106          | ligne_disco.. | 3072         |   limite_30   | 61           |\r\n|   limite_50   | 0            | pic_voiture.. | 18           | txt_name_of.. | 0            |\r\n|  txt_zone_30  | 19           | velo_chevron  | 147          |     autre     | 172          |\r\n| fleche_autre  | 0            | limite_stat.. | 2207         |               |              |\r\n|     total     | 8770         |               |              |               |              |\r\n[12/20 11:21:47 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\r\n[12/20 11:21:47 d2.data.build]: Using training sampler TrainingSampler\r\n[12/20 11:21:47 d2.data.common]: Serializing 906 elements to byte tensors and concatenating them all ...\r\n[12/20 11:21:47 d2.data.common]: Serialized dataset takes 1.71 MiB\r\n[12/20 11:21:47 d2.checkpoint.c2_model_loading]: Renaming Caffe2 weights ......\r\n[12/20 11:21:47 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.bottom_up:\r\n| Names in Model    | Names in Checkpoint      | Shapes                                          |\r\n|:------------------|:-------------------------|:------------------------------------------------|\r\n| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |\r\n| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\r\n| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\r\n| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\r\n| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\r\n| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\r\n| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |\r\n| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |\r\n| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\r\n| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\r\n| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\r\n| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |\r\n| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\r\n| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\r\n| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\r\n| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\r\n| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\r\n| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\r\n| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\r\n| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\r\n| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\r\n| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\r\n| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\r\n| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |\r\n| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |\r\nSome model parameters or buffers are not found in the checkpoint:\r\nbackbone.fpn_lateral2.{bias, weight}\r\nbackbone.fpn_lateral3.{bias, weight}\r\nbackbone.fpn_lateral4.{bias, weight}\r\nbackbone.fpn_lateral5.{bias, weight}\r\nbackbone.fpn_output2.{bias, weight}\r\nbackbone.fpn_output3.{bias, weight}\r\nbackbone.fpn_output4.{bias, weight}\r\nbackbone.fpn_output5.{bias, weight}\r\nproposal_generator.rpn_head.anchor_deltas.{bias, weight}\r\nproposal_generator.rpn_head.conv.{bias, weight}\r\nproposal_generator.rpn_head.objectness_logits.{bias, weight}\r\nroi_heads.box_head.fc1.{bias, weight}\r\nroi_heads.box_head.fc2.{bias, weight}\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\nroi_heads.mask_head.deconv.{bias, weight}\r\nroi_heads.mask_head.mask_fcn1.{bias, weight}\r\nroi_heads.mask_head.mask_fcn2.{bias, weight}\r\nroi_heads.mask_head.mask_fcn3.{bias, weight}\r\nroi_heads.mask_head.mask_fcn4.{bias, weight}\r\nroi_heads.mask_head.predictor.{bias, weight}\r\nThe checkpoint state_dict contains keys that are not used by the model:\r\n  fc1000.{bias, weight}\r\n  stem.conv1.bias\r\n```\r\n\r\n## Your Environment\r\nabsl-py==2.1.0\r\nantlr4-python3-runtime==4.9.3\r\nappdirs==1.4.4\r\nasttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1733175639022/work\r\nattrs==24.3.0\r\nbackcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\r\nbeautifulsoup4==4.12.3\r\nblack==21.4b2\r\nbleach==6.1.0\r\ncachetools==5.5.0\r\ncertifi==2024.12.14\r\ncharset-normalizer==3.4.0\r\nclick==8.1.7\r\ncloudpickle==3.1.0\r\ncomm @ file:///home/conda/feedstock_root/build_artifacts/comm_1710320294760/work\r\ncontourpy==1.1.1\r\ncycler==0.12.1\r\ndebugpy @ file:///home/conda/feedstock_root/build_artifacts/debugpy_1722923746907/work\r\ndecorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\r\ndefusedxml==0.7.1\r\ndetectron2==0.6+cu113\r\ndocopt==0.6.2\r\nexecuting @ file:///home/conda/feedstock_root/build_artifacts/executing_1725214404607/work\r\nfastjsonschema==2.21.1\r\nfonttools==4.55.3\r\nfuture==1.0.0\r\nfvcore==0.1.5.post20221221\r\ngoogle-auth==2.37.0\r\ngoogle-auth-oauthlib==1.0.0\r\ngrpcio==1.68.1\r\nhydra-core==1.3.2\r\nidna==3.10\r\nimportlib_metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1726082825846/work\r\nimportlib_resources==6.4.5\r\niopath==0.1.9\r\nipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1719845459717/work\r\nipython==8.12.3\r\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work\r\nJinja2==3.1.4\r\njsonschema==4.23.0\r\njsonschema-specifications==2023.12.1\r\njupyter_client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1726610684920/work\r\njupyter_core @ file:///home/conda/feedstock_root/build_artifacts/jupyter_core_1727163409502/work\r\njupyterlab_pygments==0.3.0\r\nkiwisolver==1.4.7\r\nMarkdown==3.7\r\nMarkupSafe==2.1.5\r\nmatplotlib==3.7.5\r\nmatplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1713250518406/work\r\nmistune==3.0.2\r\nmypy-extensions==1.0.0\r\nnbclient==0.10.1\r\nnbconvert==7.16.4\r\nnbformat==5.10.4\r\nnest_asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1705850609492/work\r\nnumpy==1.23.1\r\noauthlib==3.2.2\r\nomegaconf==2.3.0\r\nopencv-python==4.10.0.84\r\npackaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1733203243479/work\r\npandocfilters==1.5.1\r\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1712320355065/work\r\npathspec==0.12.1\r\npexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1706113125309/work\r\npickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\r\nPillow @ file:///home/conda/feedstock_root/build_artifacts/pillow_1675487152289/work\r\npipreqs==0.5.0\r\npkgutil_resolve_name==1.3.10\r\nplatformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1726613481435/work\r\nportalocker==3.0.0\r\nprompt_toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1727341649933/work\r\nprotobuf==5.29.2\r\npsutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1719274595110/work\r\nptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\r\npure_eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1721585709575/work\r\npyasn1==0.6.1\r\npyasn1_modules==0.4.1\r\npycocotools==2.0.7\r\npydot==3.0.3\r\nPygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1714846767233/work\r\npyparsing==3.1.4\r\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1709299778482/work\r\nPyYAML==6.0.2\r\npyzmq @ file:///home/conda/feedstock_root/build_artifacts/pyzmq_1724399083222/work\r\nreferencing==0.35.1\r\nregex==2024.11.6\r\nrequests==2.32.3\r\nrequests-oauthlib==2.0.0\r\nrpds-py==0.20.1\r\nrsa==4.9\r\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\r\nsoupsieve==2.6\r\nstack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work\r\ntabulate==0.9.0\r\ntensorboard==2.14.0\r\ntensorboard-data-server==0.7.2\r\ntermcolor==2.4.0\r\ntinycss2==1.4.0\r\ntoml==0.10.2\r\ntorch==1.10.0\r\ntorchaudio==0.10.0\r\ntorchvision==0.11.0\r\ntornado @ file:///home/conda/feedstock_root/build_artifacts/tornado_1717722826518/work\r\ntqdm==4.67.1\r\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1713535121073/work\r\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1717802530399/work\r\nurllib3==2.2.3\r\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1704731205417/work\r\nwebencodings==0.5.1\r\nWerkzeug==3.0.6\r\nyacs==0.1.8\r\nyarg==0.1.9\r\nzipp==3.20.2",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Your Environment\"; "
      }
    ]
  },
  {
    "issue_number": 5409,
    "title": "Different DDP ranks have varying batch normalization (BN) statistics after the PreciseBN hook because precise_bn in fvcore does not synchronize the batch size across ranks.",
    "author": "jobmart",
    "state": "open",
    "created_at": "2024-12-19T16:09:17Z",
    "updated_at": "2024-12-19T17:12:19Z",
    "labels": [],
    "body": "Bug Report: Different Batch Normalization (BN) Statistics After PreciseBN Hook\r\nSteps to Reproduce:\r\n\r\nClone the repository:\r\nbash\r\nCopy code\r\ngit clone https://github.com/facebookresearch/moco.git\r\ncd moco/detection\r\nRun the following command:\r\nbash\r\nCopy code\r\npython train_net.py \\\r\n--config-file configs/pascal_voc_R_50_C4_24k.yaml \\\r\n--num-gpus 8 \\\r\nOUTPUT_DIR \"temp/train\" \\\r\nSEED 0 \\\r\nSOLVER.MAX_ITER 1\r\nObservations:\r\n\r\nDuring update_bn_stats, the batch sizes differ across Distributed Data Parallel (DDP) ranks.\r\nThis lack of synchronization causes inconsistent BN statistics on different ranks after the PreciseBN hook.\r\nExpected Behavior:\r\n\r\nThe BN statistics should be consistent across all ranks after the PreciseBN hook.\r\nEnvironment:\r\n\r\nOS: Linux\r\nPython Version: 3.8.0\r\nFramework: Detectron2 v0.6\r\nPyTorch: 2.4.1+cu124\r\nGPU: NVIDIA GeForce RTX 4090 (8 GPUs)\r\nCUDA: Version 12.4\r\nOther dependencies:\r\nfvcore: 0.1.5.post20221221\r\niopath: 0.1.9\r\nCommand to Collect Full Environment Details:\r\n\r\nbash\r\nCopy code\r\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py\r\npython collect_env.py\r\nNote:\r\nNo private dataset is required to reproduce this bug. All required resources are publicly available.",
    "comments": [
      {
        "user": "micedevai",
        "body": "After running the `PreciseBN` hook, I observed that different DDP ranks have varying Batch Normalization (BN) statistics. This occurs because `precise_bn` in `fvcore` does not synchronize the batch size across DDP ranks, leading to inconsistent BN statistics across ranks.\r\n\r\n#### Steps to Reproduce:\r\n1. Clone the repository:\r\n    ```bash\r\n    git clone https://github.com/facebookresearch/moco.git\r\n    cd moco/detection\r\n    ```\r\n2. Run the training script:\r\n    ```bash\r\n    python train_net.py --config-file configs/pascal_voc_R_50_C4_24k.yaml --num-gpus 8 OUTPUT_DIR \"temp/train\" SEED 0 SOLVER.MAX_ITER 1\r\n    ```\r\n\r\n#### Observations:\r\nDuring the `update_bn_stats` phase, the batch sizes across DDP ranks are inconsistent. This lack of synchronization causes the BN statistics to differ after the `PreciseBN` hook.\r\n\r\n#### Expected Behavior:\r\nBatch Normalization statistics should be synchronized across all ranks after the PreciseBN hook, ensuring consistent BN statistics across all GPUs.\r\n\r\n#### Environment:\r\n- **OS**: Linux\r\n- **Python Version**: 3.8.0\r\n- **Framework**: Detectron2 v0.6\r\n- **PyTorch Version**: 2.4.1+cu124\r\n- **GPU**: NVIDIA GeForce RTX 4090 (8 GPUs)\r\n- **CUDA Version**: 12.4\r\n- **fvcore**: 0.1.5.post20221221\r\n- **iopath**: 0.1.9\r\n\r\n#### Steps to Collect Full Environment Details:\r\n```bash\r\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py\r\npython collect_env.py\r\n```\r\n\r\n---\r\n\r\nThis should help explain the issue and provide clear steps for reproduction and expectations for a fix."
      }
    ]
  },
  {
    "issue_number": 5408,
    "title": "Memory Leak During Detection Inference on Videos",
    "author": "Pratyasa123",
    "state": "open",
    "created_at": "2024-12-18T08:00:02Z",
    "updated_at": "2024-12-18T08:10:44Z",
    "labels": [],
    "body": "## Issue\r\nWhile performing detection inference on a video, memory leak is observed even after resource cleanup. Memory usage increases over time during inference, eventually causing the process to slow down, while it should stay stable.\r\n```\r\n## Installations\r\n!python -m pip install pyyaml\r\n!pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\n!pip install opencv-python\r\n!pip install torch\r\nimport cv2, os, numpy as np, tqdm, time, math, psutil, torch\r\nfrom collections import defaultdict\r\nfrom google.colab.patches import cv2_imshow\r\nfrom tqdm import tqdm\r\nfrom detectron2.utils.logger import setup_logger\r\nsetup_logger()\r\nfrom detectron2 import model_zoo\r\nfrom detectron2.engine import DefaultPredictor\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.utils.video_visualizer import VideoVisualizer\r\nfrom detectron2.utils.visualizer import ColorMode, Visualizer\r\nfrom detectron2.data import MetadataCatalog\r\n\r\n # Set up configuration and initialize Detectron2 Object Detection predictor\r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\r\ncfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\npredictor = DefaultPredictor(cfg)\r\n\r\ncap = cv2.VideoCapture(\"/content/Input_Video.mp4\") # Open video and initialize video writer\r\nfps = int(cap.get(cv2.CAP_PROP_FPS))\r\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\r\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\r\nvideo_writer = cv2.VideoWriter(\"/content/Output_Video.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\r\n\r\nstart_time = time.time()\r\nframe_idx = 0\r\n\r\n# Process Video\r\nwhile cap.isOpened(): \r\n    success, frame = cap.read()\r\n    if not success: break\r\n\r\n    outputs = predictor(frame)\r\n    boxes = outputs[\"instances\"].to(\"cpu\").pred_boxes if outputs[\"instances\"].has(\"pred_boxes\") else None\r\n    if boxes:\r\n        for box in boxes:\r\n            x1, y1, x2, y2 = map(int, box.tolist())\r\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\r\n    video_writer.write(frame)\r\n    frame_idx += 1\r\n\r\n# Resource Cleanup \r\ncap.release() \r\nvideo_writer.release()\r\ncv2.destroyAllWindows()\r\n```\r\n\r\n## Observed Behaviour\r\nTracing the memory usage before & after the video inference:\r\n`memory_before = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)`\r\n\r\n\"\"Video Inference\"\"\r\n\r\n```\r\nmemory_after = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\r\nprint(f\"Memory difference: {memory_after - memory_before:.2f} MB\")\r\n```\r\nOutput:\r\nMemory difference: 621.10 MB\r\n\r\n## Expected behavior:\r\n\r\nFor purely detection-based inference, the memory usage should remain constant for frames of similar resolution.\r\n\r\n## Environment:\r\n\r\nDetectron2 version: 0.6\r\nPython version: 3.10.12\r\nOS: Ubuntu 22.04\r\nGPU: NVIDIA-SMI 535.104.05 , CUDA 12.2\r\n\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      }
    ]
  },
  {
    "issue_number": 5405,
    "title": "Bug fix with prefetch_factor overwritten ",
    "author": "grantmerz",
    "state": "closed",
    "created_at": "2024-12-10T19:54:34Z",
    "updated_at": "2024-12-18T02:11:52Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Commit [337ca34](https://github.com/facebookresearch/detectron2/commit/337ca3490fa7879ceeeadf6c2b73d67504ff4b4f) addressed an issue with pytorch <2.0 backwards compatibility.  The changes in this commit were overwritten by commit [bce6d72](https://github.com/facebookresearch/detectron2/commit/bce6d7262b1065498481be1d6708c8dbb142975a), which re-introduces the original bug. ",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 4414,
    "title": "Properly convert a Detectron2  model to ONNX for Deployment",
    "author": "vitorbds",
    "state": "closed",
    "created_at": "2022-07-18T22:17:59Z",
    "updated_at": "2024-12-12T15:54:06Z",
    "labels": [
      "documentation"
    ],
    "body": "Hello,\r\n\r\nI am trying to convert a Detectron2 model to ONNX format and make inference without use detectron2 dependence in inference stage.\r\n\r\nEven is possible to find some information about that here :\r\n[](https://detectron2.readthedocs.io/en/latest/tutorials/deployment.html)\r\n_https://detectron2.readthedocs.io/en/latest/tutorials/deployment.html_\r\nThe implementation of this task is constantly being updated and the information found in this documentation is not clear enough to carry out this task .\r\n\r\nSome one can help me with some Demo/Tutorial of how make it ?\r\n\r\n@thiagocrepaldi\r\n\r\nSome information:\r\n\r\nMy model was trained using pre-trained weight from:\r\n\r\n'faster_rcnn_50': {\r\n            'model_path': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',\r\n            'weights_path': 'model_final_280758.pkl'\r\n        },\r\n\r\nI have 4 classes.\r\n\r\nOf course now i have my our weight.\r\nMy model was saved in .pth forrmat.\r\n\r\nI used my our dataset, with image ( .png  )\r\n \r\nCode in Python",
    "comments": [
      {
        "user": "thiagocrepaldi",
        "body": "Hi @vitorbds See if [this example](https://github.com/facebookresearch/detectron2/pull/4205/files#diff-7d768d0cd0f46e5999dcab0cb5f2f7a101611e771ff0483869568aa01e0b5240R144-R173) helps you\r\n\r\nIt exports `COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml` to ONNX and runs inference with it on ONNX Runtime\r\n\r\n![___COCO_Detection_faster_rcnn_R_101_FPN_3x](https://user-images.githubusercontent.com/5469809/180019631-7000b881-550c-4701-954b-0264ea2340ed.svg)"
      },
      {
        "user": "AidenFather",
        "body": "Hi @thiagocrepaldi Does the function in the link can handle `COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml` as well? Can the function export this to ONNX and run inference on ONNX Runtime? Please let me know. Thanks!"
      },
      {
        "user": "thiagocrepaldi",
        "body": "> Hi @thiagocrepaldi Does the function in the link can handle `COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml` as well? Can the function export this to ONNX and run inference on ONNX Runtime? Please let me know. Thanks!\r\n\r\nJust replaced `COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml` by `COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml` and it did run. The graph seemed ok too\r\n\r\n![___COCO_Detection_faster_rcnn_R_101_FPN_3x](https://user-images.githubusercontent.com/5469809/180023266-e75c90f0-6208-44ae-b265-8c1a313b19c2.svg)\r\n\r\n"
      }
    ]
  },
  {
    "issue_number": 5363,
    "title": "Unable to install from source code.",
    "author": "Vawter-001",
    "state": "closed",
    "created_at": "2024-09-12T03:20:42Z",
    "updated_at": "2024-12-06T23:29:22Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "**I tried to install detectron2 by the following codeÔºö**\r\n_git clone https://github.com/facebookresearch/detectron2.git\r\ncd detectron2\r\npython setup.py install_\r\n\r\n\r\n**but I got a errorÔºö**\r\n_gcc: fatal error: Killed signal terminated program cc1plus\r\ncompilation terminated.\r\nerror: command '/usr/bin/gcc' failed with exit code 1_\r\n\r\n**What should I do  to solve it?**",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      },
      {
        "user": "JacobB33",
        "body": "Try making sure your gcc and g++ versions are the same. I had to run this: \r\nsudo apt install gcc-12 g++-12"
      }
    ]
  },
  {
    "issue_number": 5381,
    "title": "I think there should be an update about the gcc version in the doc",
    "author": "jifeng35",
    "state": "open",
    "created_at": "2024-10-17T03:10:24Z",
    "updated_at": "2024-12-06T23:28:22Z",
    "labels": [
      "documentation"
    ],
    "body": "## üìö Documentation Issue\r\n\r\nThis issue category is for problems about existing documentation, not for asking how-to questions.\r\n\r\n* Provide a link to an existing documentation/comment/tutorial:\r\n\r\n* How should the above documentation/comment/tutorial improve:\r\n",
    "comments": [
      {
        "user": "JacobB33",
        "body": "What worked for me was having both gcc and g++ the same version (12) in my case."
      },
      {
        "user": "JacobB33",
        "body": "I had different versions and kept getting \r\n```\r\n      gcc: fatal error: cannot execute ‚Äòcc1plus‚Äô: execvp: No such file or directory\r\n      compilation terminated.\r\n      nvcc fatal   : Failed to preprocess host compiler properties.\r\n  ```"
      }
    ]
  },
  {
    "issue_number": 5206,
    "title": "When converting the Faster RCNN model to ONNX, numerous warning messages are output, including the error 'PermissionError: [Errno 13] Permission denied: 'model.ts'.owing",
    "author": "JeongHanJun",
    "state": "closed",
    "created_at": "2024-02-02T01:35:42Z",
    "updated_at": "2024-12-06T02:14:35Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "\r\n1. Full runnable code or full changes you made:\r\n- https://github.com/facebookresearch/detectron2/tree/main/tools/deploy\r\n- I used the code used for conversion to ONNX provided by detectron2.\r\n- The detailed code is below.\r\n\r\n```\r\n#!/usr/bin/env python\r\n# Copyright (c) Facebook, Inc. and its affiliates.\r\nimport argparse\r\nimport os\r\nfrom typing import Dict, List, Tuple\r\n\r\nimport detectron2.data.transforms as T\r\nimport torch\r\nfrom detectron2.checkpoint import DetectionCheckpointer\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.data import build_detection_test_loader, detection_utils\r\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset, print_csv_format\r\nfrom detectron2.export import (\r\n    dump_torchscript_IR,\r\n    scripting_with_instances,\r\n    STABLE_ONNX_OPSET_VERSION,\r\n    TracingAdapter,\r\n)\r\nfrom detectron2.modeling import build_model, GeneralizedRCNN, RetinaNet\r\nfrom detectron2.modeling.postprocessing import detector_postprocess\r\nfrom detectron2.projects.point_rend import add_pointrend_config\r\nfrom detectron2.structures import Boxes\r\nfrom detectron2.utils.env import TORCH_VERSION\r\nfrom detectron2.utils.file_io import PathManager\r\nfrom detectron2.utils.logger import setup_logger\r\nfrom torch import nn, Tensor\r\n\r\n\r\ndef setup_cfg(args):\r\n    cfg = get_cfg()\r\n    # cuda context is initialized before creating dataloader, so we don't fork anymore\r\n    cfg.DATALOADER.NUM_WORKERS = 0\r\n    add_pointrend_config(cfg)\r\n    cfg.merge_from_file(args.config_file)\r\n    cfg.merge_from_list(args.opts)\r\n    cfg.freeze()\r\n    return cfg\r\n\r\n\r\ndef export_caffe2_tracing(cfg, torch_model, inputs):\r\n    from detectron2.export import Caffe2Tracer\r\n\r\n    tracer = Caffe2Tracer(cfg, torch_model, inputs)\r\n    if args.format == \"caffe2\":\r\n        caffe2_model = tracer.export_caffe2()\r\n        caffe2_model.save_protobuf(args.output)\r\n        # draw the caffe2 graph\r\n        caffe2_model.save_graph(os.path.join(args.output, \"model.svg\"), inputs=inputs)\r\n        return caffe2_model\r\n    elif args.format == \"onnx\":\r\n        import onnx\r\n\r\n        onnx_model = tracer.export_onnx()\r\n        onnx.save(onnx_model, os.path.join(args.output, \"model.onnx\"))\r\n    elif args.format == \"torchscript\":\r\n        ts_model = tracer.export_torchscript()\r\n        with PathManager.open(os.path.join(args.output, \"model.ts\"), \"wb\") as f:\r\n            torch.jit.save(ts_model, f)\r\n        dump_torchscript_IR(ts_model, args.output)\r\n\r\n\r\n# experimental. API not yet final\r\ndef export_scripting(torch_model):\r\n    assert TORCH_VERSION >= (1, 8)\r\n    fields = {\r\n        \"proposal_boxes\": Boxes,\r\n        \"objectness_logits\": Tensor,\r\n        \"pred_boxes\": Boxes,\r\n        \"scores\": Tensor,\r\n        \"pred_classes\": Tensor,\r\n        \"pred_masks\": Tensor,\r\n        \"pred_keypoints\": torch.Tensor,\r\n        \"pred_keypoint_heatmaps\": torch.Tensor,\r\n    }\r\n    assert args.format == \"torchscript\", \"Scripting only supports torchscript format.\"\r\n\r\n    class ScriptableAdapterBase(nn.Module):\r\n        # Use this adapter to workaround https://github.com/pytorch/pytorch/issues/46944\r\n        # by not retuning instances but dicts. Otherwise the exported model is not deployable\r\n        def __init__(self):\r\n            super().__init__()\r\n            self.model = torch_model\r\n            self.eval()\r\n\r\n    if isinstance(torch_model, GeneralizedRCNN):\r\n\r\n        class ScriptableAdapter(ScriptableAdapterBase):\r\n            def forward(\r\n                self, inputs: Tuple[Dict[str, torch.Tensor]]\r\n            ) -> List[Dict[str, Tensor]]:\r\n                instances = self.model.inference(inputs, do_postprocess=False)\r\n                return [i.get_fields() for i in instances]\r\n\r\n    else:\r\n\r\n        class ScriptableAdapter(ScriptableAdapterBase):\r\n            def forward(\r\n                self, inputs: Tuple[Dict[str, torch.Tensor]]\r\n            ) -> List[Dict[str, Tensor]]:\r\n                instances = self.model(inputs)\r\n                return [i.get_fields() for i in instances]\r\n\r\n    ts_model = scripting_with_instances(ScriptableAdapter(), fields)\r\n    with PathManager.open(os.path.join(args.output, \"model.ts\"), \"wb\") as f:\r\n        torch.jit.save(ts_model, f)\r\n    dump_torchscript_IR(ts_model, args.output)\r\n    # TODO inference in Python now missing postprocessing glue code\r\n    return None\r\n\r\n\r\n# experimental. API not yet final\r\ndef export_tracing(torch_model, inputs):\r\n    assert TORCH_VERSION >= (1, 8)\r\n    image = inputs[0][\"image\"]\r\n    inputs = [{\"image\": image}]  # remove other unused keys\r\n\r\n    if isinstance(torch_model, GeneralizedRCNN):\r\n\r\n        def inference(model, inputs):\r\n            # use do_postprocess=False so it returns ROI mask\r\n            inst = model.inference(inputs, do_postprocess=False)[0]\r\n            return [{\"instances\": inst}]\r\n\r\n    else:\r\n        inference = None  # assume that we just call the model directly\r\n\r\n    traceable_model = TracingAdapter(torch_model, inputs, inference)\r\n\r\n    if args.format == \"torchscript\":\r\n        ts_model = torch.jit.trace(traceable_model, (image,))\r\n        with PathManager.open(os.path.join(args.output, \"model.ts\"), \"wb\") as f:\r\n            torch.jit.save(ts_model, f)\r\n        dump_torchscript_IR(ts_model, args.output)\r\n    elif args.format == \"onnx\":\r\n        with PathManager.open(os.path.join(args.output, \"model.onnx\"), \"wb\") as f:\r\n            torch.onnx.export(\r\n                traceable_model, (image,), f, opset_version=STABLE_ONNX_OPSET_VERSION\r\n            )\r\n    logger.info(\"Inputs schema: \" + str(traceable_model.inputs_schema))\r\n    logger.info(\"Outputs schema: \" + str(traceable_model.outputs_schema))\r\n\r\n    if args.format != \"torchscript\":\r\n        return None\r\n    if not isinstance(torch_model, (GeneralizedRCNN, RetinaNet)):\r\n        return None\r\n\r\n    def eval_wrapper(inputs):\r\n        \"\"\"\r\n        The exported model does not contain the final resize step, which is typically\r\n        unused in deployment but needed for evaluation. We add it manually here.\r\n        \"\"\"\r\n        input = inputs[0]\r\n        instances = traceable_model.outputs_schema(ts_model(input[\"image\"]))[0][\r\n            \"instances\"\r\n        ]\r\n        postprocessed = detector_postprocess(instances, input[\"height\"], input[\"width\"])\r\n        return [{\"instances\": postprocessed}]\r\n\r\n    return eval_wrapper\r\n\r\n\r\ndef get_sample_inputs(args):\r\n\r\n    if args.sample_image is None:\r\n        # get a first batch from dataset\r\n        data_loader = build_detection_test_loader(cfg, cfg.DATASETS.TEST[0])\r\n        first_batch = next(iter(data_loader))\r\n        return first_batch\r\n    else:\r\n        # get a sample data\r\n        original_image = detection_utils.read_image(\r\n            args.sample_image, format=cfg.INPUT.FORMAT\r\n        )\r\n        # Do same preprocessing as DefaultPredictor\r\n        aug = T.ResizeShortestEdge(\r\n            [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\r\n        )\r\n        height, width = original_image.shape[:2]\r\n        image = aug.get_transform(original_image).apply_image(original_image)\r\n        image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\r\n\r\n        inputs = {\"image\": image, \"height\": height, \"width\": width}\r\n\r\n        # Sample ready\r\n        sample_inputs = [inputs]\r\n        return sample_inputs\r\n\r\n\r\ndef main() -> None:\r\n    global logger, cfg, args\r\n    parser = argparse.ArgumentParser(description=\"Export a model for deployment.\")\r\n    parser.add_argument(\r\n        \"--format\",\r\n        choices=[\"caffe2\", \"onnx\", \"torchscript\"],\r\n        help=\"output format\",\r\n        default=\"torchscript\",\r\n    )\r\n    parser.add_argument(\r\n        \"--export-method\",\r\n        choices=[\"caffe2_tracing\", \"tracing\", \"scripting\"],\r\n        help=\"Method to export models\",\r\n        default=\"tracing\",\r\n    )\r\n    parser.add_argument(\r\n        \"--config-file\", default=\"\", metavar=\"FILE\", help=\"path to config file\"\r\n    )\r\n    parser.add_argument(\r\n        \"--sample-image\", default=None, type=str, help=\"sample image for input\"\r\n    )\r\n    parser.add_argument(\"--run-eval\", action=\"store_true\")\r\n    parser.add_argument(\"--output\", help=\"output directory for the converted model\")\r\n    parser.add_argument(\r\n        \"opts\",\r\n        help=\"Modify config options using the command-line\",\r\n        default=None,\r\n        nargs=argparse.REMAINDER,\r\n    )\r\n    args = parser.parse_args()\r\n    logger = setup_logger()\r\n    logger.info(\"Command line arguments: \" + str(args))\r\n    PathManager.mkdirs(args.output)\r\n    # Disable re-specialization on new shapes. Otherwise --run-eval will be slow\r\n    torch._C._jit_set_bailout_depth(1)\r\n\r\n    cfg = setup_cfg(args)\r\n\r\n    # create a torch model\r\n    torch_model = build_model(cfg)\r\n    DetectionCheckpointer(torch_model).resume_or_load(cfg.MODEL.WEIGHTS)\r\n    torch_model.eval()\r\n\r\n    # convert and save model\r\n    if args.export_method == \"caffe2_tracing\":\r\n        sample_inputs = get_sample_inputs(args)\r\n        exported_model = export_caffe2_tracing(cfg, torch_model, sample_inputs)\r\n    elif args.export_method == \"scripting\":\r\n        exported_model = export_scripting(torch_model)\r\n    elif args.export_method == \"tracing\":\r\n        sample_inputs = get_sample_inputs(args)\r\n        exported_model = export_tracing(torch_model, sample_inputs)\r\n\r\n    # run evaluation with the converted model\r\n    if args.run_eval:\r\n        assert exported_model is not None, (\r\n            \"Python inference is not yet implemented for \"\r\n            f\"export_method={args.export_method}, format={args.format}.\"\r\n        )\r\n        logger.info(\r\n            \"Running evaluation ... this takes a long time if you export to CPU.\"\r\n        )\r\n        dataset = cfg.DATASETS.TEST[0]\r\n        data_loader = build_detection_test_loader(cfg, dataset)\r\n        # NOTE: hard-coded evaluator. change to the evaluator for your dataset\r\n        evaluator = COCOEvaluator(dataset, output_dir=args.output)\r\n        metrics = inference_on_dataset(exported_model, data_loader, evaluator)\r\n        print_csv_format(metrics)\r\n    logger.info(\"Success.\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()  # pragma: no cover\r\n\r\n```\r\n\r\n\r\n2. What exact command you run:\r\n- The currently trained Faster RCNN model is saved in .pth format.\r\n- What I want to do is convert the trained model in .pth format to a model in .onnx format and save it.\r\n\r\nThe command to execute the above code is as follows.\r\n$ python detectron2/tools/deploy/export_model.py --sample-image sample_image.jpg --config-file unbiased-teacher-v2/faster_rcnn_R_101_DC5_3x_DPC_train_config.json --export-method tracing --output ./ MODEL.WEIGHTS unbiased-teacher-v2/faster_rcnn_R_101_DC5_3x_DPC_model.pth MODEL.DEVICE cpu\r\n\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n[02/02 01:19:50 detectron2]: Command line arguments: Namespace(config_file='unbiased-teacher-v2/faster_rcnn_R_101_DC5_3x_DPC_train_config.json', export_method='tracing', format='torchscript', opts=['MODEL.WEIGHTS', 'unbiased-teacher-v2/faster_rcnn_R_101_DC5_3x_DPC_model.pth', 'MODEL.DEVICE', 'cpu'], output='./', run_eval=False, sample_image='sample_image.jpg')\r\n[02/02 01:19:51 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from unbiased-teacher-v2/faster_rcnn_R_101_DC5_3x_DPC_model.pth ...\r\n/home/appuser/detectron2_repo/detectron2/structures/image_list.py:85: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert t.shape[:-2] == tensors[0].shape[:-2], t.shape\r\n/home/appuser/detectron2_repo/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\r\n/home/appuser/detectron2_repo/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\r\n/home/appuser/detectron2_repo/detectron2/modeling/proposal_generator/proposal_utils.py:106: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if not valid_mask.all():\r\n/home/appuser/detectron2_repo/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\r\n/home/appuser/.local/lib/python3.8/site-packages/torch/tensor.py:587: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\r\n  warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\r\n/home/appuser/detectron2_repo/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert boxes.shape[-1] == 4\r\n/home/appuser/.local/lib/python3.8/site-packages/torch/__init__.py:594: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert condition, message\r\n/home/appuser/detectron2_repo/detectron2/layers/roi_align.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert rois.dim() == 2 and rois.size(1) == 5\r\n/home/appuser/detectron2_repo/detectron2/modeling/roi_heads/fast_rcnn.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if not valid_mask.all():\r\n/home/appuser/detectron2_repo/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\r\n/home/appuser/detectron2_repo/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\r\n/home/appuser/.local/lib/python3.8/site-packages/torch/tensor.py:587: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\r\n  warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\r\n/home/appuser/detectron2_repo/detectron2/modeling/roi_heads/fast_rcnn.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if num_bbox_reg_classes == 1:\r\n/home/appuser/detectron2_repo/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert boxes.shape[-1] == 4\r\n/home/appuser/detectron2_repo/detectron2/structures/image_list.py:85: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert t.shape[:-2] == tensors[0].shape[:-2], t.shape\r\n/home/appuser/detectron2_repo/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\r\n/home/appuser/detectron2_repo/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\r\n/home/appuser/detectron2_repo/detectron2/modeling/proposal_generator/proposal_utils.py:106: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if not valid_mask.all():\r\n/home/appuser/detectron2_repo/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\r\n/home/appuser/.local/lib/python3.8/site-packages/torch/tensor.py:587: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\r\n  warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\r\n/home/appuser/detectron2_repo/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert boxes.shape[-1] == 4\r\n/home/appuser/.local/lib/python3.8/site-packages/torch/__init__.py:594: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert condition, message\r\n/home/appuser/detectron2_repo/detectron2/layers/roi_align.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert rois.dim() == 2 and rois.size(1) == 5\r\n/home/appuser/detectron2_repo/detectron2/modeling/roi_heads/fast_rcnn.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if not valid_mask.all():\r\n/home/appuser/detectron2_repo/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\r\n/home/appuser/detectron2_repo/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\r\n/home/appuser/.local/lib/python3.8/site-packages/torch/tensor.py:587: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\r\n  warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\r\n/home/appuser/detectron2_repo/detectron2/modeling/roi_heads/fast_rcnn.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  if num_bbox_reg_classes == 1:\r\n/home/appuser/detectron2_repo/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n  assert boxes.shape[-1] == 4\r\nTraceback (most recent call last):\r\n  File \"detectron2/tools/deploy/export_model.py\", line 261, in <module>\r\n    main()  # pragma: no cover\r\n  File \"detectron2/tools/deploy/export_model.py\", line 240, in main\r\n    exported_model = export_tracing(torch_model, sample_inputs)\r\n  File \"detectron2/tools/deploy/export_model.py\", line 131, in export_tracing\r\n    with PathManager.open(os.path.join(args.output, \"model.ts\"), \"wb\") as f:\r\n  File \"/home/appuser/.local/lib/python3.8/site-packages/iopath/common/file_io.py\", line 1012, in open\r\n    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore\r\n  File \"/home/appuser/.local/lib/python3.8/site-packages/iopath/common/file_io.py\", line 604, in _open\r\n    return open(  # type: ignore\r\nPermissionError: [Errno 13] Permission denied: 'model.ts'\r\n```\r\n\r\n\r\n5. please simplify the steps as much as possible so they do not require additional resources to run, such as a private dataset.\r\n\r\n- The directory structure and file location were accurately confirmed to be correct.\r\n- I don't know why a file called 'model.ts' appears. I have never saved, used or run any of these files.\r\n- Regarding Permission denied error, we are currently working on the detectron2 docker container, and modification permission has been granted to the user appuser.\r\n\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\n\r\nThe result of executing the above command is as follows.\r\n```\r\n-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.8.10 (default, Nov 22 2023, 10:22:35) [GCC 9.4.0]\r\nnumpy                            1.24.4\r\ndetectron2                       0.6 @/home/appuser/detectron2_repo/detectron2\r\ndetectron2._C                    not built correctly: /home/appuser/detectron2_repo/detectron2/_C.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK2at10TensorBase8data_ptrIdEEPT_v\r\nCompiler ($CXX)                  c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\r\nCUDA compiler                    Build cuda_11.1.TC455_06.29190527_0\r\ndetectron2 arch flags            3.5, 3.7, 5.0, 5.2, 5.3, 6.0, 6.1, 7.0, 7.5\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          1.8.1+cu102 @/home/appuser/.local/lib/python3.8/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0,1                          NVIDIA TITAN RTX (arch=7.5)\r\nDriver version                   525.125.06\r\nCUDA_HOME                        /usr/local/cuda\r\nTORCH_CUDA_ARCH_LIST             Kepler;Kepler+Tesla;Maxwell;Maxwell+Tegra;Pascal;Volta;Turing\r\nPillow                           10.2.0\r\ntorchvision                      0.9.1+cu102 @/home/appuser/.local/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.2.0\r\n-------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 10.2\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\r\n  - CuDNN 7.6.5\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \r\n\r\nTesting NCCL connectivity ... this should not hang.\r\nNCCL succeeded.\r\n```\r\nI don't know why so many warnings occurred, and I don't know how to solve it.\r\nAre various operations used in the Faster RCNN model not supported?\r\nHow can I convert the trained Faster RCNN model to ONNX??\r\nIf there is anyone who has successfully converted the Faster RCNN model to ONNX format, I would appreciate it if you could provide detailed advice.\r\n\r\nAnd I have no idea about 'model.ts'.\r\nWhy does this error occur??\r\nWhat role does ‚Äòmodel.ts‚Äô play when converting to ONNX?\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5170,
    "title": "No object named 'DensePoseROIHeads' found in 'ROI_HEADS' registry!",
    "author": "FurkanGozukara",
    "state": "open",
    "created_at": "2023-12-05T13:18:23Z",
    "updated_at": "2024-12-02T08:36:43Z",
    "labels": [],
    "body": "I have installed and working. But there is literally 0 documentation and examples.\r\n\r\nin the same folder `densepose_rcnn_R_101_FPN_DL_s1x.yaml` located\r\nin the same folder `Base-DensePose-RCNN-FPN.yaml` located\r\nin the same folder `model_final_844d15.pkl` located\r\nin the same folder `R-101.pkl` located\r\n\r\nmy aim is giving a video and generating DensePose video like below\r\n\r\nhttps://github.com/facebookresearch/detectron2/assets/19240467/6feb80f7-9513-4e53-be12-5cd218f0c1c5\r\n\r\nmy script is as below\r\n\r\n```\r\nimport cv2\r\nimport torch\r\nfrom detectron2.engine import DefaultPredictor\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.utils.visualizer import Visualizer\r\nfrom detectron2.data import MetadataCatalog\r\nfrom config import add_densepose_config\r\nfrom detectron2.modeling import ROI_HEADS_REGISTRY\r\n\r\n\r\ndef setup_cfg():\r\n    cfg = get_cfg()\r\n    add_densepose_config(cfg)\r\n    cfg.merge_from_file(\"densepose_rcnn_R_101_FPN_DL_s1x.yaml\")\r\n    cfg.MODEL.WEIGHTS = \"model_final_844d15.pkl\"\r\n    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n    return cfg\r\n\r\ndef process_video(input_video_path, output_video_path, cfg):\r\n    video = cv2.VideoCapture(input_video_path)\r\n    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\r\n    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\r\n    fps = video.get(cv2.CAP_PROP_FPS)\r\n    \r\n    output_video = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\r\n    \r\n    predictor = DefaultPredictor(cfg)\r\n    \r\n    while True:\r\n        ret, frame = video.read()\r\n        if not ret:\r\n            break\r\n\r\n        outputs = predictor(frame)\r\n        v = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\r\n        output = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\r\n        output_frame = output.get_image()[:, :, ::-1]\r\n\r\n        output_video.write(output_frame)\r\n\r\n    video.release()\r\n    output_video.release()\r\n\r\ncfg = setup_cfg()\r\n\r\nprocess_video(\"ex1.mp4\", \"pose1.mp4\", cfg)\r\n```\r\n\r\nthe error i get is like below\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"G:\\magic_animate\\compose_densepose\\pose_maker.py\", line 46, in <module>\r\n    process_video(\"ex1.mp4\", \"pose1.mp4\", cfg)\r\n  File \"G:\\magic_animate\\compose_densepose\\pose_maker.py\", line 27, in process_video\r\n    predictor = DefaultPredictor(cfg)\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\detectron2\\engine\\defaults.py\", line 282, in __init__\r\n    self.model = build_model(self.cfg)\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\detectron2\\modeling\\meta_arch\\build.py\", line 22, in build_model\r\n    model = META_ARCH_REGISTRY.get(meta_arch)(cfg)\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\detectron2\\config\\config.py\", line 189, in wrapped\r\n    explicit_args = _get_args_from_config(from_config_func, *args, **kwargs)\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\detectron2\\config\\config.py\", line 245, in _get_args_from_config\r\n    ret = from_config_func(*args, **kwargs)\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\detectron2\\modeling\\meta_arch\\rcnn.py\", line 77, in from_config\r\n    \"roi_heads\": build_roi_heads(cfg, backbone.output_shape()),\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\detectron2\\modeling\\roi_heads\\roi_heads.py\", line 43, in build_roi_heads\r\n    return ROI_HEADS_REGISTRY.get(name)(cfg, input_shape)\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\fvcore\\common\\registry.py\", line 71, in get\r\n    raise KeyError(\r\nKeyError: \"No object named 'DensePoseROIHeads' found in 'ROI_HEADS' registry!\"\r\nPress any key to continue . . .\r\n```\r\n\r\n\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "FurkanGozukara",
        "body": "I hope you can help me and I am so sorry for pinging you. \r\n\r\n@ppwwyyxx @vkhalidov @MarcSzafraniec @wat3rBro @alexander-kirillov @lyttonhao @wenliangzhao2018 @bowenc0221 @patricklabatut @chenbohua3 @shashimalcse @DomiSchmauser @TysonLinger @cool-xuan  @rbgirshick @SuperIRabbit @MrParosk @angelayi @HannaMao "
      },
      {
        "user": "malleng",
        "body": "you can follow this tutorial : [https://github.com/sangyun884/HR-VITON/issues/45](url)\r\n\r\nHope this helps :) "
      }
    ]
  },
  {
    "issue_number": 5122,
    "title": "Error with installing pyyaml==5.1",
    "author": "Frn1nd0",
    "state": "closed",
    "created_at": "2023-10-18T02:41:24Z",
    "updated_at": "2024-11-27T02:13:54Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Hi everyone, I got issues with running this code in google colab:\r\n\r\n!python -m pip install pyyaml==5.1\r\nimport sys, os, distutils.core\r\n!git clone 'https://github.com/facebookresearch/detectron2'\r\ndist = distutils.core.run_setup(\"./detectron2/setup.py\")\r\n!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\r\nsys.path.insert(0, os.path.abspath('./detectron2'))\r\n\r\nThe output always show:\r\n\r\nCollecting pyyaml==5.1\r\n  Downloading PyYAML-5.1.tar.gz (274 kB)\r\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 274.2/274.2 kB 5.0 MB/s eta 0:00:00\r\n  error: subprocess-exited-with-error\r\n  \r\n  √ó python setup.py egg_info did not run successfully.\r\n  ‚îÇ exit code: 1\r\n  ‚ï∞‚îÄ> See above for output.\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  Preparing metadata (setup.py) ... error\r\nerror: metadata-generation-failed\r\n\r\n√ó Encountered error while generating package metadata.\r\n‚ï∞‚îÄ> See above for output.\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for details.\r\nCloning into 'detectron2'...\r\n\r\nI am still new to python, detectron2, object detection, all these areas, so, I have no idea on what is happening here, can someone please guide me? Thanks",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      },
      {
        "user": "Rusab",
        "body": "Facing the same issue"
      }
    ]
  },
  {
    "issue_number": 5400,
    "title": "AP",
    "author": "DoMaiVietHoang",
    "state": "open",
    "created_at": "2024-11-26T07:06:24Z",
    "updated_at": "2024-11-26T07:06:24Z",
    "labels": [
      "documentation"
    ],
    "body": "## üìö Documentation Issue\r\n\r\nThis issue category is for problems about existing documentation, not for asking how-to questions.\r\n\r\n* Provide a link to an existing documentation/comment/tutorial:\r\n\r\n* How should the above documentation/comment/tutorial improve:\r\n",
    "comments": []
  },
  {
    "issue_number": 5398,
    "title": "Different DDP ranks have different bn_stats after `PreciseBN` hook as precise_bn in fvcore does not synchronize batch_size",
    "author": "guzy0324",
    "state": "open",
    "created_at": "2024-11-25T12:10:17Z",
    "updated_at": "2024-11-25T12:13:36Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\n    https://github.com/facebookresearch/moco/tree/main/detection\r\n2. What exact command you run:\r\n\r\n    ```python\r\n    python detection/train_net.py \\\r\n    --config-file detection/configs/pascal_voc_R_50_C4_24k.yaml \\\r\n    --num-gpus 8 \\\r\n    OUTPUT_DIR \"temp/train\" \\\r\n    SEED 0 \\\r\n    SOLVER.MAX_ITER 1\r\n    ```\r\n\r\n3. __Full logs__ or other relevant observations:\r\n\r\n    In `update_bn_stats`, different ranks have different batch_size as it's not synchronized, resulting in different bn_stats on different ranks after `PreciseBN` hook.\r\n\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\n    no private dataset\r\n\r\n## Expected behavior:\r\n\r\nSame bn_stats after `PreciseBN` hook.\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\n```\r\n-------------------------------  ---------------------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]\r\nnumpy                            1.24.4\r\ndetectron2                       0.6 @/mdata/guzy0324/anaconda3/envs/DICR_new/lib/python3.8/site-packages/detectron2\r\nCompiler                         GCC 11.4\r\nCUDA compiler                    CUDA 12.4\r\ndetectron2 arch flags            8.9\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.4.1+cu124 @/mdata/guzy0324/anaconda3/envs/DICR_new/lib/python3.8/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 4090 D (arch=8.9)\r\nDriver version                   550.54.14\r\nCUDA_HOME                        /usr/local/cuda\r\nPillow                           9.4.0\r\ntorchvision                      0.19.1+cu124 @/mdata/guzy0324/anaconda3/envs/DICR_new/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.9.0\r\n-------------------------------  ---------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201703\r\n  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX512\r\n  - CUDA Runtime 12.4\r\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n  - CuDNN 90.1\r\n  - Magma 2.6.1\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \r\n\r\nTesting NCCL connectivity ... this should not hang.\r\nNCCL succeeded.\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first try to solve it yourself with the instructions in\r\nhttps://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n",
    "comments": []
  },
  {
    "issue_number": 4574,
    "title": "KeyError: 'thing_dataset_id_to_contiguous_id'",
    "author": "david95j2",
    "state": "open",
    "created_at": "2022-09-28T02:09:27Z",
    "updated_at": "2024-11-24T13:45:44Z",
    "labels": [
      "documentation"
    ],
    "body": "Hi guys, i am trying to register and train a `custom panoptic dataset`. I have converted the annotations to coco format.\r\nI have only one concretcrack class and then the following is the format of the `panoptic annotations` \r\n\r\n```\r\n{\r\n \"info\": {...},\r\n \"images\": [\r\n    {\r\n      \"id\": 263,\r\n      \"width\": 4032,\r\n      \"height\": 3024,\r\n      \"file_name\": \"000263.jpg\"\r\n    }, ...\r\n    ... \r\n  ],\r\n  \"annotations\": [\r\n    {\r\n      \"image_id\": 263,\r\n      \"file_name\": \"000263_GT.png\",\r\n      \"segments_info\": [\r\n        {\r\n          \"id\": 39372,\r\n          \"category_id\": 1,\r\n          \"bbox\": [\r\n            0.0,\r\n            803.0,\r\n            4032.0,\r\n            2221.0\r\n          ],\r\n          \"iscrowd\": 0,\r\n          \"area\" : 128846\r\n        }\r\n      ]\r\n    }, ...\r\n    ...\r\n    \"categories\": [\r\n       {\r\n          \"supercateory\": \"korad\",\r\n          \"isthing\" : 1,\r\n          \"id\" : 1,\r\n          \"name\" : \"ConcreteCrack\",\r\n          \"color\": [\r\n               0,\r\n              153,\r\n              204\r\n          ]\r\n       }\r\n     ]\r\n}\r\n```\r\n\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\n```python3\r\n\r\nfrom detectron2.data.datasets import register_coco_panoptic, register_coco_panoptic_separated, load_coco_json\r\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\r\nfrom detectron2.data.datasets.coco_panoptic import load_coco_panoptic_json\r\n\r\nif 'ConcreteCrack' in DatasetCatalog.list():\r\n    DatasetCatalog.remove('ConcreteCrack')\r\n\r\nregister_coco_panoptic(\"ConcreteCrack\",{},\"./datasets/crack/train2022/\",\"./datasets/crack/panoptic_train2022/\",\r\n\"./datasets/crack/annotations/panoptic_train2022.json\",\"./datasets/crack/annotations/instances_train2022.json\")\r\n\r\nMetadataCatalog.get(\"ConcreteCrack\").thing_classes = [\"ConcreteCrack\"]\r\n\r\ndicts = load_coco_panoptic_json('./datasets/crack/annotations/panoptic_train2022.json','./datasets/crack/train2022/',\r\n'./datasets/crack/panoptic_train2022/',{})\r\n\r\n```\r\n\r\n## However I got the following error:\r\n\r\n\r\n```python3\r\n\r\nOutput exceeds the [size limit](command:workbench.action.openSettings?[). Open the full output data [in a text editor](command:workbench.action.openLargeOutput?9c19538d-6c07-4802-8860-9bb873fd1456)\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\nCell In [9], line 16\r\n     13 register_coco_panoptic(\"ConcreteCrack\",{},\"./datasets/crack/train2022/\",\"./datasets/crack/panoptic_train2022/\",\r\n     14 \"./datasets/crack/annotations/panoptic_train2022.json\",\"./datasets/crack/annotations/instances_train2022.json\")\r\n     15 MetadataCatalog.get(\"ConcreteCrack\").thing_classes = [\"ConcreteCrack\"]\r\n---> 16 dicts = load_coco_panoptic_json('./datasets/crack/annotations/panoptic_train2022.json','./datasets/crack/train2022/',\r\n     17 './datasets/crack/panoptic_train2022/',{})\r\n\r\nFile ~/vsc/Mask2Former/seg/lib/python3.8/site-packages/detectron2/data/datasets/coco_panoptic.py:51, in load_coco_panoptic_json(json_file, image_dir, gt_dir, meta)\r\n     49     image_file = os.path.join(image_dir, os.path.splitext(ann[\"file_name\"])[0] + \".jpg\")\r\n     50     label_file = os.path.join(gt_dir, ann[\"file_name\"])\r\n---> 51     segments_info = [_convert_category_id(x, meta) for x in ann[\"segments_info\"]]\r\n     52     ret.append(\r\n     53         {\r\n     54             \"file_name\": image_file,\r\n   (...)\r\n     58         }\r\n     59     )\r\n     60 assert len(ret), f\"No images found in {image_dir}!\"\r\n\r\nFile ~/vsc/Mask2Former/seg/lib/python3.8/site-packages/detectron2/data/datasets/coco_panoptic.py:51, in <listcomp>(.0)\r\n     49     image_file = os.path.join(image_dir, os.path.splitext(ann[\"file_name\"])[0] + \".jpg\")\r\n     50     label_file = os.path.join(gt_dir, ann[\"file_name\"])\r\n---> 51     segments_info = [_convert_category_id(x, meta) for x in ann[\"segments_info\"]]\r\n...\r\n     29             segment_info[\"category_id\"]\r\n     30         ]\r\n     31         segment_info[\"isthing\"] = True\r\n\r\nKeyError: 'thing_dataset_id_to_contiguous_id'\r\n\r\n```\r\n\r\nHow can i fix the problem? thx :)",
    "comments": [
      {
        "user": "Ahmed-G-ElTaher",
        "body": "@david95j2 \r\n**How to solve KeyError: 'thing_dataset_id_to_contiguous_id'**\r\n\r\n> Simply try to add classes to metadata brackets it will work\r\n\r\n\r\n**the normal is to write like that :**\r\nregister_coco_panoptic(\r\ndata_name, **{}** , image_root, panoptic_root, panoptic_json, instances_json=None\r\n)\r\n\r\n**but to solve it write like this :**\r\nregister_coco_panoptic(\r\ndata_name, **{\"thing_classes\": [\"class_1\",\"class_2\",‚Ä¶etc.]}** , image_root, panoptic_root, panoptic_json, instances_json=None\r\n)"
      }
    ]
  },
  {
    "issue_number": 5397,
    "title": "Error in prediction classes array for inference method in evaluator.py",
    "author": "MurielleMardenli200",
    "state": "open",
    "created_at": "2024-11-22T17:17:14Z",
    "updated_at": "2024-11-22T17:20:07Z",
    "labels": [],
    "body": "##  Issue with evaluation:\r\n\r\nI am using detectron in order to make predictions for 1 class only (with a value of 0). When I try to use the `inference_on_dataset()` method, I am getting the following error:\r\n\r\n```\r\n[11/22 12:05:36 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\r\nValidation run stopped due to:A prediction has class=62, but the dataset only has 1 classes and predicted class id should be in [0, 0].\r\n```\r\n\r\nWhen I try to look at outputs variable containing the pred_classes array in the `inference_on_dataset()` method ([line 165](https://github.com/facebookresearch/detectron2/blob/main/detectron2/evaluation/evaluator.py)), I see that it contains an array with some 0 values (correct class prediction), but some random values ranging from 0-100 as well, with the first number of the array being 62 (the number in the error). The number of zeros was shortened for readability:\r\n\r\n```\r\ntensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n         0,  0,  0,  0,  0,  0,  0,  0, 62,  0, 60,  0,  0,  0,  0,  0,  0,  0,\r\n         0,  0,  0,  0,  0,  0,  0, 59,  0,  0,  0,  0,  0,  0,  0,  0,  8,  0,\r\n         0,  0,  0, 60,  0, 53,  0,  0,  0, 25,  0, 60, 73, 58, 63,  0,  4,  0,\r\n        60, 69,  0,  0,  0,  6,  0, 37,  0,  0,  0,  0, 60, 74, 55, 60,  0,  0,\r\n        71,  0, 13,  0,  0, 57, 56,  2, 60, 73, 72, 13,  0, 60, 72, 39, 32, 37,\r\n        60, 37, 59, 13,  5, 50, 53, 73, 60, 60, 59])\r\n```\r\n\r\n\r\nThe `pred_classes` array has the same size as the `pred_boxes` array, which shows it does contain the right predictions. When I replace the `pred_classes` array with an array of the same size filled with zeros (expected behavior), the method does not throw an error anymore. \r\n\r\nHow can I fix this issue?\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      }
    ]
  },
  {
    "issue_number": 5396,
    "title": "Encountering issues while running PointRend in the project",
    "author": "GanYuSuki",
    "state": "closed",
    "created_at": "2024-11-20T14:59:52Z",
    "updated_at": "2024-11-21T02:48:10Z",
    "labels": [],
    "body": "## Instructions To Reproduce the Issue:\r\n1. Full runnable code or full changes you made:\r\n```\r\nimport os\r\nimport detectron2.utils.comm as comm\r\nfrom detectron2.checkpoint import DetectionCheckpointer\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.data import build_detection_train_loader\r\nfrom detectron2.engine import DefaultTrainer, default_setup, default_argument_parser, launch\r\nfrom detectron2.evaluation import COCOEvaluator, verify_results\r\nfrom detectron2.data.datasets import register_coco_instances\r\nfrom point_rend import add_pointrend_config\r\n\r\ndef register_datasets():\r\n         Omit\r\n    print(\"Datasets registered!\")\r\n\r\n\r\nclass Trainer(DefaultTrainer):\r\n    @classmethod\r\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\r\n\r\n        if output_folder is None:\r\n            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\r\n        return COCOEvaluator(dataset_name, cfg, True, output_folder)\r\n\r\n    @classmethod\r\n    def build_train_loader(cls, cfg):\r\n        return build_detection_train_loader(cfg, mapper=None)\r\n\r\ndef setup(args):\r\n    \"\"\"\r\n    Create configs and perform basic setups.\r\n    \"\"\"\r\n    cfg = get_cfg()\r\n    add_pointrend_config(cfg)  \r\n    cfg.merge_from_file(args.config_file)\r\n    cfg.merge_from_list(args.opts)\r\n    cfg.freeze()\r\n    default_setup(cfg, args)\r\n    cfg.DATASETS.TRAIN = (\"LP_train\",)\r\n    cfg.DATASETS.TEST = (\"LP_test\",)\r\n    cfg.DATALOADER.NUM_WORKERS = 1\r\n    cfg.MODEL.WEIGHTS = r\"D:\\python program\\detectron2\\projects\\PointRend\\configs\\InstanceSegmentation\\pointrend_rcnn_R_50_FPN_3x_coco.yaml\"\r\n    cfg.SOLVER.IMS_PER_BATCH = 2\r\n    cfg.SOLVER.BASE_LR = 0.00025\r\n    cfg.SOLVER.MAX_ITER = 100\r\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 \r\n    cfg.OUTPUT_DIR = r\"D:\\python program\\detectron2\\projects\\PointRend\"\r\n    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n    return cfg\r\n\r\ndef main(args):\r\n    register_datasets()  \r\n    cfg = setup(args)\r\n\r\n    if args.eval_only:\r\n        model = Trainer.build_model(cfg)\r\n        DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(cfg.MODEL.WEIGHTS, resume=args.resume)\r\n        res = Trainer.test(cfg, model)\r\n        if comm.is_main_process():\r\n            verify_results(cfg, res)\r\n        return res\r\n\r\n    trainer = Trainer(cfg)\r\n    trainer.resume_or_load(resume=args.resume)\r\n    trainer.train()\r\n\r\nif __name__ == \"__main__\":\r\n    args = default_argument_parser().parse_args()\r\n    launch(main, args.num_gpus, args=(args,))\r\n\r\n```\r\n2. What exact command you run: python train_net.py --config-file configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco.yaml\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n(detectron_env) D:\\python program\\detectron2\\projects\\PointRend>python train_net.py --config-file configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco.yaml\r\nTraceback (most recent call last):\r\n  File \"train_net.py\", line 2, in <module>\r\n    import detectron2.utils.comm as comm\r\nModuleNotFoundError: No module named 'detectron2'\r\n\r\n```\r\n\r\n## Expected behavior:\r\n\r\nHope the program runs normally\r\n\r\n## Environment:\r\n```\r\n(detectron_env) D:\\python program\\detectron2\\projects\\PointRend>conda list\r\n# packages in environment at D:\\anaconda3\\envs\\detectron_env:\r\n#\r\n# Name                    Version                   Build  Channel\r\nabsl-py                   2.1.0                    pypi_0    pypi\r\nantlr4-python3-runtime    4.9.3                    pypi_0    pypi\r\nbeautifulsoup4            4.12.3                   pypi_0    pypi\r\nblack                     24.8.0                   pypi_0    pypi\r\nblas                      2.123                       mkl    conda-forge\r\nblas-devel                3.9.0              23_win64_mkl    conda-forge\r\nca-certificates           2024.9.24            haa95532_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\ncachetools                5.5.0                    pypi_0    pypi\r\ncertifi                   2024.8.30                pypi_0    pypi\r\ncharset-normalizer        3.3.2                    pypi_0    pypi\r\nclick                     8.1.7                    pypi_0    pypi\r\ncloudpickle               3.0.0                    pypi_0    pypi\r\ncmake                     3.31.0.1                 pypi_0    pypi\r\ncolorama                  0.4.6                    pypi_0    pypi\r\ncoloredlogs               15.0.1                   pypi_0    pypi\r\ncontourpy                 1.1.1                    pypi_0    pypi\r\ncudatoolkit               11.1.1              hb074779_13    conda-forge\r\ncycler                    0.12.1                   pypi_0    pypi\r\ncython                    3.0.11                   pypi_0    pypi\r\ndetectron2                0.6                       dev_0    <develop>\r\nfilelock                  3.16.0                   pypi_0    pypi\r\nflatbuffers               24.3.25                  pypi_0    pypi\r\nfonttools                 4.53.1                   pypi_0    pypi\r\nfreetype                  2.12.1               ha860e81_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nfsspec                    2024.10.0                pypi_0    pypi\r\nfvcore                    0.1.5.post20221221          pypi_0    pypi\r\ngdown                     5.2.0                    pypi_0    pypi\r\ngiflib                    5.2.2                h7edc060_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\ngoogle-auth               2.34.0                   pypi_0    pypi\r\ngoogle-auth-oauthlib      1.0.0                    pypi_0    pypi\r\ngrpcio                    1.66.1                   pypi_0    pypi\r\nhumanfriendly             10.0                     pypi_0    pypi\r\nhydra-core                1.3.2                    pypi_0    pypi\r\nidna                      3.8                      pypi_0    pypi\r\nimageio                   2.35.1                   pypi_0    pypi\r\nimgviz                    1.7.5                    pypi_0    pypi\r\nimportlib-metadata        8.4.0                    pypi_0    pypi\r\nimportlib-resources       6.4.4                    pypi_0    pypi\r\nintel-openmp              2024.2.1          h57928b3_1083    conda-forge\r\niopath                    0.1.9                    pypi_0    pypi\r\njinja2                    3.1.4                    pypi_0    pypi\r\njoblib                    1.4.2                    pypi_0    pypi\r\njpeg                      8d                   h8ffe710_1    conda-forge\r\nkiwisolver                1.4.7                    pypi_0    pypi\r\nlabelme                   5.5.0                    pypi_0    pypi\r\nlazy-loader               0.4                      pypi_0    pypi\r\nlerc                      3.0                  hd77b12b_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nlibblas                   3.9.0              23_win64_mkl    conda-forge\r\nlibcblas                  3.9.0              23_win64_mkl    conda-forge\r\nlibdeflate                1.17                 h2bbff1b_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nlibffi                    3.4.4                hd77b12b_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nlibhwloc                  2.11.1          default_h8125262_1000    conda-forge\r\nlibiconv                  1.17                 hcfcfb64_2    conda-forge\r\nliblapack                 3.9.0              23_win64_mkl    conda-forge\r\nliblapacke                3.9.0              23_win64_mkl    conda-forge\r\nlibpng                    1.6.39               h8cc25b3_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nlibtiff                   4.5.0                h8a3f274_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nlibuv                     1.48.0               hcfcfb64_0    conda-forge\r\nlibwebp                   1.4.0                h2466b09_0    conda-forge\r\nlibwebp-base              1.4.0                hcfcfb64_0    conda-forge\r\nlibxml2                   2.13.1               h24da03e_2    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nlibzlib                   1.2.13               h2466b09_6    conda-forge\r\nlz4-c                     1.9.4                h2bbff1b_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nm2w64-gcc-libgfortran     5.3.0                         6    conda-forge\r\nm2w64-gcc-libs            5.3.0                         7    conda-forge\r\nm2w64-gcc-libs-core       5.3.0                         7    conda-forge\r\nm2w64-gmp                 6.1.0                         2    conda-forge\r\nm2w64-libwinpthread-git   5.0.0.4634.697f757               2    conda-forge\r\nmarkdown                  3.7                      pypi_0    pypi\r\nmarkupsafe                2.1.5                    pypi_0    pypi\r\nmatplotlib                3.7.5                    pypi_0    pypi\r\nmkl                       2024.1.0           h66d3029_694    conda-forge\r\nmkl-devel                 2024.1.0           h57928b3_694    conda-forge\r\nmkl-include               2024.1.0           h66d3029_694    conda-forge\r\nmpmath                    1.3.0                    pypi_0    pypi\r\nmsys2-conda-epoch         20160418                      1    conda-forge\r\nmypy-extensions           1.0.0                    pypi_0    pypi\r\nnatsort                   8.4.0                    pypi_0    pypi\r\nnetworkx                  3.1                      pypi_0    pypi\r\nninja                     1.11.1.1                 pypi_0    pypi\r\nnumpy                     1.24.4           py38h1d91fd2_0    conda-forge\r\noauthlib                  3.2.2                    pypi_0    pypi\r\nomegaconf                 2.3.0                    pypi_0    pypi\r\nonnxruntime               1.19.2                   pypi_0    pypi\r\nopencv-python             4.10.0.84                pypi_0    pypi\r\nopenssl                   3.4.0                h2466b09_0    conda-forge\r\npackaging                 24.1                     pypi_0    pypi\r\npathspec                  0.12.1                   pypi_0    pypi\r\npillow                    9.3.0                    pypi_0    pypi\r\npip                       24.2             py38haa95532_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nplatformdirs              4.2.2                    pypi_0    pypi\r\nportalocker               2.10.1                   pypi_0    pypi\r\nprotobuf                  3.20.0                   pypi_0    pypi\r\npthreads-win32            2.9.1                hfa6e2cd_3    conda-forge\r\npyasn1                    0.6.0                    pypi_0    pypi\r\npyasn1-modules            0.4.0                    pypi_0    pypi\r\npycocotools               2.0.7                    pypi_0    pypi\r\npyparsing                 3.1.4                    pypi_0    pypi\r\npyqt5                     5.15.11                  pypi_0    pypi\r\npyqt5-qt5                 5.15.2                   pypi_0    pypi\r\npyqt5-sip                 12.15.0                  pypi_0    pypi\r\npyreadline3               3.4.1                    pypi_0    pypi\r\npysocks                   1.7.1                    pypi_0    pypi\r\npython                    3.8.19               h1aa4202_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\npython-dateutil           2.9.0.post0              pypi_0    pypi\r\npython_abi                3.8                      2_cp38    conda-forge\r\npytorch                   1.8.0           py3.8_cuda11.1_cudnn8_0    pytorch\r\npywavelets                1.4.1                    pypi_0    pypi\r\npywin32                   306                      pypi_0    pypi\r\npyyaml                    6.0.2                    pypi_0    pypi\r\nqtpy                      2.4.1                    pypi_0    pypi\r\nrequests                  2.32.3                   pypi_0    pypi\r\nrequests-oauthlib         2.0.0                    pypi_0    pypi\r\nrsa                       4.9                      pypi_0    pypi\r\nscikit-image              0.21.0                   pypi_0    pypi\r\nscikit-learn              1.3.2                    pypi_0    pypi\r\nscipy                     1.10.1                   pypi_0    pypi\r\nsetuptools                72.1.0           py38haa95532_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nsix                       1.16.0                   pypi_0    pypi\r\nsoupsieve                 2.6                      pypi_0    pypi\r\nsqlite                    3.45.3               h2bbff1b_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nsympy                     1.13.2                   pypi_0    pypi\r\ntabulate                  0.9.0                    pypi_0    pypi\r\ntbb                       2021.12.0            hc790b64_4    conda-forge\r\ntensorboard               2.14.0                   pypi_0    pypi\r\ntensorboard-data-server   0.7.2                    pypi_0    pypi\r\ntensormask                0.1                       dev_0    <develop>\r\ntermcolor                 2.4.0                    pypi_0    pypi\r\nthreadpoolctl             3.5.0                    pypi_0    pypi\r\ntifffile                  2023.7.10                pypi_0    pypi\r\ntk                        8.6.14               h0416ee5_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\ntomli                     2.0.1                    pypi_0    pypi\r\ntorchaudio                0.8.0                      py38    pytorch\r\ntorchvision               0.9.0+cu111              pypi_0    pypi\r\ntqdm                      4.66.5                   pypi_0    pypi\r\ntyping_extensions         4.12.2             pyha770c72_0    conda-forge\r\nucrt                      10.0.22621.0         h57928b3_0    conda-forge\r\nurllib3                   2.2.2                    pypi_0    pypi\r\nvc                        14.40                h2eaa2aa_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nvc14_runtime              14.40.33810         hcc2c482_20    conda-forge\r\nvs2015_runtime            14.40.33810         h3bf8584_20    conda-forge\r\nwerkzeug                  3.0.4                    pypi_0    pypi\r\nwheel                     0.43.0           py38haa95532_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nxz                        5.4.6                h8cc25b3_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\nyacs                      0.1.8                    pypi_0    pypi\r\nzipp                      3.20.1                   pypi_0    pypi\r\nzlib                      1.2.13               h2466b09_6    conda-forge\r\nzstd                      1.5.6                h8880b57_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\r\n\r\n```\r\nThe relevant programs within the projects will all report the same error message.Others can operate normally",
    "comments": []
  },
  {
    "issue_number": 5378,
    "title": "Is this repo still actively maintained? Could it be updated to support more recent torch and CUDA versions.",
    "author": "rwood-97",
    "state": "open",
    "created_at": "2024-10-11T09:12:25Z",
    "updated_at": "2024-11-20T18:50:19Z",
    "labels": [],
    "body": "Hi, \r\n\r\nI am using AdelaiDet + detectron2 on HPC and keep running into issues to due having to use old dependencies. \r\n\r\nIs detectron2 still actively maintained? \r\nCould it be updated to support more recent torch versions and CUDA versions?\r\nIf not, what is the currently recommended alternative to detectron2 for running object detection?\r\n\r\nCheers",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "rwood-97",
        "body": "@stephenyan1231 @'ing you as biggest contributor over the past 6 months!"
      },
      {
        "user": "rodrigopsr",
        "body": "What is you problem exactly? I just compiled and used Detectron2 with PyTorch 2.5.1 Cuda 12.4 (on both Windows with CUDA 12.7 and Linux CUDA 12.4) and had no problemas at all. IDK about AdelaiDet."
      }
    ]
  },
  {
    "issue_number": 5198,
    "title": "Trace is useless",
    "author": "XZRRRRRR",
    "state": "closed",
    "created_at": "2024-01-18T03:25:51Z",
    "updated_at": "2024-11-15T02:12:18Z",
    "labels": [],
    "body": "### Discussed in https://github.com/facebookresearch/detectron2/discussions/5197\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **XZRRRRRR** January 18, 2024</sup>\r\nRecently, when I deployed a Detectron2 model in C++, I tried using the export_tracing function in tools/deploy/export_model.py, and it works fine but the extracted model is only available for case inputs, not for other image inputs (but it is correctly available when it should); When I try to use the export_scripting function, I get an error for modeling/backbone/swin_transformer.py:\r\nRuntimeError: \r\nArguments for call are not valid.\r\nThe following variants are available:\r\n  \r\n  aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a):\r\n  Expected a value of type 'int' for argument '<varargs>' but instead found type 'NoneType'.\r\n\r\nThe original call is:\r\n  File \"/home/xiangzhaorui/python_projects/SwinTextSpotter/detectron2/modeling/backbone/swin_transformer.py\", line 205\r\n        shortcut = x\r\n        x = self.norm1(x)\r\n        x = x.view(B, H, W, C)\r\n            ~~~~~~ <--- HERE\r\n    \r\n        # pad feature maps to multiples of window size\r\n\r\nIs anyone can help me there? Please!!!!!!!!!</div>",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "XZRRRRRR",
        "body": "Instructions To Reproduce the Issue and Full LogsÔºö\r\n(swts) (base) xiangzhaorui@tesla-a40-2:~/python_projects/SwinTextSpotter$ python cpp.py\r\n/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/utils/_contextlib.py:125: UserWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\r\n  warnings.warn(\"Decorating classes is deprecated and will be disabled in \"\r\n/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/TensorShape.cpp:3483.)\r\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\ntest\r\n/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py:266: UserWarning: 'batch_first' was found in ScriptModule constants, but was not actually set in __init__. Consider removing it.\r\n  warnings.warn(\"'{}' was found in ScriptModule constants, \"\r\nTraceback (most recent call last):\r\n  File \"/home/xiangzhaorui/python_projects/SwinTextSpotter/cpp.py\", line 88, in <module>\r\n    export_scripting(torch_model)\r\n  File \"/home/xiangzhaorui/python_projects/SwinTextSpotter/cpp.py\", line 51, in export_scripting\r\n    ts_model = scripting_with_instances(ScriptableAdapter(), fields)\r\n  File \"/home/xiangzhaorui/python_projects/SwinTextSpotter/detectron2/export/torchscript.py\", line 58, in scripting_with_instances\r\n    scripted_model = torch.jit.script(model)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_script.py\", line 1284, in script\r\n    return torch.jit._recursive.create_script_module(\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 480, in create_script_module\r\n    return create_script_module_impl(nn_module, concrete_type, stubs_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 542, in create_script_module_impl\r\n    script_module = torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_script.py\", line 614, in _construct\r\n    init_fn(script_module)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 520, in init_fn\r\n    scripted = create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 542, in create_script_module_impl\r\n    script_module = torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_script.py\", line 614, in _construct\r\n    init_fn(script_module)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 520, in init_fn\r\n    scripted = create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 542, in create_script_module_impl\r\n    script_module = torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_script.py\", line 614, in _construct\r\n    init_fn(script_module)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 520, in init_fn\r\n    scripted = create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 542, in create_script_module_impl\r\n    script_module = torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_script.py\", line 614, in _construct\r\n    init_fn(script_module)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 520, in init_fn\r\n    scripted = create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 542, in create_script_module_impl\r\n    script_module = torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_script.py\", line 614, in _construct\r\n    init_fn(script_module)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 520, in init_fn\r\n    scripted = create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 542, in create_script_module_impl\r\n    script_module = torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_script.py\", line 614, in _construct\r\n    init_fn(script_module)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 520, in init_fn\r\n    scripted = create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 542, in create_script_module_impl\r\n    script_module = torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_script.py\", line 614, in _construct\r\n    init_fn(script_module)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 520, in init_fn\r\n    scripted = create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 546, in create_script_module_impl\r\n    create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)\r\n  File \"/home/xiangzhaorui/miniconda3/envs/swts/lib/python3.10/site-packages/torch/jit/_recursive.py\", line 397, in create_methods_and_properties_from_stubs\r\n    concrete_type._create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)\r\nRuntimeError: \r\nArguments for call are not valid.\r\nThe following variants are available:\r\n  \r\n  aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a):\r\n  Expected a value of type 'int' for argument '<varargs>' but instead found type 'NoneType'.\r\n\r\nThe original call is:\r\n  File \"/home/xiangzhaorui/python_projects/SwinTextSpotter/detectron2/modeling/backbone/swin_transformer.py\", line 205\r\n        shortcut = x\r\n        x = self.norm1(x)\r\n        x = x.view(B, H, W, C)\r\n            ~~~~~~ <--- HERE\r\n    \r\n        # pad feature maps to multiples of window size\r\nmy code:\r\nimport argparse\r\nimport torch\r\nfrom detectron2.modeling import GeneralizedRCNN,RetinaNet,build_model\r\nfrom projects.SWINTS.swints import add_SWINTS_config\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.data.detection_utils import read_image\r\nfrom detectron2.checkpoint.detection_checkpoint import DetectionCheckpointer\r\nfrom detectron2.data import build_detection_test_loader\r\nfrom detectron2.structures import Boxes\r\nfrom typing import Dict, List, Tuple\r\nfrom torch import Tensor\r\nfrom detectron2.export import dump_torchscript_IR, scripting_with_instances\r\nfrom detectron2.utils.testing import reload_script_model\r\nimport torch.nn as nn\r\n\r\n\r\ndef export_scripting(torch_model):\r\n\r\n    fields = {\"pred_boxes\": Boxes, \"scores\": torch.Tensor,\"pred_masks\": torch.Tensor,\"pred_rec\":torch.Tensor}\r\n\r\n    class ScriptableAdapterBase(nn.Module):\r\n        def __init__(self):\r\n            super().__init__()\r\n            self.model = torch_model\r\n            self.eval()\r\n\r\n    if isinstance(torch_model, GeneralizedRCNN):\r\n\r\n        class ScriptableAdapter(ScriptableAdapterBase):\r\n            def forward(self, inputs: Tuple[Dict[str, torch.Tensor]]) -> List[Dict[str, Tensor]]:\r\n                instances = self.model.inference(inputs, do_postprocess=False)\r\n                return [i.get_fields() for i in instances]\r\n\r\n    else:\r\n        class ScriptableAdapter(ScriptableAdapterBase):\r\n            def forward(self, inputs: Tuple[Dict[str, torch.Tensor]]) -> List[Dict[str, Tensor]]:\r\n                instances = self.model(inputs)\r\n                return [i.get_fields() for i in instances]\r\n\r\n    ts_model = scripting_with_instances(ScriptableAdapter(), fields)\r\n    return None\r\n\r\n\r\ndef setup_cfg(args):\r\n    cfg = get_cfg()\r\n    add_SWINTS_config(cfg)\r\n    cfg.merge_from_file(args.config_file)\r\n    cfg.MODEL.RETINANET.SCORE_THRESH_TEST = args.confidence_threshold\r\n    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = args.confidence_threshold\r\n    cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = args.confidence_threshold\r\n    cfg.MODEL.WEIGHTS = '/home/xiangzhaorui/python_projects/SwinTextSpotter/output/model_final.pth'\r\n    cfg.MODEL.DEVICE = 'cuda:0'\r\n    cfg.freeze()\r\n    return cfg\r\n\r\nparser = argparse.ArgumentParser(description=\"Export a model for deployment.\")\r\nparser.add_argument(\"--config-file\", default=\"\", metavar=\"FILE\", help=\"path to config file\")\r\nparser.add_argument('--confidence-threshold', type=float, help='Confidence threshold')\r\nargs_string = \"--config-file /home/xiangzhaorui/python_projects/SwinTextSpotter/projects/SWINTS/configs/myconfig.yaml --confidence-threshold 0.4\"\r\nargs_list = args_string.split()\r\nargs = parser.parse_args(args_list)\r\ncfg = setup_cfg(args)\r\ntorch_model = build_model(cfg)\r\nDetectionCheckpointer(torch_model).resume_or_load(cfg.MODEL.WEIGHTS)\r\ntorch_model.eval()\r\n\r\nexport_scripting(torch_model)\r\n    \r\nMy env:\r\nUbuntu 18.04 with conda env:\r\nabsl-py                   2.0.0                    pypi_0    pypi\r\naiohttp                   3.9.1                    pypi_0    pypi\r\naiosignal                 1.3.1                    pypi_0    pypi\r\nantlr4-python3-runtime    4.9.3                    pypi_0    pypi\r\nasttokens                 2.4.1              pyhd8ed1ab_0    conda-forge\r\nasync-timeout             4.0.3                    pypi_0    pypi\r\nbeautifulsoup4            4.12.2                   pypi_0    pypi\r\nbinutils_impl_linux-64    2.36.1               h193b22a_2    conda-forge\r\nbinutils_linux-64         2.36                hf3e587d_10    conda-forge\r\nblack                     24.1a1                   pypi_0    pypi\r\nblas                      1.0                         mkl    defaults\r\nbrotli-python             1.0.9           py310h6a678d5_7    defaults\r\nbzip2                     1.0.8                h7b6447c_0    defaults\r\nc-ares                    1.19.1               h5eee18b_0    defaults\r\nca-certificates           2023.12.12           h06a4308_0    defaults\r\ncachetools                5.3.2                    pypi_0    pypi\r\ncertifi                   2023.11.17      py310h06a4308_0    defaults\r\ncffi                      1.16.0          py310h5eee18b_0    defaults\r\ncharset-normalizer        3.3.2                    pypi_0    pypi\r\nclick                     8.1.7           py310h06a4308_0    defaults\r\ncloudpickle               3.0.0                    pypi_0    pypi\r\ncmake                     3.26.4               hcfe8598_0    conda-forge\r\ncoloredlogs               15.0.1                   pypi_0    pypi\r\ncomm                      0.2.1              pyhd8ed1ab_0    conda-forge\r\ncontourpy                 1.2.0                    pypi_0    pypi\r\ncryptography              41.0.7          py310hdda0065_0    defaults\r\ncuda                      11.7.0                        0    nvidia/label/cuda-11.7.0\r\ncuda-cccl                 11.7.58              hc415cf5_0    nvidia/label/cuda-11.7.0\r\ncuda-command-line-tools   11.7.0                        0    nvidia/label/cuda-11.7.0\r\ncuda-compiler             11.7.0                        0    nvidia/label/cuda-11.7.0\r\ncuda-cudart               11.7.99                       0    nvidia\r\ncuda-cudart-dev           11.7.60              h6a7c232_0    nvidia/label/cuda-11.7.0\r\ncuda-cuobjdump            11.7.50              h28cc80a_0    nvidia/label/cuda-11.7.0\r\ncuda-cupti                11.7.101                      0    nvidia\r\ncuda-cuxxfilt             11.7.50              hb365495_0    nvidia/label/cuda-11.7.0\r\ncuda-demo-suite           11.7.50                       0    nvidia/label/cuda-11.7.0\r\ncuda-documentation        11.7.50                       0    nvidia/label/cuda-11.7.0\r\ncuda-driver-dev           11.7.60                       0    nvidia/label/cuda-11.7.0\r\ncuda-gdb                  11.7.50              h4a0ac72_0    nvidia/label/cuda-11.7.0\r\ncuda-libraries            11.7.1                        0    nvidia\r\ncuda-libraries-dev        11.7.0                        0    nvidia/label/cuda-11.7.0\r\ncuda-memcheck             11.7.50              hc446b2b_0    nvidia/label/cuda-11.7.0\r\ncuda-nsight               11.7.50                       0    nvidia/label/cuda-11.7.0\r\ncuda-nsight-compute       11.7.0                        0    nvidia/label/cuda-11.7.0\r\ncuda-nvcc                 11.7.64                       0    nvidia/label/cuda-11.7.0\r\ncuda-nvdisasm             11.7.50              h5bd0695_0    nvidia/label/cuda-11.7.0\r\ncuda-nvml-dev             11.7.50              h3af1343_0    nvidia/label/cuda-11.7.0\r\ncuda-nvprof               11.7.50              h7a2404d_0    nvidia/label/cuda-11.7.0\r\ncuda-nvprune              11.7.50              h7add7b4_0    nvidia/label/cuda-11.7.0\r\ncuda-nvrtc                11.7.99                       0    nvidia\r\ncuda-nvrtc-dev            11.7.50              heada363_0    nvidia/label/cuda-11.7.0\r\ncuda-nvtx                 11.7.91                       0    nvidia\r\ncuda-nvvp                 11.7.50              hd2289d5_0    nvidia/label/cuda-11.7.0\r\ncuda-runtime              11.7.1                        0    nvidia\r\ncuda-sanitizer-api        11.7.50              hb424887_0    nvidia/label/cuda-11.7.0\r\ncuda-toolkit              11.7.0                        0    nvidia/label/cuda-11.7.0\r\ncuda-tools                11.7.0                        0    nvidia/label/cuda-11.7.0\r\ncuda-version              11.7                 h67201e3_2    conda-forge\r\ncuda-visual-tools         11.7.0                        0    nvidia/label/cuda-11.7.0\r\ncudatoolkit               11.7.1              h4bc3d14_12    conda-forge\r\ncudatoolkit-dev           11.7.0               h1de0b5d_6    conda-forge\r\ncudnn                     8.9.2.26               cuda11_0    defaults\r\ncusparselt                0.5.0.1              hd5ab71f_1    conda-forge\r\ncycler                    0.12.1                   pypi_0    pypi\r\ndebugpy                   1.8.0           py310hc6cd4ac_1    conda-forge\r\ndecorator                 5.1.1              pyhd8ed1ab_0    conda-forge\r\ndetectron2                0.4                      pypi_0    pypi\r\ndpcpp-cpp-rt              2024.0.2            intel_49895    intel\r\ndpcpp_cpp_rt              2024.0.2            intel_49895    intel\r\neditdistance              0.6.2                    pypi_0    pypi\r\nefficientnet-pytorch      0.7.1                    pypi_0    pypi\r\nexceptiongroup            1.2.0              pyhd8ed1ab_0    conda-forge\r\nexecuting                 2.0.1              pyhd8ed1ab_0    conda-forge\r\nexpat                     2.5.0                h6a678d5_0    defaults\r\nffmpeg                    4.3                  hf484d3e_0    pytorch\r\nfilelock                  3.13.1          py310h06a4308_0    defaults\r\nflatbuffers               23.5.26                  pypi_0    pypi\r\nfonttools                 4.47.0                   pypi_0    pypi\r\nfreetype                  2.12.1               h4a9f257_0    defaults\r\nfrozenlist                1.4.1                    pypi_0    pypi\r\nfsspec                    2023.12.2                pypi_0    pypi\r\nfuture                    0.18.3                   pypi_0    pypi\r\ngcc_impl_linux-64         10.3.0              hf2f2afa_16    conda-forge\r\ngcc_linux-64              10.3.0              hc39de41_10    conda-forge\r\ngds-tools                 1.3.0.44                      0    nvidia/label/cuda-11.7.0\r\ngiflib                    5.2.1                h5eee18b_3    defaults\r\ngmp                       6.2.1                h295c915_3    defaults\r\ngmpy2                     2.1.2           py310heeb90bb_0    defaults\r\ngnutls                    3.6.15               he1e5248_0    defaults\r\ngoogle                    3.0.0                    pypi_0    pypi\r\ngoogle-auth               2.26.1                   pypi_0    pypi\r\ngoogle-auth-oauthlib      1.2.0                    pypi_0    pypi\r\ngrpcio                    1.60.0                   pypi_0    pypi\r\ngxx_impl_linux-64         10.3.0              hf2f2afa_16    conda-forge\r\ngxx_linux-64              10.3.0              h2593f52_10    conda-forge\r\nhuggingface-hub           0.20.2                   pypi_0    pypi\r\nhumanfriendly             10.0                     pypi_0    pypi\r\nhydra-core                1.3.2                    pypi_0    pypi\r\nicc_rt                    2024.0.2            intel_49895    intel\r\nidna                      3.6                      pypi_0    pypi\r\nimageio                   2.33.1                   pypi_0    pypi\r\nimportlib-metadata        7.0.1              pyha770c72_0    conda-forge\r\nimportlib_metadata        7.0.1                hd8ed1ab_0    conda-forge\r\nintel-cmplr-lib-rt        2024.0.2            intel_49895    intel\r\nintel-cmplr-lic-rt        2024.0.2            intel_49895    intel\r\nintel-opencl-rt           2024.0.2            intel_49895    intel\r\nintel-openmp              2024.0.2            intel_49895    intel\r\nintelpython               2024.0.0                      0    intel\r\niopath                    0.1.7                    pypi_0    pypi\r\nipykernel                 6.28.0             pyhd33586a_0    conda-forge\r\nipython                   8.20.0             pyh707e725_0    conda-forge\r\njedi                      0.19.1             pyhd8ed1ab_0    conda-forge\r\njinja2                    3.1.2           py310h06a4308_0    defaults\r\njpeg                      9e                   h5eee18b_1    defaults\r\njupyter_client            8.6.0              pyhd8ed1ab_0    conda-forge\r\njupyter_core              5.7.1           py310hff52083_0    conda-forge\r\nkernel-headers_linux-64   3.10.0              h57e8cba_10    defaults\r\nkiwisolver                1.4.5                    pypi_0    pypi\r\nkrb5                      1.20.1               h143b758_1    defaults\r\nlame                      3.100                h7b6447c_0    defaults\r\nlcms2                     2.12                 h3be6417_0    defaults\r\nld_impl_linux-64          2.36.1               hea4e1c9_2    conda-forge\r\nlerc                      3.0                  h295c915_0    defaults\r\nlibcublas                 11.10.3.66                    0    nvidia\r\nlibcublas-dev             11.10.1.25           h0c8ac2b_0    nvidia/label/cuda-11.7.0\r\nlibcufft                  10.7.2.124           h4fbf590_0    nvidia\r\nlibcufft-dev              10.7.2.50            h59a5ac8_0    nvidia/label/cuda-11.7.0\r\nlibcufile                 1.8.1.2                       0    nvidia\r\nlibcufile-dev             1.3.0.44                      0    nvidia/label/cuda-11.7.0\r\nlibcurand                 10.3.4.107                    0    nvidia\r\nlibcurand-dev             10.2.10.50           hd49a9cd_0    nvidia/label/cuda-11.7.0\r\nlibcurl                   8.5.0                h251f7ec_0    defaults\r\nlibcusolver               11.4.0.1                      0    nvidia\r\nlibcusolver-dev           11.3.5.50            hc6eba6f_0    nvidia/label/cuda-11.7.0\r\nlibcusparse               11.7.4.91                     0    nvidia\r\nlibcusparse-dev           11.7.3.50            hc644b96_0    nvidia/label/cuda-11.7.0\r\nlibcxx                    16.0.6               h00ab1b0_0    conda-forge\r\nlibcxxabi                 16.0.6               ha770c72_0    conda-forge\r\nlibdeflate                1.17                 h5eee18b_1    defaults\r\nlibedit                   3.1.20230828         h5eee18b_0    defaults\r\nlibev                     4.33                 h7f8727e_1    defaults\r\nlibexpat                  2.5.0                hcb278e6_1    conda-forge\r\nlibffi                    3.4.4                h6a678d5_0    defaults\r\nlibgcc-devel_linux-64     10.3.0              he6cfe16_16    conda-forge\r\nlibgcc-ng                 13.2.0               h807b86a_3    conda-forge\r\nlibgomp                   13.2.0               h807b86a_3    conda-forge\r\nlibiconv                  1.16                 h7f8727e_2    defaults\r\nlibidn2                   2.3.4                h5eee18b_0    defaults\r\nlibnghttp2                1.57.0               h2d74bed_0    defaults\r\nlibnpp                    11.7.4.75                     0    nvidia\r\nlibnpp-dev                11.7.3.21            hb6476a9_0    nvidia/label/cuda-11.7.0\r\nlibnuma                   2.0.16               h0b41bf4_1    conda-forge\r\nlibnvjpeg                 11.8.0.2                      0    nvidia\r\nlibnvjpeg-dev             11.7.2.34            h2e48410_0    nvidia/label/cuda-11.7.0\r\nlibpng                    1.6.39               h5eee18b_0    defaults\r\nlibprotobuf               3.20.3               he621ea3_0    defaults\r\nlibsanitizer              10.3.0              h26c7422_16    conda-forge\r\nlibsodium                 1.0.18               h36c2ea0_1    conda-forge\r\nlibssh2                   1.10.0               hdbd6064_2    defaults\r\nlibstdcxx-devel_linux-64  10.3.0              he6cfe16_16    conda-forge\r\nlibstdcxx-ng              13.2.0               h7e041cc_3    conda-forge\r\nlibtasn1                  4.19.0               h5eee18b_0    defaults\r\nlibtiff                   4.5.1                h6a678d5_0    defaults\r\nlibunistring              0.9.10               h27cfd23_0    defaults\r\nlibuuid                   1.41.5               h5eee18b_0    defaults\r\nlibuv                     1.39.0               h516909a_0    conda-forge\r\nlibwebp                   1.2.4                h11a3e52_1    defaults\r\nlibwebp-base              1.2.4                h5eee18b_1    defaults\r\nlibzlib                   1.2.13               hd590300_5    conda-forge\r\nlz4-c                     1.9.4                h6a678d5_0    defaults\r\nmarkdown                  3.5.1                    pypi_0    pypi\r\nmarkupsafe                2.1.3                    pypi_0    pypi\r\nmatplotlib                3.8.2                    pypi_0    pypi\r\nmatplotlib-inline         0.1.6              pyhd8ed1ab_0    conda-forge\r\nmkl                       2024.0.0            intel_49656    intel\r\nmkl-include               2024.0.0            intel_49656    intel\r\nmkl-service               2.4.0           py310h3539a15_41    intel\r\nmkl-static                2024.0.0            intel_49656    intel\r\nmkl_fft                   1.3.6           py310h1d81ff8_61    intel\r\nmkl_random                1.2.2           py310h5a378b4_81    intel\r\nmkl_umath                 0.1.1           py310h2b1685c_91    intel\r\nmpc                       1.1.0                h10f8cd9_1    defaults\r\nmpfr                      4.0.2                hb69a4c5_1    defaults\r\nmpmath                    1.3.0           py310h06a4308_0    defaults\r\nmultidict                 6.0.4                    pypi_0    pypi\r\nmypy-extensions           1.0.0                    pypi_0    pypi\r\nnccl                      2.19.4.1             h0800d71_0    conda-forge\r\nncurses                   6.4                  h6a678d5_0    defaults\r\nnest-asyncio              1.5.8              pyhd8ed1ab_0    conda-forge\r\nnettle                    3.7.3                hbbd107a_1    defaults\r\nnetworkx                  3.1             py310h06a4308_0    defaults\r\nnsight-compute            2022.2.0.13                   0    nvidia/label/cuda-11.7.0\r\nnumpy                     1.24.3          py310ha320b8e_5    intel\r\nnumpy-base                1.24.3          py310hbac2b65_5    intel\r\noauthlib                  3.2.2                    pypi_0    pypi\r\nolefile                   0.46               pyhd3eb1b0_0    defaults\r\nomegaconf                 2.3.0                    pypi_0    pypi\r\nonednn                    3.3              omp_hc847620_3    conda-forge\r\nonnx                      1.15.0                   pypi_0    pypi\r\nonnx-caffe2               1.0.0           pyhd8ed1ab_1004    conda-forge\r\nonnxruntime-gpu           1.16.3                   pypi_0    pypi\r\nopencv-python             4.9.0.80                 pypi_0    pypi\r\nopenh264                  2.1.1                h4ff587b_0    defaults\r\nopenjpeg                  2.4.0                h3ad879b_0    defaults\r\nopenssl                   3.2.0                hd590300_1    conda-forge\r\npackaging                 23.2               pyhd8ed1ab_0    conda-forge\r\nparso                     0.8.3              pyhd8ed1ab_0    conda-forge\r\npathspec                  0.12.1                   pypi_0    pypi\r\npexpect                   4.8.0              pyh1a96a4e_2    conda-forge\r\npickleshare               0.7.5                   py_1003    conda-forge\r\npillow                    8.4.0                    pypi_0    pypi\r\npip                       23.3.1          py310h06a4308_0    defaults\r\nplatformdirs              4.1.0              pyhd8ed1ab_0    conda-forge\r\npolygon3                  3.0.9.1                  pypi_0    pypi\r\nportalocker               2.8.2                    pypi_0    pypi\r\nprompt-toolkit            3.0.42             pyha770c72_0    conda-forge\r\nprotobuf                  4.23.4                   pypi_0    pypi\r\npsutil                    5.9.7           py310h2372a71_0    conda-forge\r\nptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\r\npure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\r\npyasn1                    0.5.1                    pypi_0    pypi\r\npyasn1-modules            0.3.0                    pypi_0    pypi\r\npycocotools               2.0.7                    pypi_0    pypi\r\npycparser                 2.21               pyhd3eb1b0_0    defaults\r\npydot                     2.0.0                    pypi_0    pypi\r\npygments                  2.17.2             pyhd8ed1ab_0    conda-forge\r\npyopenssl                 23.2.0          py310h06a4308_0    defaults\r\npyparsing                 3.1.1                    pypi_0    pypi\r\npysocks                   1.7.1           py310h06a4308_0    defaults\r\npython                    3.10.13              h955ad1f_0    defaults\r\npython-dateutil           2.8.2                    pypi_0    pypi\r\npython_abi                3.10                    2_cp310    conda-forge\r\npytorch                   2.0.1           py3.10_cuda11.7_cudnn8.5.0_0    pytorch\r\npytorch-cuda              11.7                 h778d358_5    pytorch\r\npytorch-mutex             1.0                        cuda    pytorch\r\npyyaml                    6.0.1           py310h5eee18b_0    defaults\r\npyzmq                     25.1.2          py310h795f18f_0    conda-forge\r\nrapidfuzz                 2.15.1                   pypi_0    pypi\r\nreadline                  8.2                  h5eee18b_0    defaults\r\nrequests                  2.31.0          py310h06a4308_0    defaults\r\nrequests-oauthlib         1.3.1                    pypi_0    pypi\r\nrhash                     1.4.3                hdbd6064_0    defaults\r\nrsa                       4.9                      pypi_0    pypi\r\nsafetensors               0.4.1                    pypi_0    pypi\r\nscipy                     1.11.4                   pypi_0    pypi\r\nsetuptools                68.2.2          py310h06a4308_0    defaults\r\nshapely                   2.0.2                    pypi_0    pypi\r\nsix                       1.16.0                   pypi_0    pypi\r\nsoupsieve                 2.5                      pypi_0    pypi\r\nsqlite                    3.41.2               h5eee18b_0    defaults\r\nstack_data                0.6.2              pyhd8ed1ab_0    conda-forge\r\nsympy                     1.12            py310h06a4308_0    defaults\r\nsysroot_linux-64          2.17                h57e8cba_10    defaults\r\ntabulate                  0.9.0                    pypi_0    pypi\r\ntbb                       2021.8.0             hdb19cb5_0    defaults\r\ntbb4py                    2021.8.0        py310hdb19cb5_0    defaults\r\ntensorboard               2.15.1                   pypi_0    pypi\r\ntensorboard-data-server   0.7.2                    pypi_0    pypi\r\ntermcolor                 2.4.0                    pypi_0    pypi\r\ntimm                      0.9.12                   pypi_0    pypi\r\ntk                        8.6.12               h1ccaba5_0    defaults\r\ntomli                     2.0.1                    pypi_0    pypi\r\ntorchaudio                2.0.2               py310_cu117    pytorch\r\ntorchtriton               2.0.0                     py310    pytorch\r\ntorchvision               0.15.2              py310_cu117    pytorch\r\ntornado                   6.3.3           py310h2372a71_1    conda-forge\r\ntqdm                      4.66.1                   pypi_0    pypi\r\ntraitlets                 5.14.1             pyhd8ed1ab_0    conda-forge\r\ntyping-extensions         4.9.0                    pypi_0    pypi\r\ntyping_extensions         4.7.1           py310h06a4308_0    defaults\r\ntzdata                    2023d                h04d1e81_0    defaults\r\nurllib3                   2.1.0                    pypi_0    pypi\r\nwcwidth                   0.2.13             pyhd8ed1ab_0    conda-forge\r\nwerkzeug                  3.0.1                    pypi_0    pypi\r\nwheel                     0.41.2          py310h06a4308_0    defaults\r\nxz                        5.4.5                h5eee18b_0    defaults\r\nyacs                      0.1.8                    pypi_0    pypi\r\nyaml                      0.2.5                h7b6447c_0    defaults\r\nyarl                      1.9.4                    pypi_0    pypi\r\nzeromq                    4.3.5                h59595ed_0    conda-forge\r\nzipp                      3.17.0             pyhd8ed1ab_0    conda-forge\r\nzlib                      1.2.13               hd590300_5    conda-forge\r\nzstd                      1.5.5                hc292b87_0    defaults"
      }
    ]
  },
  {
    "issue_number": 5392,
    "title": "Bugs in Pascal Context GT visualization",
    "author": "LWShowTime",
    "state": "open",
    "created_at": "2024-11-14T08:50:37Z",
    "updated_at": "2024-11-14T08:50:55Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\n\r\ndetails can refer to the failed pull requests: https://github.com/facebookresearch/detectron2/pull/5391\r\n\r\n2. What exact command you run:\r\nI run the tools/visualize_data and find the visualize.py in utils have an out of date numpy dtype.\r\n\r\n4. __Full logs__ or other relevant observations:\r\n\r\n![image](https://github.com/user-attachments/assets/cfdedf68-d43f-40d1-b7a1-26df60162f60)\r\nthis should be train(id:359) howver is overflow and refer to fly(id:359-256=103)\r\n\r\n5. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\nexpect to handle classes more than 256, however Pascal Context 459 is overflow.\r\n\r\n## Environment:\r\n\r\nPython 3.10   numpy 1.22.4  torch 1.13.1\r\n",
    "comments": []
  },
  {
    "issue_number": 5196,
    "title": "Detectron2 keypoints Rcnn Training using VertexAI custom Training Job",
    "author": "RiccardoMaistri",
    "state": "closed",
    "created_at": "2024-01-16T11:22:58Z",
    "updated_at": "2024-11-13T02:07:34Z",
    "labels": [],
    "body": "I am having issue trying to start a training of keypointsRcnn using detectron2 framework (exploiting the custom training job with vertex)\r\n\r\nI forked the [detectron2-train-docker-image](us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-detectron2-serve) provided by Vertex and added the support for keypoints Rcnn, the addition regard a few files and cfg of detectron2 (regarding keypoints).\r\n\r\nThe thing that blows my mind is that if I run the code locally, everything works fine.\r\nThe dataset contains two images with three keypoints each.\r\nThe cfg added are simply:\r\n\r\n MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS=3\r\n\r\nTEST.KEYPOINT_OKS_SIGMAS\"\r\n\r\nand `keypoint_names` and `keypoint_flip_map` in dataset Metadata\r\n\r\n\r\nIf i run using container docker deployement the traceback error is this:\r\n\r\n```\r\n\r\n   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n     \"__main__\", mod_spec)\r\n   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\r\n     exec(code, run_globals)\r\n   File \"/home/appuser/trainer/task.py\", line 295, in <module>\r\n     args=(args,),\r\n   File \"/home/appuser/detectron2_repo/detectron2/engine/launch.py\", line 82, in launch\r\n     main_func(*args)\r\n   File \"/home/appuser/trainer/task.py\", line 279, in main\r\n     trainer.train()\r\n   File \"/home/appuser/detectron2_repo/detectron2/engine/defaults.py\", line 484, in train\r\n     super().train(self.start_iter, self.max_iter)\r\n   File \"/home/appuser/detectron2_repo/detectron2/engine/train_loop.py\", line 149, in train\r\n     self.run_step()\r\n   File \"/home/appuser/detectron2_repo/detectron2/engine/defaults.py\", line 494, in run_step\r\n     self._trainer.run_step()\r\n   File \"/home/appuser/detectron2_repo/detectron2/engine/train_loop.py\", line 267, in run_step\r\n     data = next(self._data_loader_iter)\r\n   File \"/home/appuser/detectron2_repo/detectron2/data/common.py\", line 234, in __iter__\r\n     for d in self.dataset:\r\n   File \"/home/appuser/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\r\n     data = self._next_data()\r\n   File \"/home/appuser/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\r\n     return self._process_data(data)\r\n   File \"/home/appuser/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\r\n     data.reraise()\r\n   File \"/home/appuser/.local/lib/python3.7/site-packages/torch/_utils.py\", line 434, in reraise\r\n     raise exception\r\n ValueError: Caught ValueError in DataLoader worker process 1.\r\n Original Traceback (most recent call last):\r\n   File \"/home/appuser/.local/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\r\n     data = fetcher.fetch(index)\r\n   File \"/home/appuser/.local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\r\n     data.append(next(self.dataset_iter))\r\n   File \"/home/appuser/detectron2_repo/detectron2/data/common.py\", line 201, in __iter__\r\n     yield self.dataset[idx]\r\n File \"/home/appuser/detectron2_repo/detectron2/data/common.py\", line 90, in __getitem__\r\n   data = self._map_func(self._dataset[cur_idx])\r\n File \"/home/appuser/detectron2_repo/detectron2/utils/serialize.py\", line 26, in __call__\r\n   return self._obj(*args, **kwargs)\r\n File \"/home/appuser/detectron2_repo/detectron2/data/dataset_mapper.py\", line 189, in __call__\r\n   self._transform_annotations(dataset_dict, transforms, image_shape)\r\n File \"/home/appuser/detectron2_repo/detectron2/data/dataset_mapper.py\", line 128, in _transform_annotations\r\n   for obj in dataset_dict.pop(\"annotations\")\r\n File \"/home/appuser/detectron2_repo/detectron2/data/dataset_mapper.py\", line 129, in <listcomp>\r\n   if obj.get(\"iscrowd\", 0) == 0\r\n File \"/home/appuser/detectron2_repo/detectron2/data/detection_utils.py\", line 314, in transform_instance_annotations\r\n   annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\r\n File \"/home/appuser/detectron2_repo/detectron2/data/detection_utils.py\", line 360, in transform_keypoint_annotations\r\n \"contains {} points!\".format(len(keypoints), \r\n ValueError: Keypoint data has 3 points, but metadata contains 15 points!\r\n```\r\n\r\n\r\n\r\n## Specifications\r\n\r\n- Version:python 3.8, detectron2 v0.6\r\n- Platform:Ubuntu 20.24",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      }
    ]
  },
  {
    "issue_number": 5387,
    "title": "Please read & provide the following",
    "author": "DNOCHA3",
    "state": "closed",
    "created_at": "2024-11-04T23:39:13Z",
    "updated_at": "2024-11-12T02:06:08Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "## Instructions To Reproduce the üêõ Bug:\n1. Full runnable code or full changes you made:\n```\nIf making changes to the project itself, please use output of the following command:\ngit rev-parse HEAD; git diff\n\n<put code or diff here>\n```\n2. What exact command you run:\n3. __Full logs__ or other relevant observations:\n```\n<put logs here>\n```\n4. please simplify the steps as much as possible so they do not require additional resources to\n   run, such as a private dataset.\n\n## Expected behavior:\n\nIf there are no obvious error in \"full logs\" provided above,\nplease tell us the expected behavior.\n\n## Environment:\n\nProvide your environment information using the following command:\n```\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\n```\n\nIf your issue looks like an installation issue / environment issue,\nplease first try to solve it yourself with the instructions in\nhttps://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5193,
    "title": "semantic segmentation evaluation",
    "author": "msdkarimi",
    "state": "closed",
    "created_at": "2024-01-09T17:40:19Z",
    "updated_at": "2024-11-12T02:06:06Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "During the validation what would be the value of stuff_classes, it must be the list of panoptic categories? \r\nIn validation I've got an error for confusion matrix computation, it expects to have a corresponding category in pixels but it breaks.\r\nMy question is that, every time I want to validate my model, I have to fill stuff classes with the classes which model is trained for? right? \r\nThanks in advance. ",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5191,
    "title": "[Detectron2]I train the model 'FCOS' and after 54999 iter ,the model evaluate on the 'coco_val_2017' can only achieve mAP=0?",
    "author": "FLYDust1101",
    "state": "closed",
    "created_at": "2024-01-07T05:18:30Z",
    "updated_at": "2024-11-10T02:10:03Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "When it train, it run the code run_step() -- class TrainBase\r\nWhen it eval, use detectron2.evaluation.inference_on_dataset\r\n\r\n**### But why it outputs mAP=0 like:  ???**\r\n**_Outputs:_**\r\n[01/07 12:42:58 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\r\nLoading and preparing results...\r\nDONE (t=0.14s)\r\ncreating index...\r\nindex created!\r\n[01/07 12:42:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\r\n[01/07 12:43:04 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 5.97 seconds.\r\n[01/07 12:43:04 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\r\n[01/07 12:43:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.67 seconds.\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\r\n[01/07 12:43:05 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \r\n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\r\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\r\n| 0.000 | 0.001  |  nan   | 0.000 | 0.001 | 0.000 |\r\n[01/07 12:43:05 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\r\n[01/07 12:43:05 d2.evaluation.coco_evaluation]: Per-category bbox AP: \r\n| category      | AP    | category     | AP    | category       | AP    |\r\n|:--------------|:------|:-------------|:------|:---------------|:------|\r\n| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |\r\n| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |\r\n| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |\r\n| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |\r\n| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |\r\n| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |\r\n| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |\r\n| bear          | 0.000 | zebra        | 0.000 | giraffe        | 0.000 |\r\n| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |\r\n| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |\r\n| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |\r\n| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |\r\n| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |\r\n| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |\r\n| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |\r\n| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |\r\n| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |\r\n| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |\r\n| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |\r\n| couch         | 0.000 | potted plant | 0.000 | bed            | 0.019 |\r\n| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |\r\n| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |\r\n| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |\r\n| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |\r\n| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |\r\n| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |\r\n| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |\r\nOrderedDict([('bbox', {'AP': 0.00024255127390703898, 'AP50': 0.0005441165354860879, 'AP75': nan, 'APs': 0.0, 'APm': 0.0005503269509548185, 'APl': 0.0004439579840761939, 'AP-person': 0.0, 'AP-bicycle': 0.0, 'AP-car': 0.0, 'AP-motorcycle': 0.0, 'AP-airplane': 0.0, 'AP-bus': 0.0, 'AP-train': 0.0, 'AP-truck': 0.0, 'AP-boat': 0.0, 'AP-traffic light': 0.0, 'AP-fire hydrant': 0.0, 'AP-stop sign': 0.0, 'AP-parking meter': 5.207820307022969e-05, 'AP-bench': 0.0, 'AP-bird': 0.0, 'AP-cat': 0.0, 'AP-dog': 0.0, 'AP-horse': 0.0, 'AP-sheep': 0.0, 'AP-cow': 0.0, 'AP-elephant': 0.0, 'AP-bear': 0.0, 'AP-zebra': 0.0, 'AP-giraffe': 0.0, 'AP-backpack': 0.0, 'AP-umbrella': 0.0, 'AP-handbag': 0.0, 'AP-tie': 0.0, 'AP-suitcase': 0.0, 'AP-frisbee': 0.0, 'AP-skis': 0.0, 'AP-snowboard': 0.0, 'AP-sports ball': 0.0, 'AP-kite': 0.0, 'AP-baseball bat': 0.0, 'AP-baseball glove': 0.0, 'AP-skateboard': 0.0, 'AP-surfboard': 0.0, 'AP-tennis racket': 0.0, 'AP-bottle': 0.0, 'AP-wine glass': 0.0, 'AP-cup': 0.0, 'AP-fork': 0.0, 'AP-knife': 0.0, 'AP-spoon': 0.0, 'AP-bowl': 0.0, 'AP-banana': 0.0, 'AP-apple': 0.0, 'AP-sandwich': 0.0, 'AP-orange': 0.0, 'AP-broccoli': 0.0, 'AP-carrot': 0.0, 'AP-hot dog': 0.0, 'AP-pizza': 0.0, 'AP-donut': 0.0, 'AP-cake': 0.0, 'AP-chair': 0.0, 'AP-couch': 0.0, 'AP-potted plant': 0.0, 'AP-bed': 0.019352023709492887, 'AP-dining table': 0.0, 'AP-toilet': 0.0, 'AP-tv': 0.0, 'AP-laptop': 0.0, 'AP-mouse': 0.0, 'AP-remote': 0.0, 'AP-keyboard': 0.0, 'AP-cell phone': 0.0, 'AP-microwave': 0.0, 'AP-oven': 0.0, 'AP-toaster': 0.0, 'AP-sink': 0.0, 'AP-refrigerator': 0.0, 'AP-book': 0.0, 'AP-clock': 0.0, 'AP-vase': 0.0, 'AP-scissors': 0.0, 'AP-teddy bear': 0.0, 'AP-hair drier': 0.0, 'AP-toothbrush': 0.0})])\r\n\r\nProcess finished with exit code 0\r\n\r\n\r\n### **Configs:**\r\nCUDNN_BENCHMARK: false\r\nDATALOADER:\r\n  ASPECT_RATIO_GROUPING: true\r\n  FILTER_EMPTY_ANNOTATIONS: true\r\n  NUM_WORKERS: 0\r\n  REPEAT_THRESHOLD: 0.0\r\n  SAMPLER_TRAIN: TrainingSampler\r\nDATASETS:\r\n  CROSS_DATASET: false\r\n  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\r\n  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\r\n  PROPOSAL_FILES_TEST: []\r\n  PROPOSAL_FILES_TRAIN: []\r\n  TEST:\r\n  - coco_2017_val\r\n  TRAIN:\r\n  - coco_2017_train\r\n  TRAIN_LABEL: &id001\r\n  - coco_2017_train\r\n  TRAIN_UNLABEL: *id001\r\nGLOBAL:\r\n  HACK: 1.0\r\nINPUT:\r\n  CROP:\r\n    ENABLED: false\r\n    SIZE:\r\n    - 0.9\r\n    - 0.9\r\n    TYPE: relative_range\r\n  FORMAT: BGR\r\n  MASK_FORMAT: polygon\r\n  MAX_SIZE_TEST: 1333\r\n  MAX_SIZE_TRAIN: 1333\r\n  MIN_SIZE_TEST: 800\r\n  MIN_SIZE_TRAIN:\r\n  - 400\r\n  - 1200\r\n  MIN_SIZE_TRAIN_SAMPLING: range\r\n  RANDOM_FLIP: horizontal\r\nMODEL:\r\n  ANCHOR_GENERATOR:\r\n    ANGLES:\r\n    - - -90\r\n      - 0\r\n      - 90\r\n    ASPECT_RATIOS:\r\n    - - 0.5\r\n      - 1.0\r\n      - 2.0\r\n    NAME: DefaultAnchorGenerator\r\n    OFFSET: 0.0\r\n    SIZES:\r\n    - - 32\r\n      - 64\r\n      - 128\r\n      - 256\r\n      - 512\r\n  BACKBONE:\r\n    FREEZE_AT: 2\r\n    NAME: build_fcos_resnet_fpn_backbone\r\n  DEVICE: cuda\r\n  FCOS:\r\n    CENTER_SAMPLE: true\r\n    DFL_WEIGHT: 0.0\r\n    FPN_STRIDES:\r\n    - 8\r\n    - 16\r\n    - 32\r\n    - 64\r\n    - 128\r\n    INFERENCE_TH_TEST: 0.05\r\n    INFERENCE_TH_TRAIN: 0.05\r\n    IN_FEATURES:\r\n    - p3\r\n    - p4\r\n    - p5\r\n    - p6\r\n    - p7\r\n    KLLOSS_WEIGHT: 0.05\r\n    KL_LOSS: true\r\n    KL_LOSS_TYPE: nlloss\r\n    LOC_FUN_ALL: mean\r\n    LOC_LOSS_TYPE: giou\r\n    LOSS_ALPHA: 0.25\r\n    LOSS_GAMMA: 2.0\r\n    NMS_CRITERIA_REG_TRAIN: cls_n_loc\r\n    NMS_CRITERIA_TEST: cls_n_ctr\r\n    NMS_CRITERIA_TRAIN: cls\r\n    NMS_TH: 0.6\r\n    NORM: GN\r\n    NUM_BOX_CONVS: 4\r\n    NUM_CLASSES: 80\r\n    NUM_CLS_CONVS: 4\r\n    NUM_SHARE_CONVS: 0\r\n    POST_NMS_TOPK_TEST: 100\r\n    POST_NMS_TOPK_TRAIN: 100\r\n    POS_RADIUS: 1.5\r\n    PRE_NMS_TOPK_TEST: 1000\r\n    PRE_NMS_TOPK_TRAIN: 1000\r\n    PRIOR_PROB: 0.01\r\n    QUALITY_EST: centerness\r\n    REG_DISCRETE: true\r\n    REG_MAX: 16\r\n    SIZES_OF_INTEREST:\r\n    - 64\r\n    - 128\r\n    - 256\r\n    - 512\r\n    THRESH_WITH_CTR: false\r\n    TOP_LEVELS: 2\r\n    TSBETTER_CLS_SIGMA: 0.0\r\n    UNIFY_CTRCLS: false\r\n    USE_DEFORMABLE: false\r\n    USE_RELU: true\r\n    USE_SCALE: true\r\n    YIELD_PROPOSAL: true\r\n  FPN:\r\n    FUSE_TYPE: sum\r\n    IN_FEATURES:\r\n    - res3\r\n    - res4\r\n    - res5\r\n    NORM: ''\r\n    OUT_CHANNELS: 256\r\n  KEYPOINT_ON: false\r\n  LOAD_PROPOSALS: false\r\n  MASK_ON: false\r\n  META_ARCHITECTURE: OneStageDetector\r\n  PANOPTIC_FPN:\r\n    COMBINE:\r\n      ENABLED: true\r\n      INSTANCES_CONFIDENCE_THRESH: 0.5\r\n      OVERLAP_THRESH: 0.5\r\n      STUFF_AREA_LIMIT: 4096\r\n    INSTANCE_LOSS_WEIGHT: 1.0\r\n  PIXEL_MEAN:\r\n  - 103.53\r\n  - 116.28\r\n  - 123.675\r\n  PIXEL_STD:\r\n  - 1.0\r\n  - 1.0\r\n  - 1.0\r\n  PROPOSAL_GENERATOR:\r\n    MIN_SIZE: 0\r\n    NAME: FCOS\r\n  RESNETS:\r\n    DEFORM_MODULATED: false\r\n    DEFORM_NUM_GROUPS: 1\r\n    DEFORM_ON_PER_STAGE:\r\n    - false\r\n    - false\r\n    - false\r\n    - false\r\n    DEPTH: 50\r\n    NORM: FrozenBN\r\n    NUM_GROUPS: 1\r\n    OUT_FEATURES:\r\n    - res3\r\n    - res4\r\n    - res5\r\n    RES2_OUT_CHANNELS: 256\r\n    RES5_DILATION: 1\r\n    STEM_OUT_CHANNELS: 64\r\n    STRIDE_IN_1X1: true\r\n    WIDTH_PER_GROUP: 64\r\n  RETINANET:\r\n    BBOX_REG_LOSS_TYPE: smooth_l1\r\n    BBOX_REG_WEIGHTS: &id002\r\n    - 1.0\r\n    - 1.0\r\n    - 1.0\r\n    - 1.0\r\n    FOCAL_LOSS_ALPHA: 0.25\r\n    FOCAL_LOSS_GAMMA: 2.0\r\n    IN_FEATURES:\r\n    - p3\r\n    - p4\r\n    - p5\r\n    - p6\r\n    - p7\r\n    IOU_LABELS:\r\n    - 0\r\n    - -1\r\n    - 1\r\n    IOU_THRESHOLDS:\r\n    - 0.4\r\n    - 0.5\r\n    NMS_THRESH_TEST: 0.5\r\n    NORM: ''\r\n    NUM_CLASSES: 80\r\n    NUM_CONVS: 4\r\n    PRIOR_PROB: 0.01\r\n    SCORE_THRESH_TEST: 0.05\r\n    SMOOTH_L1_LOSS_BETA: 0.1\r\n    TOPK_CANDIDATES_TEST: 1000\r\n  ROI_BOX_CASCADE_HEAD:\r\n    BBOX_REG_WEIGHTS:\r\n    - - 10.0\r\n      - 10.0\r\n      - 5.0\r\n      - 5.0\r\n    - - 20.0\r\n      - 20.0\r\n      - 10.0\r\n      - 10.0\r\n    - - 30.0\r\n      - 30.0\r\n      - 15.0\r\n      - 15.0\r\n    IOUS:\r\n    - 0.5\r\n    - 0.6\r\n    - 0.7\r\n  ROI_BOX_HEAD:\r\n    BBOX_REG_LOSS_TYPE: smooth_l1\r\n    BBOX_REG_LOSS_WEIGHT: 1.0\r\n    BBOX_REG_WEIGHTS:\r\n    - 10.0\r\n    - 10.0\r\n    - 5.0\r\n    - 5.0\r\n    CLS_AGNOSTIC_BBOX_REG: false\r\n    CONV_DIM: 256\r\n    FC_DIM: 1024\r\n    FED_LOSS_FREQ_WEIGHT_POWER: 0.5\r\n    FED_LOSS_NUM_CLASSES: 50\r\n    NAME: ''\r\n    NORM: ''\r\n    NUM_CONV: 0\r\n    NUM_FC: 0\r\n    POOLER_RESOLUTION: 14\r\n    POOLER_SAMPLING_RATIO: 0\r\n    POOLER_TYPE: ROIAlignV2\r\n    SMOOTH_L1_BETA: 0.0\r\n    TRAIN_ON_PRED_BOXES: false\r\n    USE_FED_LOSS: false\r\n    USE_SIGMOID_CE: false\r\n  ROI_HEADS:\r\n    BATCH_SIZE_PER_IMAGE: 512\r\n    IN_FEATURES:\r\n    - res4\r\n    IOU_LABELS:\r\n    - 0\r\n    - 1\r\n    IOU_THRESHOLDS:\r\n    - 0.5\r\n    NAME: Res5ROIHeads\r\n    NMS_THRESH_TEST: 0.5\r\n    NUM_CLASSES: 80\r\n    POSITIVE_FRACTION: 0.25\r\n    PROPOSAL_APPEND_GT: true\r\n    SCORE_THRESH_TEST: 0.05\r\n  ROI_KEYPOINT_HEAD:\r\n    CONV_DIMS:\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    LOSS_WEIGHT: 1.0\r\n    MIN_KEYPOINTS_PER_IMAGE: 1\r\n    NAME: KRCNNConvDeconvUpsampleHead\r\n    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true\r\n    NUM_KEYPOINTS: 17\r\n    POOLER_RESOLUTION: 14\r\n    POOLER_SAMPLING_RATIO: 0\r\n    POOLER_TYPE: ROIAlignV2\r\n  ROI_MASK_HEAD:\r\n    CLS_AGNOSTIC_MASK: false\r\n    CONV_DIM: 256\r\n    NAME: MaskRCNNConvUpsampleHead\r\n    NORM: ''\r\n    NUM_CONV: 0\r\n    POOLER_RESOLUTION: 14\r\n    POOLER_SAMPLING_RATIO: 0\r\n    POOLER_TYPE: ROIAlignV2\r\n  RPN:\r\n    BATCH_SIZE_PER_IMAGE: 256\r\n    BBOX_REG_LOSS_TYPE: smooth_l1\r\n    BBOX_REG_LOSS_WEIGHT: 1.0\r\n    BBOX_REG_WEIGHTS: *id002\r\n    BOUNDARY_THRESH: -1\r\n    CONV_DIMS:\r\n    - -1\r\n    HEAD_NAME: StandardRPNHead\r\n    IN_FEATURES:\r\n    - res4\r\n    IOU_LABELS:\r\n    - 0\r\n    - -1\r\n    - 1\r\n    IOU_THRESHOLDS:\r\n    - 0.3\r\n    - 0.7\r\n    LOSS_WEIGHT: 1.0\r\n    NMS_THRESH: 0.7\r\n    POSITIVE_FRACTION: 0.5\r\n    POST_NMS_TOPK_TEST: 1000\r\n    POST_NMS_TOPK_TRAIN: 2000\r\n    PRE_NMS_TOPK_TEST: 6000\r\n    PRE_NMS_TOPK_TRAIN: 12000\r\n    SMOOTH_L1_BETA: 0.0\r\n  SEM_SEG_HEAD:\r\n    COMMON_STRIDE: 4\r\n    CONVS_DIM: 128\r\n    IGNORE_VALUE: 255\r\n    IN_FEATURES:\r\n    - p2\r\n    - p3\r\n    - p4\r\n    - p5\r\n    LOSS_WEIGHT: 1.0\r\n    NAME: SemSegFPNHead\r\n    NORM: GN\r\n    NUM_CLASSES: 54\r\n  WEIGHTS: D:\\lyb\\demo1\\output_0\\model_0029999.pth\r\nOUTPUT_DIR: ./output\r\nSEED: -1\r\nSOLVER:\r\n  AMP:\r\n    ENABLED: false\r\n  BASE_LR: 0.01\r\n  BASE_LR_END: 0.0\r\n  BIAS_LR_FACTOR: 1.0\r\n  CHECKPOINT_PERIOD: 5000\r\n  CLIP_GRADIENTS:\r\n    CLIP_TYPE: value\r\n    CLIP_VALUE: 1.0\r\n    ENABLED: false\r\n    NORM_TYPE: 2.0\r\n  GAMMA: 0.1\r\n  IMS_PER_BATCH: 4\r\n  LR_SCHEDULER_NAME: WarmupMultiStepLR\r\n  MAX_ITER: 90000\r\n  MOMENTUM: 0.9\r\n  NESTEROV: false\r\n  NUM_DECAYS: 3\r\n  REFERENCE_WORLD_SIZE: 0\r\n  RESCALE_INTERVAL: false\r\n  STEPS:\r\n  - 60000\r\n  - 80000\r\n  WARMUP_FACTOR: 0.001\r\n  WARMUP_ITERS: 1000\r\n  WARMUP_METHOD: linear\r\n  WEIGHT_DECAY: 0.0001\r\n  WEIGHT_DECAY_BIAS: null\r\n  WEIGHT_DECAY_NORM: 0.0\r\nTEST:\r\n  AUG:\r\n    ENABLED: false\r\n    FLIP: true\r\n    MAX_SIZE: 4000\r\n    MIN_SIZES:\r\n    - 400\r\n    - 500\r\n    - 600\r\n    - 700\r\n    - 800\r\n    - 900\r\n    - 1000\r\n    - 1100\r\n    - 1200\r\n  DETECTIONS_PER_IMAGE: 100\r\n  EVALUATOR: COCOeval\r\n  EVAL_PERIOD: 2000\r\n  EXPECTED_RESULTS: []\r\n  KEYPOINT_OKS_SIGMAS: []\r\n  PRECISE_BN:\r\n    ENABLED: false\r\n    NUM_ITER: 200\r\n  VAL_LOSS: false\r\nVERSION: 2\r\nVIS_PERIOD: 0\r\n\r\n### ** Codes**\r\nfrom trainer import FCOSTrainer\r\nimport os\r\nfrom modeling.fcos.FCOS import FCOS\r\nfrom detectron2.layers import ShapeSpec\r\n\r\nfrom detectron2.checkpoint import DetectionCheckpointer\r\nfrom detectron2.engine import default_argument_parser, default_setup, launch\r\nfrom detectron2.config import get_cfg\r\nfrom add_model_config import add_fcos_config\r\nfrom detectron2.engine import DefaultTrainer,DefaultPredictor\r\nfrom detectron2.evaluation import DatasetEvaluators,\r\n\r\nfrom detectron2.evaluation import inference_on_dataset\r\nfrom detectron2.data import build_detection_test_loader, MetadataCatalog\r\nfrom detectron2.data.datasets import register_coco_instances\r\n\r\n\r\ndef setup(args):\r\n    cfg = get_cfg()\r\n    add_fcos_config(cfg)  # ÈÖçÁΩÆÊñá‰ª∂1 - ÂéüÂßãÂÆö‰πâ\r\n    cfg.merge_from_file(args.config_file)  # ÈÖçÁΩÆÊñá‰ª∂2 - Ë¶ÜÁõñ\r\n    cfg.merge_from_list(args.opts)\r\n    cfg.MODEL.WEIGHTS = \"D:\\lyb\\demo1\\output_0\\model_0029999.pth\"\r\n    # cfg.DATASETS.TEST = (dataset_name,)\r\n    cfg.freeze()\r\n    default_setup(cfg, args)\r\n    return cfg\r\n\r\n\r\ndef main(args):\r\n    cfg = setup(args)\r\n    Trainer = DefaultTrainer(cfg)\r\n\r\n    if args.eval_only:\r\n        model = Trainer.build_model(cfg)\r\n\r\n        data_loader = build_detection_test_loader(cfg, cfg.DATASETS.TEST[0])\r\n\r\n        print('loading from:{}'.format(cfg.MODEL.WEIGHTS))\r\n\r\n        eval_results = inference_on_dataset(\r\n        model,\r\n        data_loader,\r\n        DatasetEvaluators([COCOEvaluator(cfg.DATASETS.TEST[0], (\"bbox\",), False, output_dir='./1_6_inference/'), ]))\r\n        \r\n        print(eval_results)\r\n        return eval_results \r\n\r\n    \r\n    return Trainer.train()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    args = default_argument_parser().parse_args()\r\n    print(\"Command Line Args:\", args)\r\n    launch(\r\n        main,\r\n        args.num_gpus,\r\n        num_machines=args.num_machines,\r\n        machine_rank=args.machine_rank,\r\n        dist_url=args.dist_url,\r\n        args=(args,),\r\n    )\r\n\r\n\r\n\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 3099,
    "title": "Pretrained models for Keypoint + Segmentation tasks",
    "author": "saidaltindis",
    "state": "open",
    "created_at": "2021-05-28T16:45:21Z",
    "updated_at": "2024-11-07T03:21:02Z",
    "labels": [
      "enhancement"
    ],
    "body": "Pretrained models for  Keypoint + Segmentation tasks\r\n\r\nAlthough there are multiple pretrained models provided for segmentation and keypoint tasks separately, there is no pretrained model that trained for multi-task.\r\n\r\nProviding such models would be an important baseline for the people that re-trained their model since it is possible to train such models using detectron2 (#17). \r\n",
    "comments": [
      {
        "user": "VGrondin",
        "body": "The keypoints model are multi-task, you just need to turn it on e.g.:\r\n```\r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml\"))\r\ncfg.MODEL.MASK_ON = True\r\ncfg.MODEL.KEYPOINT_ON = True \r\n```"
      },
      {
        "user": "saidaltindis",
        "body": "Are you sure? They did not report the mask score for keypoint models and in metrics, mask loss is not present.\r\n\r\nhttps://dl.fbaipublicfiles.com/detectron2/COCO-Keypoints/keypoint_rcnn_R_50_FPN_1x/137261548/metrics.json"
      },
      {
        "user": "chenzhutian",
        "body": "After setting `cfg.MODEL.MASK_ON = True`, the output of the mask is just noise. I guess the pre-trained models dont support keypoint detection and segmentation in the same time."
      }
    ]
  },
  {
    "issue_number": 5114,
    "title": "[Doc] How to install detectron2 on Windows Machine?",
    "author": "kdshreyas",
    "state": "open",
    "created_at": "2023-10-13T11:42:43Z",
    "updated_at": "2024-11-06T07:55:47Z",
    "labels": [
      "documentation"
    ],
    "body": "## üìö Documentation Issue\r\n\r\nThe installation page is basic and does not provide clear guidelines on how users should install detectron2 in step by step process on the Windows system.\r\n\r\nThis issue category is for problems about existing documentation, not for asking how-to questions.\r\n\r\n* Provide a link to an existing documentation/comment/tutorial:\r\nhttps://detectron2.readthedocs.io/en/latest/tutorials/install.html\r\n\r\n* How should the above documentation/comment/tutorial improve:\r\n 1. listing dependencies before starting the installation process.\r\n 2. Provide a clear step-by-step process to install detectron2 on the Windows system.",
    "comments": [
      {
        "user": "kdshreyas",
        "body": "after a lot of trial and error, I was able to install it and would like to add my process to project documentation, let me know if I can contribute, and where can I list down the details.\r\n\r\nRefer my blog: [How to install detectron2 on Windows Machine?](https://helloshreyas.com/how-to-install-detectron2-on-windows-machine)"
      },
      {
        "user": "goodstudent9",
        "body": "I think wsl can help you doing that. You just need to use it to run your code in linux system."
      },
      {
        "user": "NolenBrolen",
        "body": "You sir, are an absolute hero. Thank you making the time to make that blog. it worked!"
      }
    ]
  },
  {
    "issue_number": 5388,
    "title": "The",
    "author": "DNOCHA3",
    "state": "open",
    "created_at": "2024-11-04T23:40:39Z",
    "updated_at": "2024-11-04T23:40:53Z",
    "labels": [
      "enhancement"
    ],
    "body": "## üöÄ Feature\nA clear and concise description of the feature proposal.\n\n## Motivation & Examples\n\nTell us why the feature is useful.\n\nDescribe what the feature would look like, if it is implemented.\nBest demonstrated using **code examples** in addition to words.\n\n## Note\n\nWe only consider adding new features if they are relevant to many users.\n\nIf you request implementation of research papers -- we only consider papers that have enough significance and prevalance in the object detection field.\n\nWe do not take requests for most projects in the `projects/` directory, because they are research code release that is mainly for other researchers to reproduce results.\n\n\"Make X faster/accurate\" is not a valid feature request. \"Implement a concrete feature that can make X faster/accurate\" can be a valid feature request.\n\nInstead of adding features inside detectron2,\nyou can implement many features by [extending detectron2](https://detectron2.readthedocs.io/tutorials/extend.html).\nThe [projects/](https://github.com/facebookresearch/detectron2/tree/main/projects/) directory contains many of such examples.",
    "comments": [
      {
        "user": "DNOCHA3",
        "body": "Thank you I need all the help I can get "
      }
    ]
  },
  {
    "issue_number": 5385,
    "title": "assert img.shape[:2] == (self.h, self.w) AssertionError",
    "author": "Raneem-MT",
    "state": "open",
    "created_at": "2024-10-30T16:54:07Z",
    "updated_at": "2024-10-30T16:58:59Z",
    "labels": [],
    "body": "\r\nI am evaluating MaskDINO, which uses detectron2. I have seen a similar issue, saying this error can be caused by mismatched sizes between the masks and images, but I checked that the sizes match.\r\nI evaluated other datasets with no problem, but I ran into issues with this one. \r\nI pre-processed the images the same way and checked that the sized made sense. I printed out the shapes but cannot trace back where exactly this shape issue occurred. This is the full error message:\r\n\r\nAssertionError: Caught AssertionError in DataLoader worker process 0.\r\nOriginal Traceback (most recent call last):\r\n  File \"/jmain02/home/J2AD014/mtc11/rxt49-mtc11/.conda/envs/maskdino/lib/python3.8/site-packages/torch/util                s/data/_utils/worker.py\", line 287, in _worker_loop\r\n    data = fetcher.fetch(index)\r\n  File \"/jmain02/home/J2AD014/mtc11/rxt49-mtc11/.conda/envs/maskdino/lib/python3.8/site-packages/torch/util                s/data/_utils/fetch.py\", line 44, in fetch\r\n    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n  File \"/jmain02/home/J2AD014/mtc11/rxt49-mtc11/.conda/envs/maskdino/lib/python3.8/site-packages/torch/util                s/data/_utils/fetch.py\", line 44, in <listcomp>\r\n    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n  File \"/jmain02/home/J2AD014/mtc11/rxt49-mtc11/.conda/envs/maskdino/lib/python3.8/site-packages/detectron2                /data/common.py\", line 90, in __getitem__\r\n    data = self._map_func(self._dataset[cur_idx])\r\n  File \"/jmain02/home/J2AD014/mtc11/rxt49-mtc11/.conda/envs/maskdino/lib/python3.8/site-packages/detectron2                /data/dataset_mapper.py\", line 164, in __call__\r\n    transforms = self.augmentations(aug_input)\r\n  File \"/jmain02/home/J2AD014/mtc11/rxt49-mtc11/.conda/envs/maskdino/lib/python3.8/site-packages/detectron2                /data/transforms/augmentation.py\", line 264, in __call__\r\n    tfm = x(aug_input)\r\n  File \"/jmain02/home/J2AD014/mtc11/rxt49-mtc11/.conda/envs/maskdino/lib/python3.8/site-packages/detectron2                /data/transforms/augmentation.py\", line 170, in __call__\r\n    aug_input.transform(tfm)\r\n  File \"/jmain02/home/J2AD014/mtc11/rxt49-mtc11/.conda/envs/maskdino/lib/python3.8/site-packages/detectron2                /data/transforms/augmentation.py\", line 339, in transform\r\n    self.sem_seg = tfm.apply_segmentation(self.sem_seg)\r\n  File \"/jmain02/home/J2AD014/mtc11/rxt49-mtc11/.conda/envs/maskdino/lib/python3.8/site-packages/detectron2                /data/transforms/transform.py\", line 155, in apply_segmentation\r\n    segmentation = self.apply_image(segmentation, interp=Image.NEAREST)\r\n  File \"/jmain02/home/J2AD014/mtc11/rxt49-mtc11/.conda/envs/maskdino/lib/python3.8/site-packages/detectron2                /data/transforms/transform.py\", line 113, in apply_image\r\n    assert img.shape[:2] == (self.h, self.w)\r\nAssertionError\r\n\r\nHas anyone solved this?",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      }
    ]
  },
  {
    "issue_number": 1691,
    "title": "train Panoptic Segmentation model on custom dataset",
    "author": "Cyril9227",
    "state": "open",
    "created_at": "2020-06-29T05:25:17Z",
    "updated_at": "2024-10-28T21:35:54Z",
    "labels": [
      "enhancement"
    ],
    "body": "## ‚ùì How to train Panoptic Segmentation on a custom dataset ?\r\nHello everyone,\r\n\r\nMy question is two-fold :\r\n1. What is the expected Detectron2 format for Panoptic Segmentation ? In the PS paper, they are talking about a pixel-wise annotation (either stuff class or instance ID) but it seems that D2 requires bounding boxes as well.\r\n2. Is it possible to train PS on a custom dataset with only pixel-wise annotations ?\r\n\r\nThanks,\r\n\r\nCyril \r\n\r\n\r\n\r\n",
    "comments": [
      {
        "user": "ppwwyyxx",
        "body": "At the moment we don't have instructions to train panoptic segmentation models on custom dataset. Our code now expects panoptic segmentation data in COCO format, which is unfortunately not well-documented."
      },
      {
        "user": "JavierClearImageAI",
        "body": "> At the moment we don't have instructions to train panoptic segmentation models on custom dataset. Our code now expects panoptic segmentation data in COCO format, which is unfortunately not well-documented.\r\n\r\n[Here the link to the COCO format](https://cocodataset.org/#format-data)     ... then go to point 4: Panoptic Segmentation. I would also recommend to download the json annotations and mask labels in png format, have a look at them and create yours in the same format.\r\n\r\nI am still on my way do it. After converting the annotations into the right format, how to register panoptic annotations for training? is it the same than with instance segmentation and object detection? Since we have now an extra directory with the masks, I am wondering if it will use the same code to register the annotations.\r\n\r\nI guess the answer is no, since you created an specific script to do that:\r\n[coco_panoptic.py](https://github.com/facebookresearch/detectron2/blob/c90ff5ea62165a3e05471a56482eb29132ebbf37/detectron2/data/datasets/coco_panoptic.py#L102)\r\n\r\n[detectron2.data.datasets.register_coco_panoptic](https://detectron2.readthedocs.io/en/latest/modules/data.html?highlight=panoptic#detectron2.data.datasets.register_coco_panoptic)"
      },
      {
        "user": "mvdelt",
        "body": "@JavierClearImageAI what is your way to make your custom panoptic segmentation annotations?"
      }
    ]
  },
  {
    "issue_number": 4106,
    "title": "Getting started commands to test not working!",
    "author": "hiroto01",
    "state": "open",
    "created_at": "2022-03-29T07:11:48Z",
    "updated_at": "2024-10-28T11:22:35Z",
    "labels": [
      "documentation"
    ],
    "body": "As given in the documentation i used the following command-\r\n```\r\n\r\ncd demo/\r\npython demo.py --config-file ../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml \\\r\n  --input input1.jpg input2.jpg \\\r\n  [--other-options]\r\n  --opts MODEL.WEIGHTS detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\r\n```\r\n\r\n`\r\nthe command i used-`\r\n`python3 demo/demo.py --config-file ../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml --webcam --opts MODEL.WEIGHTS detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl`\r\n\r\n**error i got-**\r\n```\r\n File \"/usr/local/lib/python3.7/site-packages/detectron2/config/config.py\", line 45, in merge_from_file\r\n    assert PathManager.isfile(cfg_filename), f\"Config file '{cfg_filename}' does not exist!\"\r\nAssertionError: Config file '../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml' does not exist!\r\n```\r\nnot understanding why this error also, **why i did python3 instead of python is because-**\r\n\r\n`python demo/demo.py --config-file ../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml --webcam --opts MODEL.WEIGHTS detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl`\r\n\r\n**error-**\r\n`ImportError: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/detectron/lib/python3.9/site-packages/pycocotools/_mask.cpython-39-darwin.so, 0x0002): tried: '/opt/homebrew/Caskroom/miniforge/base/envs/detectron/lib/python3.9/site-packages/pycocotools/_mask.cpython-39-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e')), '/usr/local/lib/_mask.cpython-39-darwin.so' (no such file), '/usr/lib/_mask.cpython-39-darwin.so' (no such file)`",
    "comments": [
      {
        "user": "Alexander-Weinberg",
        "body": "I have the same issue"
      },
      {
        "user": "Estrellas314",
        "body": "how can I solve this problem\r\n"
      }
    ]
  },
  {
    "issue_number": 5340,
    "title": "I am trying to install detection b following the official tutorial but...",
    "author": "Sher10ckfly",
    "state": "open",
    "created_at": "2024-08-04T06:30:58Z",
    "updated_at": "2024-10-25T21:41:56Z",
    "labels": [
      "documentation"
    ],
    "body": "Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /private/var/folders/sh/68p0y75x3qj6bmf4by8cqpc80000gn/T/pip-req-build-b7g7kjfd\r\n  fatal: unable to access 'https://github.com/facebookresearch/detectron2.git/': Failed to connect to github.com port 443 after 75014 ms: Couldn't connect to server\r\n  error: subprocess-exited-with-error\r\n  \r\n  √ó git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /private/var/folders/sh/68p0y75x3qj6bmf4by8cqpc80000gn/T/pip-req-build-b7g7kjfd did not run successfully.\r\n  ‚îÇ exit code: 128\r\n  ‚ï∞‚îÄ> See above for output.\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: subprocess-exited-with-error\r\n\r\n√ó git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /private/var/folders/sh/68p0y75x3qj6bmf4by8cqpc80000gn/T/pip-req-build-b7g7kjfd did not run successfully.\r\n‚îÇ exit code: 128\r\n‚ï∞‚îÄ> See above for output.\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n\r\n",
    "comments": [
      {
        "user": "Sher10ckfly",
        "body": "Failed building wheel for detectron2ÔºåI tried again and it says"
      },
      {
        "user": "zhi-xuan-chen",
        "body": "HelloÔºÅI also meet this problem, do you solve it now?"
      },
      {
        "user": "lawrence-fw",
        "body": "First do this [recommended here](https://stackoverflow.com/questions/20370294/git-could-not-resolve-host-github-com-error-while-cloning-remote-repository-in):\r\ngit config --global --unset http.proxy\r\ngit config --global --unset https.proxy\r\n\r\nThen try this guide: https://dev.to/reckon762/how-to-install-detectron2-on-windows-3hil"
      }
    ]
  },
  {
    "issue_number": 3506,
    "title": "Deep MARC | Hourglass | SpineNet",
    "author": "AKMourato",
    "state": "open",
    "created_at": "2021-09-21T19:39:13Z",
    "updated_at": "2024-10-25T12:43:48Z",
    "labels": [
      "enhancement"
    ],
    "body": "Greetings!\r\n\r\n## üöÄ Features\r\n- Deep Mask heads Above R-CNN (**Deep MARC**)\r\n     - Hourglass\r\n     \r\n- SpineNet backbone\r\n\r\nA significant improvement to Mask R-CNN recently by bringing insights from Google Deep-MAC, and SpineNet to ResNet.\r\n \r\n## Motivation & Examples\r\nThis network is currently developed in TensorFlow, it would be a huge add-on having it here, in this great library.\r\n\r\nHere [https://ai.googleblog.com/2021/09/revisiting-mask-head-architectures-for.html](url), indicates all the improvements and main aspects and motivation behind Deep-MAC and Deep-MARC.\r\nMore info can be found in this repo: https://github.com/tensorflow/models/tree/master/official/vision/beta/projects/deepmac_maskrcnn\r\nand here [https://arxiv.org/abs/2104.00613](url).\r\n\r\nCheers!",
    "comments": [
      {
        "user": "kdexd",
        "body": "üîñ +1, subscribing. I have a private implementation of Hourglass mask head from Deep-MARC for my ongoing project. I will update here once released. :-) "
      },
      {
        "user": "jamesbc123",
        "body": "> üîñ +1, subscribing. I have a private implementation of Hourglass mask head from Deep-MARC for my ongoing project. I will update here once released. :-)\r\n\r\nHello Karan, just curious can you release your code for Hourglass mask head with detectron2? I would be really appreciated, thanks"
      }
    ]
  },
  {
    "issue_number": 438,
    "title": "GPU usage keeps increasing until OOM error on iSAID dataset.",
    "author": "engharat",
    "state": "closed",
    "created_at": "2019-12-01T20:13:53Z",
    "updated_at": "2024-10-25T08:53:10Z",
    "labels": [
      "enhancement"
    ],
    "body": "If you do not know the root cause of the problem / bug, and wish someone to help you, please\r\ninclude:\r\n\r\n## How To Reproduce the Issue\r\nRun a simple training with any detectron2 backbone on iSAID dataset [https://captain-whu.github.io/iSAID/](url). iSAID is a instance segmentation dataset with COCO-style json data, using 15 object categories and having some images with a big number of instances(cars). iSAID is preprocessed by the author's script which convert labels bboxes and metadata to the COCO format, while creating 800x800 patches of the high resolution original images. \r\n \r\n1. what changes you made (`git diff`) or what code you wrote\r\nI used the simple detectron2 colab tutorial code, using a register_coco_instances function instead of defining a custom function, as ISAID is fully compatible with COCO format. Here is a link to the code for reproducing the error: [https://drive.google.com/open?id=1bo0GOhHLlvEyc6E9DOZzlszg59THOT9x](url)\r\n\r\n2. what exact command you run\r\npython3 training_naive.py, which runs a register_coco_instances function, a cfg setup, and then a simple DefaultTrainer.train()\r\n\r\n3. what you observed (including the full logs):\r\n```\r\nThe GPU memory usage keeps increasing after several iterations, until a crash for out of memory error. Using torch.cuda_empty_cache() or the suggested\r\ncfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 200\r\ncfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 200\r\ndid not solved neither.\r\nHere is the link to the full output from bash: [https://drive.google.com/open?id=1SszOAY9pEBFSsfp7nyc0Gv_mcCiHoAKo](url)\r\n```\r\n\r\n## Expected behavior\r\n\r\nIf there are no obvious error in \"what you observed\" provided above,\r\nplease tell us the expected behavior.\r\n\r\nIf you expect the model to work better, note that we do not help you train your model.\r\nOnly in one of the two conditions we will help with it:\r\n(1) You're unable to reproduce the results in detectron2 model zoo.\r\n(2) It indicates a detectron2 bug.\r\n\r\n## Environment\r\n\r\nPlease paste the output of `python -m detectron2.utils.collect_env`.\r\nIf detectron2 hasn't been successfully installed,\r\nuse `python detectron2/utils/collect_env.py`.\r\n\r\n(pytorch) paolo@ALCOR-TITANV-WS:~/libriaries/prove_detectron2$ python -m detectron2.utils.collect_env\r\n------------------------  -----------------------------------------------------------\r\nsys.platform              linux\r\nPython                    3.6.8 (default, Oct  9 2019, 14:04:01) [GCC 5.4.0 20160609]\r\nNumpy                     1.17.4\r\nDetectron2 Compiler       GCC 5.4\r\nDetectron2 CUDA Compiler  10.1\r\nDETECTRON2_ENV_MODULE     <not set>\r\nPyTorch                   1.3.1\r\nPyTorch Debug Build       False\r\ntorchvision               0.4.2\r\nCUDA available            True\r\nGPU 0,1,2,3               TITAN V\r\nCUDA_HOME                 /usr/local/cuda-10.1\r\nNVCC                      Cuda compilation tools, release 10.1, V10.1.105\r\nPillow                    6.2.1\r\ncv2                       4.1.2\r\n------------------------  -----------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - NNPACK is enabled\r\n  - CUDA Runtime 10.1\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 7.6.3\r\n  - Magma 2.5.1\r\n  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,\r\n\r\n(pytorch) paolo@ALCOR-TITANV-WS:~/libriaries/prove_detectron2$\r\n",
    "comments": [
      {
        "user": "engharat",
        "body": "Update: the issue disappear if I remove the 100 images which show the highest number of instances. Top 100 images have 700 instances per image, with the top-10 images having 3000 instances.\r\nStill, PANnet official implementation, which is heavily based on detectron 1 code, is able to run on the whole dataset without any issue.\r\n"
      },
      {
        "user": "ppwwyyxx",
        "body": "Thanks for the information. this is quite helpful.\r\n\r\nI think there might be some optimization we can do to improve memory utilization for such cases."
      },
      {
        "user": "ppwwyyxx",
        "body": "btw, this works for detectron 1, because the part of logic that throws GPU OOM in detectron2 runs on CPU in detectron 1 (and is also part of the reason why detectron2 is faster)"
      }
    ]
  },
  {
    "issue_number": 5382,
    "title": "Please read & provide the following",
    "author": "DNOCHA3",
    "state": "closed",
    "created_at": "2024-10-17T18:59:08Z",
    "updated_at": "2024-10-25T02:09:34Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "## Instructions To Reproduce the üêõ Bug:\n1. Full runnable code or full changes you made:\n```\nIf making changes to the project itself, please use output of the following command:\ngit rev-parse HEAD; git diff\n\n<put code or diff here>\n```\n2. What exact command you run:\n3. __Full logs__ or other relevant observations:\n```\n<put logs here>\n```\n4. please simplify the steps as much as possible so they do not require additional resources to\n   run, such as a private dataset.\n\n## Expected behavior:\n\nIf there are no obvious error in \"full logs\" provided above,\nplease tell us the expected behavior.\n\n## Environment:\n\nProvide your environment information using the following command:\n```\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\n```\n\nIf your issue looks like an installation issue / environment issue,\nplease first try to solve it yourself with the instructions in\nhttps://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5384,
    "title": "Augmentation RandomCrop is not fully implemented",
    "author": "pokecheater",
    "state": "closed",
    "created_at": "2024-10-24T12:14:41Z",
    "updated_at": "2024-10-24T12:18:12Z",
    "labels": [],
    "body": "Hi detectron2 team,\r\n\r\nI noticed something strange when I used your augmentations.\r\nThe parameter crop_size had no effect at all so investigated. \r\nInside your codebase the parameter crop_size is defined and well documented but is not used at all.\r\n\r\n![image](https://github.com/user-attachments/assets/0d012d67-e9b4-490d-b5e4-675737156859)\r\n\r\n\r\nThis is also an issue in your latest version:\r\nhttps://github.com/facebookresearch/detectron2/blob/main/detectron2/data/transforms/augmentation_impl.py\r\n\r\nGreetings",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "pokecheater",
        "body": "My fault, should have read the code clearer the parameter is provided by locals()"
      }
    ]
  },
  {
    "issue_number": 5080,
    "title": "FloatingPointError: Predicted boxes or scores contain Inf/NaN. Training has diverged.",
    "author": "ouyang11111",
    "state": "open",
    "created_at": "2023-09-04T07:06:53Z",
    "updated_at": "2024-10-23T17:28:32Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n\r\nwhen I use VOC2012 dataset for my project shows the bug : \"FloatingPointError: Predicted boxes or scores contain Inf/NaN. Training has diverged.\"\r\nthis means the loss is extremely big, how can I solve it?\r\n\r\n## Environment:\r\nCUDA 12   RTX3090   detectorn2:V6.0   torch : 2.1.0.dev20230708+cu121\r\n",
    "comments": []
  },
  {
    "issue_number": 5168,
    "title": "Compiling failing on Windows 10 Python 3.10 Cu118 and Visual Studio 2022 - Any pre compiled wheels for Windows?",
    "author": "FurkanGozukara",
    "state": "closed",
    "created_at": "2023-12-05T11:28:06Z",
    "updated_at": "2024-10-21T03:28:55Z",
    "labels": [],
    "body": "installed torch and cuda\r\n\r\n`pip install torch==2.0.1 torchvision --index-url https://download.pytorch.org/whl/cu118`\r\n\r\ninstalled Cuda on system : `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8`\r\n\r\n\r\ninstalled visual studio c++ compiler `C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.33.31629\\bin\\Hostx64\\x86`\r\n\r\ninstalled python  3.10.11\r\n\r\nthis is how i install on a venv\r\n\r\n`python -m pip install -e .`\r\n\r\n\r\n```\r\n    \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\\nvcc\" -c G:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.cu -o build\\temp.win-amd64-cpython-310\\Release\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.obj -IG:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc -IG:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\torch\\include -IG:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include -IG:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\torch\\include\\TH -IG:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\torch\\include\\THC \"-IC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\include\" -IG:\\magic_animate\\compose_densepose\\detectron2\\venv\\include -IC:\\Python3108\\include -IC:\\Python3108\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.33.31629\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.33.31629\\ATLMFC\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcompiler /EHsc -Xcompiler /wd4190 -Xcompiler /wd4018 -Xcompiler /wd4275 -Xcompiler /wd4267 -Xcompiler /wd4244 -Xcompiler /wd4251 -Xcompiler /wd4819 -Xcompiler /MD -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -O3 -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --use-local-env\r\n    G:/magic_animate/compose_densepose/detectron2/venv/lib/site-packages/torch/include\\c10/macros/Macros.h(138): warning C4067: unexpected tokens following preprocessor directive - expected a newline\r\n    G:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.cu(14): error: name must be a namespace name\r\n\r\n    G:/magic_animate/compose_densepose/detectron2/venv/lib/site-packages/torch/include\\c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\r\n              detected during:\r\n                instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\r\n    (61): here\r\n                instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\r\n    G:/magic_animate/compose_densepose/detectron2/venv/lib/site-packages/torch/include\\c10/core/TensorImpl.h(77): here\r\n\r\n    G:/magic_animate/compose_densepose/detectron2/venv/lib/site-packages/torch/include\\c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\r\n              detected during:\r\n                instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=true, <unnamed>=0]\"\r\n    (61): here\r\n                instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=true, <unnamed>=0]\"\r\n    G:/magic_animate/compose_densepose/detectron2/venv/lib/site-packages/torch/include\\ATen/core/qualified_name.h(73): here\r\n\r\n    G:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.cu(68): error: identifier \"single_box_iou_rotated\" is undefined\r\n              detected during instantiation of \"void nms_rotated_cuda_kernel(int, double, const T *, unsigned long long *) [with T=double]\"\r\n    (105): here\r\n\r\n    G:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.cu(68): error: type name is not allowed\r\n              detected during instantiation of \"void nms_rotated_cuda_kernel(int, double, const T *, unsigned long long *) [with T=double]\"\r\n    (105): here\r\n\r\n    G:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.cu(68): warning #174-D: expression has no effect\r\n              detected during instantiation of \"void nms_rotated_cuda_kernel(int, double, const T *, unsigned long long *) [with T=double]\"\r\n    (105): here\r\n\r\n    G:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.cu(58): warning #550-D: variable \"cur_box\" was set but never used\r\n              detected during instantiation of \"void nms_rotated_cuda_kernel(int, double, const T *, unsigned long long *) [with T=double]\"\r\n    (105): here\r\n\r\n    G:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.cu(68): error: identifier \"single_box_iou_rotated\" is undefined\r\n              detected during instantiation of \"void nms_rotated_cuda_kernel(int, double, const T *, unsigned long long *) [with T=float]\"\r\n    (105): here\r\n\r\n    G:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.cu(68): error: type name is not allowed\r\n              detected during instantiation of \"void nms_rotated_cuda_kernel(int, double, const T *, unsigned long long *) [with T=float]\"\r\n    (105): here\r\n\r\n    G:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.cu(68): warning #174-D: expression has no effect\r\n              detected during instantiation of \"void nms_rotated_cuda_kernel(int, double, const T *, unsigned long long *) [with T=float]\"\r\n    (105): here\r\n\r\n    G:\\magic_animate\\compose_densepose\\detectron2\\detectron2\\layers\\csrc\\nms_rotated\\nms_rotated_cuda.cu(58): warning #550-D: variable \"cur_box\" was set but never used\r\n              detected during instantiation of \"void nms_rotated_cuda_kernel(int, double, const T *, unsigned long long *) [with T=float]\"\r\n    (105): here\r\n\r\n    5 errors detected in the compilation of \"G:/magic_animate/compose_densepose/detectron2/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu\".\r\n    nms_rotated_cuda.cu\r\n    error: command 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v11.8\\\\bin\\\\nvcc.exe' failed with exit code 1\r\n    [end of output]\r\n\r\nnote: This error originates from a subprocess, and is likely not a problem with pip.\r\n```\r\n\r\n\r\n",
    "comments": []
  },
  {
    "issue_number": 5182,
    "title": "Train on a new model: mesh_vertex_embeddings are all zeros in my model",
    "author": "Haozong-Zeng",
    "state": "closed",
    "created_at": "2023-12-16T03:32:09Z",
    "updated_at": "2024-10-19T02:07:23Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "I am using DensePose CSE for capturing poses from videos and guiding a mesh model. My goal is to use my own mesh and the corresponding dataset to train a DensePose CSE model.\r\n\r\nI formated the dataset & annotation correctly, and successfully registered the mesh by providing the vertices, geometric distances, symmetry, etc. information. The only thing I missed is the INIT_FILE which contains 'eigenvalues', 'features', & 'baricel_area'. My trained model seems to work well on providing the \r\n\r\n> E (tensor [1, D, H, W]): D-dimensional embedding vectors for every point of the default-sized box\r\n\r\n & \r\n\r\n> S (tensor [1, 2, H, W]): 2-dimensional segmentation mask for every point of the default-sized box\r\n\r\nHowever, when I tried to find the closest vertices, I noticed that the \r\n\r\n> mesh_vertex_embeddings (tensor [N, D]): vertex embeddings for a chosen mesh N is the number of vertices in the mesh, D is feature dimensionality\r\n\r\nis a all-zeros tensor and thus I could not calculate the squared_euclidean_distance_matrix.\r\n\r\nWhen training the model, I received the following warning:\r\n\r\n> Some model parameters or buffers are not found in the checkpoint:\r\n> roi_heads.embedder.embedder_my_mesh.{embeddings, features}\r\n\r\n\r\n1. Full changes you made:\r\n`_BASE_: \"Base-DensePose-RCNN-FPN.yaml\"\r\nMODEL:\r\n  WEIGHTS: \"https://dl.fbaipublicfiles.com/densepose/cse/a_checkpoint.pkl\"\r\n  RESNETS:\r\n    DEPTH: 50\r\n  ROI_HEADS:\r\n    NUM_CLASSES: 1\r\n  ROI_DENSEPOSE_HEAD:\r\n    NAME: \"DensePoseV1ConvXHead\"\r\n    COARSE_SEGM_TRAINED_BY_MASKS: True\r\n    CSE:\r\n      EMBED_LOSS_NAME: \"SoftEmbeddingLoss\"\r\n      EMBEDDING_DIST_GAUSS_SIGMA: 0.1\r\n      GEODESIC_DIST_GAUSS_SIGMA: 0.1\r\n      EMBEDDERS:\r\n        \"my_mesh\":\r\n          TYPE: vertex_feature\r\n          NUM_VERTICES: n\r\n          FEATURE_DIM: 256\r\n          FEATURES_TRAINABLE: True (also try False)\r\n          IS_TRAINABLE: True\r\n          INIT_FILE: \"\"`\r\n\r\n2. What exact command you run:\r\nThe train_net.py script in the [tutorial](https://github.com/facebookresearch/detectron2/blob/main/projects/DensePose/doc/GETTING_STARTED.md ) \r\n\r\n\r\n",
    "comments": []
  },
  {
    "issue_number": 5216,
    "title": "Can't install Detectron 2 on MacOS (intel Mac)",
    "author": "tripathi-genius",
    "state": "open",
    "created_at": "2024-02-12T13:16:39Z",
    "updated_at": "2024-10-18T04:59:29Z",
    "labels": [],
    "body": "I tried to run installation of Detectron 2 and I followed all the available links on GitHub, but I still got the following error:\r\n\r\n```\r\nBuilding wheels for collected packages: detectron2\r\n  Building wheel for detectron2 (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  √ó python setup.py bdist_wheel did not run successfully.\r\n  ‚îÇ exit code: 1\r\n  ‚ï∞‚îÄ> [641 lines of output]\r\n      running bdist_wheel\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\r\n        warnings.warn(msg.format('we could not find ninja.'))\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build/lib.macosx-10.9-universal2-cpython-311\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/lightning_train_net.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n... ...\r\n      copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_training_acc_test.yaml -> build/lib.macosx-\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      warning: build_py: byte-compiling is disabled, skipping.\r\n      \r\n      running build_ext\r\n      building 'detectron2._C' extension\r\n      creating build/temp.macosx-10.9-universal2-cpython-311\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/box_iou_rotated\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/cocoeval\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/nms_rotated\r\n      clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -g -arch x86_64 -I/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc -I/Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include -I/Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/TH -I/Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/THC -I/Users/shashwattripathi/my_test/venv/include -I/Library/Frameworks/Python.framework/Versions/3.11/include/python3.11 -c /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp -o build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:28:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/c10/util/OptionalArrayRef.h:159:34: error: 'value' is unavailable: introduced in macOS 10.13\r\n          return wrapped_opt_array_ref.value();\r\n                                       ^\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/c10/util/OptionalArrayRef.h:222:13: note: in instantiation of member function 'c10::OptionalArrayRef<long long>::value' requested here\r\n        return a1.value() == other;\r\n                  ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:950:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:31:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/CheckMemoryFormat.h:11:35: error: 'value' is unavailable: introduced in macOS 10.13\r\n            options.requires_grad_opt().value() == false,\r\n                                        ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:968:28: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type&& value() &&\r\n                                 ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:33:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/DeprecatedTypeProperties.h:110:34: error: 'value' is unavailable: introduced in macOS 10.13\r\n            Device device = device_opt.value();\r\n                                       ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:959:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:442:26: error: 'value' is unavailable: introduced in macOS 10.13\r\n            TORCH_CHECK(inputs.value().size() > 0, \"'inputs' argument to backward cannot be empty\")\r\n                               ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:959:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:443:30: error: 'value' is unavailable: introduced in macOS 10.13\r\n            this->_backward(inputs.value(), gradient, retain_graph, create_graph);\r\n                                   ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:959:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:28:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/c10/util/OptionalArrayRef.h:131:34: error: 'value' is unavailable: introduced in macOS 10.13\r\n          return wrapped_opt_array_ref.value();\r\n                                       ^\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:5606:152: note: in instantiation of member function 'c10::OptionalArrayRef<long long>::operator*' requested here\r\n          return at::_ops::to_padded_tensor::call(const_cast<Tensor&>(*this), padding, output_size.has_value() ? c10::make_optional(c10::fromIntArrayRefSlow(*output_size)) : c10::nullopt);\r\n                                                                                                                                                             ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:959:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:12:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:662:24: error: 'value' is unavailable: introduced in macOS 10.13\r\n            prod *= shape[i].value();\r\n                             ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:950:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:12:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:1512:28: error: 'value' is unavailable: introduced in macOS 10.13\r\n          const auto& n = name().value();\r\n                                 ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:950:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:12:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:2129:20: error: 'value' is unavailable: introduced in macOS 10.13\r\n          return reason_.value();\r\n                         ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:950:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:16:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/c10/core/DeviceGuard.h:3:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/c10/core/impl/InlineDeviceGuard.h:230:33: error: 'value' is unavailable: introduced in macOS 10.13\r\n            guard_.emplace(device_opt.value());\r\n                                      ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:959:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:16:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/c10/core/DeviceGuard.h:3:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/c10/core/impl/InlineDeviceGuard.h:242:39: error: 'value' is unavailable: introduced in macOS 10.13\r\n            guard_.emplace(device_index_opt.value());\r\n                                            ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:959:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:20:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/c10/core/StreamGuard.h:3:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/c10/core/impl/InlineStreamGuard.h:146:33: error: 'value' is unavailable: introduced in macOS 10.13\r\n            guard_.emplace(stream_opt.value());\r\n                                      ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:959:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:27:38: error: 'value' is unavailable: introduced in macOS 10.13\r\n        return t.has_value() ? device_of(t.value()) : c10::nullopt;\r\n                                           ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:950:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:18:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorIndexing.h:13:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/NativeFunctions.h:37:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ops/_addmm_activation_native.h:15:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ops/_addmm_activation_meta.h:12:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorIterator.h:311:34: error: 'value' is unavailable: introduced in macOS 10.13\r\n          return operands_[arg].device.value();\r\n                                       ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:950:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:18:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorIndexing.h:48:37: error: 'value' is unavailable: introduced in macOS 10.13\r\n            step_ = std::move(step_index).value();\r\n                                          ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:968:28: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type&& value() &&\r\n                                 ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:18:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorIndexing.h:56:39: error: 'value' is unavailable: introduced in macOS 10.13\r\n            start_ = std::move(start_index).value();\r\n                                            ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:968:28: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type&& value() &&\r\n                                 ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:18:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorIndexing.h:62:37: error: 'value' is unavailable: introduced in macOS 10.13\r\n            stop_ = std::move(stop_index).value();\r\n                                          ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:968:28: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type&& value() &&\r\n                                 ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/ATen.h:18:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorIndexing.h:243:25: error: 'value' is unavailable: introduced in macOS 10.13\r\n                !(maybe_index.value() == 0 && dim == 0 && self_sizes->empty()),\r\n                              ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:959:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zc/mb4184bj2v5gfcsc5j8y_f4r0000gn/T/pip-req-build-0jx34iss/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      In file included from /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:28:\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/c10/util/OptionalArrayRef.h:155:34: error: 'value' is unavailable: introduced in macOS 10.13\r\n          return wrapped_opt_array_ref.value();\r\n                                       ^\r\n      /Users/shashwattripathi/my_test/venv/lib/python3.11/site-packages/torch/include/ATen/WrapDimUtilsMulti.h:26:26: note: in instantiation of member function 'c10::OptionalArrayRef<long long>::value' requested here\r\n          auto dims = opt_dims.value();\r\n                               ^\r\n      /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:959:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      fatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n      20 errors generated.\r\n      error: command '/usr/bin/clang' failed with exit code 1\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for detectron2\r\n  Running setup.py clean for detectron2\r\nFailed to build detectron2\r\nERROR: Could not build wheels for detectron2, which is required to install pyproject.toml-based projects\r\n```\r\nThe installation is attempted on python 3.11.1 and the files in virtual environment are:\r\n```\r\nPackage                 Version\r\n----------------------- ------------------\r\nabsl-py                 2.1.0\r\nantlr4-python3-runtime  4.9.3\r\nblack                   24.1.1\r\ncachetools              5.3.2\r\ncertifi                 2024.2.2\r\ncharset-normalizer      3.3.2\r\nclick                   8.1.7\r\ncloudpickle             3.0.0\r\ncontourpy               1.2.0\r\ncycler                  0.12.1\r\nfilelock                3.13.1\r\nfonttools               4.48.1\r\nfsspec                  2024.2.0\r\nfvcore                  0.1.5.post20221221\r\ngoogle-auth             2.27.0\r\ngoogle-auth-oauthlib    1.2.0\r\ngrpcio                  1.60.1\r\nhydra-core              1.3.2\r\nidna                    3.6\r\niopath                  0.1.9\r\nJinja2                  3.1.3\r\nkiwisolver              1.4.5\r\nMarkdown                3.5.2\r\nMarkupSafe              2.1.5\r\nmatplotlib              3.8.2\r\nmpmath                  1.3.0\r\nmypy-extensions         1.0.0\r\nnetworkx                3.2.1\r\nnumpy                   1.26.4\r\noauthlib                3.2.2\r\nomegaconf               2.3.0\r\npackaging               23.2\r\npathspec                0.12.1\r\npillow                  10.2.0\r\npip                     24.0\r\nplatformdirs            4.2.0\r\nportalocker             2.8.2\r\nprotobuf                4.25.2\r\npyasn1                  0.5.1\r\npyasn1-modules          0.3.0\r\npycocotools             2.0.7\r\npyparsing               3.1.1\r\npython-dateutil         2.8.2\r\nPyYAML                  6.0.1\r\nrequests                2.31.0\r\nrequests-oauthlib       1.3.1\r\nrsa                     4.9\r\nsetuptools              65.5.0\r\nsix                     1.16.0\r\nsympy                   1.12\r\ntabulate                0.9.0\r\ntensorboard             2.15.2\r\ntensorboard-data-server 0.7.2\r\ntermcolor               2.4.0\r\ntorch                   2.2.0\r\ntorchaudio              2.2.0\r\ntorchvision             0.17.0\r\ntqdm                    4.66.2\r\ntyping_extensions       4.9.0\r\nurllib3                 2.2.0\r\nwatchdog                1.0.2\r\nWerkzeug                3.0.1\r\nwheel                   0.42.0\r\nyacs                    0.1.8\r\n```\r\nThe OS details are:\r\n```\r\nOS: MACOS Monterey\r\nVersion: 12.7.3 (21H1015)\r\nDevice: Air (13-inch, 2017)\r\nProcessor: 1.8 GHz Dual-Core Intel Core i5\r\nMemory: 8 GB 1600 MHz DDR3\r\n```\r\nTo reproduce this problem:\r\n1. create a virtual environment and set the  export ARCHFLAGS=\"-arch x86_64\".\r\n2. You may use the pip file to install the dependencies.\r\n3. To install the file, run: CC=clang CXX=clang++ python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' as provided in the Detectron documentation.\r\nPlease help me to solve this issue. Help is highly appreciated.",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "tripathi-genius",
        "body": "I have edited the initial file and full logs are more than the permitted characters. I have given enough information for the devs to figure out error. Thank you for understanding."
      },
      {
        "user": "apasarkar",
        "body": "I have the exact same issue on Mac OS Monterey 12.6, help greatly appreciated "
      }
    ]
  },
  {
    "issue_number": 5376,
    "title": "Please read & provide the following",
    "author": "DNOCHA3",
    "state": "closed",
    "created_at": "2024-10-10T23:19:31Z",
    "updated_at": "2024-10-18T02:09:01Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "## Instructions To Reproduce the üêõ Bug:\n1. Full runnable code or full changes you made:\n```\nIf making changes to the project itself, please use output of the following command:\ngit rev-parse HEAD; git diff\n\n<put code or diff here>\n```\n2. What exact command you run:\n3. __Full logs__ or other relevant observations:\n```\n<put logs here>\n```\n4. please simplify the steps as much as possible so they do not require additional resources to\n   run, such as a private dataset.\n\n## Expected behavior:\n\nIf there are no obvious error in \"full logs\" provided above,\nplease tell us the expected behavior.\n\n## Environment:\n\nProvide your environment information using the following command:\n```\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\n```\n\nIf your issue looks like an installation issue / environment issue,\nplease first try to solve it yourself with the instructions in\nhttps://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5374,
    "title": "Assign color when only masks are initialized (without bbox)",
    "author": "antoinedelplace",
    "state": "closed",
    "created_at": "2024-10-07T13:26:57Z",
    "updated_at": "2024-10-15T02:09:31Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Here only the option where the boxes are initialized works.\r\nThe option where the masks are initialized is not dealt with.\r\n\r\nhttps://github.com/facebookresearch/detectron2/blob/ebe8b45437f86395352ab13402ba45b75b4d1ddb/detectron2/utils/video_visualizer.py#L104\r\n\r\n```\r\nFile \"/home/ubuntu/doc/code/MIMO-unofficial/venv/lib/python3.10/site-packages/detectron2/utils/video_visualizer.py\", line 104, in <listcomp>\r\n    _DetectedInstance(classes[i], boxes[i], mask_rle=None, color=colors[i], ttl=8)\r\nTypeError: 'NoneType' object is not subscriptable\r\n```",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5351,
    "title": "Cant Install Detecron 2 properly on Kaggle Notebooks.",
    "author": "MichaelSchroter",
    "state": "open",
    "created_at": "2024-08-17T06:30:03Z",
    "updated_at": "2024-10-12T02:16:24Z",
    "labels": [],
    "body": "Hi All, \r\n\r\nI am trying to install `detectron2 on Kaggle notbook but having trouble some dependencies. Please check code below.\r\n\r\n```\r\n!pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\n```\r\noutput\r\n```\r\nCollecting git+https://github.com/facebookresearch/detectron2.git\r\n  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-h4hsrdt3\r\n  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-h4hsrdt3\r\n  Resolved https://github.com/facebookresearch/detectron2.git to commit bcfd464d0c810f0442d91a349c0f6df945467143\r\n  Preparing metadata (setup.py) ... done\r\nRequirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (9.5.0)\r\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (3.7.5)\r\nCollecting pycocotools>=2.0.2 (from detectron2==0.6)\r\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.4.0)\r\nCollecting yacs>=0.1.8 (from detectron2==0.6)\r\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (0.9.0)\r\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.2.1)\r\nRequirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (4.66.4)\r\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.15.1)\r\nCollecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\r\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\r\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50.2/50.2 kB 2.3 MB/s eta 0:00:00\r\n  Preparing metadata (setup.py) ... done\r\nCollecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\r\n  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\r\nCollecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\r\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\r\nCollecting hydra-core>=1.1 (from detectron2==0.6)\r\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\r\nCollecting black (from detectron2==0.6)\r\n  Downloading black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (78 kB)\r\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 78.2/78.2 kB 4.3 MB/s eta 0:00:00\r\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (21.3)\r\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\r\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\r\nCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\r\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\r\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 117.0/117.0 kB 8.4 MB/s eta 0:00:00\r\n  Preparing metadata (setup.py) ... done\r\nCollecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\r\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\r\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.2.0)\r\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (0.12.1)\r\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (4.47.0)\r\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.4.5)\r\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (3.1.1)\r\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\r\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (8.1.7)\r\nRequirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (1.0.0)\r\nCollecting packaging (from detectron2==0.6)\r\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\r\nCollecting pathspec>=0.9.0 (from black->detectron2==0.6)\r\n  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\r\nRequirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (3.11.0)\r\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (2.0.1)\r\nRequirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (4.9.0)\r\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.4.0)\r\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.60.0)\r\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.26.1)\r\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.2.0)\r\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.5.2)\r\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.20.3)\r\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.32.3)\r\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (69.0.3)\r\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.16.0)\r\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (0.7.2)\r\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.0.3)\r\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\r\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\r\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.6)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.18)\r\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.7.4)\r\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\r\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.1)\r\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\r\nDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\r\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 154.5/154.5 kB 9.8 MB/s eta 0:00:00\r\nDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\r\nDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\r\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79.5/79.5 kB 5.8 MB/s eta 0:00:00\r\nDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\r\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 427.8/427.8 kB 19.9 MB/s eta 0:00:00\r\nDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\nDownloading black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\r\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.8/1.8 MB 57.8 MB/s eta 0:00:00\r\nDownloading packaging-24.1-py3-none-any.whl (53 kB)\r\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54.0/54.0 kB 3.4 MB/s eta 0:00:00\r\nDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\r\nDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\r\nBuilding wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\r\n  Building wheel for detectron2 (setup.py) ... done\r\n  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=1261576 sha256=10293c49dbed8251d848d89498b30f81138706a6d2c4f3890af593108d43a0c3\r\n  Stored in directory: /tmp/pip-ephem-wheel-cache-quggxtjc/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\r\n  Building wheel for fvcore (setup.py) ... done\r\n  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=59a701abd3cf565f191538643aa95bd946a602605daac8641a883994f5efafd4\r\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\r\n  Building wheel for antlr4-python3-runtime (setup.py) ... done\r\n  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=40dae5a72f84f496785a0ab72e5102a5a5c9ba76c88d68adf641a6ee8e072347\r\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\r\nSuccessfully built detectron2 fvcore antlr4-python3-runtime\r\nInstalling collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, packaging, omegaconf, iopath, hydra-core, black, pycocotools, fvcore, detectron2\r\n  Attempting uninstall: packaging\r\n    Found existing installation: packaging 21.3\r\n    Uninstalling packaging-21.3:\r\n      Successfully uninstalled packaging-21.3\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\ncudf 24.6.1 requires cubinlinker, which is not installed.\r\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\r\ncudf 24.6.1 requires ptxcompiler, which is not installed.\r\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\r\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\r\nkeras-cv 0.9.0 requires keras-core, which is not installed.\r\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\r\ndistributed 2024.5.1 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\r\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\r\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\nrapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\r\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\r\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\r\nSuccessfully installed antlr4-python3-runtime-4.9.3 black-24.8.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 omegaconf-2.3.0 packaging-24.1 pathspec-0.12.1 portalocker-2.10.1 pycocotools-2.0.8 yacs-0.1.8\r\n```\r\nFurthermore for;\r\n```\r\ntrainer.train()\r\n```\r\nI get and it hangs at:\r\n```\r\n/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3526.)\r\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n2024-08-17 06:22:17.586073: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n2024-08-17 06:22:17.586205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n2024-08-17 06:22:17.695880: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n```\r\nLooking at some earlier notebooks (3 years old) on Kaggle this does not seem have been an issue. However, this problem does not occur in Google Colab. This code could be reproduced by simply running the initial code on a Kaggle notebooks. Which is free to create and use.\r\n\r\nPlease help.\r\n\r\nThanks & Best Regards\r\nAMJS\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "Mudassar-MLE",
        "body": "Are you still facing installation issue?\r\n"
      }
    ]
  },
  {
    "issue_number": 810,
    "title": "How do I compute validation loss during training?",
    "author": "tshead2",
    "state": "closed",
    "created_at": "2020-02-05T18:03:14Z",
    "updated_at": "2024-10-11T21:51:03Z",
    "labels": [],
    "body": "## How do I compute validation loss during training?\r\n\r\nI'm trying to compute the loss on a validation dataset for each iteration during training.  To do so, I've created my own hook:\r\n\r\n```\r\nclass ValidationLoss(detectron2.engine.HookBase):\r\n    def __init__(self, config, dataset_name):\r\n        super(ValidationLoss, self).__init__()\r\n        self._loader = detectron2.data.build_detection_test_loader(config, dataset_name)\r\n        \r\n    def after_step(self):\r\n        for batch in self._loader:\r\n            loss = self.trainer.model(batch)\r\n            log.debug(f\"validation loss: {loss}\")\r\n```\r\n\r\n... which I register with a DefaultTrainer.  The hook code is called during training, but fails with the following:\r\n\r\n```\r\nINFO:detectron2.engine.train_loop:Starting training from iteration 0\r\nERROR:detectron2.engine.train_loop:Exception during training:\r\nTraceback (most recent call last):\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/engine/train_loop.py\", line 133, in train\r\n    self.after_step()\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/engine/train_loop.py\", line 153, in after_step\r\n    h.after_step()\r\n  File \"<ipython-input-6-63b308743b7d>\", line 8, in after_step\r\n    loss = self.trainer.model(batch)\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/modeling/meta_arch/rcnn.py\", line 123, in forward\r\n    proposals, proposal_losses = self.proposal_generator(images, features, gt_instances)\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/modeling/proposal_generator/rpn.py\", line 164, in forward\r\n    losses = {k: v * self.loss_weight for k, v in outputs.losses().items()}\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/modeling/proposal_generator/rpn_outputs.py\", line 322, in losses\r\n    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/modeling/proposal_generator/rpn_outputs.py\", line 262, in _get_ground_truth\r\n    for image_size_i, anchors_i, gt_boxes_i in zip(self.image_sizes, anchors, self.gt_boxes):\r\nTypeError: zip argument #3 must support iteration\r\nINFO:detectron2.engine.hooks:Total training time: 0:00:00 (0:00:00 on hooks)\r\n```\r\n\r\nThe traceback seems to imply that ground truth data is missing, which made me think that the data loader was the problem.  However, switching to a training loader produces a different error:\r\n\r\n```\r\nclass ValidationLoss(detectron2.engine.HookBase):\r\n    def __init__(self, config, dataset_name):\r\n        super(ValidationLoss, self).__init__()\r\n        self._loader = detectron2.data.build_detection_train_loader(config, dataset_name)\r\n        \r\n    def after_step(self):\r\n        for batch in self._loader:\r\n            loss = self.trainer.model(batch)\r\n            log.debug(f\"validation loss: {loss}\")\r\n```\r\n\r\n```\r\nINFO:detectron2.engine.train_loop:Starting training from iteration 0\r\nERROR:detectron2.engine.train_loop:Exception during training:\r\nTraceback (most recent call last):\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/engine/train_loop.py\", line 133, in train\r\n    self.after_step()\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/engine/train_loop.py\", line 153, in after_step\r\n    h.after_step()\r\n  File \"<ipython-input-6-e0d2c509cc72>\", line 7, in after_step\r\n    for batch in self._loader:\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/data/common.py\", line 109, in __iter__\r\n    for d in self.dataset:\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\r\n    data = self._next_data()\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 856, in _next_data\r\n    return self._process_data(data)\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 881, in _process_data\r\n    data.reraise()\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/torch/_utils.py\", line 394, in reraise\r\n    raise self.exc_type(msg)\r\nTypeError: Caught TypeError in DataLoader worker process 0.\r\nOriginal Traceback (most recent call last):\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\r\n    data = fetcher.fetch(index)\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\r\n    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\r\n    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/data/common.py\", line 39, in __getitem__\r\n    data = self._map_func(self._dataset[cur_idx])\r\n  File \"/ascldap/users/tshead/miniconda3/lib/python3.7/site-packages/detectron2/utils/serialize.py\", line 23, in __call__\r\n    return self._obj(*args, **kwargs)\r\nTypeError: 'str' object is not callable\r\n\r\nINFO:detectron2.engine.hooks:Total training time: 0:00:00 (0:00:00 on hooks)\r\n```\r\n\r\nAs a sanity check, *inference* works just fine:\r\n\r\n```\r\nclass ValidationLoss(detectron2.engine.HookBase):\r\n    def __init__(self, config, dataset_name):\r\n        super(ValidationLoss, self).__init__()\r\n        self._loader = detectron2.data.build_detection_test_loader(config, dataset_name)\r\n        \r\n    def after_step(self):\r\n        for batch in self._loader:\r\n            with detectron2.evaluation.inference_context(self.trainer.model):\r\n                loss = self.trainer.model(batch)\r\n                log.debug(f\"validation loss: {loss}\")\r\n```\r\n\r\n```\r\nINFO:detectron2.engine.train_loop:Starting training from iteration 0\r\nDEBUG:root:validation loss: [{'instances': Instances(num_instances=100, image_height=720, image_width=720, fields=[pred_boxes = Boxes(tensor([[4.4867e+02, 1.9488e+02, 5.1496e+02, 3.9878e+02],\r\n        [4.2163e+02, 1.1204e+02, 6.1118e+02, 5.5378e+02],\r\n        [8.7323e-01, 3.0374e+02, 9.2917e+01, 3.8698e+02],\r\n        [4.3202e+02, 2.0296e+02, 5.7938e+02, 3.6817e+02],\r\n        ...\r\n```\r\n\r\n... but that isn't what I want, of course.  Any thoughts?\r\n\r\nThanks in advance,\r\nTim\r\n",
    "comments": [
      {
        "user": "ppwwyyxx",
        "body": "> The traceback seems to imply that ground truth data is missing, \r\n\r\nThat's correct and it's because the default dataloader for test-set does not include ground truth: https://github.com/facebookresearch/detectron2/blob/ee0cbd8c67622ff2753493ce0dcfeb3e3dd9945e/detectron2/data/dataset_mapper.py#L109-L112\r\n\r\nYou can provide `mapper=` to create a dataloader that loads test data with ground truth.\r\n\r\n> However, switching to a training loader produces a different error:\r\n\r\nThat's because you're not calling `data.build_detection_train_loader` following its API: https://detectron2.readthedocs.io/modules/data.html#detectron2.data.build_detection_train_loader"
      },
      {
        "user": "tshead2",
        "body": "Ah, copy-and-paste error.  It's working now, thanks for the assist.\r\n\r\nCheers,\r\nTim"
      },
      {
        "user": "GorkemP",
        "body": "Hi @tshead2, \r\n\r\nafter creating hooker class, I performed the following:\r\n\r\n```\r\nvalLoss = ValidationLoss(cfg, 'my_validation_set')  \r\nhooks = [valLoss]  \r\ntrainer.register_hooks(hooks)  \r\nDefaultTrainer.build_test_loader(cfg, \"my_validation_set\")  \r\n```\r\nStill get the same error, do I have to create my own mapper function? Can  you provide me a template?\r\n\r\nThanks.\r\n"
      }
    ]
  },
  {
    "issue_number": 5379,
    "title": "Bug",
    "author": "DNOCHA3",
    "state": "open",
    "created_at": "2024-10-11T17:14:41Z",
    "updated_at": "2024-10-11T17:14:53Z",
    "labels": [
      "documentation"
    ],
    "body": "## üìö Documentation Issue\n\nThis issue category is for problems about existing documentation, not for asking how-to questions.\n\n* Provide a link to an existing documentation/comment/tutorial:\n\n* How should the above documentation/comment/tutorial improve:",
    "comments": [
      {
        "user": "DNOCHA3",
        "body": "Merger "
      }
    ]
  },
  {
    "issue_number": 5364,
    "title": "Please read & provide the following",
    "author": "Lin-UH",
    "state": "closed",
    "created_at": "2024-09-18T20:12:58Z",
    "updated_at": "2024-10-11T15:12:51Z",
    "labels": [
      "needs-more-info"
    ],
    "body": "    Install detectron2 on linux\r\nconda create --prefix ./envs python==3.10\r\nsource activate ./envs\r\nconda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\r\npip install opencv-python\r\ngit clone https://github.com/facebookresearch/detectron2.git\r\npython -m pip install -e detectron2\r\n\r\nRun demo \r\n\r\ncd demo/\r\npython demo.py --config-file ../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml \\\r\n  --input input1.jpg input2.jpg \\\r\n  --opts MODEL.WEIGHTS detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\r\n\r\n**Get error\r\nfrom vision.fair.detectron2.demo.predictor import VisualizationDemo\r\nModuleNotFoundError: No module named 'vision'**\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "yingqichao",
        "body": "i encountered the same. how did you resolve it? thx~"
      },
      {
        "user": "yfq512",
        "body": "\r\n\r\n\r\n\r\n> i encountered the same. how did you resolve it? thx~\r\n\r\ni encountered the same.  did you resolve it?‚Ä¶‚Ä¶"
      }
    ]
  },
  {
    "issue_number": 5377,
    "title": "YOLO-based series of detectors and  DERT need be update",
    "author": "ouyang11111",
    "state": "open",
    "created_at": "2024-10-11T07:32:29Z",
    "updated_at": "2024-10-11T07:33:29Z",
    "labels": [
      "enhancement"
    ],
    "body": "The YOLO-based series of detectors and DERT have long been the SOTA and widely used. We are still based on the FRCNN-2015 framework, which is too old. When will the detection base model be updated to add the YOLO series models and DERT?",
    "comments": []
  },
  {
    "issue_number": 4504,
    "title": "Python 3.10 support",
    "author": "tiagofrepereira2012",
    "state": "open",
    "created_at": "2022-08-26T12:19:09Z",
    "updated_at": "2024-10-09T15:26:56Z",
    "labels": [
      "enhancement"
    ],
    "body": "## üöÄ Feature\r\nSupport to python 3.10\r\n\r\n## Motivation & Examples\r\n\r\nWould be useful for the community to have support to python 3.10\r\nDetectron2 is supported from py3.6 until py3.9 as we can be seen here: https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.10/index.html\r\n\r\nIs it complicated to have a wheel for python 3.10?\r\n\r\nThanks\r\n\r\n\r\n",
    "comments": [
      {
        "user": "CodePint",
        "body": "2 years later and still no response, guess this library is headed for the scrapheap."
      }
    ]
  },
  {
    "issue_number": 5359,
    "title": "Unable to build detectron2 with python 3.10 since 3.8 version is going to close soon.",
    "author": "DivyaKanniah",
    "state": "open",
    "created_at": "2024-09-03T11:54:17Z",
    "updated_at": "2024-10-09T15:25:52Z",
    "labels": [],
    "body": "hi team,\r\n\r\ni am unable to build the docker image with python 3.10 version since i need to upgrade from 3.8 as it expires sooner ,\r\n\r\nbelow is my error :\r\nnumpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\"",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "DivyaKanniah",
        "body": "\"Instructions To Reproduce the Issue and Full Logs :\r\n\r\nBuild docker with python 3.10 \r\n\r\nlogs:\r\n{\r\n    \"errorMessage\": \"numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\",\r\n    \"errorType\": \"ValueError\",\r\n    \"requestId\": \"\",\r\n    \"stackTrace\": [\r\n        \"  File \\\"/var/lang/lib/python3.9/importlib/__init__.py\\\", line 127, in import_module\\n    return _bootstrap._gcd_import(name[level:], package, level)\\n\",\r\n        \"  File \\\"<frozen importlib._bootstrap>\\\", line 1030, in _gcd_import\\n\",\r\n        \"  File \\\"<frozen importlib._bootstrap>\\\", line 1007, in _find_and_load\\n\",\r\n        \"  File \\\"<frozen importlib._bootstrap>\\\", line 986, in _find_and_load_unlocked\\n\",\r\n        \"  File \\\"<frozen importlib._bootstrap>\\\", line 680, in _load_unlocked\\n\",\r\n        \"  File \\\"<frozen importlib._bootstrap_external>\\\", line 850, in exec_module\\n\",\r\n        \"  File \\\"<frozen importlib._bootstrap>\\\", line 228, in _call_with_frames_removed\\n\",\r\n        \"  File \\\"/var/task/Summary_New_Post_JSON_Lambda.py\\\", line 6, in <module>\\n    import pandas as pd\\n\",\r\n        \"  File \\\"/var/task/pandas/__init__.py\\\", line 22, in <module>\\n    from pandas.compat import is_numpy_dev as _is_numpy_dev\\n\",\r\n        \"  File \\\"/var/task/pandas/compat/__init__.py\\\", line 15, in <module>\\n    from pandas.compat.numpy import (\\n\",\r\n        \"  File \\\"/var/task/pandas/compat/numpy/__init__.py\\\", line 4, in <module>\\n    from pandas.util.version import Version\\n\",\r\n        \"  File \\\"/var/task/pandas/util/__init__.py\\\", line 1, in <module>\\n    from pandas.util._decorators import (  # noqa:F401\\n\",\r\n        \"  File \\\"/var/task/pandas/util/_decorators.py\\\", line 14, in <module>\\n    from pandas._libs.properties import cache_readonly  # noqa:F401\\n\",\r\n        \"  File \\\"/var/task/pandas/_libs/__init__.py\\\", line 13, in <module>\\n    from pandas._libs.interval import Interval\\n\",\r\n        \"  File \\\"pandas/_libs/interval.pyx\\\", line 1, in init pandas._libs.interval\\n    import numbers\\n\"\r\n    ]\r\n}"
      },
      {
        "user": "CodePint",
        "body": "Anyone? We just need a new wheel building and publishing to pypy?"
      }
    ]
  },
  {
    "issue_number": 5173,
    "title": "yolov5 model while trying to create a confusion matrix, I encountered an issue. Please help.",
    "author": "asdfzxcvasdfdsaf",
    "state": "closed",
    "created_at": "2023-12-06T08:42:53Z",
    "updated_at": "2024-10-09T02:07:44Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "code : \r\nimport torch\r\nfrom torch.utils.data import DataLoader\r\nfrom torchvision import transforms\r\nfrom torchvision.datasets import ImageFolder\r\nfrom sklearn.metrics import confusion_matrix, classification_report\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nfrom PIL import Image\r\n\r\ndata_dir = \"/content/testdataset\"\r\n\r\ntransform = transforms.Compose([\r\n    transforms.Resize((224, 224)),\r\n    transforms.ToTensor(),\r\n])\r\n\r\ndataset = ImageFolder(data_dir, transform=transform)\r\ndataloader = DataLoader(dataset, batch_size=32, shuffle=False)\r\nprint(dataset)\r\n\r\noutput : \r\nDataset ImageFolder\r\n    Number of datapoints: 1491\r\n    Root location: /content/testdataset\r\n    StandardTransform\r\nTransform: Compose(\r\n               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\r\n               ToTensor()\r\n           )\r\n           \r\n           \r\nI was fine until now, but I'm encountering issues from this point onward.       \r\n\r\ncode : \r\nmodel.eval()\r\n\r\n\r\nall_predictions = []\r\nall_labels = []\r\n\r\n\r\nfor inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\r\n    # Î™®Îç∏ ÏòàÏ∏° ÏàòÌñâ\r\n    with torch.no_grad():\r\n        outputs = model(inputs)\r\n\r\n----> 8 for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\r\nUnidentifiedImageError: cannot identify image file <_io.BufferedReader name='/content/testdataset/with_mask/1 (371).jpeg'>",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5241,
    "title": "inference_on_dataset get Killed ",
    "author": "antof27",
    "state": "open",
    "created_at": "2024-03-16T14:56:07Z",
    "updated_at": "2024-10-08T09:10:20Z",
    "labels": [],
    "body": "Hi everyone, \r\nI'm currently working on evaluating my model using the validation dataset. However, I'm encountering an error after running the inference_on_dataset method.\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\n```\r\nfrom detectron2.engine import DefaultPredictor\r\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\r\nfrom detectron2.data import build_detection_test_loader\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2 import model_zoo\r\nimport os\r\nimport torch\r\nfrom register_dataset import load_dataset \r\n\r\n# Paths to JSON annotations and image roots\r\ntrain_json_path = \"<path/to/train/json>\"\r\ntrain_image_root = \"<path/to/train/images>\"\r\nval_json_path = \"<path/to/val/json>\"\r\n val_image_root = \"<path/to/val/images>\"\r\n\r\n# Load test dataset\r\n_, _, val_dataset_dicts, val_metadata = load_dataset(train_json_path, train_image_root, val_json_path, val_image_root)\r\n\r\n# Initialize configuration\r\ncfg = get_cfg()\r\ncfg.OUTPUT_DIR = \"<path/as/destination>\"\r\ncfg.DATASETS.TEST = (\"validation_set\",)\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"))\r\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"one_epoch.pth\")  \r\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.01\r\nnumber_of_classes = len(val_metadata.thing_classes)\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = number_of_classes\r\ncfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\nprint(\"Model device, \", cfg.MODEL.DEVICE)\r\n\r\n\r\n# Create a predictor\r\npredictor = DefaultPredictor(cfg)\r\nprint(\"Predictor created\")\r\n\r\n# Set up evaluator\r\nevaluator = COCOEvaluator(\"validation_set\", cfg, False, output_dir=cfg.OUTPUT_DIR)\r\nprint(\"Evaluator created\")\r\n\r\n# Create validation data loader\r\nvalidation_loader = build_detection_test_loader(cfg, \"validation_set\", batch_size=1, num_workers=2)\r\nprint(\"Validation loader created\")\r\n\r\n# Perform inference on the validation dataset\r\nresults = inference_on_dataset(predictor.model, validation_loader, evaluator)\r\nprint(\"Evaluation results:\", results)\r\n\r\n```\r\nWhere `load_dataset` is: \r\n\r\n```\r\ndef load_dataset(train_json_path, train_image_root, val_json_path, val_image_root):\r\n    # Register COCO instances for training and validation sets\r\n    register_coco_instances(\"training_set\", {}, train_json_path, train_image_root)\r\n    register_coco_instances(\"validation_set\", {}, val_json_path, val_image_root)\r\n    \r\n    # Retrieve dataset dictionaries and metadata for training set\r\n    train_dataset_dicts = DatasetCatalog.get(\"training_set\")\r\n    train_metadata = MetadataCatalog.get(\"training_set\")\r\n    \r\n    # Retrieve dataset dictionaries and metadata for validation set\r\n    val_dataset_dicts = DatasetCatalog.get(\"validation_set\")\r\n    val_metadata = MetadataCatalog.get(\"validation_set\")\r\n    return train_dataset_dicts, train_metadata, val_dataset_dicts, val_metadata\r\n\r\n```\r\n\r\nI'm expecting to obtain the predictions on the validation set, but I when I compile it, this error occurs:\r\n\r\n\r\n\r\n```\r\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\r\nModel device,  cuda\r\nSkip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (2861, 1024) in the checkpoint but (1180, 1024) in the model! You might want to double check if this is expected.\r\nSkip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (2861,) in the checkpoint but (1180,) in the model! You might want to double check if this is expected.\r\nSkip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (11440, 1024) in the checkpoint but (4716, 1024) in the model! You might want to double check if this is expected.\r\nSkip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (11440,) in the checkpoint but (4716,) in the model! You might want to double check if this is expected.\r\nSome model parameters or buffers are not found in the checkpoint:\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\nPredictor created\r\nCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\r\nEvaluator created\r\n\r\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\r\n\r\nValidation loader created\r\nStarting inference on the validation dataset...\r\nLoading and preparing results...\r\nDONE (t=11.53s)\r\ncreating index...\r\nindex created!\r\nKilled\r\n```\r\nI don't get why the process is killed. Have anyone had the same issue? Thanks in advance! ",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Your Environment\"; "
      },
      {
        "user": "antoinedelplace",
        "body": "You are probably running out of CPU RAM.\r\nMaybe you can dynamically fetch your data so that the CPU RAM is not overloaded."
      },
      {
        "user": "antoinedelplace",
        "body": "Also, you can use this module to raise an exception when CPU RAM is overloaded instead of having your process killed.\r\n\r\n```\r\nimport resource\r\n\r\n# Set a limit of 500 MB on memory usage (hard and soft limit)\r\ndef set_memory_limit(max_memory_mb):\r\n    max_memory_bytes = max_memory_mb * 1024 * 1024\r\n    resource.setrlimit(resource.RLIMIT_AS, (max_memory_bytes, max_memory_bytes))\r\n\r\ndef memory_intensive_task():\r\n    try:\r\n        set_memory_limit(500)  # Set limit to 500 MB\r\n        # Simulate memory intensive task\r\n        huge_list = [i for i in range(10**8)]\r\n    except MemoryError:\r\n        print(\"Memory limit exceeded!\")\r\n\r\nif __name__ == \"__main__\":\r\n    memory_intensive_task()\r\n```"
      }
    ]
  },
  {
    "issue_number": 1020,
    "title": "Cannot train on gray image",
    "author": "MabinogiX",
    "state": "closed",
    "created_at": "2020-03-10T05:19:00Z",
    "updated_at": "2024-10-07T17:41:18Z",
    "labels": [
      "enhancement"
    ],
    "body": "I installed torch, torchvision, detectron2 via pip. I have set MODEL.PIXEL_MEAN/STD to single-item list like:\r\n```\r\ncfg.MODEL.PIXEL_MEAN = [103.530]\r\ncfg.MODEL.PIXEL_STD = [1.0]\r\ncfg.INPUT.FORMAT = \"L\"\r\n```\r\n\r\nBut I got this error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/site-packages/detectron2/engine/train_loop.py\", line 132, in train\r\n    self.run_step()\r\n  File \"/usr/local/lib/python3.7/site-packages/detectron2/engine/train_loop.py\", line 208, in run_step\r\n    data = next(self._data_loader_iter)\r\n  File \"/usr/local/lib/python3.7/site-packages/detectron2/data/common.py\", line 109, in __iter__\r\n    for d in self.dataset:\r\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\r\n    data = self._next_data()\r\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 856, in _next_data\r\n    return self._process_data(data)\r\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 881, in _process_dat\r\na\r\n    data.reraise()\r\n  File \"/usr/local/lib/python3.7/site-packages/torch/_utils.py\", line 394, in reraise\r\n    raise self.exc_type(msg)\r\nTypeError: Caught TypeError in DataLoader worker process 0.\r\nOriginal Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/site-packages/PIL/Image.py\", line 2645, in fromarray\r\n    mode, rawmode = _fromarray_typemap[typekey]\r\nKeyError: ((1, 1, 1), '|u1')\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_l\r\noop\r\n    data = fetcher.fetch(index)\r\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\r\n    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\r\n    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n  File \"/usr/local/lib/python3.7/site-packages/detectron2/data/common.py\", line 39, in __getitem__\r\n    data = self._map_func(self._dataset[cur_idx])\r\n  File \"/usr/local/lib/python3.7/site-packages/detectron2/utils/serialize.py\", line 23, in __call__\r\n    return self._obj(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/detectron2/data/dataset_mapper.py\", line 92, in __call__\r\n    image, transforms = T.apply_transform_gens(self.tfm_gens, image)\r\n  File \"/usr/local/lib/python3.7/site-packages/detectron2/data/transforms/transform_gen.py\", line 445, in\r\n apply_transform_gens\r\n    img = tfm.apply_image(img)\r\n  File \"/usr/local/lib/python3.7/site-packages/detectron2/data/transforms/transform.py\", line 81, in appl\r\ny_image\r\n    pil_image = Image.fromarray(img)\r\n  File \"/usr/local/lib/python3.7/site-packages/PIL/Image.py\", line 2647, in fromarray\r\n    raise TypeError(\"Cannot handle this data type\")\r\nTypeError: Cannot handle this data type\r\n```\r\n\r\nIt seems has something to do with the image shape. When reading image with format \"L\", the image array dimension was expanded (line 68 in `detection_utils.py`):\r\n```\r\nif format == \"L\":\r\n    image = np.expand_dims(image, -1)\r\n```\r\nAnd when the image array was converted back to PIL.Image in `transform.py`(line 81), data type error was raised.",
    "comments": [
      {
        "user": "rtarquini",
        "body": "I plan on doing something similar with my single channel 16-bit single channel dataset.  I noticed format 'L'  is 8-bit. What the datatype+shape of pil_image, single channel grayscale 0-255?  "
      },
      {
        "user": "ppwwyyxx",
        "body": "It seems PIL does not support 16bit images, so you'll need to use https://detectron2.readthedocs.io/tutorials/data_loading.html#write-a-custom-dataloader to read the image with other libraries.\r\n\r\nWe do need to improve the transformation support for gray scale images."
      },
      {
        "user": "rtarquini",
        "body": "Writing a custom dataloader seems pretty straight forward for me. I was just uncertain how to build/train a Faster RCNN model with 16-bit single channel data. I would not be loading a preconfigured model, but training from scratch since my data is not RGB images.  "
      }
    ]
  },
  {
    "issue_number": 5372,
    "title": "Machine crashing before run trainer.train() line",
    "author": "VictorGimenez",
    "state": "open",
    "created_at": "2024-10-03T17:44:29Z",
    "updated_at": "2024-10-03T17:45:33Z",
    "labels": [],
    "body": "I ran a script to inference a custom dataset made by myself with more than 300 annotation following this tutorial: https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5 I used the following parameters in the config:\r\n\r\n``` \r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\r\ncfg.DATASETS.TRAIN = [\"objects\" + \"_\" + \"train\"]\r\ncfg.DATASETS.TEST = []\r\ncfg.DATALOADER.NUM_WORKERS = 3\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\r\ncfg.SOLVER.IMS_PER_BATCH = 2\r\ncfg.SOLVER.BASE_LR = 0.0025\r\ncfg.SOLVER.MAX_ITER = 400\r\ncfg.SOLVER.STEPS = []      \r\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 200\r\ncfg.MODEL.DEVICE = \"cuda\"\r\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\r\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\r\n```\r\n\r\nAt the moment that I ran this line:\r\n```\r\nimport numpy as np\r\nfrom threading import Thread\r\nfrom queue import Queue\r\nimport sys\r\nimport os\r\nfrom tqdm import tqdm\r\nimport cv2 as cv\r\nimport torch\r\nimport json\r\nimport paho.mqtt.publish as publish\r\nimport time\r\n\r\nnp.set_printoptions(threshold=sys.maxsize)\r\n\r\n# import some common detectron2 utilities\r\nfrom detectron2 import model_zoo\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\r\nfrom detectron2.checkpoint import DetectionCheckpointer\r\n# from detectron2.utils.video_visualizer import VideoVisualizer\r\nfrom detectron2.utils.visualizer import ColorMode, Visualizer\r\nfrom detectron2.modeling import build_model\r\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\r\nfrom detectron2.structures import BoxMode, Boxes, Instances\r\n\r\n\r\nfrom shapely.geometry import Polygon, Point\r\n...\r\n...\r\ncfg.OUTPUT_DIR=\"./output\"\r\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\ntrainer = DefaultTrainer(cfg) \r\ntrainer.resume_or_load(resume=False)\r\ntrainer.train()\r\n```\r\n\r\nUnfortunately my execution didn't come to run the ```trainer.train()``` line and my machine crashed on the trainer.resume_or_load(resume=False), I checked my main memory and swap partitions with ```htop``` and at the time that my script came in this line the progress bar stays whole red and both bars went until their limit.\r\n\r\nI ran the script directly as python <name_of_my_script.py>.\r\n\r\nI would like to know if anyone faced the same as me, and how to fix it!",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      }
    ]
  },
  {
    "issue_number": 5064,
    "title": "AssertionError: RPN requires gt_instances in training!",
    "author": "gabrieldevopsai",
    "state": "open",
    "created_at": "2023-08-22T14:17:13Z",
    "updated_at": "2024-10-01T13:16:06Z",
    "labels": [],
    "body": "## I can't train object detection:\r\n\r\n\r\n\r\nDataset dicts:\r\n{'bbox': [305, 709, 538, 577],\r\n 'bbox_mode': <BoxMode.XYXY_ABS: 0>,\r\n 'category_id': 6,\r\n 'file_name': '/home/azureuser/projects/1.jpg',\r\n 'height': 841,\r\n 'image_id': 8309,\r\n 'segmentation': [[[305, 709, 538, 577]]],\r\n 'width': 595}\r\n}\r\n\r\nMy code:\r\n\r\n\r\n```\r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\r\ncfg.DATASETS.TRAIN = (\"vda_train_v31\",)\r\ncfg.DATASETS.TEST = ()\r\ncfg.DATALOADER.NUM_WORKERS = 2\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\r\ncfg.SOLVER.IMS_PER_BATCH = 2\r\ncfg.SOLVER.BASE_LR = 0.00025  # pick a good LR 0.00025 \r\ncfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\r\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 7  # only has one class (ballon)\r\n\r\ntrainer = CocoTrainer(cfg)\r\ntrainer.resume_or_load(resume=False)\r\ntrainer.train()\r\n```\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "ALIABB17",
        "body": "Hello, i encountered the same issue, did you solve it?"
      }
    ]
  },
  {
    "issue_number": 5169,
    "title": "KeyError: 'Non-existent config key: MODEL.DENSEPOSE_ON'",
    "author": "FurkanGozukara",
    "state": "closed",
    "created_at": "2023-12-05T12:56:19Z",
    "updated_at": "2024-10-01T02:14:07Z",
    "labels": [],
    "body": "I have installed like below\r\n\r\npip install git+https://github.com/facebookresearch/detectron2.git\r\n\r\nit is working\r\n\r\nthe problem is when I try like below I am getting below error\r\n\r\nI think you fixed this issue how? \r\n\r\n@andrewjong @malcolmgarner-movement @ak9250 \r\n\r\n```\r\nimport cv2\r\nimport torch\r\nfrom detectron2.engine import DefaultPredictor\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.utils.visualizer import Visualizer\r\nfrom detectron2.data import MetadataCatalog\r\n\r\ndef setup_cfg():\r\n    cfg = get_cfg()\r\n    cfg.merge_from_file(\"densepose_rcnn_R_101_FPN_DL_s1x.yaml\")\r\n    cfg.MODEL.WEIGHTS = \"model_final_844d15.pkl\"\r\n    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n    return cfg\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"G:\\magic_animate\\compose_densepose\\pose_maker.py\", line 45, in <module>\r\n    process_video('ex1.mp4', 'output_video.mp4')\r\n  File \"G:\\magic_animate\\compose_densepose\\pose_maker.py\", line 18, in process_video\r\n    cfg = setup_cfg()\r\n  File \"G:\\magic_animate\\compose_densepose\\pose_maker.py\", line 11, in setup_cfg\r\n    cfg.merge_from_file(\"densepose_rcnn_R_50_FPN_s1x.yaml\")\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\detectron2\\config\\config.py\", line 69, in merge_from_file\r\n    self.merge_from_other_cfg(loaded_cfg)\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\fvcore\\common\\config.py\", line 132, in merge_from_other_cfg\r\n    return super().merge_from_other_cfg(cfg_other)\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\yacs\\config.py\", line 217, in merge_from_other_cfg\r\n    _merge_a_into_b(cfg_other, self, self, [])\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\yacs\\config.py\", line 478, in _merge_a_into_b\r\n    _merge_a_into_b(v, b[k], root, key_list + [k])\r\n  File \"G:\\magic_animate\\compose_densepose\\detectron2\\venv\\lib\\site-packages\\yacs\\config.py\", line 491, in _merge_a_into_b\r\n    raise KeyError(\"Non-existent config key: {}\".format(full_key))\r\nKeyError: 'Non-existent config key: MODEL.DENSEPOSE_ON'\r\nPress any key to continue . . .\r\n```\r\n\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      }
    ]
  },
  {
    "issue_number": 5167,
    "title": "How to genersate a Dense Pose video with this",
    "author": "FurkanGozukara",
    "state": "closed",
    "created_at": "2023-12-05T02:00:44Z",
    "updated_at": "2024-10-01T02:14:07Z",
    "labels": [
      "needs-more-info"
    ],
    "body": "I need to generate a Dense Pose video like below from given raw video\r\n\r\nAny examples?\r\n\r\n\r\nhttps://github.com/facebookresearch/detectron2/assets/19240467/af0e97e6-0bbd-4caf-9510-978d779890c6\r\n\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      }
    ]
  },
  {
    "issue_number": 5086,
    "title": "assert prefetch_factor > 0 issue when run the example",
    "author": "shefrat",
    "state": "closed",
    "created_at": "2023-09-11T02:21:03Z",
    "updated_at": "2024-09-30T02:11:27Z",
    "labels": [],
    "body": "Hello,\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nI was following \"Detectron2 Tutorial\", but when I try to train on the custom dataset (balloon example), but after running this code:\r\n```\r\nfrom detectron2.engine import DefaultTrainer\r\n\r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\r\ncfg.DATASETS.TRAIN = (\"balloon_train\",)\r\ncfg.DATASETS.TEST = ()\r\ncfg.DATALOADER.NUM_WORKERS = 2\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\r\ncfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\r\ncfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\r\ncfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\r\ncfg.SOLVER.STEPS = []        # do not decay learning rate\r\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\r\n# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\r\n\r\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\ntrainer = DefaultTrainer(cfg) \r\ntrainer.resume_or_load(resume=False)\r\ntrainer.train()\r\n```\r\n\r\n\r\nI got this error:\r\n```\r\n[09/11 01:38:29 d2.engine.defaults]: Model:\r\nGeneralizedRCNN(\r\n  (backbone): FPN(\r\n    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (top_block): LastLevelMaxPool()\r\n    (bottom_up): ResNet(\r\n      (stem): BasicStem(\r\n        (conv1): Conv2d(\r\n          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\r\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n        )\r\n      )\r\n      (res2): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res3): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res4): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (4): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (5): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res5): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n    )\r\n  )\r\n  (proposal_generator): RPN(\r\n    (rpn_head): StandardRPNHead(\r\n      (conv): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n    (anchor_generator): DefaultAnchorGenerator(\r\n      (cell_anchors): BufferList()\r\n    )\r\n  )\r\n  (roi_heads): StandardROIHeads(\r\n    (box_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (box_head): FastRCNNConvFCHead(\r\n      (flatten): Flatten(start_dim=1, end_dim=-1)\r\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\r\n      (fc_relu1): ReLU()\r\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\r\n      (fc_relu2): ReLU()\r\n    )\r\n    (box_predictor): FastRCNNOutputLayers(\r\n      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\r\n      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\r\n    )\r\n    (mask_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (mask_head): MaskRCNNConvUpsampleHead(\r\n      (mask_fcn1): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn2): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn3): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn4): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\r\n      (deconv_relu): ReLU()\r\n      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n  )\r\n)\r\n[09/11 01:38:30 d2.data.build]: Removed 0 images with no usable annotations. 61 images left.\r\n[09/11 01:38:30 d2.data.build]: Distribution of instances among all 1 categories:\r\n|  category  | #instances   |\r\n|:----------:|:-------------|\r\n|  balloon   | 255          |\r\n|            |              |\r\n[09/11 01:38:30 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\r\n[09/11 01:38:30 d2.data.build]: Using training sampler TrainingSampler\r\n[09/11 01:38:30 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\r\n[09/11 01:38:30 d2.data.common]: Serializing 61 elements to byte tensors and concatenating them all ...\r\n[09/11 01:38:30 d2.data.common]: Serialized dataset takes 0.17 MiB\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nCell In[30], line 18\r\n     15 # NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\r\n     17 os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n---> 18 trainer = DefaultTrainer(cfg) \r\n     19 trainer.resume_or_load(resume=False)\r\n     20 trainer.train()\r\n\r\nFile ~/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py:378, in DefaultTrainer.__init__(self, cfg)\r\n    376 model = self.build_model(cfg)\r\n    377 optimizer = self.build_optimizer(cfg, model)\r\n--> 378 data_loader = self.build_train_loader(cfg)\r\n    380 model = create_ddp_model(model, broadcast_buffers=False)\r\n    381 self._trainer = (AMPTrainer if cfg.SOLVER.AMP.ENABLED else SimpleTrainer)(\r\n    382     model, data_loader, optimizer\r\n    383 )\r\n\r\nFile ~/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py:547, in DefaultTrainer.build_train_loader(cls, cfg)\r\n    538 @classmethod\r\n    539 def build_train_loader(cls, cfg):\r\n    540     \"\"\"\r\n    541     Returns:\r\n    542         iterable\r\n   (...)\r\n    545     Overwrite it if you'd like a different data loader.\r\n    546     \"\"\"\r\n--> 547     return build_detection_train_loader(cfg)\r\n\r\nFile ~/.local/lib/python3.8/site-packages/detectron2/config/config.py:208, in configurable.<locals>.wrapper.<locals>.wrapped(*args, **kwargs)\r\n    206 if _called_with_cfg(*args, **kwargs):\r\n    207     explicit_args = _get_args_from_config(from_config, *args, **kwargs)\r\n--> 208     return orig_func(**explicit_args)\r\n    209 else:\r\n    210     return orig_func(*args, **kwargs)\r\n\r\nFile ~/.local/lib/python3.8/site-packages/detectron2/data/build.py:538, in build_detection_train_loader(dataset, mapper, sampler, total_batch_size, aspect_ratio_grouping, num_workers, collate_fn, prefetch_factor, persistent_workers, pin_memory)\r\n    536         sampler = TrainingSampler(len(dataset))\r\n    537     assert isinstance(sampler, torchdata.Sampler), f\"Expect a Sampler but got {type(sampler)}\"\r\n--> 538 return build_batch_data_loader(\r\n    539     dataset,\r\n    540     sampler,\r\n    541     total_batch_size,\r\n    542     aspect_ratio_grouping=aspect_ratio_grouping,\r\n    543     num_workers=num_workers,\r\n    544     collate_fn=collate_fn,\r\n    545     prefetch_factor=prefetch_factor,\r\n    546     persistent_workers=persistent_workers,\r\n    547     pin_memory=pin_memory,\r\n    548 )\r\n\r\nFile ~/.local/lib/python3.8/site-packages/detectron2/data/build.py:328, in build_batch_data_loader(dataset, sampler, total_batch_size, aspect_ratio_grouping, num_workers, collate_fn, drop_last, prefetch_factor, persistent_workers, pin_memory)\r\n    326 if aspect_ratio_grouping:\r\n    327     assert drop_last, \"Aspect ratio grouping will drop incomplete batches.\"\r\n--> 328     data_loader = torchdata.DataLoader(\r\n    329         dataset,\r\n    330         num_workers=num_workers,\r\n    331         collate_fn=operator.itemgetter(0),  # don't batch, but yield individual elements\r\n    332         worker_init_fn=worker_init_reset_seed,\r\n    333         prefetch_factor=prefetch_factor,\r\n    334         persistent_workers=persistent_workers,\r\n    335         pin_memory=pin_memory,\r\n    336     )  # yield individual mapped dict\r\n    337     data_loader = AspectRatioGroupedDataset(data_loader, batch_size)\r\n    338     if collate_fn is None:\r\n\r\nFile ~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:187, in DataLoader.__init__(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\r\n    184 if num_workers == 0 and prefetch_factor != 2:\r\n    185     raise ValueError('prefetch_factor option could only be specified in multiprocessing.'\r\n    186                      'let num_workers > 0 to enable multiprocessing.')\r\n--> 187 assert prefetch_factor > 0\r\n    189 if persistent_workers and num_workers == 0:\r\n    190     raise ValueError('persistent_workers option needs num_workers > 0')\r\n\r\nTypeError: '>' not supported between instances of 'NoneType' and 'int'\r\n\r\n```\r\n\r\n\r\n## Environment:\r\n\r\n```\r\n-------------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.8.0 (default, Dec  9 2021, 17:53:27) [GCC 8.4.0]\r\nnumpy                            1.24.4\r\ndetectron2                       0.6 @/home/ubuntu/.local/lib/python3.8/site-packages/detectron2\r\ndetectron2._C                    not built correctly: /home/ubuntu/.local/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor7reshapeEN3c108ArrayRefIlEE\r\nCompiler ($CXX)                  c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCUDA compiler                    Cuda compilation tools, release 10.0, V10.0.130\r\ndetectron2 arch flags            5.2\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          1.11.0+cu102 @/home/ubuntu/.local/lib/python3.8/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0                            Tesla M60 (arch=5.2)\r\nDriver version                   450.142.00\r\nCUDA_HOME                        /usr/local/cuda\r\nPillow                           10.0.0\r\ntorchvision                      0.12.0+cu102 @/home/ubuntu/.local/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.8.0\r\n-------------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 10.2\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\r\n  - CuDNN 7.6.5\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n\r\n```\r\n\r\nI hope this is the correct place to get help to solve the issue, I'm not sure if I need to post it here or in the Torch repository issues.\r\n\r\n",
    "comments": [
      {
        "user": "yannqi",
        "body": "I meet the same error. \r\nAnd I find it is caused by the latest detectron2 version of fc9c33b1f6e5d4c37bbb46dde19af41afc1ddb2a. (But I don't know why). \r\nYou need to go back to the past version. "
      },
      {
        "user": "shefrat",
        "body": "> I meet the same error. And I find it is caused by the latest detectron2 version of [fc9c33b](https://github.com/facebookresearch/detectron2/commit/fc9c33b1f6e5d4c37bbb46dde19af41afc1ddb2a). (But I don't know why). You need to go back to the past version.\r\n\r\nYes, when I changed the file, it worked.\r\nThanks a lot."
      },
      {
        "user": "UNHYUN-LEE",
        "body": "same issue. how it solve"
      }
    ]
  },
  {
    "issue_number": 5178,
    "title": "New release detectron2 v1.0",
    "author": "bouachalazhar",
    "state": "open",
    "created_at": "2023-12-09T11:37:42Z",
    "updated_at": "2024-09-23T07:23:48Z",
    "labels": [
      "enhancement"
    ],
    "body": "## üöÄ Feature\nSince PyTorch v2.0 some functions are not compatible, we can add SAM, ViT and GPT. Finally clean up project.\n\n## Motivation & Examples\n\ndetectron2 v1.0 can be more stable  and fast if we add `torch.compile()`. It's primordial to create a PyPi project and who can be used by all OS (I think at Windows). \n\nAn example for installation detectron2 : \n\n`python -m pip install detectron2`",
    "comments": [
      {
        "user": "RiccardoMaistri",
        "body": "I agree, with you!. I am just wondering why no more versions of detectron2 have been released since Nov 2021"
      },
      {
        "user": "SergiyShebotnov",
        "body": "> I agree, with you!. I am just wondering why no more versions of detectron2 have been released since Nov 2021\r\n\r\nEveryone probably uses HuggingFace, Meta included."
      },
      {
        "user": "HppZ",
        "body": "Sorry, I don't understand. Where to get the latest detectron2 and pre-trained models?"
      }
    ]
  },
  {
    "issue_number": 5366,
    "title": "Add ability to disable EXIF orientations.",
    "author": "Erotemic",
    "state": "open",
    "created_at": "2024-09-21T17:35:47Z",
    "updated_at": "2024-09-21T18:06:03Z",
    "labels": [
      "enhancement"
    ],
    "body": "## üöÄ Feature\r\n\r\nI would like to be able to specify a config option that disables EXIF orientation corrections. \r\n\r\n## Motivation & Examples\r\n\r\nI have a coco-style dataset where all annotations are stored with respect to the encoded image size on disk. In other words the annotations ignore the EXIF information. I could attempt to modify my dataset to correct for this, but then it will break with all of my tools which will not apply any EXIF transforms. It would be much easier to interoperate with detectron2.\r\n\r\nI've been able to work around this on my end by just adding the patch:\r\n\r\n```diff\r\ndiff --git a/detectron2/data/detection_utils.py b/detectron2/data/detection_utils.py\r\nindex 8d6173e..4b7bc19 100644\r\n--- a/detectron2/data/detection_utils.py\r\n+++ b/detectron2/data/detection_utils.py\r\n@@ -135,6 +135,7 @@ def _apply_exif_orientation(image):\r\n     Returns:\r\n         (PIL.Image): the PIL image with exif orientation applied, if applicable\r\n     \"\"\"\r\n+    return image\r\n     if not hasattr(image, \"getexif\"):\r\n         return image\r\n```\r\n\r\nwhich simply skips the exif correction. It would be nice if I could just do something like:\r\n\r\n```python\r\ncfg = get_cfg()\r\ncfg.merge_from_file(repo_path / 'configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml')\r\ncfg.DATASETS.TRAIN = ('train_imgs5747_1e73d54f',)\r\ncfg.DATASETS.TEST = ()\r\ncfg.DATASETS.IGNORE_EXIF = True\r\n```\r\n\r\nand use detectron2 without modification of the code or dataset.\r\n\r\nI could make this PR, but I would like input from maintainers before I do. \r\n",
    "comments": [
      {
        "user": "Erotemic",
        "body": "Note on my end, I need to think about how to support EXIF data for the case where the user does want to respect it by default. I've opened an issue for that here:  https://gitlab.kitware.com/computer-vision/kwcoco/-/issues/15 but it would be nice if detectron2 could also provide the ability to work with both the case where the underlying coco-style dataset registers the images in a way that ignores exif or accounts for exif, and I think the patch would be rather small. "
      }
    ]
  },
  {
    "issue_number": 4676,
    "title": "Is the \"size_divisiblity\" in vit should be \"size_divisibility\"?",
    "author": "yourlovedu",
    "state": "open",
    "created_at": "2022-11-23T11:08:11Z",
    "updated_at": "2024-09-19T09:25:06Z",
    "labels": [
      "documentation"
    ],
    "body": "I notice that in file \"https://github.com/facebookresearch/detectron2/blob/main/detectron2/modeling/backbone/vit.py\", in line 471:\r\n\"size_divisiblity\": self._size_divisibility,\r\nThe key is \"size_divisiblity\".\r\nBut in file \"https://github.com/facebookresearch/detectron2/blob/main/detectron2/structures/image_list.py\", line 96:\r\nif \"size_divisibility\" in padding_constraints:\r\nThe key is \"size_divisibility\", which means that the key in \"vit.py\" is missing one ‚Äúi‚ÄùÔºåwhich leads to different padding foramt for images( one is square and the other is not).\r\nI want to know that is this a bug? Or it's just right to pad the image to square in vitdet?\r\n\r\n",
    "comments": [
      {
        "user": "matejsuchanek",
        "body": "#4981 deals with this."
      }
    ]
  },
  {
    "issue_number": 2117,
    "title": "Batched inference on images using DensePose?",
    "author": "RSKothari",
    "state": "open",
    "created_at": "2020-10-09T00:53:36Z",
    "updated_at": "2024-09-18T20:23:23Z",
    "labels": [
      "densepose"
    ],
    "body": "## ‚ùì How to do something using detectron2\r\nCurrently, DensePose reads in single images and infer dense annotations. This is very slow and quite wasteful. Does DensePose have the ability to read in batches of images to perform inference?\r\n\r\nDescribe what you want to do, including:\r\n1. what inputs you will provide, if any:\r\nA video filled with images\r\n\r\n2. what outputs you are expecting:\r\nA pickle file with dense pose annotations, except inferred a lot faster. \r\n\r\n## ‚ùì What does an API do and how to use it?\r\nPlease link to which API or documentation you're asking about from\r\nhttps://detectron2.readthedocs.io/\r\n\r\n\r\nNOTE:\r\n\r\n1. Only general answers are provided.\r\n   If you want to ask about \"why X did not work\", please use the\r\n   [Unexpected behaviors](https://github.com/facebookresearch/detectron2/issues/new/choose) issue template.\r\n\r\n2. About how to implement new models / new dataloader / new training logic, etc., check documentation first.\r\n\r\n3. We do not answer general machine learning / computer vision questions that are not specific to detectron2, such as how a model works, how to improve your training/make it converge, or what algorithm/methods can be used to achieve X.\r\n",
    "comments": [
      {
        "user": "MathijsNL",
        "body": "Hi there,\r\n\r\nThis might be a duplicate of Duplicate of #282 \r\nI haven't used DensePose myself, but I suppose the usage should be the same as described in the issue\r\n\r\n> You just need to call model with a batch of inputs\r\n\r\nAlso there is #1986 which explains how to sort images as well before doing inference. You should be able to work it out with this info, let us know if there is anything unclear."
      },
      {
        "user": "RSKothari",
        "body": "@MathijsNL Thanks, my question however is specific to the DensePose module within Detectron2. It seems it reads in one image after the other to perform inference. "
      },
      {
        "user": "vkhalidov",
        "body": "yes, currently DensePose doesn't provide an efficient reader that would batch video inputs. I've got a pending PR to `torchvision` that addresses this issue."
      }
    ]
  },
  {
    "issue_number": 5117,
    "title": "Torch is not found in Dockerfile",
    "author": "Tickets14",
    "state": "open",
    "created_at": "2023-10-16T06:56:40Z",
    "updated_at": "2024-09-18T18:25:24Z",
    "labels": [],
    "body": "Error when building a detectron2 on docker \r\nHello. Im experiencing a weird behavior where if im building a docker with detectron2 it always showing an error \r\n```\r\n3.930   √ó python setup.py egg_info did not run successfully.\r\n3.930   ‚îÇ exit code: 1\r\n3.930   ‚ï∞‚îÄ> [6 lines of output]\r\n3.930       Traceback (most recent call last):\r\n3.930         File \"<string>\", line 2, in <module>\r\n3.930         File \"<pip-setuptools-caller>\", line 34, in <module>\r\n3.930         File \"/tmp/pip-req-build-sz8hbgh3/setup.py\", line 10, in <module>\r\n3.930           import torch\r\n3.930       ModuleNotFoundError: No module named 'torch'\r\n3.930       [end of output]\r\n```\r\nHere is my Dokerfile\r\n\r\n```\r\nFROM public.ecr.aws/lambda/python:3.9\r\n\r\n\r\n# Install Git\r\nRUN yum install -y git\r\n\r\n# Copy requirements.txt\r\nCOPY requirements.txt ./\r\n\r\n# Install the specified packages\r\nRUN pip3 install -r requirements.txt;\r\n\r\n\r\nCOPY sample.py ./\r\nCMD [ \"sampl.handler\"]\r\n```\r\n\r\nHere is my requirements.txt\r\n```\r\nboto3==1.28.62\r\nPillow==10.0.1\r\nnumpy==1.24.3\r\ntorch==2.0.0\r\ntorchvision==0.15.1\r\nopencv-python==4.6.0.66\r\ngit+https://github.com/facebookresearch/detectron2.git\r\n\r\n```",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "Tickets14",
        "body": "I also tried this on my docker \r\n\r\n```\r\nFROM public.ecr.aws/lambda/python:3.9\r\n\r\n\r\n# Install Git\r\nRUN yum install -y git\r\n\r\n# Copy requirements.txt\r\nCOPY requirements.txt ./\r\n\r\n# Install the specified packages\r\nRUN pip3 install -r requirements.txt;\r\nRUN git clone https://github.com/facebookresearch/detectron2.git\r\nRUN pip3 install -e detectron2\r\n\r\nCOPY sample.py ./\r\nCMD [ \"sample.handler\"]\r\n```\r\n\r\nHere is the error\r\n```\r\n21.34   Running setup.py install for antlr4-python3-runtime: started\r\n21.49   Running setup.py install for antlr4-python3-runtime: finished with status 'done'\r\n21.83   Attempting uninstall: iopath\r\n21.83     Found existing installation: iopath 0.1.10\r\n21.83     Uninstalling iopath-0.1.10:\r\n21.94       Successfully uninstalled iopath-0.1.10\r\n22.75   Attempting uninstall: fvcore\r\n22.75     Found existing installation: fvcore 0.1.6\r\n22.75     Uninstalling fvcore-0.1.6:\r\n22.82       Successfully uninstalled fvcore-0.1.6\r\n22.82   DEPRECATION: fvcore is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\r\n22.82   Running setup.py install for fvcore: started\r\n22.96   Running setup.py install for fvcore: finished with status 'done'\r\n24.18   Running setup.py develop for detectron2\r\n25.38     error: subprocess-exited-with-error\r\n25.38     \r\n25.38     √ó python setup.py develop did not run successfully.\r\n25.38     ‚îÇ exit code: 1\r\n25.38     ‚ï∞‚îÄ> [15 lines of output]\r\n25.38         running develop\r\n25.38         running egg_info\r\n25.38         creating detectron2.egg-info\r\n25.38         writing detectron2.egg-info/PKG-INFO\r\n25.38         writing dependency_links to detectron2.egg-info/dependency_links.txt\r\n25.38         writing requirements to detectron2.egg-info/requires.txt\r\n25.38         writing top-level names to detectron2.egg-info/top_level.txt\r\n25.38         writing manifest file 'detectron2.egg-info/SOURCES.txt'\r\n25.38         /var/lang/lib/python3.9/site-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\r\n25.38           warnings.warn(msg.format('we could not find ninja.'))\r\n25.38         reading manifest file 'detectron2.egg-info/SOURCES.txt'\r\n25.38         adding license file 'LICENSE'\r\n25.38         writing manifest file 'detectron2.egg-info/SOURCES.txt'\r\n25.38         running build_ext\r\n25.38         error: [Errno 2] No such file or directory: 'which'\r\n25.38         [end of output]\r\n25.38     \r\n25.38     note: This error originates from a subprocess, and is likely not a problem with pip.\r\n25.38 error: subprocess-exited-with-error\r\n25.38 \r\n25.38 √ó python setup.py develop did not run successfully.\r\n25.38 ‚îÇ exit code: 1\r\n25.38 ‚ï∞‚îÄ> [15 lines of output]\r\n25.38     running develop\r\n25.38     running egg_info\r\n25.38     creating detectron2.egg-info\r\n25.38     writing detectron2.egg-info/PKG-INFO\r\n25.38     writing dependency_links to detectron2.egg-info/dependency_links.txt\r\n25.38     writing requirements to detectron2.egg-info/requires.txt\r\n25.38     writing top-level names to detectron2.egg-info/top_level.txt\r\n25.38     writing manifest file 'detectron2.egg-info/SOURCES.txt'\r\n25.38     /var/lang/lib/python3.9/site-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\r\n25.38       warnings.warn(msg.format('we could not find ninja.'))\r\n25.38     reading manifest file 'detectron2.egg-info/SOURCES.txt'\r\n25.38     adding license file 'LICENSE'\r\n25.38     writing manifest file 'detectron2.egg-info/SOURCES.txt'\r\n25.38     running build_ext\r\n25.38     error: [Errno 2] No such file or directory: 'which'\r\n25.38     [end of output]\r\n25.38 \r\n25.38 note: This error originates from a subprocess, and is likely not a problem with pip.```"
      },
      {
        "user": "Prayag22",
        "body": "```\r\nFROM` public.ecr.aws/lambda/python:3.9\r\n# Install packages\r\nRUN pip install torch==2.0.0\r\n\r\n# Install Git\r\nRUN yum install -y git\r\n\r\n# Copy requirements.txt\r\nCOPY requirements.txt ./\r\n\r\n# Install the specified packages\r\nRUN pip3 install -r requirements.txt;\r\nRUN git clone https://github.com/facebookresearch/detectron2.git\r\nRUN pip3 install -e detectron2\r\n\r\nCOPY sample.py ./\r\nCMD [ \"sample.handler\"]```\r\n"
      }
    ]
  },
  {
    "issue_number": 2901,
    "title": "Can not process video in the colab example.",
    "author": "josenxx",
    "state": "closed",
    "created_at": "2021-04-12T19:16:46Z",
    "updated_at": "2024-09-18T09:02:32Z",
    "labels": [
      "documentation",
      "enhancement",
      "contributions welcome"
    ],
    "body": "## üìö Documentation\r\nI try to run the colab example and it breaks in the video part.\r\n* Link to the relevant documentation/comment:\r\nhere is error message\r\n# Run frame-by-frame inference demo on this video (takes 3-4 minutes) with the \"demo.py\" tool we provided in the repo.\r\n!git clone https://github.com/facebookresearch/detectron2\r\n!python detectron2/demo/demo.py --config-file detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml --video-input video-clip.mp4 --confidence-threshold 0.6 --output video-output.mkv \\\r\n  --opts MODEL.WEIGHTS detectron2://COCO-PanopticSegmentation/panoptic_fpn_R_101_3x/139514519/model_final_cafdb1.pkl\r\n* What is missing or inaccurate?\r\n*May be there is an error about video encoder.\r\nchangeÔºöfourcc=cv2.VideoWriter_fourcc(*\"x264\")\r\ntoÔºöfourcc=cv2.VideoWriter_fourcc(*\"mp4v\"), # x264 ==> mp4",
    "comments": [
      {
        "user": "ppwwyyxx",
        "body": "Yes, the opencv on colab is missing x264 codec so a workaround is to change it to use mp4. Added a note to colab.\r\n\r\nIdeally there should be a utility function that first checks if x264 is available (by writing to a temp video file). Leaving this open as an enhancement."
      },
      {
        "user": "ArtistBanda",
        "body": "@ppwwyyxx could this be solved just for colab like:\r\n```python\r\nif \"google.colab\" in sys.modules:\r\n     [required changes...]\r\n```\r\nIdeally, it should be able to catch the exception raised by C++ but I don't know how to do that, if you could guide me or maybe I could apply the above fix?\r\n\r\nP.S : This is my first time contributing to detectron2"
      },
      {
        "user": "ppwwyyxx",
        "body": "A function like this would probably work:\r\n```\r\ndef test_opencv_video_format(fourcc):\r\n   writer = # create video writer with this format to a temporary file\r\n   writer.write(.. write 30 empty frames)\r\n   writer.close()\r\n   return whether the tempoary file is empty\r\n\r\ntest_opencv_video_format(\"mp4v\") -> True\r\ntest_opencv_video_format(\"x264\") -> maybe false on some platforms\r\n```"
      }
    ]
  },
  {
    "issue_number": 5142,
    "title": "coco_evaluation: No predictions from the model!",
    "author": "aymanaboghonim",
    "state": "closed",
    "created_at": "2023-11-07T07:02:45Z",
    "updated_at": "2024-09-18T02:05:14Z",
    "labels": [],
    "body": "If you do not know the root cause of the problem, please post according to this template:\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nCheck https://stackoverflow.com/help/minimal-reproducible-example for how to ask good questions.\r\nSimplify the steps to reproduce the issue using suggestions from the above link, and provide them below:\r\n\r\n1. Full runnable code or full changes you made:\r\n```\r\nIf making changes to the project itself, please use output of the following command:\r\ngit rev-parse HEAD; git diff\r\n\r\n# check torch version and cuda availability \r\nimport torch, torchvision\r\nprint(torch.__version__, torch.cuda.is_available())\r\n\r\n# Some basic setup:\r\n# Setup detectron2 logger\r\nimport detectron2\r\nfrom detectron2.utils.logger import setup_logger\r\nsetup_logger()\r\n\r\n# import some common libraries\r\nimport numpy as np\r\nimport cv2\r\nimport torch , os\r\n\r\n# import some common detectron2 utilities\r\nfrom detectron2 import model_zoo\r\nfrom detectron2.engine import DefaultPredictor\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\r\nfrom detectron2.data import MetadataCatalog\r\n#coco_metadata = MetadataCatalog.get(\"coco_2017_val\")\r\nfrom detectron2.engine import DefaultTrainer\r\n\r\n# import PointRend project\r\nfrom detectron2.projects import point_rend\r\n\r\n# import other modules \r\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\r\nfrom detectron2.data import build_detection_test_loader\r\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\r\nfrom detectron2.engine import HookBase\r\nfrom detectron2.data import build_detection_train_loader\r\nimport detectron2.utils.comm as comm\r\nfrom detectron2.data.datasets import register_coco_instances\r\n\r\n# register dataset\r\nregister_coco_instances(\"buildings_riyadh-images_google_train\", {}, \"data/train.json\", \"images/\")\r\nregister_coco_instances(\"buildings_riyadh-images_google_val\", {}, \"data/val.json\", \"images/\")\r\n\r\n\r\n# get dataset metadata\r\nbuildings_metadata = MetadataCatalog.get(\"buildings_riyadh-images_google_train\").thing_classes = [\"building\"]\r\nprint(buildings_metadata)\r\n\r\n# intitate config\r\ncfg = get_cfg()\r\n\r\n# Add PointRend-specific config\r\npoint_rend.add_pointrend_config(cfg)\r\n# Load a config from file\r\ncfg.merge_from_file(\"pointrend_rcnn_R_50_FPN_3x_coco_config.yaml\")\r\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\r\ncfg.MODEL.WEIGHTS = \"model_0113999.pth\"\r\ncfg.DEVICE = \"cuda:0\"\r\ncfg.SOLVER.BASE_LR =  0.00025 \r\ncfg.DATASETS.TRAIN = (\"buildings_riyadh-images_google_train\",)\r\ncfg.DATASETS.TEST = (\"buildings_riyadh-images_google_val\",)\r\ncfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS= False # include Negative examples \r\ncfg.DATALOADER.NUM_WORKERS =12\r\ncfg.SOLVER.IMS_PER_BATCH = 8\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\r\ncfg.MODEL.POINT_HEAD.NUM_CLASSES = 1\r\ncfg.SOLVER.CHECKPOINT_PERIOD = 2000\r\ncfg.CUDNN_BENCHMARK = True\r\ncfg.SOLVER.MAX_ITER = 40000000\r\ncfg.OUTPUT_DIR = \"google_output_22_5_23\"\r\ncfg.SOLVER.CHECKPOINT_PERIOD = 2000\r\ncfg.TEST.EVAL_PERIOD = 2000 # run evaluation every 2000 iterations \r\n\r\n\r\n\r\n\r\n\r\n# create val class\r\nclass ValidationLoss(HookBase):\r\n    def __init__(self, cfg):\r\n        super().__init__()\r\n        self.cfg = cfg.clone()\r\n        self.cfg.DATASETS.TRAIN = cfg.DATASETS.TEST\r\n        self._loader = iter(build_detection_train_loader(self.cfg))\r\n        \r\n    def after_step(self):\r\n        data = next(self._loader)\r\n        with torch.no_grad():\r\n            loss_dict = self.trainer.model(data)\r\n            \r\n            losses = sum(loss_dict.values())\r\n            assert torch.isfinite(losses).all(), loss_dict\r\n\r\n            loss_dict_reduced = {\"val_\" + k: v.item() for k, v in \r\n                                 comm.reduce_dict(loss_dict).items()}\r\n            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\r\n            if comm.is_main_process():\r\n                self.trainer.storage.put_scalars(total_val_loss=losses_reduced, \r\n                                                 **loss_dict_reduced)\r\nval_loss = ValidationLoss(cfg)  \r\n\r\n# create trainner class\r\nclass MyTrainer(DefaultTrainer):\r\n    @classmethod\r\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\r\n        if output_folder is None:\r\n            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\r\n        return COCOEvaluator(dataset_name, cfg, True, output_folder)\r\n\r\n\r\n#print(cfg)\r\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\ntrainer = MyTrainer(cfg) \r\ntrainer.register_hooks([val_loss])\r\ntrainer._hooks = trainer._hooks[:-2] + trainer._hooks[-2:][::-1]\r\ntrainer.resume_or_load(resume=False)\r\ntrainer.train()\r\n\r\n\r\n```\r\n2. What exact command you run: python  the_above_code.py\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n\r\n[11/07 04:37:43 d2.data.datasets.coco]: Loaded 3277 images in COCO format from data/val.json\r\n[11/07 04:37:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\r\n[11/07 04:37:43 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\r\n[11/07 04:37:43 d2.data.common]: Serializing 3277 elements to byte tensors and concatenating them all ...\r\n[11/07 04:37:43 d2.data.common]: Serialized dataset takes 7.75 MiB\r\n[11/07 04:37:43 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\r\nWARNING [11/07 04:37:43 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\r\n[11/07 04:37:44 d2.evaluation.evaluator]: Start inference on 3277 batches\r\n[11/07 04:37:45 d2.evaluation.evaluator]: Inference done 11/3277. Dataloading: 0.0010 s/iter. Inference: 0.0805 s/iter. Eval: 0.0001 s/iter. Total: 0.0816 s/iter. ETA=0:04:26\r\n[11/07 04:37:50 d2.evaluation.evaluator]: Inference done 72/3277. Dataloading: 0.0011 s/iter. Inference: 0.0819 s/iter. Eval: 0.0001 s/iter. Total: 0.0831 s/iter. ETA=0:04:26\r\n[11/07 04:37:55 d2.evaluation.evaluator]: Inference done 132/3277. Dataloading: 0.0011 s/iter. Inference: 0.0820 s/iter. Eval: 0.0001 s/iter. Total: 0.0833 s/iter. ETA=0:04:21\r\n[11/07 04:38:00 d2.evaluation.evaluator]: Inference done 192/3277. Dataloading: 0.0011 s/iter. Inference: 0.0821 s/iter. Eval: 0.0001 s/iter. Total: 0.0833 s/iter. ETA=0:04:17\r\n[11/07 04:38:05 d2.evaluation.evaluator]: Inference done 252/3277. Dataloading: 0.0012 s/iter. Inference: 0.0821 s/iter. Eval: 0.0001 s/iter. Total: 0.0834 s/iter. ETA=0:04:12\r\n[11/07 04:38:10 d2.evaluation.evaluator]: Inference done 312/3277. Dataloading: 0.0012 s/iter. Inference: 0.0822 s/iter. Eval: 0.0001 s/iter. Total: 0.0835 s/iter. ETA=0:04:07\r\n[11/07 04:38:15 d2.evaluation.evaluator]: Inference done 372/3277. Dataloading: 0.0012 s/iter. Inference: 0.0822 s/iter. Eval: 0.0001 s/iter. Total: 0.0835 s/iter. ETA=0:04:02\r\n[11/07 04:38:20 d2.evaluation.evaluator]: Inference done 432/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0836 s/iter. ETA=0:03:57\r\n[11/07 04:38:25 d2.evaluation.evaluator]: Inference done 492/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0836 s/iter. ETA=0:03:52\r\n[11/07 04:38:30 d2.evaluation.evaluator]: Inference done 552/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0836 s/iter. ETA=0:03:47\r\n[11/07 04:38:35 d2.evaluation.evaluator]: Inference done 612/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:03:42\r\n[11/07 04:38:41 d2.evaluation.evaluator]: Inference done 672/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:03:37\r\n[11/07 04:38:46 d2.evaluation.evaluator]: Inference done 732/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:03:32\r\n[11/07 04:38:51 d2.evaluation.evaluator]: Inference done 792/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:03:27\r\n[11/07 04:38:56 d2.evaluation.evaluator]: Inference done 852/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:03:22\r\n[11/07 04:39:01 d2.evaluation.evaluator]: Inference done 912/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:03:17\r\n[11/07 04:39:06 d2.evaluation.evaluator]: Inference done 972/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:03:12\r\n[11/07 04:39:11 d2.evaluation.evaluator]: Inference done 1032/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:03:07\r\n[11/07 04:39:16 d2.evaluation.evaluator]: Inference done 1092/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:03:02\r\n[11/07 04:39:21 d2.evaluation.evaluator]: Inference done 1152/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:02:57\r\n[11/07 04:39:26 d2.evaluation.evaluator]: Inference done 1212/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:02:52\r\n[11/07 04:39:31 d2.evaluation.evaluator]: Inference done 1272/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:02:47\r\n[11/07 04:39:36 d2.evaluation.evaluator]: Inference done 1332/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:02:42\r\n[11/07 04:39:41 d2.evaluation.evaluator]: Inference done 1392/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:02:37\r\n[11/07 04:39:46 d2.evaluation.evaluator]: Inference done 1452/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:02:32\r\n[11/07 04:39:51 d2.evaluation.evaluator]: Inference done 1512/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:02:27\r\n[11/07 04:39:56 d2.evaluation.evaluator]: Inference done 1572/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:02:22\r\n[11/07 04:40:01 d2.evaluation.evaluator]: Inference done 1632/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:02:17\r\n[11/07 04:40:06 d2.evaluation.evaluator]: Inference done 1692/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:02:12\r\n[11/07 04:40:11 d2.evaluation.evaluator]: Inference done 1752/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:02:07\r\n[11/07 04:40:16 d2.evaluation.evaluator]: Inference done 1812/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:02:02\r\n[11/07 04:40:21 d2.evaluation.evaluator]: Inference done 1873/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:57\r\n[11/07 04:40:26 d2.evaluation.evaluator]: Inference done 1933/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:52\r\n[11/07 04:40:31 d2.evaluation.evaluator]: Inference done 1993/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:47\r\n[11/07 04:40:36 d2.evaluation.evaluator]: Inference done 2053/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:42\r\n[11/07 04:40:41 d2.evaluation.evaluator]: Inference done 2113/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:37\r\n[11/07 04:40:46 d2.evaluation.evaluator]: Inference done 2173/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:32\r\n[11/07 04:40:51 d2.evaluation.evaluator]: Inference done 2233/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:27\r\n[11/07 04:40:56 d2.evaluation.evaluator]: Inference done 2293/3277. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:22\r\n[11/07 04:41:01 d2.evaluation.evaluator]: Inference done 2353/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:17\r\n[11/07 04:41:06 d2.evaluation.evaluator]: Inference done 2413/3277. Dataloading: 0.0012 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:12\r\n[11/07 04:41:11 d2.evaluation.evaluator]: Inference done 2473/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:01:07\r\n[11/07 04:41:16 d2.evaluation.evaluator]: Inference done 2533/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:01:02\r\n[11/07 04:41:22 d2.evaluation.evaluator]: Inference done 2593/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:00:57\r\n[11/07 04:41:27 d2.evaluation.evaluator]: Inference done 2653/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:00:52\r\n[11/07 04:41:32 d2.evaluation.evaluator]: Inference done 2713/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:00:47\r\n[11/07 04:41:37 d2.evaluation.evaluator]: Inference done 2773/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:00:42\r\n[11/07 04:41:42 d2.evaluation.evaluator]: Inference done 2833/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:00:37\r\n[11/07 04:41:47 d2.evaluation.evaluator]: Inference done 2893/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:00:32\r\n[11/07 04:41:52 d2.evaluation.evaluator]: Inference done 2953/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0838 s/iter. ETA=0:00:27\r\n[11/07 04:41:57 d2.evaluation.evaluator]: Inference done 3013/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:00:22\r\n[11/07 04:42:02 d2.evaluation.evaluator]: Inference done 3074/3277. Dataloading: 0.0013 s/iter. Inference: 0.0824 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:00:16\r\n[11/07 04:42:07 d2.evaluation.evaluator]: Inference done 3135/3277. Dataloading: 0.0013 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:00:11\r\n[11/07 04:42:12 d2.evaluation.evaluator]: Inference done 3196/3277. Dataloading: 0.0013 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:00:06\r\n[11/07 04:42:17 d2.evaluation.evaluator]: Inference done 3256/3277. Dataloading: 0.0013 s/iter. Inference: 0.0823 s/iter. Eval: 0.0001 s/iter. Total: 0.0837 s/iter. ETA=0:00:01\r\n[11/07 04:42:19 d2.evaluation.evaluator]: Total inference time: 0:04:33.946270 (0.083724 s / iter per device, on 1 devices)\r\n[11/07 04:42:19 d2.evaluation.evaluator]: Total inference pure compute time: 0:04:29 (0.082327 s / iter per device, on 1 devices)\r\n[11/07 04:42:19 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\r\n[11/07 04:42:19 d2.evaluation.coco_evaluation]: Saving results to google_output_22_5_23/inference/coco_instances_results.json\r\n[11/07 04:42:19 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\r\nWARNING [11/07 04:42:19 d2.evaluation.coco_evaluation]: No predictions from the model!\r\n[11/07 04:42:19 d2.engine.defaults]: Evaluation results for buildings_riyadh-images_google_val in csv format:\r\n[11/07 04:42:19 d2.evaluation.testing]: copypaste: Task: bbox\r\n[11/07 04:42:19 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\r\n[11/07 04:42:19 d2.evaluation.testing]: copypaste: nan,nan,nan,nan,nan,nan```\r\n\r\n## Expected behavior:\r\n\r\nIf there are no obvious crash in \"full logs\" provided above,\r\nplease tell us the expected behavior.\r\nI've previously used this code to evaluate my model during training,\r\n and it should display metrics for both bounding boxes and segmentation masks.\r\n However, it's not showing any metrics because it's not producing any predictions.\r\n Despite this, the training and validation losses are decreasing as expected. \r\nSince I'm fine-tuning a custom model that was trained on a very similar dataset, \r\nit should work even if it hasn't been trained extensively. \r\nThis suggests that there isn't a training issue here.\r\nIf you expect a model to converge / work better, we do not help with such issues, unless\r\na model fails to reproduce the results in detectron2 model zoo, or proves existence of bugs.\r\n\r\n## Environment:\r\n\r\nPaste the output of the following command:\r\n```\r\ncuobjdump info    : File '/home/jupyter/detectron2/point_rend/detectron2-main/detectron2/_C.cpython-38-x86_64-linux-gnu.so' does not contain device code\r\n-------------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]\r\nnumpy                            1.24.3\r\ndetectron2                       0.6 @/home/jupyter/detectron2/point_rend/detectron2-main/detectron2\r\ndetectron2._C                    not built correctly: /home/jupyter/detectron2/point_rend/detectron2-main/detectron2/_C.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor7reshapeEN3c108ArrayRefIlEE\r\nCompiler ($CXX)                  c++ (Debian 8.3.0-6) 8.3.0\r\nCUDA compiler                    Build cuda_11.3.r11.3/compiler.29920130_0\r\ndetectron2 arch flags            /home/jupyter/detectron2/point_rend/detectron2-main/detectron2/_C.cpython-38-x86_64-linux-gnu.so\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          1.13.1+cu116 @/opt/conda/envs/detectron2/lib/python3.8/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0                            Tesla T4 (arch=7.5)\r\nDriver version                   510.47.03\r\nCUDA_HOME                        /usr/local/cuda\r\nPillow                           9.5.0\r\ntorchvision                      0.14.1+cu116 @/opt/conda/envs/detectron2/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.8.1\r\n-------------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201402\r\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 11.6\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\r\n  - CuDNN 8.2  (built against CUDA 11.3)\r\n    - Built with CuDNN 8.3.2\r\n  - Magma 2.6.1\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first check common issues in https://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n ",
    "comments": [
      {
        "user": "wangzitao777",
        "body": " @aymanaboghonim Hello, I've got the same problem, how do you solve it?"
      }
    ]
  },
  {
    "issue_number": 5150,
    "title": "unable to install detectron2 in python version 3.11 ",
    "author": "DivyaKanniah",
    "state": "closed",
    "created_at": "2023-11-14T04:59:49Z",
    "updated_at": "2024-09-17T01:58:30Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Python 3.11 is unable to install detectron2.\r\n We were unable to install the most recent version of detectron2 with Python 3.11 since the installation documents indicated Python version >3.7. Please assist with that.\r\n\r\n\r\n\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 1654,
    "title": "Error in extract semantic annotations from panoptic annotations.",
    "author": "kaenkogashi",
    "state": "closed",
    "created_at": "2020-06-22T07:38:02Z",
    "updated_at": "2024-09-12T09:14:57Z",
    "labels": [
      "documentation"
    ],
    "body": "To Reproduce\r\n1. full code you wrote or full changes you made : Nothing\r\n2. what exact command you run: followed instructions from https://github.com/facebookresearch/detectron2/tree/master/datasets\r\nfirst, down load panoptic dataset from http://cocodataset.org/#download\r\n2017 Panoptic Train/Val annotations [821MB] and push the dataset in expected dataset structure.\r\nthen Install panopticapi by:\r\npip install git+https://github.com/cocodataset/panopticapi.git\r\nThen, cd datasets and run python prepare_panoptic_fpn.py, to extract semantic annotations from panoptic annotations.\r\n3. __full logs__ you observed:\r\n```\r\npython prepare_panoptic_fpn.py\r\nStart writing to coco/panoptic_stuff_val2017 ...\r\nFinished. time: 2.59s\r\nStart writing to coco/panoptic_stuff_train2017 ...\r\nmultiprocessing.pool.RemoteTraceback:\r\n\"\"\"\r\nTraceback (most recent call last):\r\n  File \"/home/kogashi/miniconda3/envs/detectron/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\r\n    result = (True, func(*args, **kwds))\r\n  File \"/home/kogashi/miniconda3/envs/detectron/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\r\n    return list(itertools.starmap(args[0], args[1]))\r\n  File \"prepare_panoptic_fpn.py\", line 19, in _process_panoptic_to_semantic\r\n    panoptic = np.asarray(Image.open(input_panoptic), dtype=np.uint32)\r\n  File \"/home/kogashi/miniconda3/envs/detectron/lib/python3.7/site-packages/PIL/Image.py\", line 2809, in open\r\n    fp = builtins.open(filename, \"rb\")\r\nFileNotFoundError: [Errno 2] No such file or directory: 'coco/panoptic_train2017/000000000540.png'\r\n\"\"\"\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"prepare_panoptic_fpn.py\", line 87, in <module>\r\n    COCO_CATEGORIES,\r\n  File \"prepare_panoptic_fpn.py\", line 75, in separate_coco_semantic_from_panoptic\r\n    chunksize=100,\r\n  File \"/home/kogashi/miniconda3/envs/detectron/lib/python3.7/multiprocessing/pool.py\", line 276, in starmap\r\n    return self._map_async(func, iterable, starmapstar, chunksize).get()\r\n  File \"/home/kogashi/miniconda3/envs/detectron/lib/python3.7/multiprocessing/pool.py\", line 657, in get\r\n    raise self._value\r\nFileNotFoundError: [Errno 2] No such file or directory: 'coco/panoptic_train2017/000000000540.png'\r\n```\r\n\r\n## Expected behavior:\r\n\r\nextract semantic annotations from panoptic annotations.\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\nsys.platform              linux\r\nPython                    3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\r\nnumpy                     1.18.1\r\ndetectron2                0.1.1 @/home/kogashi/miniconda3/envs/detectron/lib/python3.7/site-packages/detectron2\r\ndetectron2 compiler       GCC 7.3\r\ndetectron2 CUDA compiler  10.0\r\ndetectron2 arch flags     sm_35, sm_37, sm_50, sm_52, sm_60, sm_61, sm_70, sm_75\r\nDETECTRON2_ENV_MODULE     <not set>\r\nPyTorch                   1.4.0+cu100 @/home/kogashi/miniconda3/envs/detectron/lib/python3.7/site-packages/torch\r\nPyTorch debug build       False\r\nCUDA available            True\r\nGPU 0                     Tesla V100-SXM2-16GB\r\nCUDA_HOME                 /home/kogashi/miniconda3/cuda-9.0\r\nNVCC                      Cuda compilation tools, release 9.0, V9.0.176\r\nPillow                    7.0.0\r\ntorchvision               0.5.0+cu100 @/home/kogashi/miniconda3/envs/detectron/lib/python3.7/site-packages/torchvision\r\ntorchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75\r\ncv2                       4.2.0\r\n------------------------  --------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - NNPACK is enabled\r\n  - CUDA Runtime 10.0\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 7.6.3\r\n  - Magma 2.5.1\r\n  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,\r\n\r\n```\r\n\r\n",
    "comments": [
      {
        "user": "ppwwyyxx",
        "body": "Currently the script has to be moved to the dataset directory defined by `DETECTRON2_DATASETS` and run there. The directory is expected to have `coco/panoptic_train2017/000000000540.png` according to https://github.com/facebookresearch/detectron2/tree/master/datasets."
      },
      {
        "user": "kaenkogashi",
        "body": "@ppwwyyxx  thank you for your reply! I download panoptic dataset from official coco-site, but they do not have 000000000540.png. And COCO2017 have 118287 pictures, but Panoptic datasets only provide 52751. Where can I download full Panoptic dataset? Would you provide me some links?\r\n>first, down load panoptic dataset from http://cocodataset.org/#download\r\n>2017 Panoptic Train/Val annotations [821MB] and push the dataset in expected dataset structure."
      },
      {
        "user": "ppwwyyxx",
        "body": "The file exists. You probably downloaded something wrong."
      }
    ]
  },
  {
    "issue_number": 4737,
    "title": "Loading pre-trained model configuration from Python file",
    "author": "buckeye17",
    "state": "closed",
    "created_at": "2023-01-04T08:19:11Z",
    "updated_at": "2024-09-12T00:51:34Z",
    "labels": [
      "documentation"
    ],
    "body": "## üìö Documentation Issue\r\n\r\nI'm struggling to load the pre-trained model defined by `new_baselines/mask_rcnn_R_101_FPN_400ep_LSJ.py`.\r\nI've found relevant documentation [here](https://github.com/facebookresearch/detectron2/blob/51704141a5e6d92136c6df1cc2728aedcef9885f/docs/tutorials/lazyconfigs.md), [here](https://detectron2.readthedocs.io/en/latest/tutorials/lazyconfigs.html) and issue #3225.  However none of these clearly elucidate my error.\r\n\r\nI'm trying to load the configuration with:\r\n```\r\ncfg = LazyConfig.load(\"detectron2/configs/new_baselines/mask_rcnn_R_101_FPN_400ep_LSJ.py\")\r\ncfg = setup_cfg(args)\r\n```\r\n\r\nThis produces the following traceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \"quality_test.py\", line 97, in <module>\r\n    results_ls = get_person_seg_masks(img_path, model_family, model)\r\n  File \"detectron2_wrapper.py\", line 107, in get_person_seg_masks\r\n    cfg = setup_cfg(args)\r\n  File \"detectron2/demo/demo.py\", line 29, in setup_cfg\r\n    cfg.merge_from_file(args.config_file)\r\n  File \"/home/appuser/detectron2_repo/detectron2/config/config.py\", line 46, in merge_from_file\r\n    loaded_cfg = self.load_yaml_with_base(cfg_filename, allow_unsafe=allow_unsafe)\r\n  File \"/home/appuser/.local/lib/python3.8/site-packages/fvcore/common/config.py\", line 61, in load_yaml_with_base\r\n    cfg = yaml.safe_load(f)\r\n  File \"/home/appuser/.local/lib/python3.8/site-packages/yaml/__init__.py\", line 125, in safe_load\r\n    return load(stream, SafeLoader)\r\n  File \"/home/appuser/.local/lib/python3.8/site-packages/yaml/__init__.py\", line 81, in load\r\n    return loader.get_single_data()\r\n  File \"/home/appuser/.local/lib/python3.8/site-packages/yaml/constructor.py\", line 49, in get_single_data\r\n    node = self.get_single_node()\r\n  File \"/home/appuser/.local/lib/python3.8/site-packages/yaml/composer.py\", line 39, in get_single_node\r\n    if not self.check_event(StreamEndEvent):\r\n  File \"/home/appuser/.local/lib/python3.8/site-packages/yaml/parser.py\", line 98, in check_event\r\n    self.current_event = self.state()\r\n  File \"/home/appuser/.local/lib/python3.8/site-packages/yaml/parser.py\", line 171, in parse_document_start\r\n    raise ParserError(None, None,\r\nyaml.parser.ParserError: expected '<document start>', but found '<scalar>'\r\n  in \"detectron2/configs/new_baselines/mask_rcnn_R_101_FPN_400ep_LSJ.py\", line 11, column 1\r\n```\r\n",
    "comments": [
      {
        "user": "ppwwyyxx",
        "body": "`demo.py` does not support python configs"
      },
      {
        "user": "aylinaydincs",
        "body": "How can we see the demo of python configs such as MViT? and  If we trained MViTv2 does do instance segmentation?\r\n"
      },
      {
        "user": "buckeye17",
        "body": "Since I struggled to get Densepose working, I wanted to share my function for working with it.  Hopefully other people can get going quicker with this as a guide.\r\n```\r\ndef get_person_mesh_mask(\r\n    img_path: str,\r\n    file_out_path: str = \"\",\r\n    model_family: str = \"iuv\",\r\n    model: str = \"rcnn_R_101_FPN_DL_WC1M_s1x\"\r\n):\r\n    '''\r\n    Generates segmentation mask for most prominent person's body in input image\r\n\r\n    Input Parameters:\r\n    img_path: defines input image to be analyzed, string like \"/path/to/image.jpg\"\r\n    file_out_path: defines image files to be produced, string like \"/path/to/image.jpg\", must end with \".jpg\", no images made if \"\"\r\n    model_family: defines which family of models to use, must be one of: \"cse\" or \"iuv\"\r\n    model: defines which model to use within provided model family, see model_dict for valid values depending on the model family\r\n    \r\n    Returns a list consisting of a bounding box, the segmentation mask and confidence mask\r\n    NOTE: this function should be executed with detectron2_repo/projects/DensePose as the current working directory\r\n    '''\r\n    \r\n    # this function utilizes detectron2/projects/DensePose/apply_net.py\r\n    # documentation for it can be found at https://github.com/facebookresearch/detectron2/blob/cbbc1ce26473cb2a5cc8f58e8ada9ae14cb41052/projects/DensePose/doc/TOOL_APPLY_NET.md\r\n    \r\n    import subprocess\r\n    import sys\r\n    \r\n    import numpy as np\r\n    import plotly.graph_objects as go\r\n    from plotly.subplots import make_subplots\r\n    import torch\r\n    \r\n    # the following model dictionary was built using the documentation at:\r\n    # https://github.com/facebookresearch/detectron2/blob/main/projects/DensePose/doc/DENSEPOSE_IUV.md#ModelZoo\r\n    # https://github.com/facebookresearch/detectron2/blob/main/projects/DensePose/doc/DENSEPOSE_CSE.md#ModelZoo\r\n    # note that the dictionary does not include all available models mentioned in the documnetation above\r\n    # based on ~10 test images, some of the best models are: iuv - rcnn_R_50_FPN_s1x, iuv - rcnn_R_101_FPN_s1x & iuv - rcnn_R_101_FPN_DL_WC1M_s1x\r\n    # for most of ~10 test images, resulting segmentation masks were very similar\r\n    model_dict = {\r\n        \"cse\": {\r\n            \"rcnn_R_50_FPN_s1x\": {\r\n                \"yaml\": \"configs/densepose_rcnn_R_50_FPN_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/cse/densepose_rcnn_R_50_FPN_s1x/251155172/model_final_c4ea5f.pkl\"\r\n            },\r\n            \"R_101_FPN_s1x\": {\r\n                \"yaml\": \"configs/densepose_rcnn_R_101_FPN_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/cse/densepose_rcnn_R_101_FPN_s1x/251155500/model_final_5c995f.pkl\"\r\n            },\r\n            # NOTE: the following model fails to run!?\r\n            \"rcnn_R_50_FPN_DL_s1x\": {\r\n                \"yaml\": \"configs/cse/densepose_rcnn_R_50_FPN_DL_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/cse/densepose_rcnn_R_50_FPN_DL_s1x/251156349/model_final_e96218.pkl\"\r\n            },\r\n            # NOTE: the following model fails to run!?\r\n            \"rcnn_R_101_FPN_DL_s1x\": {\r\n                \"yaml\": \"configs/cse/densepose_rcnn_R_101_FPN_DL_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/cse/densepose_rcnn_R_101_FPN_DL_s1x/251156606/model_final_b236ce.pkl\"\r\n            }\r\n        },\r\n        \"iuv\": {\r\n            \"rcnn_R_50_FPN_s1x\": {\r\n                \"yaml\": \"configs/densepose_rcnn_R_50_FPN_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x/165712039/model_final_162be9.pkl\"\r\n            },\r\n            \"rcnn_R_101_FPN_s1x\": {\r\n                \"yaml\": \"configs/densepose_rcnn_R_101_FPN_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_101_FPN_s1x/165712084/model_final_c6ab63.pkl\"\r\n            },\r\n            \"rcnn_R_50_FPN_DL_s1x\": {\r\n                \"yaml\": \"configs/densepose_rcnn_R_50_FPN_DL_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_DL_s1x/165712097/model_final_0ed407.pkl\"\r\n            },\r\n            \"rcnn_R_101_FPN_DL_s1x\": {\r\n                \"yaml\": \"configs/densepose_rcnn_R_101_FPN_DL_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_101_FPN_DL_s1x/165712116/model_final_844d15.pkl\"\r\n            },\r\n            \"rcnn_R_101_FPN_WC1M_s1x\": {\r\n                \"yaml\": \"configs/densepose_rcnn_R_101_FPN_WC1M_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_101_FPN_WC1M_s1x/216453687/model_final_0a7287.pkl\"\r\n            },\r\n            \"rcnn_R_101_FPN_WC2M_s1x\": {\r\n                \"yaml\": \"configs/densepose_rcnn_R_101_FPN_WC2M_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_101_FPN_WC2M_s1x/216245682/model_final_e354d9.pkl\"\r\n            },\r\n            \"rcnn_R_101_FPN_DL_WC1M_s1x\": {\r\n                \"yaml\": \"configs/densepose_rcnn_R_101_FPN_DL_WC1M_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_101_FPN_DL_WC1M_s1x/216245771/model_final_0ebeb3.pkl\"\r\n            },\r\n            \"rcnn_R_101_FPN_DL_WC2M_s1x\": {\r\n                \"yaml\": \"configs/densepose_rcnn_R_101_FPN_DL_WC2M_s1x.yaml\",\r\n                \"weights\": \"https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_101_FPN_DL_WC2M_s1x/216245790/model_final_de6e7a.pkl\"\r\n            },\r\n        }\r\n    }\r\n    \r\n    temp_pkl_path = \"/home/appuser/results.pkl\" # this assumes the function is being executed in a detectron2 Docker container\r\n    make_images_bool = file_out_path.endswith(\".jpg\")\r\n    if make_images_bool:\r\n        cmd = f\"python apply_net.py show {model_dict[model_family][model]['yaml']} {model_dict[model_family][model]['weights']} {img_path} dp_segm -v --output {file_out_path}\"\r\n        cmd = cmd.split(\" \")\r\n        \r\n        # returns output as byte string\r\n        returned_output = subprocess.check_output(cmd)\r\n\r\n        # using decode() function to convert byte string to string\r\n        output_str = returned_output.decode(\"utf-8\")\r\n        \r\n        # make subprocess outputs visible to terminal\r\n        print(output_str)\r\n        \r\n    cmd = f\"python apply_net.py dump {model_dict[model_family][model]['yaml']} {model_dict[model_family][model]['weights']} {img_path} -v --output {temp_pkl_path}\"\r\n    cmd = cmd.split(\" \")\r\n    \r\n    # returns output as byte string\r\n    returned_output = subprocess.check_output(cmd)\r\n\r\n    # using decode() function to convert byte string to string\r\n    output_str = returned_output.decode(\"utf-8\")\r\n    \r\n    # make subprocess outputs visible to terminal\r\n    print(output_str)\r\n    \r\n    # make sure DensePose is in your PYTHONPATH, or use the following line to add it:\r\n    sys.path.append(\"/home/appuser/detectron2_repo/projects/DensePose/\")\r\n    \r\n    with open(temp_pkl_path, \"rb\") as hFile:\r\n        data = torch.load(hFile)\r\n    \r\n    data_dict = data[0]\r\n    \r\n    # valid keys for data_dict: 'file_name', 'scores', 'pred_boxes_XYXY', 'pred_densepose'\r\n    # assume the first predicted item is the intended subject, as observed with test images\r\n    bbox = data_dict[\"pred_boxes_XYXY\"][0].cpu().numpy()\r\n    pred_densepose = data_dict[\"pred_densepose\"][0]\r\n    \r\n    # valid pred_densepose properties: coarse_segm_confidence, fine_segm_confidence, kappa_u, kappa_v, labels, sigma_1, sigma_2, to, uv\r\n    mask = pred_densepose.labels.cpu().numpy()\r\n    conf = pred_densepose.fine_segm_confidence.cpu().numpy()\r\n        \r\n    if make_images_bool and hasattr(pred_densepose.fine_segm_confidence, '__iter__'):\r\n        fig = make_subplots(rows=1, cols=2, subplot_titles=[\"label\", \"confidence\"])\r\n        fig.add_trace(\r\n            go.Heatmap(z=pred_densepose.labels.cpu().numpy()),\r\n            row = 1,\r\n            col = 1\r\n        )\r\n        fig.add_trace(\r\n            go.Heatmap(z=pred_densepose.fine_segm_confidence.cpu().numpy()),\r\n            row = 1,\r\n            col = 2\r\n        )\r\n        fig['layout']['yaxis1']['autorange'] = \"reversed\"\r\n        fig['layout']['yaxis1']['scaleanchor'] = \"x1\"\r\n        fig['layout']['yaxis1']['scaleratio'] = 1\r\n        fig['layout']['yaxis2']['autorange'] = \"reversed\"\r\n        fig['layout']['yaxis2']['scaleanchor'] = \"x2\"\r\n        fig['layout']['yaxis2']['scaleratio'] = 1\r\n        \r\n        file_out_base_path = file_out_path.replace(\".jpg\", \"\")\r\n        fig.write_html(f\"{file_out_base_path}_mask_plots.html\")\r\n    \r\n    elif make_images_bool:\r\n        # show confidence plot as all zeros\r\n        labels = pred_densepose.labels.cpu().numpy()\r\n        fig = make_subplots(rows=1, cols=2, subplot_titles=[\"label\", \"confidence\"])\r\n        fig.add_trace(\r\n            go.Heatmap(z=labels),\r\n            row = 1,\r\n            col = 1\r\n        )\r\n        fig.add_trace(\r\n            go.Heatmap(z=np.zeros_like(labels)),\r\n            row = 1,\r\n            col = 2\r\n        )\r\n        fig['layout']['yaxis1']['autorange'] = \"reversed\"\r\n        fig['layout']['yaxis1']['scaleanchor'] = \"x1\"\r\n        fig['layout']['yaxis1']['scaleratio'] = 1\r\n        fig['layout']['yaxis2']['autorange'] = \"reversed\"\r\n        fig['layout']['yaxis2']['scaleanchor'] = \"x2\"\r\n        fig['layout']['yaxis2']['scaleratio'] = 1\r\n        \r\n        file_out_base_path = file_out_path.replace(\".jpg\", \"\")\r\n        fig.write_html(f\"{file_out_base_path}_mask_plots.html\")\r\n    \r\n    return bbox, mask, conf\r\n```"
      }
    ]
  },
  {
    "issue_number": 5145,
    "title": "Exception has occurred: AttributeError module 'PIL.Image' has no attribute 'LINEAR' ",
    "author": "Veer-Singh2",
    "state": "closed",
    "created_at": "2023-11-08T15:35:08Z",
    "updated_at": "2024-09-11T02:05:04Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\n```\r\nIf making changes to the project itself, please use output of the following command:\r\ngit rev-parse HEAD; git diff\r\n\r\n<put code or diff here>\r\n```\r\n2. What exact command you run:\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n<put logs here>\r\n```\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\n## Expected behavior:\r\n\r\nIf there are no obvious error in \"full logs\" provided above,\r\nplease tell us the expected behavior.\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first try to solve it yourself with the instructions in\r\nhttps://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5141,
    "title": "Issue : @META_ARCH_REGISTRY.register() NameError: name 'META_ARCH_REGISTRY' is not defined",
    "author": "mahdid-lilia",
    "state": "closed",
    "created_at": "2023-11-06T00:55:41Z",
    "updated_at": "2024-09-09T02:06:24Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "If you do not know the root cause of the problem, please post according to this template:\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nCheck https://stackoverflow.com/help/minimal-reproducible-example for how to ask good questions.\r\nSimplify the steps to reproduce the issue using suggestions from the above link, and provide them below:\r\n\r\n1. Full runnable code or full changes you made:\r\n```\r\nIf making changes to the project itself, please use output of the following command:\r\ngit rev-parse HEAD; git diff\r\n\r\n<put code or diff here>\r\n```\r\n2. What exact command you run:\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n<put logs here>\r\n```\r\n\r\n## Expected behavior:\r\n\r\nIf there are no obvious crash in \"full logs\" provided above,\r\nplease tell us the expected behavior.\r\n\r\nIf you expect a model to converge / work better, we do not help with such issues, unless\r\na model fails to reproduce the results in detectron2 model zoo, or proves existence of bugs.\r\n\r\n## Environment:\r\n\r\nPaste the output of the following command:\r\n```\r\nwget -nc -nv https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first check common issues in https://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5358,
    "title": "Import detectron2.engine ",
    "author": "bio-mlhui",
    "state": "closed",
    "created_at": "2024-08-29T11:53:44Z",
    "updated_at": "2024-09-06T02:05:00Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "If you do not know the root cause of the problem, please post according to this template:\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nCheck https://stackoverflow.com/help/minimal-reproducible-example for how to ask good questions.\r\nSimplify the steps to reproduce the issue using suggestions from the above link, and provide them below:\r\n\r\n1. Full runnable code or full changes you made:\r\n```\r\nIf making changes to the project itself, please use output of the following command:\r\ngit rev-parse HEAD; git diff\r\n\r\n<put code or diff here>\r\n```\r\n2. What exact command you run:\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n<put logs here>\r\n```\r\n\r\n## Expected behavior:\r\n\r\nIf there are no obvious crash in \"full logs\" provided above,\r\nplease tell us the expected behavior.\r\n\r\nIf you expect a model to converge / work better, we do not help with such issues, unless\r\na model fails to reproduce the results in detectron2 model zoo, or proves existence of bugs.\r\n\r\n## Environment:\r\n\r\nPaste the output of the following command:\r\n```\r\nwget -nc -nv https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first check common issues in https://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5146,
    "title": "ValueError: DistributedDataParallel device_ids and output_device arguments only work with single-device/multiple-device GPU modules or CPU modules, but got device_ids [3], output_device None, and module parameters {device(type='cpu')}",
    "author": "cherlw",
    "state": "closed",
    "created_at": "2023-11-09T11:36:42Z",
    "updated_at": "2024-09-06T02:04:59Z",
    "labels": [],
    "body": "If you do not know the root cause of the problem, please post according to this template:\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nHi, I am new to Detectron2 and I am trying to run the original train_net.py from your project on 4 Nvidia 2080Ti GPUs, but a ValeError occured\r\n\r\n1. Full runnable code or full changes you made:\r\nI didn't make any change to train_net.py\r\n\r\n2. What exact command you run:\r\n```\r\n./train_net.py --num-gpus 4  --config-file ../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\r\n```\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n[11/09 19:55:41 d2.data.build]: Using training sampler TrainingSampler\r\n[11/09 19:55:42 d2.data.common]: Serializing 117266 elements to byte tensors and concatenating them all ...\r\n[11/09 19:55:46 d2.data.common]: Serialized dataset takes 451.21 MiB\r\nTraceback (most recent call last):\r\n  File \"/data/xbjin_data/wq/detectron2/tools/./train_net.py\", line 156, in <module>\r\n    launch(\r\n  File \"/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/detectron2/engine/launch.py\", line 55, in launch\r\n    mp.spawn(\r\n  File \"/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 240, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 198, in start_processes\r\n    while not context.join():\r\n  File \"/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 160, in join\r\n    raise ProcessRaisedException(msg, error_index, failed_process.pid)\r\ntorch.multiprocessing.spawn.ProcessRaisedException: \r\n\r\n-- Process 3 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\r\n    fn(i, *args)\r\n  File \"/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/detectron2/engine/launch.py\", line 94, in _distributed_worker\r\n    main_func(*args)\r\n  File \"/data/xbjin_data/wq/detectron2/tools/train_net.py\", line 144, in main\r\n    trainer = Trainer(cfg)\r\n  File \"/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/detectron2/engine/defaults.py\", line 316, in __init__\r\n    model = DistributedDataParallel(\r\n  File \"/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 571, in __init__\r\n    self._log_and_throw(\r\n  File \"/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 674, in _log_and_throw\r\n    raise err_type(err_msg)\r\nValueError: DistributedDataParallel device_ids and output_device arguments only work with single-device/multiple-device GPU modules or CPU modules, but got device_ids [3], output_device None, and module parameters {device(type='cpu')}.\r\n```\r\n\r\n## Expected behavior:\r\n\r\n\r\n\r\n## Environment:\r\n\r\nPaste the output of the following command:\r\n```\r\nPython                  3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:39:03) [GCC 11.3.0]\r\nnumpy                   1.23.1\r\ndetectron2              0.3 @/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/detectron2\r\nCompiler                GCC 5.4\r\nCUDA compiler           CUDA 11.3\r\ndetectron2 arch flags   7.5\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.11.0 @/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/torch\r\nPyTorch debug build     False\r\nGPU available           True\r\nGPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti (arch=7.5)\r\nCUDA_HOME               /usr/local/cuda\r\nPillow                  8.2.0\r\ntorchvision             0.12.0 @/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision\r\ntorchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\r\nfvcore                  0.1.3.post20210317\r\ncv2                     4.8.0\r\n----------------------  -----------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 11.3\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 8.2\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n\r\nTesting NCCL connectivity ... this should not hang.\r\nNCCL succeeded.Python                  3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:39:03) [GCC 11.3.0]\r\nnumpy                   1.23.1\r\ndetectron2              0.3 @/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/detectron2\r\nCompiler                GCC 5.4\r\nCUDA compiler           CUDA 11.3\r\ndetectron2 arch flags   7.5\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.11.0 @/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/torch\r\nPyTorch debug build     False\r\nGPU available           True\r\nGPU 0,1,2,3             NVIDIA GeForce RTX 2080 Ti (arch=7.5)\r\nCUDA_HOME               /usr/local/cuda\r\nPillow                  8.2.0\r\ntorchvision             0.12.0 @/data/xbjin_data/miniconda3/envs/d2/lib/python3.9/site-packages/torchvision\r\ntorchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\r\nfvcore                  0.1.3.post20210317\r\ncv2                     4.8.0\r\n----------------------  -----------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 11.3\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 8.2\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n\r\nTesting NCCL connectivity ... this should not hang.\r\nNCCL succeeded.\r\n```\r\n\r\ncould you please help me with this error? I'm not sure why this occurred",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "cherlw",
        "body": "solved it by downgrading the environment\r\n```\r\n-------------------------------  ----------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]\r\nnumpy                            1.23.5\r\ndetectron2                       0.6 @/data/xbjin_data/wq/detectron2/detectron2\r\ndetectron2._C                    not built correctly: No module named 'detectron2._C'\r\nCompiler ($CXX)                  c++ (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCUDA compiler                    Build cuda_11.3.r11.3/compiler.29920130_0\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          1.8.0 @/data/xbjin_data/miniconda3/envs/d2/lib/python3.8/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0,1,2,3                      NVIDIA GeForce RTX 2080 Ti (arch=7.5)\r\nDriver version                   470.94\r\nCUDA_HOME                        /usr/local/cuda\r\nPillow                           9.3.0\r\ntorchvision                      0.9.0 @/data/xbjin_data/miniconda3/envs/d2/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.7.0\r\n-------------------------------  ----------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 10.1\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 7.6.3\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \r\n\r\nTesting NCCL connectivity ... this should not hang.\r\nNCCL succeeded.\r\n```"
      }
    ]
  },
  {
    "issue_number": 5008,
    "title": "Can't install Detectron2",
    "author": "pfcouto",
    "state": "open",
    "created_at": "2023-06-25T23:06:46Z",
    "updated_at": "2024-09-04T15:21:49Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\n```\r\nconda create -n detectronTestNew python=3.8.10\r\nconda activate detectronTestNew\r\nconda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch -c conda-forge\r\npython -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\n```\r\n2. __Full logs__ or other relevant observations:\r\n```\r\n(downloads and copies done before are ommited)\r\n      copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.py -> build/lib.linux-x86_64-cpython-38/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/fcos_R_50_FPN_1x.py -> build/lib.linux-x86_64-cpython-38/detectron2/model_zoo/configs/COCO-Detection\r\n      running build_ext\r\n      building 'detectron2._C' extension\r\n      creating build/temp.linux-x86_64-cpython-38\r\n      creating build/temp.linux-x86_64-cpython-38/tmp\r\n      creating build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q\r\n      creating build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q/detectron2\r\n      creating build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q/detectron2/layers\r\n      creating build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc\r\n      creating build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/ROIAlignRotated\r\n      creating build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/box_iou_rotated\r\n      creating build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/cocoeval\r\n      creating build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/nms_rotated\r\n      gcc -pthread -B /home/pedrobolsa/anaconda3/envs/detectronTestNew/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/TH -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/THC -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/include/python3.8 -c /tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp -o build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\n      cc1plus: warning: command-line option ‚Äò-Wstrict-prototypes‚Äô is valid for C/ObjC but not for C++\r\n      gcc -pthread -B /home/pedrobolsa/anaconda3/envs/detectronTestNew/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/TH -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/THC -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/include/python3.8 -c /tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.cpp -o build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\n      cc1plus: warning: command-line option ‚Äò-Wstrict-prototypes‚Äô is valid for C/ObjC but not for C++\r\n      gcc -pthread -B /home/pedrobolsa/anaconda3/envs/detectronTestNew/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/TH -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/THC -I/home/pedrobolsa/anaconda3/envs/detectronTestNew/include/python3.8 -c /tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/cocoeval/cocoeval.cpp -o build/temp.linux-x86_64-cpython-38/tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/cocoeval/cocoeval.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\n      cc1plus: warning: command-line option ‚Äò-Wstrict-prototypes‚Äô is valid for C/ObjC but not for C++\r\n      In file included from /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:45,\r\n                       from /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/numpy.h:12,\r\n                       from /tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/cocoeval/cocoeval.h:4,\r\n                       from /tmp/pip-req-build-dlzbi57q/detectron2/layers/csrc/cocoeval/cocoeval.cpp:2:\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h:199:10: error: ‚Äòuint16_t‚Äô in namespace ‚Äòstd‚Äô does not name a type; did you mean ‚Äòwint_t‚Äô?\r\n        199 |     std::uint16_t nargs;\r\n            |          ^~~~~~~~\r\n            |          wint_t\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h:202:10: error: ‚Äòuint16_t‚Äô in namespace ‚Äòstd‚Äô does not name a type; did you mean ‚Äòwint_t‚Äô?\r\n        202 |     std::uint16_t nargs_kw_only = 0;\r\n            |          ^~~~~~~~\r\n            |          wint_t\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h:205:10: error: ‚Äòuint16_t‚Äô in namespace ‚Äòstd‚Äô does not name a type; did you mean ‚Äòwint_t‚Äô?\r\n        205 |     std::uint16_t nargs_pos_only = 0;\r\n            |          ^~~~~~~~\r\n            |          wint_t\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h: In constructor ‚Äòpybind11::detail::function_call::function_call(const pybind11::detail::function_record&, pybind11::handle)‚Äô:\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h:310:20: error: ‚Äòconst struct pybind11::detail::function_record‚Äô has no member named ‚Äònargs‚Äô; did you mean ‚Äòargs‚Äô?\r\n        310 |     args.reserve(f.nargs);\r\n            |                    ^~~~~\r\n            |                    args\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h:311:28: error: ‚Äòconst struct pybind11::detail::function_record‚Äô has no member named ‚Äònargs‚Äô; did you mean ‚Äòargs‚Äô?\r\n        311 |     args_convert.reserve(f.nargs);\r\n            |                            ^~~~~\r\n            |                            args\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h: In function ‚Äòvoid pybind11::detail::process_kw_only_arg(const pybind11::arg&, function_record*)‚Äô:\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h:382:10: error: ‚Äòstruct pybind11::detail::function_record‚Äô has no member named ‚Äònargs_kw_only‚Äô\r\n        382 |     ++r->nargs_kw_only;\r\n            |          ^~~~~~~~~~~~~\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h: In static member function ‚Äòstatic void pybind11::detail::process_attribute<pybind11::pos_only>::init(const pybind11::pos_only&, pybind11::detail::function_record*)‚Äô:\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h:439:12: error: ‚Äòstruct pybind11::detail::function_record‚Äô has no member named ‚Äònargs_pos_only‚Äô\r\n        439 |         r->nargs_pos_only = static_cast<std::uint16_t>(r->args.size());\r\n            |            ^~~~~~~~~~~~~~\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/attr.h:439:46: error: ‚Äòuint16_t‚Äô in namespace ‚Äòstd‚Äô does not name a type; did you mean ‚Äòwint_t‚Äô?\r\n        439 |         r->nargs_pos_only = static_cast<std::uint16_t>(r->args.size());\r\n            |                                              ^~~~~~~~\r\n            |                                              wint_t\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h: In member function ‚Äòvoid pybind11::cpp_function::initialize_generic(unique_function_record&&, const char*, const std::type_info* const*, pybind11::size_t)‚Äô:\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:311:26: error: ‚Äòstruct pybind11::detail::function_record‚Äô has no member named ‚Äònargs_kw_only‚Äô\r\n        311 |                 if (rec->nargs_kw_only > 0 && arg_index + rec->nargs_kw_only == args)\r\n            |                          ^~~~~~~~~~~~~\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:311:64: error: ‚Äòstruct pybind11::detail::function_record‚Äô has no member named ‚Äònargs_kw_only‚Äô\r\n        311 |                 if (rec->nargs_kw_only > 0 && arg_index + rec->nargs_kw_only == args)\r\n            |                                                                ^~~~~~~~~~~~~\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:329:26: error: ‚Äòstruct pybind11::detail::function_record‚Äô has no member named ‚Äònargs_pos_only‚Äô\r\n        329 |                 if (rec->nargs_pos_only > 0 && (arg_index + 1) == rec->nargs_pos_only)\r\n            |                          ^~~~~~~~~~~~~~\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:329:72: error: ‚Äòstruct pybind11::detail::function_record‚Äô has no member named ‚Äònargs_pos_only‚Äô\r\n        329 |                 if (rec->nargs_pos_only > 0 && (arg_index + 1) == rec->nargs_pos_only)\r\n            |                                                                        ^~~~~~~~~~~~~~\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:371:14: error: ‚Äòstruct pybind11::detail::function_record‚Äô has no member named ‚Äònargs‚Äô; did you mean ‚Äòargs‚Äô?\r\n        371 |         rec->nargs = (std::uint16_t) args;\r\n            |              ^~~~~\r\n            |              args\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:371:28: error: ‚Äòuint16_t‚Äô is not a member of ‚Äòstd‚Äô; did you mean ‚Äòwint_t‚Äô?\r\n        371 |         rec->nargs = (std::uint16_t) args;\r\n            |                            ^~~~~~~~\r\n            |                            wint_t\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h: In static member function ‚Äòstatic PyObject* pybind11::cpp_function::dispatcher(PyObject*, PyObject*, PyObject*)‚Äô:\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:604:40: error: ‚Äòconst struct pybind11::detail::function_record‚Äô has no member named ‚Äònargs‚Äô; did you mean ‚Äòargs‚Äô?\r\n        604 |                 size_t num_args = func.nargs;    // Number of positional arguments that we need\r\n            |                                        ^~~~~\r\n            |                                        args\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:607:51: error: ‚Äòconst struct pybind11::detail::function_record‚Äô has no member named ‚Äònargs_kw_only‚Äô\r\n        607 |                 size_t pos_args = num_args - func.nargs_kw_only;\r\n            |                                                   ^~~~~~~~~~~~~\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:657:40: error: ‚Äòconst struct pybind11::detail::function_record‚Äô has no member named ‚Äònargs_pos_only‚Äô\r\n        657 |                 if (args_copied < func.nargs_pos_only) {\r\n            |                                        ^~~~~~~~~~~~~~\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:658:47: error: ‚Äòconst struct pybind11::detail::function_record‚Äô has no member named ‚Äònargs_pos_only‚Äô\r\n        658 |                     for (; args_copied < func.nargs_pos_only; ++args_copied) {\r\n            |                                               ^~~~~~~~~~~~~~\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:672:44: error: ‚Äòconst struct pybind11::detail::function_record‚Äô has no member named ‚Äònargs_pos_only‚Äô\r\n        672 |                     if (args_copied < func.nargs_pos_only)\r\n            |                                            ^~~~~~~~~~~~~~\r\n      /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch/include/pybind11/pybind11.h:760:53: error: ‚Äòconst struct pybind11::detail::function_record‚Äô has no member named ‚Äònargs‚Äô; did you mean ‚Äòargs‚Äô?\r\n        760 |                     second_pass_convert.resize(func.nargs, false);\r\n            |                                                     ^~~~~\r\n            |                                                     args\r\n      error: command '/usr/bin/gcc' failed with exit code 1\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for detectron2\r\n  Running setup.py clean for detectron2\r\nFailed to build detectron2\r\nERROR: Could not build wheels for detectron2, which is required to install pyproject.toml-based projects\r\n```\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\n-------------------------------  ------------------------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\r\nnumpy                            1.24.3\r\ndetectron2                       failed to import\r\ndetectron2._C                    not built correctly: No module named 'detectron2'\r\nCompiler ($CXX)                  c++ (GCC) 13.1.1 20230614 (Red Hat 13.1.1-4)\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          1.10.0 @/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0                            NVIDIA GeForce RTX 3080 Laptop GPU (arch=8.6)\r\nDriver version                   530.41.03\r\nCUDA_HOME                        None - invalid!\r\nPillow                           8.2.0\r\ntorchvision                      0.11.0 @/home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags           /home/pedrobolsa/anaconda3/envs/detectronTestNew/lib/python3.8/site-packages/torchvision/_C.so\r\ncv2                              Not found\r\n-------------------------------  ------------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX512\r\n  - CUDA Runtime 11.3\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 8.2\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,\r\n```\r\n\r\nHope someone can help me out. Thanks!\r\n",
    "comments": [
      {
        "user": "satishjasthi",
        "body": "Hi @pfcouto \r\n\r\nThere seems to be an issue with your PyTorch installation. You can follow these steps to install detectron2 within your environment constraints(like python 3.8.10, CUDA 11.3 and linux platform). I hope this resolves your issue, if you face any further issue even after following these steps, let me know.\r\n\r\n- Install pyenv from their [repository](https://github.com/pyenv/pyenv). Its a great tool to maintain different python versions\r\n- Install python 3.8.10 version using pyenv\r\n```bash\r\npyenv install 3.8.10\r\n```\r\n- Set python 3.8.10 as python version for current terminal session using \r\n```bash\r\npyenv shell 3.8.10\r\n```\r\n- create a new virtual env using and activate it \r\n```bash\r\npython -m venv env && source ./env/bin/activate\r\n```\r\n- check your python version and path using \r\n```bash\r\npython --version && which python\r\n```\r\n- Now install torch and torch vision using pip. I suggest using torch 1.12.0 and respective torchvision unless you have a very specific requirement for torch 1.10.0. Because you can still run detectron2 with torch 1.12.0 on CUDA 11.3\r\n```bash\r\npython -m pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113\r\n```\r\n- I see that you already have GCC and G++ installed on your system and they are above v5 so you need not install them again\r\n- Next clone detectron repo using \r\n```bash\r\ngit clone https://github.com/facebookresearch/detectron2.git\r\n```\r\n- Install detectron2 using \r\n```bash\r\npython -m pip install -e detectron2\r\n```\r\n"
      },
      {
        "user": "pfcouto",
        "body": "Hi @satishjasthi, if possible I would like to keep using conda. I am running in Linux (Fedora) but using the `nvidia-smi` command it shows I have `CUDA Version: 12.1`, so I can use a higher CUDA version if the detectron installation allows it.  I tried to replicate those steps using it with the following commands:\r\n\r\n```\r\nconda create -n detectron2 python=3.8.10\r\nconda activate detectron2\r\nconda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch\r\npython -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\n```\r\n\r\nAnd still got the error building detectron2."
      },
      {
        "user": "satishjasthi",
        "body": "Hi @pfcouto \r\n\r\nI see that the root cause is the mismatch between your CUDA version and torch version you are trying to install. In your case you are trying to install torch based on CUDA 11.3 for CUDA 12.1, which may not work and you might end up getting the same error. Instead if your environment supports try installing CUDA 11.7 as latest PyTorch version supports this. \r\n\r\nYou can do this using Docker. If you have Docker installed, you can use a Docker image that includes CUDA 11.7. NVIDIA provides Docker images with different CUDA versions through the [NVIDIA GPU Cloud](https://ngc.nvidia.com/catalog/containers/nvidia:cuda). You can pull the CUDA 11.7 image with:\r\n\r\n   ```bash\r\n   docker pull nvcr.io/nvidia/cuda:11.7.0-base-ubuntu20.04\r\n   ```\r\n\r\n   Then you can run your program inside a Docker container using this image. This has the advantage of not affecting your system's CUDA installation, but it requires you to have Docker installed and to be familiar with Docker usage."
      }
    ]
  },
  {
    "issue_number": 5134,
    "title": "Can't change Pointrend Input Layer ",
    "author": "Yousefshukry",
    "state": "closed",
    "created_at": "2023-10-29T12:54:20Z",
    "updated_at": "2024-09-02T02:05:07Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Hello, \r\n\r\nI'm trying to modify Pointrend project to do the following: \r\nInstead of using 3 channel RGB input for training, I'll increase the number of channels to 4 and include the depth dimension.\r\n\r\nIn order to do that, I created my own build_train_loader and DatasetMapper (build_custom_train_loader) to load my data correctly given depth files. I also made sure input images and depth are of the same size. \r\n\r\nMy data loader now returns (4, 1333, 1920) dimension images. \r\n\r\nNow I'm getting an expected error: \r\n\r\n`Pytorch RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0`\r\n\r\nWhat I'm trying to do is change the input layer dimensions to 4 instead of 3, then modify the pretrained weights by loading them into a Dict and adding a 4th dimension that is the average of RGB channels and train accordingly. \r\n\r\nI tried the following to change the input layer from (3) to (4) dimension:\r\n\r\nI tried modifying the Base-RCNN-FPN.yaml file to add INPUT.NUM_CHANNELS = 4 as follows:\r\n```\r\nMODEL:\r\n  META_ARCHITECTURE: \"GeneralizedRCNN\"\r\n  BACKBONE:\r\n    NAME: \"build_resnet_fpn_backbone\"\r\n  RESNETS:\r\n    OUT_FEATURES: [\"res2\", \"res3\", \"res4\", \"res5\"]\r\n  FPN:\r\n    IN_FEATURES: [\"res2\", \"res3\", \"res4\", \"res5\"]\r\n  ANCHOR_GENERATOR:\r\n    SIZES: [[32], [64], [128], [256], [512]]  # One size for each in feature map\r\n    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]  # Three aspect ratios (same for all in feature maps)\r\n  RPN:\r\n    IN_FEATURES: [\"p2\", \"p3\", \"p4\", \"p5\", \"p6\"]\r\n    PRE_NMS_TOPK_TRAIN: 2000  # Per FPN level\r\n    PRE_NMS_TOPK_TEST: 1000  # Per FPN level\r\n    # Detectron1 uses 2000 proposals per-batch,\r\n    # (See \"modeling/rpn/rpn_outputs.py\" for details of this legacy issue)\r\n    # which is approximately 1000 proposals per-image since the default batch size for FPN is 2.\r\n    POST_NMS_TOPK_TRAIN: 1000\r\n    POST_NMS_TOPK_TEST: 1000\r\n  ROI_HEADS:\r\n    NAME: \"StandardROIHeads\"\r\n    IN_FEATURES: [\"p2\", \"p3\", \"p4\", \"p5\"]\r\n  ROI_BOX_HEAD:\r\n    NAME: \"FastRCNNConvFCHead\"\r\n    NUM_FC: 2\r\n    POOLER_RESOLUTION: 7\r\n  ROI_MASK_HEAD:\r\n    NAME: \"MaskRCNNConvUpsampleHead\"\r\n    NUM_CONV: 4\r\n    POOLER_RESOLUTION: 14\r\nDATASETS:\r\n  TRAIN: (\"coco_2017_train\",)\r\n  TEST: (\"coco_2017_val\",)\r\nSOLVER:\r\n  IMS_PER_BATCH: 2\r\n  BASE_LR: 0.02\r\n  STEPS: (60000, 80000)\r\n  MAX_ITER: 90000\r\nINPUT:\r\n  # MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\r\n  FORMAT: \"RGB\"  # Image format (typically \"RGB\")\r\n  NUM_CHANNELS: 4  # Change this to 4\r\n  HEIGHT: 1333  # Input image height\r\n  WIDTH: 1920   # Input image width\r\nVERSION: 2\r\n```\r\n\r\nI also tried modifying the setup function where I changed:\r\ncfg.MODEL.RESNETS.STEM_OUT_CHANNELS\r\ncfg.MODEL.FPN.IN_FEATURES = 4\r\n\r\nI also played around with cfg.MODEL.RESNETS.OUT_FEATURES\r\n```\r\ndef setup(args):\r\n    \"\"\"\r\n    Create configs and perform basic setups.\r\n    \"\"\"\r\n    cfg = get_cfg()\r\n    \r\n    #import pdb; pdb.set_trace()\r\n    add_pointrend_config(cfg)\r\n    cfg.merge_from_file(args.config_file)\r\n    cfg.merge_from_list(args.opts)\r\n\r\n    # Update this line if we want to resume training from a previous checkpoints file\r\n    # cfg.MODEL.WEIGHTS = \"checkpoints/active_train/model_0000099.pth\"\r\n\r\n\r\n    cfg.MODEL.DEVICE = \"cuda\"\r\n    cfg.DATALOADER.NUM_WORKERS = 1\r\n    cfg.SOLVER.CHECKPOINT_PERIOD = 500\r\n\r\n    # number of classes\r\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\r\n    cfg.MODEL.POINT_HEAD.NUM_CLASSES = 2\r\n\r\n    # Change number of channels\r\n    # cfg.INPUT.NUM_CHANNELS = 4\r\n    input_channels = 4  \r\n    cfg.MODEL.RESNETS.STEM_OUT_CHANNELS = input_channels * 2  # Default is 3 * 2 = 6  \r\n    # cfg.MODEL.INPUT.NUM_CHANNELS = 4\r\n    cfg.MODEL.FPN.IN_FEATURES = 4\r\n    cfg.MODEL.RESNETS.OUT_FEATURES = ['res2', 'res3', 'res4', 'res5', 'res6']\r\n    cfg.MODEL.ROI_HEADS.OUT_FEATURES = ['p2', 'p3', 'p4', 'p5', 'p6']\r\n    cfg.MODEL.SEM_SEG_HEAD.IN_FEATURES = ['p2', 'p3', 'p4', 'p5', 'p6']\r\n    \r\n    # not flipping\r\n    if args.dataset in ['epick_hos']:\r\n        cfg.INPUT.RANDOM_FLIP = \"none\"\r\n        \r\n\r\n    cfg.freeze()\r\n    default_setup(cfg, args)\r\n    return cfg\r\n```\r\n\r\nNothing seems to be working with me, Am I missing something? \r\nWhat exactly do I need to do in order to modify the input layer dimensions to be (4) and allow me to train the modeling using an extra signal? \r\n\r\nThank you.\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5353,
    "title": "loss_box_reg increasing while training mask rcnn",
    "author": "ArpanGyawali",
    "state": "closed",
    "created_at": "2024-08-23T15:20:48Z",
    "updated_at": "2024-08-31T02:04:29Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "### üêõ Describe the bug\r\n\r\nI am trying to train maskRcnn model on my custom LVO deteset. My dataset is a single class dataset and some of the image have no annotation in it. The architecture need to learn negative examples as well for proper training as the test data contains both positive and negative lvo cases. I have segmentation annotation in coco format and have registered it using CocoRegistration.\r\nWhen I try to train the maskrcnn model the overall loss decreases but the loss_box_reg increases, and the prediction results bounding box have scores less then 0.1 for every cases (even positive cases). Why is this happening.\r\n\r\nHow to reproduce this error:\r\n\r\n```\r\ncfg = get_cfg()\r\n# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\r\ncfg.DATASETS.TRAIN = (\"train\",)\r\ncfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\r\ncfg.DATALOADER.NUM_WORKERS = 2\r\ncfg.INPUT.MAX_SIZE_TRAIN = 512         # every training image have size 512\r\ncfg.INPUT.MIN_SIZE_TRAIN = (512,)\r\ncfg.INPUT.MAX_SIZE_TEST = 512\r\ncfg.INPUT.MIN_SIZE_TEST = 512\r\ncfg.INPUT.MASK_FORMAT = \"bitmask\"\r\n# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")  # initialize from model zoo\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\r\ncfg.SOLVER.IMS_PER_BATCH = 2\r\ncfg.SOLVER.BASE_LR = 0.00025\r\ncfg.SOLVER.MAX_ITER = 2000\r\ncfg.SOLVER.CHECKPOINT_PERIOD = 200\r\ncfg.SOLVER.STEPS = []        # do not decay learning rate\r\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\r\ncfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\r\ncfg.OUTPUT_DIR = out_dir\r\ntrainer = DefaultTrainer(cfg) \r\ntrainer.resume_or_load(resume=False)\r\ntrainer.train()\r\n```\r\nMy positive and negative dataset sample\r\n![image](https://github.com/user-attachments/assets/b59b688a-9709-44a2-beb5-53cd12916e41)\r\nAnnotation example:\r\n ```  \r\n {\r\n      \"id\": 80,\r\n      \"image_id\": 180,\r\n      \"category_id\": 1,\r\n      \"segmentation\": {\r\n        \"counts\": [\r\n          large list\r\n        ],\r\n        \"size\": [512, 512]\r\n      },\r\n      \"area\": 247.0,\r\n      \"bbox\": [302.0, 227.0, 24.0, 13.0],\r\n      \"iscrowd\": 0,\r\n      \"attributes\": {  \"occluded\": false\r\n      }},\r\n```\r\n \r\nIssue:\r\nTotal loss:\r\n![image](https://github.com/user-attachments/assets/5095c1e6-c692-48a2-845d-5f4c54b77be9)\r\n\r\nLoss_box_reg:\r\n![image](https://github.com/user-attachments/assets/8ce4cfe0-820a-4646-9921-10d527ce3987)\r\n\r\nMy prediction scoreexample for positive cases:\r\nscores: tensor([0.0901, 0.0862, 0.0737, 0.0697, 0.0679, 0.0670, 0.0668, 0.0665, 0.0664, ........])\r\n\r\nHelp me solve this problem\r\n\r\n### Versions\r\n\r\nVersions:\r\nPyTorch version: 2.0.0+cu117\r\nIs debug build: False\r\nCUDA used to build PyTorch: 11.7\r\nROCM used to build PyTorch: N/A\r\n\r\nOS: Red Hat Enterprise Linux 9.4 (Plow) (x86_64)\r\nGCC version: (GCC) 11.3.0\r\nClang version: Could not collect\r\nCMake version: version 3.28.3\r\nLibc version: glibc-2.34\r\n\r\nPython version: 3.9.18 (main, May 16 2024, 00:00:00)  [GCC 11.4.1 20231218 (Red Hat 11.4.1-3)] (64-bit runtime)\r\nPython platform: Linux-5.14.0-427.18.1.el9_4.x86_64-x86_64-with-glibc2.34\r\n\r\nVersions of relevant libraries:\r\n[pip3] mypy-extensions==1.0.0\r\n[pip3] numpy==1.26.4\r\n[pip3] torch==2.0.0\r\n[pip3] torchvision==0.15.1\r\n[pip3] triton==2.0.0\r\n[conda] Could not collect\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 4335,
    "title": "Dockerfile Python 3.6 doesn't match the new 3.7 version requirement",
    "author": "bpetit2019",
    "state": "open",
    "created_at": "2022-06-15T14:41:18Z",
    "updated_at": "2024-08-30T12:28:15Z",
    "labels": [
      "enhancement"
    ],
    "body": "You've updated the requirement of Python's version to 3.7 but in the Dockerfile, the 3.6 version is still install.",
    "comments": [
      {
        "user": "mahesh-musashi",
        "body": "Hi @bpetit2019, I had the same issue and fixed it by using a different base image,\r\n```\r\nFROM pytorch/pytorch:1.10.0-cuda11.3-cudnn8-devel\r\n```\r\nand commented out the installation of tensorboard, torch, and torchvision as they are already installed in the pytorch base image."
      },
      {
        "user": "bpetit2019",
        "body": "Thanks @mahesh-musashi  I tested it, and it worked after a few modifications."
      },
      {
        "user": "MatthiasCami8",
        "body": "@bpetit2019 what were the other modifications, as I seem to have an issue getting it to work"
      }
    ]
  },
  {
    "issue_number": 5357,
    "title": "Exporting Faster RCNN Model trained on a Custom Dataset with TorchScript does not produce any Output",
    "author": "kirillmeisser",
    "state": "closed",
    "created_at": "2024-08-28T09:24:57Z",
    "updated_at": "2024-08-28T12:57:01Z",
    "labels": [],
    "body": "If you do not know the root cause of the problem, please post according to this template:\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nHi,\r\n\r\nI need help regarding the export of a trained model for object detection (precisely the faster_rcnn_R_101_FPN_3x version). I have fine-tuned the model on a custom dataset containing one object class using the [colab tutorial](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=h9tECBQCvMv3) as inspiration. I have the saved model and would now like to export it into the TorschScript format, to then deploy it in DJL. To do this I have used the [export_model.py](https://github.com/facebookresearch/detectron2/blob/main/tools/deploy/export_model.py) script. The exporting seems to be going just fine and I managed to get the model exported and saved under model.ts. Now, as a sanity check, I tried to load the TorchScript model into a simple Python script and run an image to see whether the output makes sense, unfortunately, it outputs an empty Tensor Tuple. Here is the example:\r\n\r\n```\r\nimport torch\r\nimport torchvision\r\nfrom PIL import Image\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    model = torch.jit.load(\"PATH_TO_MODEL/model.ts\")\r\n    model.eval()\r\n\r\n    image = Image.open(\"PATH_TO_IMG/img.png\")\r\n    transform = torchvision.transforms.ToTensor()\r\n    test_input = transform(image)\r\n\r\n    output = model(test_input)\r\n    print(output)\r\n```\r\n\r\nWhere the printed output is as follows:\r\n\r\n```\r\n(tensor([], size=(0, 4), grad_fn=<IndexBackward0>), tensor([], dtype=torch.int64), tensor([], grad_fn=<IndexBackward0>), tensor([408, 612]))\r\n```\r\n\r\nI have looked through the documentation, issues, and the [deployment example](https://github.com/facebookresearch/detectron2/blob/main/tools/deploy/torchscript_mask_rcnn.cpp) and can't find a way to solve this problem. Any help would be greatly appreciated!\r\n\r\nP.S: This issue may be related with this open [discussion](https://github.com/facebookresearch/detectron2/discussions/5355). \r\n\r\n\r\n\r\n\r\n## Expected behavior:\r\n\r\nThere should be one detected object as output. I visualized the same image during evaluation and the object was detected. It is not a training issue\r\n\r\n## Environment:\r\n\r\nThe environment runs Python 3.9.6 with the following package versions:\r\n\r\n``` \r\ntorch 1.12.1\r\ntorchvision 0.13.1\r\ndetectron2 0.6\r\n```",
    "comments": [
      {
        "user": "kirillmeisser",
        "body": "I found a solution by following the script shared in #5156. If I modify the former script to:\r\n\r\n```\r\ndef get_input(image_file):\r\n    input_img = cv2.imread(image_file, cv2.IMREAD_COLOR)\r\n    # input_img = cv2.resize(input_img,(1333,800), interpolation=cv2.INTER_LINEAR)\r\n    height, width, channels = input_img.shape\r\n    img_tensor = torch.from_numpy(input_img).view(height, width, channels).to(torch.float32)\r\n    img_tensor = img_tensor.permute(2, 0, 1).contiguous()\r\n\r\n    return img_tensor\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    model_path = \".../model.ts\"\r\n    img_path = \".../img.png\"\r\n\r\n    model = torch.jit.load(model_path)\r\n    model.eval()\r\n\r\n    input = get_input(img_path)\r\n\r\n    output = model.forward(input)\r\n    print(\"Output:\", output)\r\n```\r\nThe processing works although the input and output are strangely not dictionaries as is in the documentation. Here I feed a Tensor as input and get a Tuple as output that looks as the following:\r\n\r\n```\r\n(tensor([[377.6366, 397.9915, 779.1143, 561.9951],[550.6393, 388.4034, 778.9048, 546.3689]], grad_fn=<IndexBackward0>), tensor([0, 0]), tensor([0.9840, 0.0890], grad_fn=<IndexBackward0>), tensor([1527,  990]))\r\n```\r\nWhere the first tensor denotes the bounding boxes, the second denotes the predicted classes, and the third one outputs the confidence scores.\r\n"
      }
    ]
  },
  {
    "issue_number": 5156,
    "title": "Detectro 2 deployment inference interpretation",
    "author": "blackHorz",
    "state": "closed",
    "created_at": "2023-11-20T12:43:21Z",
    "updated_at": "2024-08-28T12:48:40Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "I have tried to replicate the torchscript C++ inference file into Python. I am getting the results similar to what is expected. However I am not sure on how to map my pred_masks over my original image size.\r\n\r\nWhich C++ script i am talking about.\r\nhttps://github.com/facebookresearch/detectron2/blob/main/tools/deploy/torchscript_mask_rcnn.cpp\r\n\r\nHow did i export my model to .ts\r\nhttps://github.com/facebookresearch/detectron2/blob/main/tools/deploy/export_model.py\r\n\r\nWhich method I have used (scripting)\r\n\r\nThe output of the pred_masks is (batch_size, 1, 28, 28). Whereas original image size was 2048x2448, which i resize to 800x1333.\r\n\r\nHow can i get the masks that corresponds to my original image size?\r\n\r\n1. Full runnable code or full changes you made:\r\n```\r\ndef get_scripting_inputs(img, device):\r\n    height, width, channels = img.shape\r\n    print(\"DEBUG 1 : \", height, width, channels)\r\n    #img_tensor = torch.from_numpy(img).view(height, width, channels).to(torch.uint8)\r\n    img_tensor = torch.from_numpy(img).view(height, width, channels).to(torch.float32)\r\n    img_tensor = img_tensor.to(device, torch.float).permute(2, 0, 1).contiguous()\r\n\r\n    dic = {'image': img_tensor}\r\n    return (dic,)\r\n\r\nclass MaskRCNNOutputs:\r\n    def __init__(self, pred_boxes, pred_classes, pred_masks, scores):\r\n        self.pred_boxes = pred_boxes\r\n        self.pred_classes = pred_classes\r\n        self.pred_masks = pred_masks\r\n        self.scores = scores\r\n\r\n    def num_instances(self):\r\n        return self.pred_boxes.size(0)\r\n\r\ndef get_outputs(outputs):\r\n    out_dict = outputs[0]\r\n    return MaskRCNNOutputs(out_dict['pred_boxes'], out_dict['pred_classes'], out_dict['pred_masks'], out_dict['scores'])\r\n\r\ndef main():\r\n\r\n\r\n    image_file = 'TOP.png'\r\n\r\n    #fusion_strategy = {torch.jit.FusionType.DYNAMIC: 1}\r\n    torch.jit._set_fusion_strategy([(\"DYNAMIC\", 2)])\r\n    torch.set_grad_enabled(False)\r\n\r\n    module = torch.jit.load('D:\\\\AI\\\\Research\\\\YOLOV8\\\\n_o\\\\model.ts')\r\n    assert len(list(module.buffers())) > 0\r\n\r\n    # Assume that the entire model is on the same device.\r\n    # We just put input to this device.\r\n    device = list(module.buffers())[0].device\r\n\r\n    input_img = cv2.imread(image_file, cv2.IMREAD_COLOR)\r\n    input_img = cv2.resize(input_img,(1333,800), interpolation=cv2.INTER_LINEAR)\r\n    inputs = get_scripting_inputs(input_img, device)\r\n\r\n    # Run the network\r\n    output = module.forward(inputs)\r\n    if torch.cuda.is_available():\r\n        torch.cuda.current_stream().synchronize()\r\n\r\n    # Run 3 more times to benchmark\r\n    N_benchmark, N_warmup = 3, 1\r\n\r\n    for i in range(N_benchmark + N_warmup):\r\n        output = module.forward(inputs)\r\n        if torch.cuda.is_available():\r\n            torch.cuda.current_stream().synchronize()\r\n\r\n\r\n\r\n    # Parse Mask R-CNN outputs\r\n    rcnn_outputs = get_outputs(output)\r\n    print(\"Number of detected objects:\", rcnn_outputs.num_instances())\r\n    print(\"pred_boxes:\", rcnn_outputs.pred_boxes, rcnn_outputs.pred_boxes.size())\r\n    print(\"scores:\", rcnn_outputs.scores, rcnn_outputs.scores.size())\r\n    print(\"pred_classes:\", rcnn_outputs.pred_classes, rcnn_outputs.pred_classes.size())\r\n    print(\"pred_masks:\", rcnn_outputs.pred_masks, rcnn_outputs.pred_masks.size())\r\n```\r\n\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      },
      {
        "user": "kirillmeisser",
        "body": "Hi @blackHorz,\r\n\r\nI'm also challenged by the export of a fine-tuned object detection Detectron2 model. Your script really helped me solve a problem. However, in my case, my model does not want a dictionary as input (just the image as a Tensor) and it also does not output a dictionary of outputs but a tuple that looks like this:\r\n```\r\n(tensor([[377.6366, 397.9915, 779.1143, 561.9951], [550.6393, 388.4034, 778.9048, 546.3689]], grad_fn=<IndexBackward0>), tensor([0, 0]), tensor([0.9840, 0.0890], grad_fn=<IndexBackward0>), tensor([1527,  990]))\r\n```\r\n\r\nDo you know how you managed to get the model to accept input and output in the dictionary format? It seems to match the documented behavior, whereas mine does not.\r\n\r\nTo answer your question, can it be that the masks are relative to the bounding box origin (top-left point of the bounding box)? I have also noticed that you do not have to resize the image if you do not want to. In that case, Detectron2 will output the coordinates in the unresized image dimensions. However, in that case, as I understood, larger images will require longer computation."
      }
    ]
  },
  {
    "issue_number": 5356,
    "title": "Exporting Faster RCNN Model trained on a Custom Dataset with TorchScript does not produce any Output",
    "author": "kirillmeisser",
    "state": "closed",
    "created_at": "2024-08-28T09:17:42Z",
    "updated_at": "2024-08-28T09:25:33Z",
    "labels": [
      "needs-more-info"
    ],
    "body": "Hi,\r\n\r\nI need help regarding the export of a trained model for object detection (precisely the faster_rcnn_R_101_FPN_3x version). I have fine-tuned the model on a custom dataset containing one object class using the [colab tutorial](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=h9tECBQCvMv3) as inspiration. I have the saved model and would now like to export it into the TorschScript format, to then deploy it in DJL. To do this I have used the [export_model.py](https://github.com/facebookresearch/detectron2/blob/main/tools/deploy/export_model.py) script. The exporting seems to be going just fine and I managed to get the model exported and saved under model.ts. Now, as a sanity check, I tried to load the TorchScript model into a simple Python script and run an image to see whether the output makes sense, unfortunately, it outputs an empty Tensor Tuple. Here is the example:\r\n\r\n```\r\nimport torch\r\nimport torchvision\r\nfrom PIL import Image\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    model = torch.jit.load(\"PATH_TO_MODEL/model.ts\")\r\n    model.eval()\r\n\r\n    image = Image.open(\"PATH_TO_IMG/img.png\")\r\n    transform = torchvision.transforms.ToTensor()\r\n    test_input = transform(image)\r\n\r\n    output = model(test_input)\r\n    print(output)\r\n```\r\n\r\nWhere the printed output is as follows:\r\n\r\n```\r\n(tensor([], size=(0, 4), grad_fn=<IndexBackward0>), tensor([], dtype=torch.int64), tensor([], grad_fn=<IndexBackward0>), tensor([408, 612]))\r\n```\r\n\r\nI have looked through the documentation, issues, and the [deployment example](https://github.com/facebookresearch/detectron2/blob/main/tools/deploy/torchscript_mask_rcnn.cpp) and can't find a way to solve this problem. Any help would be greatly appreciated.\r\n\r\nP.S: This issue may be related with this open [discussion](https://github.com/facebookresearch/detectron2/discussions/5355). \r\n\r\n\r\nThe environment runs Python 3.9.6 with the following package versions:\r\n\r\n``` \r\ntorch 1.12.1\r\ntorchvision 0.13.1\r\ndetectron2 0.6\r\n```",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      }
    ]
  },
  {
    "issue_number": 5133,
    "title": "Issue in resizing the images",
    "author": "Ziyadmysterio",
    "state": "closed",
    "created_at": "2023-10-24T11:20:51Z",
    "updated_at": "2024-08-27T02:04:11Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "i have a Coco dataset with uneven image shapes. I get the following error while segment training.\r\n![image](https://github.com/facebookresearch/detectron2/assets/54292052/d3b98103-3559-4338-91e9-900240b552c9)\r\nIs there any way to resize the images before feeding into the network or is the resizing done manually? ",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5131,
    "title": "Repeated information makes interface confused",
    "author": "duoxiangqinzuo",
    "state": "closed",
    "created_at": "2023-10-24T07:54:50Z",
    "updated_at": "2024-08-27T02:04:11Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "When I train with n GPUs, a lot of information is printed n times repeatedlyÔºåwhich makes it difficult for me to discover important information.\r\n![image](https://github.com/facebookresearch/detectron2/assets/74463511/33e9cce2-7f0c-43df-b7e9-767639fab557)\r\n\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5129,
    "title": "could not support CUDA version higher than 11.3",
    "author": "ouyang11111",
    "state": "closed",
    "created_at": "2023-10-24T03:14:03Z",
    "updated_at": "2024-08-27T02:04:11Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\n```\r\nIf making changes to the project itself, please use output of the following command:\r\ngit rev-parse HEAD; git diff\r\n\r\n<put code or diff here>\r\n```\r\n2. What exact command you run:\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n<put logs here>\r\n```\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\n## Expected behavior:\r\n\r\nIf there are no obvious error in \"full logs\" provided above,\r\nplease tell us the expected behavior.\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first try to solve it yourself with the instructions in\r\nhttps://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5136,
    "title": "Can not run google colab in the local",
    "author": "gobears21",
    "state": "closed",
    "created_at": "2023-10-29T13:38:54Z",
    "updated_at": "2024-08-25T02:05:07Z",
    "labels": [
      "needs-more-info"
    ],
    "body": "1. Full runnable code or full changes you made:\r\n```\r\nimport sys, os, distutils.core\r\nimport torch, detectron2, subprocess\r\ndef get_nvcc_version():\r\n    result = subprocess.run(['nvcc', '--version'], stdout=subprocess.PIPE, text=True)\r\n    return result.stdout\r\n# Get nvcc version\r\nnvcc_version = get_nvcc_version()\r\nprint(nvcc_version)\r\n# Get torch and cuda versions\r\nTORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\r\nCUDA_VERSION = torch.__version__.split(\"+\")[-1]\r\nprint(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\r\n# Get detectron2 version\r\nprint(\"detectron2:\", detectron2.__version__)\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\r\n# Some basic setup:\r\n# Setup detectron2 logger\r\nimport detectron2\r\nfrom detectron2.utils.logger import setup_logger\r\nsetup_logger()\r\n\r\n# import some common libraries\r\nimport numpy as np\r\nimport os, json, cv2, random\r\n# from google.colab.patches import cv2_imshow\r\n\r\n# import some common detectron2 utilities\r\nfrom detectron2 import model_zoo\r\nfrom detectron2.engine import DefaultPredictor\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.utils.visualizer import Visualizer\r\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\r\n\r\n# if your dataset is in COCO format, this cell can be replaced by the following three lines:\r\n# from detectron2.data.datasets import register_coco_instances\r\n# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\r\n# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\r\n\r\nfrom detectron2.structures import BoxMode\r\n\r\ndef get_balloon_dicts(img_dir):\r\n    json_file = os.path.join(img_dir, \"via_region_data.json\")\r\n    with open(json_file) as f:\r\n        imgs_anns = json.load(f)\r\n\r\n    dataset_dicts = []\r\n    for idx, v in enumerate(imgs_anns.values()):\r\n        record = {}\r\n        \r\n        filename = os.path.join(img_dir, v[\"filename\"])\r\n        height, width = cv2.imread(filename).shape[:2]\r\n        \r\n        record[\"file_name\"] = filename\r\n        record[\"image_id\"] = idx\r\n        record[\"height\"] = height\r\n        record[\"width\"] = width\r\n      \r\n        annos = v[\"regions\"]\r\n        objs = []\r\n        for _, anno in annos.items():\r\n            assert not anno[\"region_attributes\"]\r\n            anno = anno[\"shape_attributes\"]\r\n            px = anno[\"all_points_x\"]\r\n            py = anno[\"all_points_y\"]\r\n            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\r\n            poly = [p for x in poly for p in x]\r\n\r\n            obj = {\r\n                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\r\n                \"bbox_mode\": BoxMode.XYXY_ABS,\r\n                \"segmentation\": [poly],\r\n                \"category_id\": 0,\r\n            }\r\n            objs.append(obj)\r\n        record[\"annotations\"] = objs\r\n        dataset_dicts.append(record)\r\n    return dataset_dicts\r\n\r\nfor d in [\"train\", \"val\"]:\r\n    DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(\"/root/detectron2/balloon/\" + d))  #also add absolate path\r\n    MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\r\nballoon_metadata = MetadataCatalog.get(\"balloon_train\")\r\n\r\ndataset_dicts = get_balloon_dicts(\"/root/detectron2/balloon/train\")  #add absoluate path\r\n\r\n# for d in random.sample(dataset_dicts, 3):\r\n#     img = cv2.imread(d[\"file_name\"])\r\n#     visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=0.5)\r\n#     out = visualizer.draw_dataset_dict(d)\r\n#     # Display using cv2.imshow\r\n#     cv2.imshow('Image', out.get_image()[:, :, ::-1])\r\n    \r\n#     # Wait for a key press and close the window\r\n#     cv2.waitKey(0)\r\n#     cv2.destroyAllWindows()\r\n    \r\nfrom detectron2.engine import DefaultTrainer\r\n\r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\r\ncfg.DATASETS.TRAIN = (\"balloon_train\",)\r\ncfg.DATASETS.TEST = ()\r\ncfg.DATALOADER.NUM_WORKERS = 2\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\r\ncfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\r\ncfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\r\ncfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\r\ncfg.SOLVER.STEPS = []        # do not decay learning rate\r\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\r\n# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\r\n\r\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\ntrainer = DefaultTrainer(cfg) \r\ntrainer.resume_or_load(resume=False)\r\ntrainer.train()\r\n\r\n```\r\n\r\n2. What exact command you run:\r\n```\r\npython bollon_test.py\r\n```\r\n\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n(detectron2) root@f3c85edb8996:~/detectron2# python bollon_test.py \r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2021 NVIDIA Corporation\r\nBuilt on Mon_Sep_13_19:13:29_PDT_2021\r\nCuda compilation tools, release 11.5, V11.5.50\r\nBuild cuda_11.5.r11.5/compiler.30411180_0\r\n\r\ntorch:  1.10 ; cuda:  1.10.0\r\ndetectron2: 0.6\r\n[10/29 22:29:48 d2.engine.defaults]: Model:\r\nGeneralizedRCNN(\r\n  (backbone): FPN(\r\n    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (top_block): LastLevelMaxPool()\r\n    (bottom_up): ResNet(\r\n      (stem): BasicStem(\r\n        (conv1): Conv2d(\r\n          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\r\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n        )\r\n      )\r\n      (res2): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res3): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res4): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (4): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (5): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res5): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n    )\r\n  )\r\n  (proposal_generator): RPN(\r\n    (rpn_head): StandardRPNHead(\r\n      (conv): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n    (anchor_generator): DefaultAnchorGenerator(\r\n      (cell_anchors): BufferList()\r\n    )\r\n  )\r\n  (roi_heads): StandardROIHeads(\r\n    (box_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (box_head): FastRCNNConvFCHead(\r\n      (flatten): Flatten(start_dim=1, end_dim=-1)\r\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\r\n      (fc_relu1): ReLU()\r\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\r\n      (fc_relu2): ReLU()\r\n    )\r\n    (box_predictor): FastRCNNOutputLayers(\r\n      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\r\n      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\r\n    )\r\n    (mask_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (mask_head): MaskRCNNConvUpsampleHead(\r\n      (mask_fcn1): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn2): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn3): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn4): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\r\n      (deconv_relu): ReLU()\r\n      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n  )\r\n)\r\n[10/29 22:29:50 d2.data.build]: Removed 0 images with no usable annotations. 61 images left.\r\n[10/29 22:29:50 d2.data.build]: Distribution of instances among all 1 categories:\r\n\r\n|  category  | #instances   |\r\n|:----------:|:-------------|\r\n|  balloon   | 255          |\r\n|            |              |\r\n\r\n[10/29 22:29:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\r\n[10/29 22:29:50 d2.data.build]: Using training sampler TrainingSampler\r\n[10/29 22:29:50 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\r\n[10/29 22:29:50 d2.data.common]: Serializing 61 elements to byte tensors and concatenating them all ...\r\n[10/29 22:29:50 d2.data.common]: Serialized dataset takes 0.17 MiB\r\nTraceback (most recent call last):\r\n  File \"bollon_test.py\", line 132, in <module>\r\n    trainer = DefaultTrainer(cfg) \r\n  File \"/root/detectron2/detectron2/engine/defaults.py\", line 380, in __init__\r\n    data_loader = self.build_train_loader(cfg)\r\n  File \"/root/detectron2/detectron2/engine/defaults.py\", line 549, in build_train_loader\r\n    return build_detection_train_loader(cfg)\r\n  File \"/root/detectron2/detectron2/config/config.py\", line 208, in wrapped\r\n    return orig_func(**explicit_args)\r\n  File \"/root/detectron2/detectron2/data/build.py\", line 549, in build_detection_train_loader\r\n    return build_batch_data_loader(\r\n  File \"/root/detectron2/detectron2/data/build.py\", line 339, in build_batch_data_loader\r\n    data_loader = torchdata.DataLoader(\r\n  File \"/opt/conda/envs/detectron2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 183, in __init__\r\n    assert prefetch_factor > 0\r\nTypeError: '>' not supported between instances of 'NoneType' and 'int'\r\n(detectron2) root@f3c85edb8996:~/detectron2# \r\n\r\n```\r\n\r\n4. I copied the \"train on a custom dataset\" of the google colab tutorial notebook, run in the local. However, there is an error occured. \r\n\r\n\r\n## Environment:\r\n\r\n\r\n```\r\n-------------------------------  --------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]\r\nnumpy                            1.23.1\r\ndetectron2                       0.6 @/root/detectron2/detectron2\r\ndetectron2._C                    not built correctly: No module named 'detectron2._C'\r\nCompiler ($CXX)                  c++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\nCUDA compiler                    Build cuda_11.5.r11.5/compiler.30411180_0\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          1.10.0 @/opt/conda/envs/detectron2/lib/python3.8/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0,1                          NVIDIA GeForce RTX 2080 Ti (arch=7.5)\r\nDriver version                   535.113.01\r\nCUDA_HOME                        /usr/local/cuda\r\nTORCH_CUDA_ARCH_LIST             5.2 6.0 6.1 7.0 7.5 8.0 8.6+PTX\r\nPillow                           9.4.0\r\ntorchvision                      0.11.0 @/opt/conda/envs/detectron2/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.7.0\r\n-------------------------------  --------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX512\r\n  - CUDA Runtime 11.3\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 8.2\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \r\n\r\nTesting NCCL connectivity ... this should not hang.\r\nNCCL succeeded.\r\n```\r\n\r\n\r\n\r\n ",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      }
    ]
  },
  {
    "issue_number": 5135,
    "title": "can not run colab Detectron2 tutorial in local",
    "author": "gobears21",
    "state": "closed",
    "created_at": "2023-10-29T13:25:15Z",
    "updated_at": "2024-08-25T02:05:07Z",
    "labels": [],
    "body": "1. Full runnable code or full changes you made:\r\n```\r\nimport sys, os, distutils.core\r\nimport torch, detectron2, subprocess\r\ndef get_nvcc_version():\r\n    result = subprocess.run(['nvcc', '--version'], stdout=subprocess.PIPE, text=True)\r\n    return result.stdout\r\n# Get nvcc version\r\nnvcc_version = get_nvcc_version()\r\nprint(nvcc_version)\r\n# Get torch and cuda versions\r\nTORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\r\nCUDA_VERSION = torch.__version__.split(\"+\")[-1]\r\nprint(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\r\n# Get detectron2 version\r\nprint(\"detectron2:\", detectron2.__version__)\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\r\n# Some basic setup:\r\n# Setup detectron2 logger\r\nimport detectron2\r\nfrom detectron2.utils.logger import setup_logger\r\nsetup_logger()\r\n\r\n# import some common libraries\r\nimport numpy as np\r\nimport os, json, cv2, random\r\n# from google.colab.patches import cv2_imshow\r\n\r\n# import some common detectron2 utilities\r\nfrom detectron2 import model_zoo\r\nfrom detectron2.engine import DefaultPredictor\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.utils.visualizer import Visualizer\r\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\r\n\r\n# if your dataset is in COCO format, this cell can be replaced by the following three lines:\r\n# from detectron2.data.datasets import register_coco_instances\r\n# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\r\n# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\r\n\r\nfrom detectron2.structures import BoxMode\r\n\r\ndef get_balloon_dicts(img_dir):\r\n    json_file = os.path.join(img_dir, \"via_region_data.json\")\r\n    with open(json_file) as f:\r\n        imgs_anns = json.load(f)\r\n\r\n    dataset_dicts = []\r\n    for idx, v in enumerate(imgs_anns.values()):\r\n        record = {}\r\n        \r\n        filename = os.path.join(img_dir, v[\"filename\"])\r\n        height, width = cv2.imread(filename).shape[:2]\r\n        \r\n        record[\"file_name\"] = filename\r\n        record[\"image_id\"] = idx\r\n        record[\"height\"] = height\r\n        record[\"width\"] = width\r\n      \r\n        annos = v[\"regions\"]\r\n        objs = []\r\n        for _, anno in annos.items():\r\n            assert not anno[\"region_attributes\"]\r\n            anno = anno[\"shape_attributes\"]\r\n            px = anno[\"all_points_x\"]\r\n            py = anno[\"all_points_y\"]\r\n            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\r\n            poly = [p for x in poly for p in x]\r\n\r\n            obj = {\r\n                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\r\n                \"bbox_mode\": BoxMode.XYXY_ABS,\r\n                \"segmentation\": [poly],\r\n                \"category_id\": 0,\r\n            }\r\n            objs.append(obj)\r\n        record[\"annotations\"] = objs\r\n        dataset_dicts.append(record)\r\n    return dataset_dicts\r\n\r\nfor d in [\"train\", \"val\"]:\r\n    DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(\"/root/detectron2/balloon/\" + d))  #also add absolate path\r\n    MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\r\nballoon_metadata = MetadataCatalog.get(\"balloon_train\")\r\n\r\ndataset_dicts = get_balloon_dicts(\"/root/detectron2/balloon/train\")  #add absoluate path\r\n\r\n# for d in random.sample(dataset_dicts, 3):\r\n#     img = cv2.imread(d[\"file_name\"])\r\n#     visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=0.5)\r\n#     out = visualizer.draw_dataset_dict(d)\r\n#     # Display using cv2.imshow\r\n#     cv2.imshow('Image', out.get_image()[:, :, ::-1])\r\n    \r\n#     # Wait for a key press and close the window\r\n#     cv2.waitKey(0)\r\n#     cv2.destroyAllWindows()\r\n    \r\nfrom detectron2.engine import DefaultTrainer\r\n\r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\r\ncfg.DATASETS.TRAIN = (\"balloon_train\",)\r\ncfg.DATASETS.TEST = ()\r\ncfg.DATALOADER.NUM_WORKERS = 2\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\r\ncfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\r\ncfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\r\ncfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\r\ncfg.SOLVER.STEPS = []        # do not decay learning rate\r\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\r\n# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\r\n\r\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\ntrainer = DefaultTrainer(cfg) \r\ntrainer.resume_or_load(resume=False)\r\ntrainer.train()\r\n\r\n```\r\n\r\n2. What exact command you run:\r\n```\r\npython bollon_test.py\r\n```\r\n\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n(detectron2) root@f3c85edb8996:~/detectron2# python bollon_test.py \r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2021 NVIDIA Corporation\r\nBuilt on Mon_Sep_13_19:13:29_PDT_2021\r\nCuda compilation tools, release 11.5, V11.5.50\r\nBuild cuda_11.5.r11.5/compiler.30411180_0\r\n\r\ntorch:  1.10 ; cuda:  1.10.0\r\ndetectron2: 0.6\r\n[10/29 22:29:48 d2.engine.defaults]: Model:\r\nGeneralizedRCNN(\r\n  (backbone): FPN(\r\n    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (top_block): LastLevelMaxPool()\r\n    (bottom_up): ResNet(\r\n      (stem): BasicStem(\r\n        (conv1): Conv2d(\r\n          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\r\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n        )\r\n      )\r\n      (res2): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res3): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res4): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (4): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (5): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res5): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n    )\r\n  )\r\n  (proposal_generator): RPN(\r\n    (rpn_head): StandardRPNHead(\r\n      (conv): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n    (anchor_generator): DefaultAnchorGenerator(\r\n      (cell_anchors): BufferList()\r\n    )\r\n  )\r\n  (roi_heads): StandardROIHeads(\r\n    (box_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (box_head): FastRCNNConvFCHead(\r\n      (flatten): Flatten(start_dim=1, end_dim=-1)\r\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\r\n      (fc_relu1): ReLU()\r\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\r\n      (fc_relu2): ReLU()\r\n    )\r\n    (box_predictor): FastRCNNOutputLayers(\r\n      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\r\n      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\r\n    )\r\n    (mask_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (mask_head): MaskRCNNConvUpsampleHead(\r\n      (mask_fcn1): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn2): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn3): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn4): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\r\n      (deconv_relu): ReLU()\r\n      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n  )\r\n)\r\n[10/29 22:29:50 d2.data.build]: Removed 0 images with no usable annotations. 61 images left.\r\n[10/29 22:29:50 d2.data.build]: Distribution of instances among all 1 categories:\r\n\r\n|  category  | #instances   |\r\n|:----------:|:-------------|\r\n|  balloon   | 255          |\r\n|            |              |\r\n\r\n[10/29 22:29:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\r\n[10/29 22:29:50 d2.data.build]: Using training sampler TrainingSampler\r\n[10/29 22:29:50 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\r\n[10/29 22:29:50 d2.data.common]: Serializing 61 elements to byte tensors and concatenating them all ...\r\n[10/29 22:29:50 d2.data.common]: Serialized dataset takes 0.17 MiB\r\nTraceback (most recent call last):\r\n  File \"bollon_test.py\", line 132, in <module>\r\n    trainer = DefaultTrainer(cfg) \r\n  File \"/root/detectron2/detectron2/engine/defaults.py\", line 380, in __init__\r\n    data_loader = self.build_train_loader(cfg)\r\n  File \"/root/detectron2/detectron2/engine/defaults.py\", line 549, in build_train_loader\r\n    return build_detection_train_loader(cfg)\r\n  File \"/root/detectron2/detectron2/config/config.py\", line 208, in wrapped\r\n    return orig_func(**explicit_args)\r\n  File \"/root/detectron2/detectron2/data/build.py\", line 549, in build_detection_train_loader\r\n    return build_batch_data_loader(\r\n  File \"/root/detectron2/detectron2/data/build.py\", line 339, in build_batch_data_loader\r\n    data_loader = torchdata.DataLoader(\r\n  File \"/opt/conda/envs/detectron2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 183, in __init__\r\n    assert prefetch_factor > 0\r\nTypeError: '>' not supported between instances of 'NoneType' and 'int'\r\n(detectron2) root@f3c85edb8996:~/detectron2# \r\n\r\n```\r\n\r\n4. I copied the \"train on a custom dataset\" of the google colab tutorial notebook, run in the local. However, there is an error occured. \r\n\r\n\r\n## Environment:\r\n\r\n\r\n```\r\n-------------------------------  --------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]\r\nnumpy                            1.23.1\r\ndetectron2                       0.6 @/root/detectron2/detectron2\r\ndetectron2._C                    not built correctly: No module named 'detectron2._C'\r\nCompiler ($CXX)                  c++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\nCUDA compiler                    Build cuda_11.5.r11.5/compiler.30411180_0\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          1.10.0 @/opt/conda/envs/detectron2/lib/python3.8/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0,1                          NVIDIA GeForce RTX 2080 Ti (arch=7.5)\r\nDriver version                   535.113.01\r\nCUDA_HOME                        /usr/local/cuda\r\nTORCH_CUDA_ARCH_LIST             5.2 6.0 6.1 7.0 7.5 8.0 8.6+PTX\r\nPillow                           9.4.0\r\ntorchvision                      0.11.0 @/opt/conda/envs/detectron2/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.7.0\r\n-------------------------------  --------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX512\r\n  - CUDA Runtime 11.3\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 8.2\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \r\n\r\nTesting NCCL connectivity ... this should not hang.\r\nNCCL succeeded.\r\n```\r\n\r\n\r\n\r\n ",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      }
    ]
  },
  {
    "issue_number": 5162,
    "title": " Problems with installing detectron2",
    "author": "xwcUP",
    "state": "closed",
    "created_at": "2023-11-27T06:18:30Z",
    "updated_at": "2024-08-24T04:04:06Z",
    "labels": [
      "needs-more-info"
    ],
    "body": "When I execute the following code in the terminal\r\n\r\n![1](https://github.com/facebookresearch/detectron2/assets/150986190/008f66be-13f5-4855-afda-1be70a26d74d)\r\nhappeningÔºö\r\n![image](https://github.com/facebookresearch/detectron2/assets/150986190/ed0a3ef0-5a10-4be4-acc2-bb6160545475)\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "oktaysabak",
        "body": "Same issue here:\r\n```bash\r\n‚ùØ pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\nCollecting git+https://github.com/facebookresearch/detectron2.git\r\n  Cloning https://github.com/facebookresearch/detectron2.git to /private/var/folders/22/sxp0ryq923s3qz4_fx4jxg_h0000gn/T/pip-req-build-4r3x2713\r\n  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /private/var/folders/22/sxp0ryq923s3qz4_fx4jxg_h0000gn/T/pip-req-build-4r3x2713\r\n  Resolved https://github.com/facebookresearch/detectron2.git to commit 017abbfa5f2c2a2afa045200c2af9ccf2fc6227f\r\n  Preparing metadata (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  √ó python setup.py egg_info did not run successfully.\r\n  ‚îÇ exit code: -11\r\n  ‚ï∞‚îÄ> [0 lines of output]\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: metadata-generation-failed\r\n\r\n√ó Encountered error while generating package metadata.\r\n‚ï∞‚îÄ> See above for output.\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for details.\r\n```"
      },
      {
        "user": "gau-nernst",
        "body": "I found the solution. Install the corresponding NVCC (CUDA compiler) and CUDA development libraries from conda\r\n\r\n```bash\r\nconda install \"cuda-nvcc==11.8.*\" \"cuda-libraries-dev==11.8.*\" -c nvidia\r\n```\r\n\r\nMake sure the version matches your PyTorch CUDA version."
      }
    ]
  },
  {
    "issue_number": 4917,
    "title": "AttributeError: Attribute 'stuff_classes' does not exist in the metadata of dataset 'coco_my_val_separated'. Available keys are dict_keys(['name', 'panoptic_root', 'image_root', 'panoptic_json', 'sem_seg_root', 'json_file', 'evaluator_type', 'ignore_label', 'thing_classes', 'thing_dataset_id_to_contiguous_id']).",
    "author": "quentinagao",
    "state": "open",
    "created_at": "2023-04-18T02:29:31Z",
    "updated_at": "2024-08-22T20:52:01Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full changes I have made:\r\n```\r\ndef setup(args):\r\n    \"\"\"\r\n    Create configs and perform basic setups.\r\n    \"\"\"\r\n    cfg = get_cfg()\r\n    args.config_file = 'configfile/panoptic/panoptic_fpn_R_50_3x.yaml'\r\n    #cfg.MODEL.DEVICE = 'cpu'\r\n    #cfg.INPUT.MASK_FORMAT = 'bitmask'\r\n\r\n    cfg.merge_from_file(args.config_file)\r\n    cfg.merge_from_list(args.opts)\r\n\r\n    cfg.DATASETS.TRAIN = (\"coco_my_train_separated\",) \r\n    cfg.DATASETS.TEST = (\"coco_my_val_separated\",)\r\n    cfg.DATALOADER.NUM_WORKERS = 0\r\n\r\n    cfg.INPUT.CROP.ENABLED = True\r\n   \r\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 80\r\n    cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = 54\r\n    cfg.MODEL.SEM_SEG_HEAD.IGNORE_VALUE = 255\r\n    #cfg.MODEL.RETINANET.NUM_CLASSES = 134\r\n    cfg.MODEL.WEIGHTS = 'configfile/model_final_c10459.pkl'\r\n    cfg.SOLVER.IMS_PER_BATCH = 1  # batch_size=2\r\n    ITERS_IN_ONE_EPOCH = int(1000 / cfg.SOLVER.IMS_PER_BATCH)\r\n\r\n    cfg.SOLVER.MAX_ITER = 10000\r\n    cfg.SOLVER.BASE_LR = 0.0002\r\n    cfg.SOLVER.MOMENTUM = 0.9\r\n    cfg.SOLVER.WEIGHT_DECAY = 0.0001\r\n    cfg.SOLVER.WEIGHT_DECAY_NORM = 0.0\r\n    cfg.SOLVER.GAMMA = 0.1\r\n    cfg.SOLVER.STEPS = (9000,)\r\n    cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000\r\n    cfg.SOLVER.WARMUP_ITERS = 500\r\n    cfg.SOLVER.WARMUP_METHOD = \"linear\"\r\n\r\n    cfg.TEST.EVAL_PERIOD = ITERS_IN_ONE_EPOCH\r\n    cfg.TEST.EVAL_PERIOD = 100\r\n\r\n    cfg.freeze()\r\n    default_setup(cfg, args)\r\n    return cfg\r\n```\r\n\r\n\r\n2. What exact command you run:\r\npython train_net.py\r\n\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n[04/18 09:09:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\r\n[04/18 09:09:05 d2.data.build]: Using training sampler TrainingSampler\r\n[04/18 09:09:05 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...\r\n[04/18 09:09:08 d2.data.common]: Serialized dataset takes 461.71 MiB\r\n2023-04-18 09:09:11.993950: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n[04/18 09:09:14 fvcore.common.checkpoint]: [Checkpointer] Loading from configfile/model_final_c10459.pkl ...\r\n[04/18 09:09:14 fvcore.common.checkpoint]: Reading a file from 'Detectron2 Model Zoo'\r\n[04/18 09:09:15 d2.engine.train_loop]: Starting training from iteration 0\r\n[04/18 09:09:29 d2.utils.events]:  eta: 1:42:08  iter: 19  total_loss: 0.8808  loss_sem_seg: 0.163  loss_rpn_cls: 0.01234  loss_rpn_loc: 0.02302  loss_cls: 0.1425  loss_box_reg: 0.2256  loss_mask: 0.1804  time: 0.6293  data_time: 0.0296  lr: 7.7924e-06  max_mem: 2437M\r\nD:\\Users\\gaotsingyuan\\anaconda3\\envs\\python37\\lib\\site-packages\\fvcore\\transforms\\transform.py:724: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\r\n  for poly in cropped:\r\nD:\\Users\\gaotsingyuan\\anaconda3\\envs\\python37\\lib\\site-packages\\fvcore\\transforms\\transform.py:724: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\r\n  for poly in cropped:\r\nD:\\Users\\gaotsingyuan\\anaconda3\\envs\\python37\\lib\\site-packages\\fvcore\\transforms\\transform.py:724: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\r\n  for poly in cropped:\r\n[04/18 09:09:41 d2.utils.events]:  eta: 1:43:32  iter: 39  total_loss: 0.673  loss_sem_seg: 0.09647  loss_rpn_cls: 0.01844  loss_rpn_loc: 0.04783  loss_cls: 0.1308  loss_box_reg: 0.1333  loss_mask: 0.188  time: 0.6390  data_time: 0.0271  lr: 1.5784e-05  max_mem: 2437M\r\nD:\\Users\\gaotsingyuan\\anaconda3\\envs\\python37\\lib\\site-packages\\fvcore\\transforms\\transform.py:724: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\r\n  for poly in cropped:\r\n[04/18 09:09:54 d2.utils.events]:  eta: 1:44:25  iter: 59  total_loss: 0.8675  loss_sem_seg: 0.1861  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.01953  loss_cls: 0.2103  loss_box_reg: 0.2019  loss_mask: 0.2035  time: 0.6389  data_time: 0.0248  lr: 2.3776e-05  max_mem: 2437M\r\nD:\\Users\\gaotsingyuan\\anaconda3\\envs\\python37\\lib\\site-packages\\fvcore\\transforms\\transform.py:724: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\r\n  for poly in cropped:\r\nD:\\Users\\gaotsingyuan\\anaconda3\\envs\\python37\\lib\\site-packages\\fvcore\\transforms\\transform.py:724: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\r\n  for poly in cropped:\r\n[04/18 09:10:07 d2.utils.events]:  eta: 1:43:45  iter: 79  total_loss: 0.8721  loss_sem_seg: 0.1211  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.03563  loss_cls: 0.1317  loss_box_reg: 0.1683  loss_mask: 0.216  time: 0.6371  data_time: 0.0266  lr: 3.1768e-05  max_mem: 2437M\r\nD:\\Users\\gaotsingyuan\\anaconda3\\envs\\python37\\lib\\site-packages\\fvcore\\transforms\\transform.py:724: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\r\n  for poly in cropped:\r\n[04/18 09:10:20 d2.data.datasets.coco]: Loaded 5000 images in COCO format from E:\\Êï∞ÊçÆÈõÜ\\MS COCO\\annotations\\instances_val2017.json\r\n[04/18 09:10:20 d2.data.datasets.coco]: Loaded 5000 images with semantic segmentation from E:\\Êï∞ÊçÆÈõÜ\\MS COCO\\val2017\r\n[04/18 09:10:20 d2.data.build]: Distribution of instances among all 80 categories:\r\n|   category    | #instances   |   category   | #instances   |   category    | #instances   |\r\n|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\r\n|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\r\n|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\r\n|     train     | 190          |    truck     | 414          |     boat      | 424          |\r\n| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\r\n| parking meter | 60           |    bench     | 411          |     bird      | 427          |\r\n|      cat      | 202          |     dog      | 218          |     horse     | 272          |\r\n|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\r\n|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\r\n|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\r\n|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\r\n|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\r\n|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\r\n|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\r\n|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\r\n|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\r\n|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\r\n|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\r\n|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\r\n|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\r\n|     couch     | 261          | potted plant | 342          |      bed      | 163          |\r\n| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\r\n|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\r\n|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\r\n|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\r\n| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\r\n|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\r\n|  hair drier   | 11           |  toothbrush  | 57           |               |              |\r\n|     total     | 36335        |              |              |               |              |\r\n[04/18 09:10:20 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\r\n[04/18 09:10:20 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...\r\n[04/18 09:10:20 d2.data.common]: Serialized dataset takes 19.53 MiB\r\n[04/18 09:10:21 d2.data.datasets.coco]: Loaded 5000 images in COCO format from E:\\Êï∞ÊçÆÈõÜ\\MS COCO\\annotations\\instances_val2017.json\r\n[04/18 09:10:21 d2.data.datasets.coco]: Loaded 5000 images with semantic segmentation from E:\\Êï∞ÊçÆÈõÜ\\MS COCO\\val2017\r\nERROR [04/18 09:10:22 d2.engine.train_loop]: Exception during training:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\train_loop.py\", line 150, in train\r\n    self.after_step()\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\train_loop.py\", line 180, in after_step\r\n    h.after_step()\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\hooks.py\", line 555, in after_step\r\n    self._do_eval()\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\hooks.py\", line 528, in _do_eval\r\n    results = self._func()\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\defaults.py\", line 453, in test_and_save_results\r\n    self._last_eval_results = self.test(self.cfg, self.model)\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\defaults.py\", line 609, in test\r\n    evaluator = cls.build_evaluator(cfg, dataset_name)\r\n  File \"D:/Users/gaotsingyuan/PycharmProjects/pythonProject3/test3-panoptic.py\", line 123, in build_evaluator\r\n    return build_evaluator(cfg, dataset_name, output_folder)\r\n  File \"D:/Users/gaotsingyuan/PycharmProjects/pythonProject3/test3-panoptic.py\", line 89, in build_evaluator\r\n    output_dir=output_folder,\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\evaluation\\sem_seg_evaluation.py\", line 89, in __init__\r\n    self._class_names = meta.stuff_classes\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\data\\catalog.py\", line 128, in __getattr__\r\n    \"keys are {}.\".format(key, self.name, str(self.__dict__.keys()))\r\nAttributeError: Attribute 'stuff_classes' does not exist in the metadata of dataset 'coco_my_val_separated'. Available keys are dict_keys(['name', 'panoptic_root', 'image_root', 'panoptic_json', 'sem_seg_root', 'json_file', 'evaluator_type', 'ignore_label', 'thing_classes', 'thing_dataset_id_to_contiguous_id']).\r\n[04/18 09:10:22 d2.engine.hooks]: Overall training speed: 97 iterations in 0:01:01 (0.6389 s / it)\r\n[04/18 09:10:22 d2.engine.hooks]: Total training time: 0:01:04 (0:00:02 on hooks)\r\n[04/18 09:10:22 d2.utils.events]:  eta: 1:43:08  iter: 99  total_loss: 0.6138  loss_sem_seg: 0.08962  loss_rpn_cls: 0.006415  loss_rpn_loc: 0.02325  loss_cls: 0.1036  loss_box_reg: 0.1353  loss_mask: 0.1793  time: 0.6324  data_time: 0.0248  lr: 3.976e-05  max_mem: 2437M\r\nTraceback (most recent call last):\r\n  File \"D:/Users/gaotsingyuan/PycharmProjects/pythonProject3/test3-panoptic.py\", line 456, in <module>\r\n    args=(args,),\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\launch.py\", line 82, in launch\r\n    main_func(*args)\r\n  File \"D:/Users/gaotsingyuan/PycharmProjects/pythonProject3/test3-panoptic.py\", line 440, in main\r\n    return trainer.train()\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\defaults.py\", line 484, in train\r\n    super().train(self.start_iter, self.max_iter)\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\train_loop.py\", line 150, in train\r\n    self.after_step()\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\train_loop.py\", line 180, in after_step\r\n    h.after_step()\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\hooks.py\", line 555, in after_step\r\n    self._do_eval()\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\hooks.py\", line 528, in _do_eval\r\n    results = self._func()\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\defaults.py\", line 453, in test_and_save_results\r\n    self._last_eval_results = self.test(self.cfg, self.model)\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\engine\\defaults.py\", line 609, in test\r\n    evaluator = cls.build_evaluator(cfg, dataset_name)\r\n  File \"D:/Users/gaotsingyuan/PycharmProjects/pythonProject3/test3-panoptic.py\", line 123, in build_evaluator\r\n    return build_evaluator(cfg, dataset_name, output_folder)\r\n  File \"D:/Users/gaotsingyuan/PycharmProjects/pythonProject3/test3-panoptic.py\", line 89, in build_evaluator\r\n    output_dir=output_folder,\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\evaluation\\sem_seg_evaluation.py\", line 89, in __init__\r\n    self._class_names = meta.stuff_classes\r\n  File \"C:\\Users\\gaotsingyuan\\detectron2\\detectron2\\data\\catalog.py\", line 128, in __getattr__\r\n    \"keys are {}.\".format(key, self.name, str(self.__dict__.keys()))\r\nAttributeError: Attribute 'stuff_classes' does not exist in the metadata of dataset 'coco_my_val_separated'. Available keys are dict_keys(['name', 'panoptic_root', 'image_root', 'panoptic_json', 'sem_seg_root', 'json_file', 'evaluator_type', 'ignore_label', 'thing_classes', 'thing_dataset_id_to_contiguous_id']).\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\nI used **official** COCO2017 datsets, and registered by using `register_coco_panoptic_separated`. The **image_root, panoptic_root, panoptic_json and instances_json** are referred to the files directly downloaded from [(https://cocodataset.org/#download)](url). The **sem_seg_root** refers to the file which is coverted from panoptic files, following [https://github.com/facebookresearch/detectron2/blob/main/datasets/prepare_panoptic_fpn.py](url). The **metadata** I put an empty dict.\r\nThe other training methods and settings are the same as what I used to train on Mask-RCNN, which can train and evaluate sucessfully.\r\n\r\nIt can do training, but when it starts to do panoptic evaluations, I get an error: AttributeError: Attribute 'stuff_classes' does not exist in the metadata of dataset 'coco_my_val_separated'. Available keys are dict_keys(['name', 'panoptic_root', 'image_root', 'panoptic_json', 'sem_seg_root', 'json_file', 'evaluator_type', 'ignore_label', 'thing_classes', 'thing_dataset_id_to_contiguous_id']).\r\nWhen I set `MetadataCatalog.get('coco_my_val_separated').set(stuff_classes= [])`, I get another error: AttributeError: Attribute 'stuff_dataset_id_to_contiguous_id' does not exist in the metadata of dataset 'coco_my_val_separated'. Available keys are dict_keys(['name', 'stuff_classes', 'panoptic_root', 'image_root', 'panoptic_json', 'sem_seg_root', 'json_file', 'evaluator_type', 'ignore_label', 'thing_classes', 'thing_dataset_id_to_contiguous_id']).\r\n\r\nIt seems that 'stuff_classes' and 'stuff_dataset_id_to_contiguous_id' do not exist in the matadata.\r\nHow can I set them? Should I put all stuff categories in the metadata manually? \r\n\r\n## Expected behavior:\r\nI want to train panoptic fpn on official COCO2017 datasets and expect it can works.\r\n\r\n## Environment:\r\n```\r\nsys.platform            win32\r\nPython                  3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]\r\nnumpy                   1.21.5\r\ndetectron2              0.6 @C:\\Users\\gaotsingyuan\\detectron2\\detectron2\r\ndetectron2._C           not built correctly: DLL load failed: Êâæ‰∏çÂà∞ÊåáÂÆöÁöÑÁ®ãÂ∫è„ÄÇ\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.8.0 @D:\\Users\\gaotsingyuan\\anaconda3\\envs\\python37\\lib\\site-packages\\torch\r\nPyTorch debug build     False\r\nGPU available           Yes\r\nGPU 0                   NVIDIA GeForce GTX 1650 Ti (arch=7.5)\r\nDriver version          512.78\r\nCUDA_HOME               C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nPillow                  9.2.0\r\ntorchvision             0.9.0 @D:\\Users\\gaotsingyuan\\anaconda3\\envs\\python37\\lib\\site-packages\\torchvision\r\ntorchvision arch flags  D:\\Users\\gaotsingyuan\\anaconda3\\envs\\python37\\lib\\site-packages\\torchvision\\_C.pyd; cannot find cuobjdump\r\nfvcore                  0.1.5.post20220512\r\niopath                  0.1.9\r\ncv2                     4.6.0\r\n----------------------  ---------------------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - C++ Version: 199711\r\n  - MSVC 192829337\r\n  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\r\n  - OpenMP 2019\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 10.2\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 7.6.5\r\n  - Magma 2.5.4\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -DNDEBUG -DUSE_FBGEMM -DUSE_XNNPACK, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, \r\n```\r\n\r\n",
    "comments": [
      {
        "user": "zacklew",
        "body": "Did you ever get a fix for this issue? I'm trying to run the COCOPanopticEvaluator and I'm getting the same issue with\r\n'stuff_dataset_id_to_contiguous_id' does not exist in the metadata of dataset '\r\n"
      }
    ]
  },
  {
    "issue_number": 5316,
    "title": "New conda release",
    "author": "diogo-sr",
    "state": "open",
    "created_at": "2024-06-24T09:29:04Z",
    "updated_at": "2024-08-22T07:50:08Z",
    "labels": [
      "enhancement"
    ],
    "body": "## üöÄ Feature\r\nMake new conda release\r\n\r\n## Motivation & Examples\r\n\r\nThe last release on conda is almost 3 years old. There have been several improvements in the meantime, it would be great to have them released.\r\n\r\nCheers, \r\nDiogo\r\n\r\n\r\n",
    "comments": [
      {
        "user": "Programmer-RD-AI",
        "body": "Hi,\r\nThis is actually something that can be looked into :)\r\nGreat Suggestion, IMO!\r\nThank you"
      },
      {
        "user": "hiyyg",
        "body": "> Hi, This is actually something that can be looked into :) Great Suggestion, IMO! Thank you\r\n\r\nWhat about the new pypi wheels?"
      },
      {
        "user": "diogo-sr",
        "body": "@Programmer-RD-AI is there any update on the releases? I can manually build the latest version of the code using the feed-stock repo"
      }
    ]
  },
  {
    "issue_number": 5121,
    "title": "Timed out waiting 1800000ms",
    "author": "YH-2023",
    "state": "closed",
    "created_at": "2023-10-18T02:00:52Z",
    "updated_at": "2024-08-21T02:03:16Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "  \r\nFile \"/home/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py\", line 2010, in all_gather\r\n    else:\r\nRuntimeError: [../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:136] Timed out waiting 1800000ms for send operation to complete\r\nHow to deal with it?",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5352,
    "title": "Hamer bounding box detection very slow",
    "author": "richardrl",
    "state": "open",
    "created_at": "2024-08-18T06:46:17Z",
    "updated_at": "2024-08-18T07:35:43Z",
    "labels": [],
    "body": "Hi,\r\nI am using the detectron2 cascade mask rcnn vitdet h checkpoint in the demo for hamer and it is very slow for inference on one image compared to detectron2 model zoo numbers. I get .78s/im vs the model zoo ~.2s/im\r\n\r\nThis is the line I timed: https://github.com/geopavlakos/hamer/blob/dc19e5686198a7c3fc3938bff3951f238a85fd11/demo.py#L81\r\n\r\nI have an RTX A5000\r\n\r\nIs there a setting in the config file that can speed things up?",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      }
    ]
  },
  {
    "issue_number": 4972,
    "title": "PermissionError: [Errno 13] Permission denied: '/home/detectron2-main/detectron2/model_zoo/configs'",
    "author": "LLL-YUE",
    "state": "open",
    "created_at": "2023-05-25T07:30:22Z",
    "updated_at": "2024-08-17T14:21:47Z",
    "labels": [],
    "body": "After the instruction\r\npython -m pip install -e detectron2-main\r\nI met this error\r\nHow to deal with this situation?",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "xiaoliujapan",
        "body": "me too, same issue. i use Windows10"
      },
      {
        "user": "damdafayton",
        "body": "you need to give permissions to the folder content.\r\nif you are on docker like this\r\n`RUN sudo chmod -R 777 detectron2_repo`"
      }
    ]
  },
  {
    "issue_number": 5073,
    "title": "Export layoutlmv3 model to onnx model",
    "author": "iweirman",
    "state": "open",
    "created_at": "2023-08-29T10:12:51Z",
    "updated_at": "2024-08-17T13:11:17Z",
    "labels": [
      "documentation"
    ],
    "body": "I encountered some errors when attempting to export the [layoutlmv3](https://github.com/microsoft/unilm/blob/master/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml) model using [export_model.py](https://github.com/facebookresearch/detectron2/blob/main/tools/deploy/export_model.py).\r\n\r\n>   (myconda) root@Z95jJV:/mnt/detectron2/tools/deploy# python export_model.py --config-file /mnt/unilm-master/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml --output ./output --export-method tracing --format torchscript MODEL.WEIGHTS /home/layoutlmv3-base-finetuned-publaynet/model_final.pth MODEL.DEVICE cuda\r\n>   [08/29 09:56:16 detectron2]: Command line arguments: Namespace(config_file='/mnt/unilm-master/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml', export_method='tracing', format='torchscript', opts=['MODEL.WEIGHTS', '/home/layoutlmv3-base-finetuned-publaynet/model_final.pth', 'MODEL.DEVICE', 'cuda'], output='./output', run_eval=False, sample_image=None)\r\n>   Traceback (most recent call last):\r\n>     File \"export_model.py\", line 210, in <module>\r\n>       cfg = setup_cfg(args)\r\n>     File \"export_model.py\", line 34, in setup_cfg\r\n>       cfg.merge_from_file(args.config_file)\r\n>     File \"/mnt/detectron2/detectron2/config/config.py\", line 69, in merge_from_file\r\n>       self.merge_from_other_cfg(loaded_cfg)\r\n>     File \"/root/miniconda3/envs/myconda/lib/python3.8/site-packages/fvcore/common/config.py\", line 132, in merge_from_other_cfg\r\n>       return super().merge_from_other_cfg(cfg_other)\r\n>     File \"/root/miniconda3/envs/myconda/lib/python3.8/site-packages/yacs/config.py\", line 217, in merge_from_other_cfg\r\n>       _merge_a_into_b(cfg_other, self, self, [])\r\n>     File \"/root/miniconda3/envs/myconda/lib/python3.8/site-packages/yacs/config.py\", line 478, in _merge_a_into_b\r\n>       _merge_a_into_b(v, b[k], root, key_list + [k])\r\n>     File \"/root/miniconda3/envs/myconda/lib/python3.8/site-packages/yacs/config.py\", line 491, in _merge_a_into_b\r\n>       raise KeyError(\"Non-existent config key: {}\".format(full_key))\r\n>   KeyError: 'Non-existent config key: MODEL.IMAGE_ONLY'\r\n>       \r\n>   [08/29 09:56:42 detectron2]: Command line arguments: Namespace(config_file='/mnt/unilm-master/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml', export_method='tracing', format='torchscript', opts=['MODEL.WEIGHTS', '/home/layoutlmv3-base-finetuned-publaynet/model_final.pth', 'MODEL.DEVICE', 'cuda'], output='./output', run_eval=False, sample_image=None)\r\n>   Traceback (most recent call last):\r\n>     File \"export_model.py\", line 210, in <module>\r\n>       cfg = setup_cfg(args)\r\n>     File \"export_model.py\", line 34, in setup_cfg\r\n>       cfg.merge_from_file(args.config_file)\r\n>     File \"/mnt/detectron2/detectron2/config/config.py\", line 69, in merge_from_file\r\n>       self.merge_from_other_cfg(loaded_cfg)\r\n>     File \"/root/miniconda3/envs/myconda/lib/python3.8/site-packages/fvcore/common/config.py\", line 132, in merge_from_other_cfg\r\n>       return super().merge_from_other_cfg(cfg_other)\r\n>     File \"/root/miniconda3/envs/myconda/lib/python3.8/site-packages/yacs/config.py\", line 217, in merge_from_other_cfg\r\n>       _merge_a_into_b(cfg_other, self, self, [])\r\n>     File \"/root/miniconda3/envs/myconda/lib/python3.8/site-packages/yacs/config.py\", line 478, in _merge_a_into_b\r\n>       _merge_a_into_b(v, b[k], root, key_list + [k])\r\n>     File \"/root/miniconda3/envs/myconda/lib/python3.8/site-packages/yacs/config.py\", line 491, in _merge_a_into_b\r\n>       raise KeyError(\"Non-existent config key: {}\".format(full_key))\r\n>   KeyError: 'Non-existent config key: MODEL.VIT\r\n\r\nIt seems like the problem is caused by the yaml file, but I am unsure of how to resolve it.",
    "comments": [
      {
        "user": "qrsssh",
        "body": "> -base-finetuned-publaynet/model_fi\r\n\r\nsame question, have you solved?"
      }
    ]
  },
  {
    "issue_number": 5115,
    "title": "ImportError: cannot import name 'TORCH_VERSION' from 'mmcv.utils'",
    "author": "mahilaMoghadami",
    "state": "closed",
    "created_at": "2023-10-14T08:24:55Z",
    "updated_at": "2024-08-17T02:02:15Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "hello\r\n**ImportError: cannot import name 'TORCH_VERSION' from 'mmcv.utils'**\r\n\r\nwhat should I do?\r\n\r\nPyTorch version: 1.7.0\r\nCUDA is available.\r\nNumber of available GPUs: 2\r\nCuda compilation tools, release 10.1, V10.1.243",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5195,
    "title": "running detectron2 on mps - poolers.py \"repeatBuffer && cumsumBuffer && resultBuffer to be true\" error",
    "author": "bartmch",
    "state": "open",
    "created_at": "2024-01-16T06:03:33Z",
    "updated_at": "2024-08-16T17:17:45Z",
    "labels": [],
    "body": "When running the demo.py on Ultra M2 with below arguments I get the error \"Expected repeatBuffer && cumsumBuffer && resultBuffer to be true, but got false.\".\r\nWhen running on cpu (MODEL.DEVICE cpu), it runs fine!\r\nInstructions To Reproduce the Issue:\r\n```\r\npython demo.py\r\n        --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\r\n        --input demo/input2.jpg\r\n        --opts MODEL.DEVICE mps MODEL.WEIGHTS detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\r\n```\r\n\r\nThis is the error, Full Logs:\r\n```\r\nException has occurred: RuntimeError       (note: full exception trace is shown but execution is paused at: _run_module_as_main)\r\nExpected repeatBuffer && cumsumBuffer && resultBuffer to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/detectron2-0.6-py3.9-macosx-14-arm64.egg/detectron2/modeling/poolers.py\", line 66, in _convert_boxes_to_pooler_format\r\n    indices = torch.repeat_interleave(\r\n  File \"detectron2/.env/lib/python3.9/site-packages/torch/jit/_trace.py\", line 1230, in wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/detectron2-0.6-py3.9-macosx-14-arm64.egg/detectron2/modeling/poolers.py\", line 98, in convert_boxes_to_pooler_format\r\n    return _convert_boxes_to_pooler_format(boxes, sizes)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/detectron2-0.6-py3.9-macosx-14-arm64.egg/detectron2/modeling/poolers.py\", line 243, in forward\r\n    pooler_fmt_boxes = convert_boxes_to_pooler_format(box_lists)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/detectron2-0.6-py3.9-macosx-14-arm64.egg/detectron2/modeling/roi_heads/roi_heads.py\", line 843, in _forward_mask\r\n    features = self.mask_pooler(features, boxes)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/detectron2-0.6-py3.9-macosx-14-arm64.egg/detectron2/modeling/roi_heads/roi_heads.py\", line 776, in forward_with_given_boxes\r\n    instances = self._forward_mask(features, instances)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/detectron2-0.6-py3.9-macosx-14-arm64.egg/detectron2/modeling/roi_heads/roi_heads.py\", line 750, in forward\r\n    pred_instances = self.forward_with_given_boxes(features, pred_instances)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/detectron2-0.6-py3.9-macosx-14-arm64.egg/detectron2/modeling/meta_arch/rcnn.py\", line 213, in inference\r\n    results, _ = self.roi_heads(images, features, proposals, None)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/detectron2-0.6-py3.9-macosx-14-arm64.egg/detectron2/modeling/meta_arch/rcnn.py\", line 150, in forward\r\n    return self.inference(batched_inputs)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"detectron2/.env/lib/python3.9/site-packages/detectron2-0.6-py3.9-macosx-14-arm64.egg/detectron2/engine/defaults.py\", line 319, in __call__\r\n    predictions = self.model([inputs])[0]\r\n  File \"detectron2/demo/predictor.py\", line 48, in run_on_image\r\n    predictions = self.predictor(image)\r\n  File \"detectron2/demo/demo.py\", line 112, in <module>\r\n    predictions, visualized_output = demo.run_on_image(img)\r\n  File \"/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main (Current frame)\r\n    return _run_code(code, main_globals, None,\r\nRuntimeError: Expected repeatBuffer && cumsumBuffer && resultBuffer to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)\r\n```\r\n\r\nYour Environment:\r\nMac M2 Ultra, torch==2.1.2 torchvision==0.16.2",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "marquies",
        "body": "I got the same issue. Maybe it is something in torch, but I can't tell without digging in the code.\r\n\r\n## Instructions To Reproduce the Issue:\r\n1. Setup Installation with described environment\r\n2. Run the demo.py on a mac with mps (MODEL.DEVICE mps) - `python3 demo.py --config-file ../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml --input image1.png` \r\n\r\n## Environment\r\n- macOS 14.4.1 (23E224)\r\n- Python: Python 3.11.9 (via homebrew)\r\n- torch: torch 2.3.0, torchaudio 2.3.0, torchvision 0.18.0\r\n- detectron2: git current main branch\r\n\r\n"
      },
      {
        "user": "marquies",
        "body": "Never mind, as soon as I add the MODEL.WEIGHTS option, it works (slow but) fine for --input ... and --webcam"
      }
    ]
  },
  {
    "issue_number": 5113,
    "title": "Category ids in annotations are not in [1, #categories]!",
    "author": "giteec",
    "state": "closed",
    "created_at": "2023-10-13T09:09:43Z",
    "updated_at": "2024-08-16T02:03:13Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "If you do not know the root cause of the problem, please post according to this template:\r\n\r\n## Instructions To Reproduce the Issue:\r\n\r\nCheck https://stackoverflow.com/help/minimal-reproducible-example for how to ask good questions.\r\nSimplify the steps to reproduce the issue using suggestions from the above link, and provide them below:\r\n\r\n1. Full runnable code or full changes you made:\r\n```\r\nIf making changes to the project itself, please use output of the following command:\r\ngit rev-parse HEAD; git diff\r\n\r\n<put code or diff here>\r\n```\r\n2. What exact command you run:\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n<put logs here>\r\n```\r\n\r\n## Expected behavior:\r\n\r\nIf there are no obvious crash in \"full logs\" provided above,\r\nplease tell us the expected behavior.\r\n\r\nIf you expect a model to converge / work better, we do not help with such issues, unless\r\na model fails to reproduce the results in detectron2 model zoo, or proves existence of bugs.\r\n\r\n## Environment:\r\n\r\nPaste the output of the following command:\r\n```\r\nwget -nc -nv https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first check common issues in https://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5350,
    "title": "Error using custom mapper",
    "author": "zacklew",
    "state": "open",
    "created_at": "2024-08-15T22:38:36Z",
    "updated_at": "2024-08-15T22:38:36Z",
    "labels": [],
    "body": "If you do not know the root cause of the problem, please post according to this template:\r\n\r\n## Instructions To Reproduce the Issue:\r\nI tried to create a custom mapping function to increase the number of augmentations performed on my input images. Code for custom trainer below\r\n\r\ndef custom_mapper(dataset_dict):\r\n    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\r\n    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\r\n    transform_list = [\r\n        T.Resize((800,600)),\r\n        T.RandomBrightness(0.8, 1.8),\r\n        T.RandomContrast(0.6, 1.3),\r\n        T.RandomSaturation(0.8, 1.4),\r\n        T.RandomRotation(angle=[90, 90]),\r\n        T.RandomLighting(0.7),\r\n        T.RandomFlip(prob=0.4, horizontal=False, vertical=True),\r\n    ]\r\n    image, transforms = T.apply_transform_gens(transform_list, image)\r\n    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\r\n\r\n    annos = [\r\n        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\r\n        for obj in dataset_dict.pop(\"annotations\")\r\n        if obj.get(\"iscrowd\", 0) == 0\r\n    ]\r\n    instances = utils.annotations_to_instances(annos, image.shape[:2])\r\n    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\r\n    return dataset_dict\r\n\r\nclass CustomTrainer(DefaultTrainer):\r\n    @classmethod\r\n    def build_train_loader(cls, cfg):\r\n        return build_detection_train_loader(cfg, mapper=custom_mapper)\r\n\r\ntorch.cuda.empty_cache()\r\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\r\ntrainer = CustomTrainer(cfg)\r\ntrainer.register_hooks([MemoryTrackingHook(period=1)])\r\ntrainer.resume_or_load(resume=False)\r\ntrainer.train()\r\n\r\n2. What exact command you run:\r\n3. __Full logs__ or other relevant observations:\r\nAssertionError                            Traceback (most recent call last)\r\nCell In[15], line 7\r\n      5 trainer.register_hooks([MemoryTrackingHook(period=1)])\r\n      6 trainer.resume_or_load(resume=False)\r\n----> 7 trainer.train()\r\n\r\nFile ~/detectron_uw_repo/detectron2/engine/defaults.py:488, in DefaultTrainer.train(self)\r\n    481 def train(self):\r\n    482     \"\"\"\r\n    483     Run training.\r\n    484 \r\n    485     Returns:\r\n    486         OrderedDict of results, if evaluation is enabled. Otherwise None.\r\n    487     \"\"\"\r\n--> 488     super().train(self.start_iter, self.max_iter)\r\n    489     if len(self.cfg.TEST.EXPECTED_RESULTS) and comm.is_main_process():\r\n    490         assert hasattr(\r\n    491             self, \"_last_eval_results\"\r\n    492         ), \"No evaluation results obtained during training!\"\r\n\r\nFile ~/detectron_uw_repo/detectron2/engine/train_loop.py:155, in TrainerBase.train(self, start_iter, max_iter)\r\n    153 for self.iter in range(start_iter, max_iter):\r\n    154     self.before_step()\r\n--> 155     self.run_step()\r\n    156     self.after_step()\r\n    157 # self.iter == max_iter can be used by `after_train` to\r\n    158 # tell whether the training successfully finished or failed\r\n    159 # due to exceptions.\r\n\r\nFile ~/detectron_uw_repo/detectron2/engine/defaults.py:498, in DefaultTrainer.run_step(self)\r\n    496 def run_step(self):\r\n    497     self._trainer.iter = self.iter\r\n--> 498     self._trainer.run_step()\r\n\r\nFile ~/detectron_uw_repo/detectron2/engine/train_loop.py:494, in AMPTrainer.run_step(self)\r\n    492     self.optimizer.zero_grad()\r\n    493 with autocast(dtype=self.precision):\r\n--> 494     loss_dict = self.model(data)\r\n    495     if isinstance(loss_dict, torch.Tensor):\r\n    496         losses = loss_dict\r\n\r\nFile ~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532, in Module._wrapped_call_impl(self, *args, **kwargs)\r\n   1530     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\r\n   1531 else:\r\n-> 1532     return self._call_impl(*args, **kwargs)\r\n\r\nFile ~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541, in Module._call_impl(self, *args, **kwargs)\r\n   1536 # If we don't have any hooks, we want to skip the rest of the logic in\r\n   1537 # this function, and just call forward.\r\n   1538 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\r\n   1539         or _global_backward_pre_hooks or _global_backward_hooks\r\n   1540         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1541     return forward_call(*args, **kwargs)\r\n   1543 try:\r\n   1544     result = None\r\n\r\nFile ~/detectron_uw_repo/detectron2/modeling/meta_arch/panoptic_fpn.py:119, in PanopticFPN.forward(self, batched_inputs)\r\n    116 images = self.preprocess_image(batched_inputs)\r\n    117 features = self.backbone(images.tensor)\r\n--> 119 assert \"sem_seg\" in batched_inputs[0]\r\n    120 gt_sem_seg = [x[\"sem_seg\"].to(self.device) for x in batched_inputs]\r\n    121 gt_sem_seg = ImageList.from_tensors(\r\n    122     gt_sem_seg,\r\n    123     self.backbone.size_divisibility,\r\n    124     self.sem_seg_head.ignore_value,\r\n    125     self.backbone.padding_constraints,\r\n    126 ).tensor\r\n\r\nAssertionError: \r\n\r\n\r\n## Expected behavior:\r\n\r\nExpected model to train as normal. Not sure what's causing this error. Followed some other examples I've seen on here on how others have implemented custom mappers and haven't found any examples of others getting this error.\r\nAny and all help or advice would be greatly appreciated.\r\n\r\n## Environment:\r\n\r\nsys.platform                     linux\r\nPython                           3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:12:24) [GCC 11.2.0]\r\nnumpy                            1.26.4\r\ndetectron2                       0.6 @/home/computational/anaconda3/lib/python3.12/site-packages/detectron2\r\nCompiler                         GCC 11.2\r\nCUDA compiler                    CUDA 12.5\r\ndetectron2 arch flags            8.6\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.3.1+cu121 @/home/computational/anaconda3/lib/python3.12/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0                            NVIDIA RTX A2000 12GB (arch=8.6)\r\nDriver version                   555.58.02\r\nCUDA_HOME                        /home/computational/anaconda3\r\nPillow                           10.3.0\r\ntorchvision                      0.18.1+cu121 @/home/computational/anaconda3/lib/python3.12/site-packages/torchvision\r\ntorchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.10.0\r\n-------------------------------  ------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201703\r\n  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX512\r\n  - CUDA Runtime 12.1\r\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n  - CuDNN 8.9.2\r\n  - Magma 2.6.1\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \r\n\r\n",
    "comments": []
  },
  {
    "issue_number": 5349,
    "title": "Size mismatch error between images and masks AFTER loading dataset",
    "author": "zacklew",
    "state": "open",
    "created_at": "2024-08-15T22:27:55Z",
    "updated_at": "2024-08-15T22:30:40Z",
    "labels": [],
    "body": "## Instructions To Reproduce the Issue:\r\nTrying to train a model using panoptic_fpn\r\n\r\n\r\ntorch.cuda.empty_cache()\r\nconfig_file = \"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\"\r\ncfg = get_cfg()\r\ncfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\ncfg.merge_from_file(model_zoo.get_config_file(config_file))\r\ncfg.DATASETS.TRAIN = (f\"{data_name}_separated\",)\r\ncfg.DATASETS.TEST = ()\r\ncfg.DATALOADER.NUM_WORKERS = 0\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_file)  \r\ncfg.SOLVER.IMS_PER_BATCH = 1\r\ncfg.SOLVER.BASE_LR = 0.00025 \r\ncfg.SOLVER.MAX_ITER = 5000\r\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 16 \r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 \r\ncfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = 2 \r\ncfg.MODEL.PANOPTIC_FPN.NUM_CLASSES = 1  \r\ncfg.SOLVER.AMP.ENABLED = True\r\n\r\nMetadataCatalog.get(cfg.DATASETS.TRAIN[0]).set(thing_classes=things, stuff_classes=stuff, thing_dataset_id_to_contiguous_id={1: 0}) \r\n\r\nExample images that are causing error\r\n[bad_imgs_2.zip](https://github.com/user-attachments/files/16630840/bad_imgs_2.zip)\r\n\r\n\r\n## Expected behavior:\r\nI've run this exact code with a different custom image set and the model ran fine. \r\nThere are a few images in this image set (i.e. example images and masks below attached) that we have found to through this size error that says the masks and images are different sizes. I manually checked the dimensions of the masks and images using img properties on my PC, and it says the images and masks are the same dimensions. However, when I check the image and mask sizes after the model loads the dataset, the sizes are different.\r\nMy running theory is that there is some transformation that occurs with the dataset mapper that changes the dimensions of the masks, but I'm not sure how to see if that is the case or if something else in the code is changing the dimensions of the mask and the image separately.\r\n\r\nAny and all help trying to solve this error would be appreciated.\r\n\r\n**Example images used in dataset in this repo: ([(https://github.com/zacklew/bad_images)])*\r\n\r\n\r\n## Environment:\r\n\r\nsys.platform                     linux\r\nPython                           3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:12:24) [GCC 11.2.0]\r\nnumpy                            1.26.4\r\ndetectron2                       0.6 @/home/computational/anaconda3/lib/python3.12/site-packages/detectron2\r\nCompiler                         GCC 11.2\r\nCUDA compiler                    CUDA 12.5\r\ndetectron2 arch flags            8.6\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.3.1+cu121 @/home/computational/anaconda3/lib/python3.12/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0                            NVIDIA RTX A2000 12GB (arch=8.6)\r\nDriver version                   555.58.02\r\nCUDA_HOME                        /home/computational/anaconda3\r\nPillow                           10.3.0\r\ntorchvision                      0.18.1+cu121 @/home/computational/anaconda3/lib/python3.12/site-packages/torchvision\r\ntorchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.10.0\r\n-------------------------------  ------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201703\r\n  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX512\r\n  - CUDA Runtime 12.1\r\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n  - CuDNN 8.9.2\r\n  - Magma 2.6.1\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      }
    ]
  },
  {
    "issue_number": 5109,
    "title": "Airdrop",
    "author": "Asiachanel",
    "state": "closed",
    "created_at": "2023-10-10T12:00:55Z",
    "updated_at": "2024-08-13T02:04:02Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "\nhttps://social.zalopay.vn/mega/sharing/ref-fs-luckywheel/r?share_type=referral&share_key=dQYFjKbfnztBeZe_KZAlWFkuVUiVlrS6PxyzxuzomLDhppcIpxOXMzamuGkSdGCK",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 4640,
    "title": "How to use the trained VitDet model for inference and visualize the inference resultsÔºü",
    "author": "ahxiaofengzheng",
    "state": "open",
    "created_at": "2022-11-04T09:08:12Z",
    "updated_at": "2024-08-12T12:37:04Z",
    "labels": [],
    "body": "I used cascade_mask_rcnn_vitdet_l_100ep.py to train a custom dataset, which can be trained and verified normally, but I can't reason, I didn't find the corresponding yaml configuration file, I only have the config.yaml file saved during training.\r\n\r\nWhen I use DefaultPredictor, I don't have `Model.WEIGHTS,INPUT.MIN_SIZE_TEST,DATASETS` in my config.yaml,How should I use the trained ViTDet model for inference, or where is the corresponding configuration file for ViTDet for inference.\r\n\r\nThe commands I use when training are as followsÔºö\r\n`python ./tools/lazyconfig_train_net_VitDet.py --config-file=./projects/ViTDet/configs/COCO/cascade_mask_rcnn_vitdet_l_100ep.py`\r\nThe command I use when verifying is as follows:\r\n`python ./tools/lazyconfig_train_net_VitDet.py --config-file=./projects/ViTDet/configs/COCO/cascade_mask_rcnn_vitdet_l_100ep.py --eval-only train.init_checkpoint=./output_L_lr_1e-4/model_final.pth`\r\nMy environments is as follows:\r\n![image](https://user-images.githubusercontent.com/81721256/199931020-b6232247-0bea-4f56-843d-871ec85aaef5.png)\r\n![image](https://user-images.githubusercontent.com/81721256/199931104-b76799e1-5a92-46c0-bd92-da42c0458d78.png)\r\n![image](https://user-images.githubusercontent.com/81721256/199931169-4331c816-de81-4517-b861-d4ea47952b39.png)\r\nThe yaml file obtained in training is as followsÔºö\r\n```\r\ndataloader:\r\n  evaluator: {_target_: detectron2.evaluation.COCOEvaluator, dataset_name: '${..test.dataset.names}'}\r\n  test:\r\n    _target_: detectron2.data.build_detection_test_loader\r\n    dataset: {_target_: detectron2.data.get_detection_dataset_dicts, filter_empty: false, names: coco_2017_val_UTDAC}\r\n    mapper:\r\n      _target_: detectron2.data.DatasetMapper\r\n      augmentations:\r\n      - {_target_: detectron2.data.transforms.ResizeShortestEdge, max_size: 1024, short_edge_length: 1024}\r\n      image_format: ${...train.mapper.image_format}\r\n      is_train: false\r\n    num_workers: 1\r\n  train:\r\n    _target_: detectron2.data.build_detection_train_loader\r\n    dataset: {_target_: detectron2.data.get_detection_dataset_dicts, names: coco_2017_train_UTDAC}\r\n    mapper:\r\n      _target_: detectron2.data.DatasetMapper\r\n      augmentations:\r\n      - {_target_: detectron2.data.transforms.RandomFlip, horizontal: true}\r\n      - {_target_: detectron2.data.transforms.ResizeScale, max_scale: 2.0, min_scale: 0.1, target_height: 1024, target_width: 1024}\r\n      - _target_: detectron2.data.transforms.FixedSizeCrop\r\n        crop_size: [1024, 1024]\r\n        pad: false\r\n      image_format: RGB\r\n      is_train: true\r\n      recompute_boxes: true\r\n      use_instance_mask: true\r\n    num_workers: 1\r\n    total_batch_size: 2\r\nlr_multiplier:\r\n  _target_: detectron2.solver.WarmupParamScheduler\r\n  scheduler:\r\n    _target_: fvcore.common.param_scheduler.MultiStepParamScheduler\r\n    milestones: [229689, 248829]\r\n    num_updates: 258400\r\n    values: [1.0, 0.1, 0.01]\r\n  warmup_factor: 0.001\r\n  warmup_length: 0.0009674922600619195\r\nmodel:\r\n  _target_: detectron2.modeling.GeneralizedRCNN\r\n  backbone:\r\n    _target_: detectron2.modeling.SimpleFeaturePyramid\r\n    in_feature: ${.net.out_feature}\r\n    net:\r\n      _target_: detectron2.modeling.ViT\r\n      depth: 24\r\n      drop_path_rate: 0.4\r\n      embed_dim: 1024\r\n      img_size: 1024\r\n      mlp_ratio: 4\r\n      norm_layer: !!python/object/apply:functools.partial\r\n        args: [&id001 !!python/name:torch.nn.modules.normalization.LayerNorm '']\r\n        state: !!python/tuple\r\n        - *id001\r\n        - !!python/tuple []\r\n        - {eps: 1.0e-06}\r\n        - null\r\n      num_heads: 16\r\n      out_feature: last_feat\r\n      patch_size: 16\r\n      qkv_bias: true\r\n      residual_block_indexes: []\r\n      use_rel_pos: true\r\n      window_block_indexes: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22]\r\n      window_size: 14\r\n    norm: LN\r\n    out_channels: 256\r\n    scale_factors: [4.0, 2.0, 1.0, 0.5]\r\n    square_pad: 1024\r\n    top_block: {_target_: detectron2.modeling.backbone.fpn.LastLevelMaxPool}\r\n  input_format: RGB\r\n  pixel_mean: [123.675, 116.28, 103.53]\r\n  pixel_std: [58.395, 57.12, 57.375]\r\n  proposal_generator:\r\n    _target_: detectron2.modeling.proposal_generator.RPN\r\n    anchor_generator:\r\n      _target_: detectron2.modeling.anchor_generator.DefaultAnchorGenerator\r\n      aspect_ratios: [0.5, 1.0, 2.0]\r\n      offset: 0.0\r\n      sizes:\r\n      - [32]\r\n      - [64]\r\n      - [128]\r\n      - [256]\r\n      - [512]\r\n      strides: [4, 8, 16, 32, 64]\r\n    anchor_matcher:\r\n      _target_: detectron2.modeling.matcher.Matcher\r\n      allow_low_quality_matches: true\r\n      labels: [0, -1, 1]\r\n      thresholds: [0.3, 0.7]\r\n    batch_size_per_image: 256\r\n    box2box_transform:\r\n      _target_: detectron2.modeling.box_regression.Box2BoxTransform\r\n      weights: [1.0, 1.0, 1.0, 1.0]\r\n    head:\r\n      _target_: detectron2.modeling.proposal_generator.StandardRPNHead\r\n      conv_dims: [-1, -1]\r\n      in_channels: 256\r\n      num_anchors: 3\r\n    in_features: [p2, p3, p4, p5, p6]\r\n    nms_thresh: 0.7\r\n    positive_fraction: 0.5\r\n    post_nms_topk: [1000, 1000]\r\n    pre_nms_topk: [2000, 1000]\r\n  roi_heads:\r\n    _target_: detectron2.modeling.roi_heads.CascadeROIHeads\r\n    batch_size_per_image: 512\r\n    box_heads:\r\n    - _target_: detectron2.modeling.roi_heads.FastRCNNConvFCHead\r\n      conv_dims: [256, 256, 256, 256]\r\n      conv_norm: LN\r\n      fc_dims: [1024]\r\n      input_shape: !!python/object:detectron2.layers.shape_spec.ShapeSpec {channels: 256, height: 7, stride: null, width: 7}\r\n    - _target_: detectron2.modeling.roi_heads.FastRCNNConvFCHead\r\n      conv_dims: [256, 256, 256, 256]\r\n      conv_norm: LN\r\n      fc_dims: [1024]\r\n      input_shape: !!python/object:detectron2.layers.shape_spec.ShapeSpec {channels: 256, height: 7, stride: null, width: 7}\r\n    - _target_: detectron2.modeling.roi_heads.FastRCNNConvFCHead\r\n      conv_dims: [256, 256, 256, 256]\r\n      conv_norm: LN\r\n      fc_dims: [1024]\r\n      input_shape: !!python/object:detectron2.layers.shape_spec.ShapeSpec {channels: 256, height: 7, stride: null, width: 7}\r\n    box_in_features: [p2, p3, p4, p5]\r\n    box_pooler:\r\n      _target_: detectron2.modeling.poolers.ROIPooler\r\n      output_size: 7\r\n      pooler_type: ROIAlignV2\r\n      sampling_ratio: 0\r\n      scales: [0.25, 0.125, 0.0625, 0.03125]\r\n    box_predictors:\r\n    - _target_: detectron2.modeling.FastRCNNOutputLayers\r\n      box2box_transform:\r\n        _target_: detectron2.modeling.box_regression.Box2BoxTransform\r\n        weights: [10, 10, 5, 5]\r\n      cls_agnostic_bbox_reg: true\r\n      input_shape: !!python/object:detectron2.layers.shape_spec.ShapeSpec {channels: 1024, height: null, stride: null, width: null}\r\n      num_classes: ${...num_classes}\r\n      test_score_thresh: 0.05\r\n    - _target_: detectron2.modeling.FastRCNNOutputLayers\r\n      box2box_transform:\r\n        _target_: detectron2.modeling.box_regression.Box2BoxTransform\r\n        weights: [20, 20, 10, 10]\r\n      cls_agnostic_bbox_reg: true\r\n      input_shape: !!python/object:detectron2.layers.shape_spec.ShapeSpec {channels: 1024, height: null, stride: null, width: null}\r\n      num_classes: ${...num_classes}\r\n      test_score_thresh: 0.05\r\n    - _target_: detectron2.modeling.FastRCNNOutputLayers\r\n      box2box_transform:\r\n        _target_: detectron2.modeling.box_regression.Box2BoxTransform\r\n        weights: [30, 30, 15, 15]\r\n      cls_agnostic_bbox_reg: true\r\n      input_shape: !!python/object:detectron2.layers.shape_spec.ShapeSpec {channels: 1024, height: null, stride: null, width: null}\r\n      num_classes: ${...num_classes}\r\n      test_score_thresh: 0.05\r\n    mask_head:\r\n      _target_: detectron2.modeling.roi_heads.MaskRCNNConvUpsampleHead\r\n      conv_dims: [256, 256, 256, 256, 256]\r\n      conv_norm: LN\r\n      input_shape: !!python/object:detectron2.layers.shape_spec.ShapeSpec {channels: 256, height: 14, stride: null, width: 14}\r\n      num_classes: ${..num_classes}\r\n    mask_in_features: [p2, p3, p4, p5]\r\n    mask_pooler:\r\n      _target_: detectron2.modeling.poolers.ROIPooler\r\n      output_size: 14\r\n      pooler_type: ROIAlignV2\r\n      sampling_ratio: 0\r\n      scales: [0.25, 0.125, 0.0625, 0.03125]\r\n    num_classes: 80\r\n    positive_fraction: 0.25\r\n    proposal_matchers:\r\n    - _target_: detectron2.modeling.matcher.Matcher\r\n      allow_low_quality_matches: false\r\n      labels: [0, 1]\r\n      thresholds: [0.5]\r\n    - _target_: detectron2.modeling.matcher.Matcher\r\n      allow_low_quality_matches: false\r\n      labels: [0, 1]\r\n      thresholds: [0.6]\r\n    - _target_: detectron2.modeling.matcher.Matcher\r\n      allow_low_quality_matches: false\r\n      labels: [0, 1]\r\n      thresholds: [0.7]\r\noptimizer:\r\n  _target_: torch.optim.AdamW\r\n  betas: [0.9, 0.999]\r\n  lr: 0.0001\r\n  params:\r\n    _target_: detectron2.solver.get_default_optimizer_params\r\n    base_lr: ${..lr}\r\n    lr_factor_func: !!python/object/apply:functools.partial\r\n      args: [&id002 !!python/name:detectron2.modeling.backbone.vit.get_vit_lr_decay_rate '']\r\n      state: !!python/tuple\r\n      - *id002\r\n      - !!python/tuple []\r\n      - {lr_decay_rate: 0.8, num_layers: 24}\r\n      - null\r\n    overrides:\r\n      pos_embed: {weight_decay: 0.0}\r\n    weight_decay_norm: 0.0\r\n  weight_decay: 0.1\r\ntrain:\r\n  amp: {enabled: true}\r\n  checkpointer: {max_to_keep: 100, period: 20000}\r\n  ddp: {broadcast_buffers: false, find_unused_parameters: false, fp16_compression: true}\r\n  device: cuda\r\n  eval_period: 2584\r\n  init_checkpoint: ./output_L_lr_1e-4/model_final.pth\r\n  log_period: 10\r\n  max_iter: 258400\r\n  output_dir: ./output_L_lr_1e-4\r\n```\r\n\r\n\r\n\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "ahxiaofengzheng",
        "body": "__Full logs__ or other relevant observations:\r\n\r\n`[11/04 17:15:33 detectron2]: Arguments: Namespace(confidence_threshold=0.5, config_file='./output_L_lr_1e-4/config.yaml', input=['./Data/UTDAC2020_enhance/val2017/'], opts=['MODEL.WEIGHTS', './output_L_lr_1e-4/model_final.pth'], output='./UTDAC2020_enhance', video_input=None, webcam=False)\r\nWARNING [11/04 17:15:33 fvcore.common.config]: Loading config ./output_L_lr_1e-4/config.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\r\nTraceback (most recent call last):\r\n  File \"./demo/demo.py\", line 100, in <module>\r\n    cfg = setup_cfg(args)\r\n  File \"./demo/demo.py\", line 29, in setup_cfg\r\n    cfg.merge_from_file(args.config_file)\r\n  File \"/public/home/wangzheng/detectron2/detectron2/config/config.py\", line 47, in merge_from_file\r\n    loaded_cfg = type(self)(loaded_cfg)\r\n  File \"/public/home/wangzheng/.conda/envs/detectron2/lib/python3.8/site-packages/yacs/config.py\", line 86, in __init__\r\n    init_dict = self._create_config_tree_from_dict(init_dict, key_list)\r\n  File \"/public/home/wangzheng/.conda/envs/detectron2/lib/python3.8/site-packages/yacs/config.py\", line 126, in _create_config_tree_from_dict\r\n    dic[k] = cls(v, key_list=key_list + [k])\r\n  File \"/public/home/wangzheng/.conda/envs/detectron2/lib/python3.8/site-packages/yacs/config.py\", line 86, in __init__\r\n    init_dict = self._create_config_tree_from_dict(init_dict, key_list)\r\n  File \"/public/home/wangzheng/.conda/envs/detectron2/lib/python3.8/site-packages/yacs/config.py\", line 126, in _create_config_tree_from_dict\r\n    dic[k] = cls(v, key_list=key_list + [k])\r\n  File \"/public/home/wangzheng/.conda/envs/detectron2/lib/python3.8/site-packages/yacs/config.py\", line 86, in __init__\r\n    init_dict = self._create_config_tree_from_dict(init_dict, key_list)\r\n  File \"/public/home/wangzheng/.conda/envs/detectron2/lib/python3.8/site-packages/yacs/config.py\", line 126, in _create_config_tree_from_dict\r\n    dic[k] = cls(v, key_list=key_list + [k])\r\n  File \"/public/home/wangzheng/.conda/envs/detectron2/lib/python3.8/site-packages/yacs/config.py\", line 86, in __init__\r\n    init_dict = self._create_config_tree_from_dict(init_dict, key_list)\r\n  File \"/public/home/wangzheng/.conda/envs/detectron2/lib/python3.8/site-packages/yacs/config.py\", line 129, in _create_config_tree_from_dict\r\n    _assert_with_logging(\r\n  File \"/public/home/wangzheng/.conda/envs/detectron2/lib/python3.8/site-packages/yacs/config.py\", line 545, in _assert_with_logging\r\n    assert cond, msg\r\nAssertionError: Key model.backbone.net.norm_layer with value <class 'functools.partial'> is not a valid type; valid types: {<class 'float'>, <class 'list'>, <class 'str'>, <class 'bool'>, <class 'NoneType'>, <class 'tuple'>, <class 'int'>}`"
      },
      {
        "user": "QuanLNTU",
        "body": "Hey,I have the same question,how did you sovle it?"
      }
    ]
  },
  {
    "issue_number": 685,
    "title": "Will detectron2 support FCOS detector?",
    "author": "Anikily",
    "state": "closed",
    "created_at": "2020-01-13T09:15:21Z",
    "updated_at": "2024-08-11T15:20:29Z",
    "labels": [
      "enhancement"
    ],
    "body": "",
    "comments": [
      {
        "user": "ppwwyyxx",
        "body": "Currently we don't have such plans"
      },
      {
        "user": "Keiku",
        "body": "The FCOS author seems to be considering it.\r\nhttps://github.com/tianzhi0549/FCOS/issues/203"
      },
      {
        "user": "Harold-lkk",
        "body": "https://github.com/aim-uofa/adet"
      }
    ]
  },
  {
    "issue_number": 5234,
    "title": "docker file error",
    "author": "PushpakAg",
    "state": "open",
    "created_at": "2024-03-08T15:00:52Z",
    "updated_at": "2024-08-07T08:55:04Z",
    "labels": [],
    "body": "when you try installing detectron2 locally on windows it gives you CUDA error though toolkit is installed and it can identify system GPU.\r\ni tried installing it from the docker file and I am getting python version mismatch errror.\r\n\r\nto reproduce the issue\r\n```\r\ngit clone https://github.com/facebookresearch/detectron2.git\r\ncd detectron2\r\ndocker build -t detectron2 -f docker/Dockerfile .\r\n```\r\nRUN pip install --user -e detectron2_repo (when docker runs this it will throw python mismatch error)\r\n\r\n",
    "comments": [
      {
        "user": "grogou",
        "body": "Same with Apple M3"
      },
      {
        "user": "Huxwell",
        "body": "Please always include actual error messages, this increases chances that smb (a maintainer or a random person that had similar problem in the past) will be able to actually able to help you."
      },
      {
        "user": "Gustav-Proxi",
        "body": "`FROM nvidia/cuda:11.1.1-cudnn8-devel-ubuntu20.04\r\n\r\nENV DEBIAN_FRONTEND noninteractive\r\nRUN apt-get update && apt-get install -y \\\r\n    python3-opencv ca-certificates python3.8 python3.8-dev git wget sudo ninja-build && \\\r\n    ln -sv /usr/bin/python3.8 /usr/bin/python3\r\n\r\n# create a non-root user\r\nARG USER_ID=1000\r\nRUN useradd -m --no-log-init --system --uid ${USER_ID} appuser -g sudo\r\nRUN echo '%sudo ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers\r\nUSER appuser\r\nWORKDIR /home/appuser\r\n\r\nENV PATH=\"/home/appuser/.local/bin:${PATH}\"\r\nRUN wget https://bootstrap.pypa.io/get-pip.py && \\\r\n    python3 get-pip.py --user && \\\r\n    rm get-pip.py\r\n\r\n# install dependencies\r\nRUN pip install --user tensorboard cmake onnx\r\nRUN pip install --user torch==1.10 torchvision==0.11.1 -f https://download.pytorch.org/whl/cu111/torch_stable.html\r\n\r\nRUN pip install --user 'git+https://github.com/facebookresearch/fvcore'\r\n# install detectron2\r\nRUN git clone https://github.com/facebookresearch/detectron2 detectron2_repo\r\nENV FORCE_CUDA=\"1\"\r\nARG TORCH_CUDA_ARCH_LIST=\"Kepler;Kepler+Tesla;Maxwell;Maxwell+Tegra;Pascal;Volta;Turing\"\r\nENV TORCH_CUDA_ARCH_LIST=\"${TORCH_CUDA_ARCH_LIST}\"\r\n\r\nRUN pip install --user -e detectron2_repo\r\n\r\n# Set a fixed model cache directory.\r\nENV FVCORE_CACHE=\"/tmp\"\r\nWORKDIR /home/appuser/detectron2_repo`\r\n\r\n\r\nreplace this in the docker file this will fix the issue\r\n\r\n\r\n\r\n"
      }
    ]
  },
  {
    "issue_number": 5342,
    "title": "Coreml conversion",
    "author": "Mayor2305",
    "state": "open",
    "created_at": "2024-08-05T23:50:34Z",
    "updated_at": "2024-08-05T23:50:34Z",
    "labels": [
      "enhancement"
    ],
    "body": "## üöÄ Feature\r\nSimple and streamlined conversion of custom models to coreml\r\n\r\n## Motivation & Examples\r\n\r\nthis feature would help to deploy custom trained models on ios devices\r\n\r\nthe feature could be as simple as a saving format to coreml\r\n\r\n## Note\r\n\r\nWe only consider adding new features if they are relevant to many users.\r\n\r\nIf you request implementation of research papers -- we only consider papers that have enough significance and prevalance in the object detection field.\r\n\r\nWe do not take requests for most projects in the `projects/` directory, because they are research code release that is mainly for other researchers to reproduce results.\r\n\r\n\"Make X faster/accurate\" is not a valid feature request. \"Implement a concrete feature that can make X faster/accurate\" can be a valid feature request.\r\n\r\nInstead of adding features inside detectron2,\r\nyou can implement many features by [extending detectron2](https://detectron2.readthedocs.io/tutorials/extend.html).\r\nThe [projects/](https://github.com/facebookresearch/detectron2/tree/main/projects/) directory contains many of such examples.\r\n\r\n",
    "comments": []
  },
  {
    "issue_number": 5341,
    "title": "the problem of visualization and self-made dataset metadata setting",
    "author": "lelelelelelelelelelelelele",
    "state": "open",
    "created_at": "2024-08-04T13:49:15Z",
    "updated_at": "2024-08-04T13:51:24Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n### description:  \r\nI wanna split the origin dataset (coco json format) to train and test parts. \r\nTherefore, I compared 2 methods by `register_coco_instance` and `load_coco_json`, and get the dicts respectively.\r\n```\r\nregister_coco_instances(\"my_dataset\", {}, \"./dataset/annotations/train_test2017.json\", \"./dataset/JPEGImages\")\r\na = DatasetCatalog.get(\"my_dataset\")\r\n# or\r\nmetadata = MetadataCatalog.get(\"my_dataset\").set(\r\n    thing_classes = [\"ship\"],\r\n    thing_dataset_id_to_contiguous_id = {1: 0},\r\n    json_file=json_path,\r\n    image_root=img_path,\r\n    evaluator_type='coco',\r\n)\r\na = load_coco_json(json_path, img_path)\r\nDatasetCatalog.register(\"my_dataset\", lambda: a)\r\n```\r\nboth of which follow the tutorials.\r\n\r\n**however**, it faced issue when implementing visualization code:\r\n`visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5, instance_mode=ColorMode.IMAGE_BW)`\r\n`out = visualizer.draw_dataset_dict(d)`\r\n\r\n### problem / log\r\nwhat is weird is that method 1 went smoothly yet method 2 went wrong and shows\r\n```\r\n  File \"h:\\github\\training\\self_dataload.py\", line 56, in <module>\r\n    out = visualizer.draw_dataset_dict(d)\r\n  File \"h:\\github\\detectron2\\detectron2\\utils\\visualizer.py\", line 589, in draw_dataset_dict\r\n    labels = _create_text_labels(\r\n  File \"h:\\github\\detectron2\\detectron2\\utils\\visualizer.py\", line 244, in _create_text_labels\r\n    labels = [class_names[i] for i in classes]\r\n  File \"h:\\github\\detectron2\\detectron2\\utils\\visualizer.py\", line 244, in <listcomp>\r\n    labels = [class_names[i] for i in classes]\r\nIndexError: list index out of range\r\n```\r\n\r\n## Environment:\r\ncommon windows environment  \r\npython 3.10  \r\n\r\n## solution:  \r\nI faced the same question with https://github.com/facebookresearch/detectron2/issues/546\r\nI check the source code and debug it.  It turned out that the IDs of my categories started at 1 and not as expected at 0.\r\nThe problem should be solved by setting an internal parameter  `thing_dataset_id_to_contiguous_id` in the metadata of the dataset. However, during my debugging, no matter how I set the parameter by `metadata = MetadataCatalog.get(\"my_dataset\").set()`, the visualizer cant solve the mapping. I also try to register by `a = load_coco_json(json_path, img_path, \"my_dataset_1\")`(very similar to method 2 but register automatically and i cant filter or change the dataset manually), in that case, even i dont set the metadata, The visualizer can understand the mapping and shows the image.\r\n\r\nAbove all, I deduce that self-setting metadata in coco format cant be understood by function *visualizer.draw_dataset_dict(d)*, or even worse by the trainer( i haven't check but since the `register_coco_instance` works well, I doubt if the self-setting metadata works at all).\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      }
    ]
  },
  {
    "issue_number": 4502,
    "title": "riding_horse.png: detected 0 instances in 0.10s",
    "author": "doantientai",
    "state": "open",
    "created_at": "2022-08-25T09:07:27Z",
    "updated_at": "2024-08-02T03:01:15Z",
    "labels": [],
    "body": "Hi everyone,\r\n\r\nI followed the instructions in [here](https://detectron2.readthedocs.io/en/latest/tutorials/install.html) for the installation. Things went well. But then I tried running the [first demo](https://detectron2.readthedocs.io/en/latest/tutorials/getting_started.html). The model did not detect any object.\r\n\r\nI have made **no change** to the code.\r\n\r\nInstructions To Reproduce the Issue:\r\n```\r\npyenv local 3.7.6\r\npoetry init\r\npoetry shell\r\npython -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\ncd detectron2/demo/\r\npython demo.py --config-file ../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml   --input  ~/Downloads/riding_horse.png\r\n```\r\nAnd this is the __Full logs__ of what I got\r\n```\r\n[08/25 10:53:42 detectron2]: Arguments: Namespace(confidence_threshold=0.5, config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', input=['/home/tai/Downloads/riding_horse.png'], opts=[], output=None, video_input=None, webcam=False)\r\n[08/25 10:53:44 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...\r\n[08/25 10:53:44 d2.checkpoint.c2_model_loading]: Renaming Caffe2 weights ......\r\n[08/25 10:53:44 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.bottom_up:\r\n| Names in Model    | Names in Checkpoint      | Shapes                                          |\r\n|:------------------|:-------------------------|:------------------------------------------------|\r\n| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |\r\n| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\r\n| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\r\n| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\r\n| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\r\n| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\r\n| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\r\n| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |\r\n| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |\r\n| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\r\n| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\r\n| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\r\n| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\r\n| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\r\n| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |\r\n| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\r\n| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\r\n| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\r\n| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\r\n| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\r\n| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\r\n| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\r\n| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\r\n| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\r\n| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\r\n| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\r\n| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\r\n| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\r\n| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\r\n| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |\r\n| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |\r\nWARNING [08/25 10:53:44 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:\r\nbackbone.fpn_lateral2.{bias, weight}\r\nbackbone.fpn_lateral3.{bias, weight}\r\nbackbone.fpn_lateral4.{bias, weight}\r\nbackbone.fpn_lateral5.{bias, weight}\r\nbackbone.fpn_output2.{bias, weight}\r\nbackbone.fpn_output3.{bias, weight}\r\nbackbone.fpn_output4.{bias, weight}\r\nbackbone.fpn_output5.{bias, weight}\r\nproposal_generator.rpn_head.anchor_deltas.{bias, weight}\r\nproposal_generator.rpn_head.conv.{bias, weight}\r\nproposal_generator.rpn_head.objectness_logits.{bias, weight}\r\nroi_heads.box_head.fc1.{bias, weight}\r\nroi_heads.box_head.fc2.{bias, weight}\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\nroi_heads.mask_head.deconv.{bias, weight}\r\nroi_heads.mask_head.mask_fcn1.{bias, weight}\r\nroi_heads.mask_head.mask_fcn2.{bias, weight}\r\nroi_heads.mask_head.mask_fcn3.{bias, weight}\r\nroi_heads.mask_head.mask_fcn4.{bias, weight}\r\nroi_heads.mask_head.predictor.{bias, weight}\r\nWARNING [08/25 10:53:44 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:\r\n  fc1000.{bias, weight}\r\n  stem.conv1.bias\r\n/media/tai/6TB/Projects/Segmentation/Detectron2/.venv/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\r\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n[08/25 10:53:44 detectron2]: /home/tai/Downloads/riding_horse.png: detected 0 instances in 0.10s\r\n\r\n```\r\n\r\n## Expected behavior:\r\n\r\nThe model is expected to detect objects as being shown in [the Colaboratory example](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5) with multiple detected objects.\r\n\r\n## Environment:\r\n\r\n```\r\n2022-08-25 11:03:19 URL:https://raw.githubusercontent.com/facebookresearch/detectron2/main/detectron2/utils/collect_env.py [8391/8391] -> \"collect_env.py\" [1]\r\n----------------------  -----------------------------------------------------------------------------------------------------------\r\nsys.platform            linux\r\nPython                  3.7.6 (default, Nov  3 2021, 18:42:57) [GCC 9.3.0]\r\nnumpy                   1.21.6\r\ndetectron2              0.6 @/media/tai/6TB/Projects/Segmentation/Detectron2/detectron2/detectron2\r\nCompiler                GCC 10.3\r\nCUDA compiler           CUDA 10.2\r\ndetectron2 arch flags   6.1\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.10.2+cu102 @/media/tai/6TB/Projects/Segmentation/Detectron2/.venv/lib/python3.7/site-packages/torch\r\nPyTorch debug build     False\r\nGPU available           Yes\r\nGPU 0                   NVIDIA GeForce GTX 1080 Ti (arch=6.1)\r\nDriver version          515.65.01\r\nCUDA_HOME               /usr/local/cuda-10.2\r\nPillow                  9.2.0\r\ntorchvision             0.11.3+cu102 @/media/tai/6TB/Projects/Segmentation/Detectron2/.venv/lib/python3.7/site-packages/torchvision\r\ntorchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5\r\nfvcore                  0.1.5.post20220512\r\niopath                  0.1.9\r\ncv2                     4.6.0\r\n----------------------  -----------------------------------------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 10.2\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\r\n  - CuDNN 7.6.5\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \r\n\r\n```\r\n\r\nHopefully someone know how to fix this. Thanks a lot for your attetion! :smiley: ",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "doantientai",
        "body": "One thing I'm wondering is that, in the output of `collect_env.py`, we have\r\n```\r\nCompiler                GCC 10.3\r\n```\r\nBut when I do `gcc --version`, it gives\r\n```\r\ngcc (Ubuntu 8.4.0-3ubuntu2) 8.4.0\r\nCopyright (C) 2018 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n```\r\nOne more detail, I have multiple version of CUDA and GCC and I manage them using `sudo update-alternatives --config cuda` and `sudo update-alternatives --config gcc`. I don't know if this may be the cause?\r\n"
      },
      {
        "user": "kimile599",
        "body": "Exactly same issue here:\r\nckbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\r\n| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\r\n| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\r\n| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\r\n| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\r\n| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |\r\n| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |\r\n| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |\r\n| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |\r\n| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |\r\n| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                             | (256,) (256,256,2,2)                            |\r\n| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\r\n| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\r\n| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\r\n| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\r\nWARNING [08/29 07:34:11 fvcore.common.checkpoint]: Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (4,) in the checkpoint but (320,) in the model! You might want to double check if this is expected.\r\nWARNING [08/29 07:34:11 fvcore.common.checkpoint]: Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (4, 1024) in the checkpoint but (320, 1024) in the model! You might want to double check if this is expected.\r\nWARNING [08/29 07:34:11 fvcore.common.checkpoint]: Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (2,) in the checkpoint but (81,) in the model! You might want to double check if this is expected.\r\nWARNING [08/29 07:34:11 fvcore.common.checkpoint]: Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (2, 1024) in the checkpoint but (81, 1024) in the model! You might want to double check if this is expected.\r\nWARNING [08/29 07:34:11 fvcore.common.checkpoint]: Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (1,) in the checkpoint but (80,) in the model! You might want to double check if this is expected.\r\nWARNING [08/29 07:34:11 fvcore.common.checkpoint]: Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (1, 256, 1, 1) in the checkpoint but (80, 256, 1, 1) in the model! You might want to double check if this is expected.\r\nWARNING [08/29 07:34:11 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\nroi_heads.mask_head.predictor.{bias, weight}\r\n  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\r\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n[08/29 07:34:12 detectron2]: /content/dataset/test/DSC00280.JPG: detected 0 instances in 1.55s\r\n\r\n\r\nI know that it is the config file doesn't match our trained model, \" incompatible shapes: (1, 256, 1, 1) in the checkpoint but (80, 256, 1, 1) \", the 1 should be my one class target, but the 80 should  be coco dataet with 80 classes, based on my knowledge. But i failed to solve it. I have tried added the :\r\n**cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1**\r\npredictor = DefaultPredictor(cfg)\r\n\r\nBut no luck."
      }
    ]
  },
  {
    "issue_number": 5210,
    "title": "Error while exporting Detectron2 model to Onnx model",
    "author": "AakashGoyal25",
    "state": "open",
    "created_at": "2024-02-08T22:08:33Z",
    "updated_at": "2024-08-02T02:17:09Z",
    "labels": [],
    "body": "I am trying to export my detectron2 model to onnx model but I am getting a KeyError: 'Non-existent config key: DATASETS.VAL'\r\n\r\nCommand I run:\r\n```\r\npython detectron2/tools/deploy/export_model.py --config-file output.yaml --output model.onnx --format onnx --sample-image /home/aakash/Aakash Workings/HB_Codes/detectron2_working/XYZ/val/images/0e3561a5-am_c1_20231004-094138.jpeg --export-method caffe2_tracing MODEL.DEVICE cuda MODEL.WEIGHTS /home/aakash/Aakash Workings/HB_Codes/detectron2_working/output/model_final.pth`\r\n```\r\n\r\nError Traceback:\r\n```\r\n(detectron_env) aakash@Goyal:~/Aakash Workings/HB_Codes/detectron2_working$ python detectron2/tools/deploy/export_model.py --config-file output.yaml --output model \r\n--format onnx --sample-image /home/aakash/Aakash Workings/HB_Codes/detectron2_working/d2_seal_control_ob_l/val/images/0e3561a5-am_c1_20231004-094138.jpeg --export-m\r\nethod caffe2_tracing MODEL.DEVICE cuda MODEL.WEIGHTS /home/aakash/Aakash Workings/HB_Codes/detectron2_working/output/model_final.pth\r\n[02/08 22:51:33 detectron2]: Command line arguments: Namespace(format='onnx', export_method='tracing', config_file='output.yaml', sample_image='/home/aakash/Aakash', run_eval=False, output='model', opts=['Workings/HB_Codes/detectron2_working/d2_seal_control_ob_l/val/images/0e3561a5-am_c1_20231004-094138.jpeg', '--export-method', 'caffe2_tracing', 'MODEL.DEVICE', 'cuda', 'MODEL.WEIGHTS', '/home/aakash/Aakash', 'Workings/HB_Codes/detectron2_working/output/model_final.pth'])\r\n[W init.cpp:855] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 1) (function operator())\r\nTraceback (most recent call last):\r\n  File \"/home/aakash/Aakash Workings/HB_Codes/detectron2_working/detectron2/tools/deploy/export_model.py\", line 210, in <module>\r\n    cfg = setup_cfg(args)\r\n  File \"/home/aakash/Aakash Workings/HB_Codes/detectron2_working/detectron2/tools/deploy/export_model.py\", line 34, in setup_cfg\r\n    cfg.merge_from_file(args.config_file)\r\n  File \"/home/aakash/Aakash Workings/HB_Codes/detectron2_working/detectron2/detectron2/config/config.py\", line 69, in merge_from_file\r\n    self.merge_from_other_cfg(loaded_cfg)\r\n  File \"/home/aakash/Aakash Workings/HB_Codes/detectron2_working/detectron_env/lib/python3.10/site-packages/fvcore/common/config.py\", line 132, in merge_from_other_cfg\r\n    return super().merge_from_other_cfg(cfg_other)\r\n  File \"/home/aakash/Aakash Workings/HB_Codes/detectron2_working/detectron_env/lib/python3.10/site-packages/yacs/config.py\", line 217, in merge_from_other_cfg\r\n    _merge_a_into_b(cfg_other, self, self, [])\r\n  File \"/home/aakash/Aakash Workings/HB_Codes/detectron2_working/detectron_env/lib/python3.10/site-packages/yacs/config.py\", line 478, in _merge_a_into_b\r\n    _merge_a_into_b(v, b[k], root, key_list + [k])\r\n  File \"/home/aakash/Aakash Workings/HB_Codes/detectron2_working/detectron_env/lib/python3.10/site-packages/yacs/config.py\", line 491, in _merge_a_into_b\r\n    raise KeyError(\"Non-existent config key: {}\".format(full_key))\r\nKeyError: 'Non-existent config key: DATASETS.VAL'\r\n```\r\nconfig.yaml\r\n```\r\nCUDNN_BENCHMARK: false\r\nDATALOADER:\r\n  ASPECT_RATIO_GROUPING: true\r\n  FILTER_EMPTY_ANNOTATIONS: true\r\n  NUM_WORKERS: 2\r\n  REPEAT_THRESHOLD: 0.0\r\n  SAMPLER_TRAIN: TrainingSampler\r\nDATASETS:\r\n  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\r\n  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\r\n  PROPOSAL_FILES_TEST: []\r\n  PROPOSAL_FILES_TRAIN: []\r\n  TEST: []\r\n  TRAIN:\r\n  - train\r\n  VAL:\r\n  - val\r\nGLOBAL:\r\n  HACK: 1.0\r\nINPUT:\r\n  CROP:\r\n    ENABLED: false\r\n    SIZE:\r\n    - 0.9\r\n    - 0.9\r\n    TYPE: relative_range\r\n  FORMAT: BGR\r\n  MASK_FORMAT: polygon\r\n  MAX_SIZE_TEST: 1333\r\n  MAX_SIZE_TRAIN: 1333\r\n  MIN_SIZE_TEST: 800\r\n  MIN_SIZE_TRAIN:\r\n  - 640\r\n  - 672\r\n  - 704\r\n  - 736\r\n  - 768\r\n  - 800\r\n  MIN_SIZE_TRAIN_SAMPLING: choice\r\n  RANDOM_FLIP: horizontal\r\nMODEL:\r\n  ANCHOR_GENERATOR:\r\n    ANGLES:\r\n    - - -90\r\n      - 0\r\n      - 90\r\n    ASPECT_RATIOS:\r\n    - - 0.5\r\n      - 1.0\r\n      - 2.0\r\n    NAME: DefaultAnchorGenerator\r\n    OFFSET: 0.0\r\n    SIZES:\r\n    - - 32\r\n    - - 64\r\n    - - 128\r\n    - - 256\r\n    - - 512\r\n  BACKBONE:\r\n    FREEZE_AT: 2\r\n    NAME: build_resnet_fpn_backbone\r\n  DEVICE: cuda\r\n  FPN:\r\n    FUSE_TYPE: sum\r\n    IN_FEATURES:\r\n    - res2\r\n    - res3\r\n    - res4\r\n    - res5\r\n    NORM: ''\r\n    OUT_CHANNELS: 256\r\n  KEYPOINT_ON: false\r\n  LOAD_PROPOSALS: false\r\n  MASK_ON: false\r\n  META_ARCHITECTURE: GeneralizedRCNN\r\n  PANOPTIC_FPN:\r\n    COMBINE:\r\n      ENABLED: true\r\n      INSTANCES_CONFIDENCE_THRESH: 0.5\r\n      OVERLAP_THRESH: 0.5\r\n      STUFF_AREA_LIMIT: 4096\r\n    INSTANCE_LOSS_WEIGHT: 1.0\r\n  PIXEL_MEAN:\r\n  - 103.53\r\n  - 116.28\r\n  - 123.675\r\n  PIXEL_STD:\r\n  - 1.0\r\n  - 1.0\r\n  - 1.0\r\n  PROPOSAL_GENERATOR:\r\n    MIN_SIZE: 0\r\n    NAME: RPN\r\n  RESNETS:\r\n    DEFORM_MODULATED: false\r\n    DEFORM_NUM_GROUPS: 1\r\n    DEFORM_ON_PER_STAGE:\r\n    - false\r\n    - false\r\n    - false\r\n    - false\r\n    DEPTH: 101\r\n    NORM: FrozenBN\r\n    NUM_GROUPS: 1\r\n    OUT_FEATURES:\r\n    - res2\r\n    - res3\r\n    - res4\r\n    - res5\r\n    RES2_OUT_CHANNELS: 256\r\n    RES5_DILATION: 1\r\n    STEM_OUT_CHANNELS: 64\r\n    STRIDE_IN_1X1: true\r\n    WIDTH_PER_GROUP: 64\r\n  RETINANET:\r\n    BBOX_REG_LOSS_TYPE: smooth_l1\r\n    BBOX_REG_WEIGHTS: &id002\r\n    - 1.0\r\n    - 1.0\r\n    - 1.0\r\n    - 1.0\r\n    FOCAL_LOSS_ALPHA: 0.25\r\n    FOCAL_LOSS_GAMMA: 2.0\r\n    IN_FEATURES:\r\n    - p3\r\n    - p4\r\n    - p5\r\n    - p6\r\n    - p7\r\n    IOU_LABELS:\r\n    - 0\r\n    - -1\r\n    - 1\r\n    IOU_THRESHOLDS:\r\n    - 0.4\r\n    - 0.5\r\n    NMS_THRESH_TEST: 0.5\r\n    NORM: ''\r\n    NUM_CLASSES: 80\r\n    NUM_CONVS: 4\r\n    PRIOR_PROB: 0.01\r\n    SCORE_THRESH_TEST: 0.05\r\n    SMOOTH_L1_LOSS_BETA: 0.1\r\n    TOPK_CANDIDATES_TEST: 1000\r\n  ROI_BOX_CASCADE_HEAD:\r\n    BBOX_REG_WEIGHTS:\r\n    - &id001\r\n      - 10.0\r\n      - 10.0\r\n      - 5.0\r\n      - 5.0\r\n    - - 20.0\r\n      - 20.0\r\n      - 10.0\r\n      - 10.0\r\n    - - 30.0\r\n      - 30.0\r\n      - 15.0\r\n      - 15.0\r\n    IOUS:\r\n    - 0.5\r\n    - 0.6\r\n    - 0.7\r\n  ROI_BOX_HEAD:\r\n    BBOX_REG_LOSS_TYPE: smooth_l1\r\n    BBOX_REG_LOSS_WEIGHT: 1.0\r\n    BBOX_REG_WEIGHTS: *id001\r\n    CLS_AGNOSTIC_BBOX_REG: false\r\n    CONV_DIM: 256\r\n    FC_DIM: 1024\r\n    FED_LOSS_FREQ_WEIGHT_POWER: 0.5\r\n    FED_LOSS_NUM_CLASSES: 50\r\n    NAME: FastRCNNConvFCHead\r\n    NORM: ''\r\n    NUM_CONV: 0\r\n    NUM_FC: 2\r\n    POOLER_RESOLUTION: 7\r\n    POOLER_SAMPLING_RATIO: 0\r\n    POOLER_TYPE: ROIAlignV2\r\n    SMOOTH_L1_BETA: 0.0\r\n    TRAIN_ON_PRED_BOXES: false\r\n    USE_FED_LOSS: false\r\n    USE_SIGMOID_CE: false\r\n  ROI_HEADS:\r\n    BATCH_SIZE_PER_IMAGE: 128\r\n    IN_FEATURES:\r\n    - p2\r\n    - p3\r\n    - p4\r\n    - p5\r\n    IOU_LABELS:\r\n    - 0\r\n    - 1\r\n    IOU_THRESHOLDS:\r\n    - 0.5\r\n    NAME: StandardROIHeads\r\n    NMS_THRESH_TEST: 0.5\r\n    NUM_CLASSES: 7\r\n    POSITIVE_FRACTION: 0.25\r\n    PROPOSAL_APPEND_GT: true\r\n    SCORE_THRESH_TEST: 0.05\r\n  ROI_KEYPOINT_HEAD:\r\n    CONV_DIMS:\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    - 512\r\n    LOSS_WEIGHT: 1.0\r\n    MIN_KEYPOINTS_PER_IMAGE: 1\r\n    NAME: KRCNNConvDeconvUpsampleHead\r\n    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true\r\n    NUM_KEYPOINTS: 17\r\n    POOLER_RESOLUTION: 14\r\n    POOLER_SAMPLING_RATIO: 0\r\n    POOLER_TYPE: ROIAlignV2\r\n  ROI_MASK_HEAD:\r\n    CLS_AGNOSTIC_MASK: false\r\n    CONV_DIM: 256\r\n    NAME: MaskRCNNConvUpsampleHead\r\n    NORM: ''\r\n    NUM_CONV: 4\r\n    POOLER_RESOLUTION: 14\r\n    POOLER_SAMPLING_RATIO: 0\r\n    POOLER_TYPE: ROIAlignV2\r\n  RPN:\r\n    BATCH_SIZE_PER_IMAGE: 256\r\n    BBOX_REG_LOSS_TYPE: smooth_l1\r\n    BBOX_REG_LOSS_WEIGHT: 1.0\r\n    BBOX_REG_WEIGHTS: *id002\r\n    BOUNDARY_THRESH: -1\r\n    CONV_DIMS:\r\n    - -1\r\n    HEAD_NAME: StandardRPNHead\r\n    IN_FEATURES:\r\n    - p2\r\n    - p3\r\n    - p4\r\n    - p5\r\n    - p6\r\n    IOU_LABELS:\r\n    - 0\r\n    - -1\r\n    - 1\r\n    IOU_THRESHOLDS:\r\n    - 0.3\r\n    - 0.7\r\n    LOSS_WEIGHT: 1.0\r\n    NMS_THRESH: 0.7\r\n    POSITIVE_FRACTION: 0.5\r\n    POST_NMS_TOPK_TEST: 1000\r\n    POST_NMS_TOPK_TRAIN: 1000\r\n    PRE_NMS_TOPK_TEST: 1000\r\n    PRE_NMS_TOPK_TRAIN: 2000\r\n    SMOOTH_L1_BETA: 0.0\r\n  SEM_SEG_HEAD:\r\n    COMMON_STRIDE: 4\r\n    CONVS_DIM: 128\r\n    IGNORE_VALUE: 255\r\n    IN_FEATURES:\r\n    - p2\r\n    - p3\r\n    - p4\r\n    - p5\r\n    LOSS_WEIGHT: 1.0\r\n    NAME: SemSegFPNHead\r\n    NORM: GN\r\n    NUM_CLASSES: 54\r\n  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\r\nOUTPUT_DIR: ./output\r\nSEED: -1\r\nSOLVER:\r\n  AMP:\r\n    ENABLED: false\r\n  BASE_LR: 0.00025\r\n  BASE_LR_END: 0.0\r\n  BIAS_LR_FACTOR: 1.0\r\n  CHECKPOINT_PERIOD: 50\r\n  CLIP_GRADIENTS:\r\n    CLIP_TYPE: value\r\n    CLIP_VALUE: 1.0\r\n    ENABLED: false\r\n    NORM_TYPE: 2.0\r\n  GAMMA: 0.1\r\n  IMS_PER_BATCH: 4\r\n  LR_SCHEDULER_NAME: WarmupMultiStepLR\r\n  MAX_ITER: 100\r\n  MOMENTUM: 0.9\r\n  NESTEROV: false\r\n  NUM_DECAYS: 3\r\n  REFERENCE_WORLD_SIZE: 0\r\n  RESCALE_INTERVAL: false\r\n  STEPS: []\r\n  WARMUP_FACTOR: 0.001\r\n  WARMUP_ITERS: 1000\r\n  WARMUP_METHOD: linear\r\n  WEIGHT_DECAY: 0.0001\r\n  WEIGHT_DECAY_BIAS: null\r\n  WEIGHT_DECAY_NORM: 0.0\r\nTEST:\r\n  AUG:\r\n    ENABLED: false\r\n    FLIP: true\r\n    MAX_SIZE: 4000\r\n    MIN_SIZES:\r\n    - 400\r\n    - 500\r\n    - 600\r\n    - 700\r\n    - 800\r\n    - 900\r\n    - 1000\r\n    - 1100\r\n    - 1200\r\n  DETECTIONS_PER_IMAGE: 100\r\n  EVAL_PERIOD: 0\r\n  EXPECTED_RESULTS: []\r\n  KEYPOINT_OKS_SIGMAS: []\r\n  PRECISE_BN:\r\n    ENABLED: false\r\n    NUM_ITER: 200\r\nVERSION: 2\r\nVIS_PERIOD: 0\r\n\r\n```\r\nIn the config.yaml file, I can see that \"val\" is there still I am getting this issue. What am I doing wrong? \r\n\r\n\"Instructions To Reproduce the Issue and Full Logs\":\r\nconfig.yaml file is provided and It can be run using the above command. \r\n\r\nEnvironment:\r\nIt is  environemnt is setup using https://detectron2.readthedocs.io/en/latest/tutorials/install.html\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "RajUpadhyay",
        "body": "@AakashGoyal25 trying changing your export-method from **caffe2_tracing** to **tracing**."
      },
      {
        "user": "AakashGoyal25",
        "body": "@RajUpadhyay Even after changing export method to \"tracing\", I am getting same error mentioned above. Any other suggestion?"
      }
    ]
  },
  {
    "issue_number": 4566,
    "title": "VitDet huge checkpoint says about incompatible shapes & missing layers in the backbone",
    "author": "kretes",
    "state": "open",
    "created_at": "2022-09-23T18:28:15Z",
    "updated_at": "2024-07-31T16:00:32Z",
    "labels": [],
    "body": "\r\n## Instructions To Reproduce the Issue:\r\n\r\n1. Full runnable code or full changes you made:\r\n```\r\nno changes\r\n```\r\n2. What exact command you run:\r\n`tools/lazyconfig_train_net.py --config-file projects/ViTDet/configs/COCO/mask_rcnn_vitdet_h_75ep.py \"dataloader.train.total_batch_size=1\"`\r\n4. __Full logs__ or other relevant observations:\r\n```\r\n[09/23 17:55:36 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://ImageNetPretrained/MAE/mae_pretrain_vit_huge_p14to16.pth ...\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of backbone.simfp_2.4.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of backbone.simfp_2.4.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of backbone.simfp_2.5.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of backbone.simfp_2.5.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of backbone.simfp_3.1.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of backbone.simfp_3.1.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of backbone.simfp_3.2.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of backbone.simfp_3.2.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of backbone.simfp_4.0.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of backbone.simfp_4.0.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of backbone.simfp_4.1.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of backbone.simfp_4.1.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of backbone.simfp_5.1.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of backbone.simfp_5.1.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of backbone.simfp_5.2.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of backbone.simfp_5.2.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of roi_heads.box_head.conv1.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of roi_heads.box_head.conv1.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of roi_heads.box_head.conv2.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of roi_heads.box_head.conv2.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of roi_heads.box_head.conv3.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of roi_heads.box_head.conv3.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of roi_heads.box_head.conv4.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of roi_heads.box_head.conv4.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of roi_heads.mask_head.mask_fcn1.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of roi_heads.mask_head.mask_fcn1.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of roi_heads.mask_head.mask_fcn2.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of roi_heads.mask_head.mask_fcn2.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of roi_heads.mask_head.mask_fcn3.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of roi_heads.mask_head.mask_fcn3.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([1280]), while shape of roi_heads.mask_head.mask_fcn4.norm.bias in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([1280]), while shape of roi_heads.mask_head.mask_fcn4.norm.weight in model is torch.Size([256]).\r\nWARNING [09/23 17:55:37 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\n[09/23 17:55:37 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.net:\r\n| Names in Model        | Names in Checkpoint               | Shapes                 |\r\n|:----------------------|:----------------------------------|:-----------------------|\r\n| blocks.0.attn.proj.*  | blocks.0.attn.proj.{bias,weight}  | (1280,) (1280,1280)    |\r\n| blocks.0.attn.qkv.*   | blocks.0.attn.qkv.{bias,weight}   | (3840,) (3840,1280)    |\r\n| blocks.0.mlp.fc1.*    | blocks.0.mlp.fc1.{bias,weight}    | (5120,) (5120,1280)    |\r\n| blocks.0.mlp.fc2.*    | blocks.0.mlp.fc2.{bias,weight}    | (1280,) (1280,5120)    |\r\n| blocks.0.norm1.*      | blocks.0.norm1.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.0.norm2.*      | blocks.0.norm2.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.1.attn.proj.*  | blocks.1.attn.proj.{bias,weight}  | (1280,) (1280,1280)    |\r\n| blocks.1.attn.qkv.*   | blocks.1.attn.qkv.{bias,weight}   | (3840,) (3840,1280)    |\r\n| blocks.1.mlp.fc1.*    | blocks.1.mlp.fc1.{bias,weight}    | (5120,) (5120,1280)    |\r\n| blocks.1.mlp.fc2.*    | blocks.1.mlp.fc2.{bias,weight}    | (1280,) (1280,5120)    |\r\n| blocks.1.norm1.*      | blocks.1.norm1.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.1.norm2.*      | blocks.1.norm2.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.10.attn.proj.* | blocks.10.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.10.attn.qkv.*  | blocks.10.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.10.mlp.fc1.*   | blocks.10.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.10.mlp.fc2.*   | blocks.10.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.10.norm1.*     | blocks.10.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.10.norm2.*     | blocks.10.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.11.attn.proj.* | blocks.11.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.11.attn.qkv.*  | blocks.11.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.11.mlp.fc1.*   | blocks.11.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.11.mlp.fc2.*   | blocks.11.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.11.norm1.*     | blocks.11.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.11.norm2.*     | blocks.11.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.12.attn.proj.* | blocks.12.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.12.attn.qkv.*  | blocks.12.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.12.mlp.fc1.*   | blocks.12.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.12.mlp.fc2.*   | blocks.12.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.12.norm1.*     | blocks.12.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.12.norm2.*     | blocks.12.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.13.attn.proj.* | blocks.13.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.13.attn.qkv.*  | blocks.13.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.13.mlp.fc1.*   | blocks.13.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.13.mlp.fc2.*   | blocks.13.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.13.norm1.*     | blocks.13.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.13.norm2.*     | blocks.13.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.14.attn.proj.* | blocks.14.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.14.attn.qkv.*  | blocks.14.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.14.mlp.fc1.*   | blocks.14.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.14.mlp.fc2.*   | blocks.14.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.14.norm1.*     | blocks.14.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.14.norm2.*     | blocks.14.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.15.attn.proj.* | blocks.15.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.15.attn.qkv.*  | blocks.15.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.15.mlp.fc1.*   | blocks.15.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.15.mlp.fc2.*   | blocks.15.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.15.norm1.*     | blocks.15.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.15.norm2.*     | blocks.15.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.16.attn.proj.* | blocks.16.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.16.attn.qkv.*  | blocks.16.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.16.mlp.fc1.*   | blocks.16.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.16.mlp.fc2.*   | blocks.16.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.16.norm1.*     | blocks.16.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.16.norm2.*     | blocks.16.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.17.attn.proj.* | blocks.17.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.17.attn.qkv.*  | blocks.17.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.17.mlp.fc1.*   | blocks.17.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.17.mlp.fc2.*   | blocks.17.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.17.norm1.*     | blocks.17.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.17.norm2.*     | blocks.17.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.18.attn.proj.* | blocks.18.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.18.attn.qkv.*  | blocks.18.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.18.mlp.fc1.*   | blocks.18.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.18.mlp.fc2.*   | blocks.18.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.18.norm1.*     | blocks.18.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.18.norm2.*     | blocks.18.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.19.attn.proj.* | blocks.19.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.19.attn.qkv.*  | blocks.19.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.19.mlp.fc1.*   | blocks.19.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.19.mlp.fc2.*   | blocks.19.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.19.norm1.*     | blocks.19.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.19.norm2.*     | blocks.19.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.2.attn.proj.*  | blocks.2.attn.proj.{bias,weight}  | (1280,) (1280,1280)    |\r\n| blocks.2.attn.qkv.*   | blocks.2.attn.qkv.{bias,weight}   | (3840,) (3840,1280)    |\r\n| blocks.2.mlp.fc1.*    | blocks.2.mlp.fc1.{bias,weight}    | (5120,) (5120,1280)    |\r\n| blocks.2.mlp.fc2.*    | blocks.2.mlp.fc2.{bias,weight}    | (1280,) (1280,5120)    |\r\n| blocks.2.norm1.*      | blocks.2.norm1.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.2.norm2.*      | blocks.2.norm2.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.20.attn.proj.* | blocks.20.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.20.attn.qkv.*  | blocks.20.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.20.mlp.fc1.*   | blocks.20.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.20.mlp.fc2.*   | blocks.20.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.20.norm1.*     | blocks.20.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.20.norm2.*     | blocks.20.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.21.attn.proj.* | blocks.21.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.21.attn.qkv.*  | blocks.21.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.21.mlp.fc1.*   | blocks.21.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.21.mlp.fc2.*   | blocks.21.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.21.norm1.*     | blocks.21.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.21.norm2.*     | blocks.21.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.22.attn.proj.* | blocks.22.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.22.attn.qkv.*  | blocks.22.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.22.mlp.fc1.*   | blocks.22.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.22.mlp.fc2.*   | blocks.22.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.22.norm1.*     | blocks.22.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.22.norm2.*     | blocks.22.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.23.attn.proj.* | blocks.23.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.23.attn.qkv.*  | blocks.23.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.23.mlp.fc1.*   | blocks.23.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.23.mlp.fc2.*   | blocks.23.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.23.norm1.*     | blocks.23.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.23.norm2.*     | blocks.23.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.24.attn.proj.* | blocks.24.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.24.attn.qkv.*  | blocks.24.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.24.mlp.fc1.*   | blocks.24.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.24.mlp.fc2.*   | blocks.24.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.24.norm1.*     | blocks.24.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.24.norm2.*     | blocks.24.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.25.attn.proj.* | blocks.25.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.25.attn.qkv.*  | blocks.25.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.25.mlp.fc1.*   | blocks.25.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.25.mlp.fc2.*   | blocks.25.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.25.norm1.*     | blocks.25.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.25.norm2.*     | blocks.25.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.26.attn.proj.* | blocks.26.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.26.attn.qkv.*  | blocks.26.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.26.mlp.fc1.*   | blocks.26.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.26.mlp.fc2.*   | blocks.26.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.26.norm1.*     | blocks.26.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.26.norm2.*     | blocks.26.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.27.attn.proj.* | blocks.27.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.27.attn.qkv.*  | blocks.27.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.27.mlp.fc1.*   | blocks.27.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.27.mlp.fc2.*   | blocks.27.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.27.norm1.*     | blocks.27.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.27.norm2.*     | blocks.27.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.28.attn.proj.* | blocks.28.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.28.attn.qkv.*  | blocks.28.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.28.mlp.fc1.*   | blocks.28.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.28.mlp.fc2.*   | blocks.28.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.28.norm1.*     | blocks.28.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.28.norm2.*     | blocks.28.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.29.attn.proj.* | blocks.29.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.29.attn.qkv.*  | blocks.29.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.29.mlp.fc1.*   | blocks.29.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.29.mlp.fc2.*   | blocks.29.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.29.norm1.*     | blocks.29.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.29.norm2.*     | blocks.29.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.3.attn.proj.*  | blocks.3.attn.proj.{bias,weight}  | (1280,) (1280,1280)    |\r\n| blocks.3.attn.qkv.*   | blocks.3.attn.qkv.{bias,weight}   | (3840,) (3840,1280)    |\r\n| blocks.3.mlp.fc1.*    | blocks.3.mlp.fc1.{bias,weight}    | (5120,) (5120,1280)    |\r\n| blocks.3.mlp.fc2.*    | blocks.3.mlp.fc2.{bias,weight}    | (1280,) (1280,5120)    |\r\n| blocks.3.norm1.*      | blocks.3.norm1.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.3.norm2.*      | blocks.3.norm2.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.30.attn.proj.* | blocks.30.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.30.attn.qkv.*  | blocks.30.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.30.mlp.fc1.*   | blocks.30.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.30.mlp.fc2.*   | blocks.30.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.30.norm1.*     | blocks.30.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.30.norm2.*     | blocks.30.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.31.attn.proj.* | blocks.31.attn.proj.{bias,weight} | (1280,) (1280,1280)    |\r\n| blocks.31.attn.qkv.*  | blocks.31.attn.qkv.{bias,weight}  | (3840,) (3840,1280)    |\r\n| blocks.31.mlp.fc1.*   | blocks.31.mlp.fc1.{bias,weight}   | (5120,) (5120,1280)    |\r\n| blocks.31.mlp.fc2.*   | blocks.31.mlp.fc2.{bias,weight}   | (1280,) (1280,5120)    |\r\n| blocks.31.norm1.*     | blocks.31.norm1.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.31.norm2.*     | blocks.31.norm2.{bias,weight}     | (1280,) (1280,)        |\r\n| blocks.4.attn.proj.*  | blocks.4.attn.proj.{bias,weight}  | (1280,) (1280,1280)    |\r\n| blocks.4.attn.qkv.*   | blocks.4.attn.qkv.{bias,weight}   | (3840,) (3840,1280)    |\r\n| blocks.4.mlp.fc1.*    | blocks.4.mlp.fc1.{bias,weight}    | (5120,) (5120,1280)    |\r\n| blocks.4.mlp.fc2.*    | blocks.4.mlp.fc2.{bias,weight}    | (1280,) (1280,5120)    |\r\n| blocks.4.norm1.*      | blocks.4.norm1.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.4.norm2.*      | blocks.4.norm2.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.5.attn.proj.*  | blocks.5.attn.proj.{bias,weight}  | (1280,) (1280,1280)    |\r\n| blocks.5.attn.qkv.*   | blocks.5.attn.qkv.{bias,weight}   | (3840,) (3840,1280)    |\r\n| blocks.5.mlp.fc1.*    | blocks.5.mlp.fc1.{bias,weight}    | (5120,) (5120,1280)    |\r\n| blocks.5.mlp.fc2.*    | blocks.5.mlp.fc2.{bias,weight}    | (1280,) (1280,5120)    |\r\n| blocks.5.norm1.*      | blocks.5.norm1.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.5.norm2.*      | blocks.5.norm2.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.6.attn.proj.*  | blocks.6.attn.proj.{bias,weight}  | (1280,) (1280,1280)    |\r\n| blocks.6.attn.qkv.*   | blocks.6.attn.qkv.{bias,weight}   | (3840,) (3840,1280)    |\r\n| blocks.6.mlp.fc1.*    | blocks.6.mlp.fc1.{bias,weight}    | (5120,) (5120,1280)    |\r\n| blocks.6.mlp.fc2.*    | blocks.6.mlp.fc2.{bias,weight}    | (1280,) (1280,5120)    |\r\n| blocks.6.norm1.*      | blocks.6.norm1.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.6.norm2.*      | blocks.6.norm2.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.7.attn.proj.*  | blocks.7.attn.proj.{bias,weight}  | (1280,) (1280,1280)    |\r\n| blocks.7.attn.qkv.*   | blocks.7.attn.qkv.{bias,weight}   | (3840,) (3840,1280)    |\r\n| blocks.7.mlp.fc1.*    | blocks.7.mlp.fc1.{bias,weight}    | (5120,) (5120,1280)    |\r\n| blocks.7.mlp.fc2.*    | blocks.7.mlp.fc2.{bias,weight}    | (1280,) (1280,5120)    |\r\n| blocks.7.norm1.*      | blocks.7.norm1.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.7.norm2.*      | blocks.7.norm2.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.8.attn.proj.*  | blocks.8.attn.proj.{bias,weight}  | (1280,) (1280,1280)    |\r\n| blocks.8.attn.qkv.*   | blocks.8.attn.qkv.{bias,weight}   | (3840,) (3840,1280)    |\r\n| blocks.8.mlp.fc1.*    | blocks.8.mlp.fc1.{bias,weight}    | (5120,) (5120,1280)    |\r\n| blocks.8.mlp.fc2.*    | blocks.8.mlp.fc2.{bias,weight}    | (1280,) (1280,5120)    |\r\n| blocks.8.norm1.*      | blocks.8.norm1.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.8.norm2.*      | blocks.8.norm2.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.9.attn.proj.*  | blocks.9.attn.proj.{bias,weight}  | (1280,) (1280,1280)    |\r\n| blocks.9.attn.qkv.*   | blocks.9.attn.qkv.{bias,weight}   | (3840,) (3840,1280)    |\r\n| blocks.9.mlp.fc1.*    | blocks.9.mlp.fc1.{bias,weight}    | (5120,) (5120,1280)    |\r\n| blocks.9.mlp.fc2.*    | blocks.9.mlp.fc2.{bias,weight}    | (1280,) (1280,5120)    |\r\n| blocks.9.norm1.*      | blocks.9.norm1.{bias,weight}      | (1280,) (1280,)        |\r\n| blocks.9.norm2.*      | blocks.9.norm2.{bias,weight}      | (1280,) (1280,)        |\r\n| patch_embed.proj.*    | patch_embed.proj.{bias,weight}    | (1280,) (1280,3,16,16) |\r\n| pos_embed             | pos_embed                         | (1, 197, 1280)         |\r\nWARNING [09/23 17:55:37 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:\r\nbackbone.net.blocks.0.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.1.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.10.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.11.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.12.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.13.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.14.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.15.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.16.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.17.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.18.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.19.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.2.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.20.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.21.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.22.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.23.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.24.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.25.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.26.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.27.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.28.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.29.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.3.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.30.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.31.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.4.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.5.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.6.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.7.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.8.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.9.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.simfp_2.0.{bias, weight}\r\nbackbone.simfp_2.1.{bias, weight}\r\nbackbone.simfp_2.3.{bias, weight}\r\nbackbone.simfp_2.4.norm.{bias, weight}\r\nbackbone.simfp_2.4.weight\r\nbackbone.simfp_2.5.norm.{bias, weight}\r\nbackbone.simfp_2.5.weight\r\nbackbone.simfp_3.0.{bias, weight}\r\nbackbone.simfp_3.1.norm.{bias, weight}\r\nbackbone.simfp_3.1.weight\r\nbackbone.simfp_3.2.norm.{bias, weight}\r\nbackbone.simfp_3.2.weight\r\nbackbone.simfp_4.0.norm.{bias, weight}\r\nbackbone.simfp_4.0.weight\r\nbackbone.simfp_4.1.norm.{bias, weight}\r\nbackbone.simfp_4.1.weight\r\nbackbone.simfp_5.1.norm.{bias, weight}\r\nbackbone.simfp_5.1.weight\r\nbackbone.simfp_5.2.norm.{bias, weight}\r\nbackbone.simfp_5.2.weight\r\nproposal_generator.rpn_head.anchor_deltas.{bias, weight}\r\nproposal_generator.rpn_head.conv.conv0.{bias, weight}\r\nproposal_generator.rpn_head.conv.conv1.{bias, weight}\r\nproposal_generator.rpn_head.objectness_logits.{bias, weight}\r\nroi_heads.box_head.conv1.norm.{bias, weight}\r\nroi_heads.box_head.conv1.weight\r\nroi_heads.box_head.conv2.norm.{bias, weight}\r\nroi_heads.box_head.conv2.weight\r\nroi_heads.box_head.conv3.norm.{bias, weight}\r\nroi_heads.box_head.conv3.weight\r\nroi_heads.box_head.conv4.norm.{bias, weight}\r\nroi_heads.box_head.conv4.weight\r\nroi_heads.box_head.fc1.{bias, weight}\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\nroi_heads.mask_head.deconv.{bias, weight}\r\nroi_heads.mask_head.mask_fcn1.norm.{bias, weight}\r\nroi_heads.mask_head.mask_fcn1.weight\r\nroi_heads.mask_head.mask_fcn2.norm.{bias, weight}\r\nroi_heads.mask_head.mask_fcn2.weight\r\nroi_heads.mask_head.mask_fcn3.norm.{bias, weight}\r\nroi_heads.mask_head.mask_fcn3.weight\r\nroi_heads.mask_head.mask_fcn4.norm.{bias, weight}\r\nroi_heads.mask_head.mask_fcn4.weight\r\nroi_heads.mask_head.predictor.{bias, weight}\r\nWARNING [09/23 17:55:37 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:\r\n  cls_token\r\n  norm.{bias, weight}\r\ncheckpointer resumed\r\n```\r\n\r\n## Expected behavior:\r\n\r\nThe logs above are about loading the ImageNet pretrained on MAE checkpoint into a VitDet. The messages about incompatible shapes & missing weights *in the backbone* are unexpected and lead me to a belief this is a wrong checkpoint for the model.\r\nI think it boils down ito missing weights in patterns:\r\n```\r\n- backbone.net.blocks.*.attn.rel_pos*\r\n- backbone.simfp_*.*\r\n```\r\n\r\nIn case those were were ignored on purpose when exporting checkpoint - I think it would be best to specify the `expected missing weights` (as e.g. the rpn and roi_heads are not expected to be in this checkpoint). If not - maybe good idea to add a print before loading the checkpoint about the expected output, or a comment in configuration file in places like https://github.com/facebookresearch/detectron2/blob/main/projects/ViTDet/configs/COCO/mask_rcnn_vitdet_h_75ep.py#L12\r\n \r\n## Environment:\r\n\r\nPaste the output of the following command:\r\n```\r\nwget -nc -nv https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\n```\r\n----------------------  --------------------------------------------------------------------------\r\nsys.platform            linux\r\nPython                  3.8.10 (default, Jun 22 2022, 20:18:18) [GCC 9.4.0]\r\nnumpy                   1.23.3\r\ndetectron2              0.6 @/home/appuser/focal-detectron2/detectron2\r\nCompiler                GCC 9.4\r\nCUDA compiler           CUDA 11.1\r\ndetectron2 arch flags   3.5, 3.7, 5.0, 5.2, 5.3, 6.0, 6.1, 7.0, 7.5\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.10.0+cu111 @/home/appuser/.local/lib/python3.8/site-packages/torch\r\nPyTorch debug build     False\r\nGPU available           Yes\r\nGPU 0                   NVIDIA A100-SXM4-40GB (arch=8.0)\r\nDriver version          510.47.03\r\nCUDA_HOME               /usr/local/cuda\r\nTORCH_CUDA_ARCH_LIST    Kepler;Kepler+Tesla;Maxwell;Maxwell+Tegra;Pascal;Volta;Turing\r\nPillow                  8.1.0\r\ntorchvision             0.11.1+cu111 @/home/appuser/.local/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\r\nfvcore                  0.1.5\r\niopath                  0.1.9\r\ncv2                     4.6.0\r\n----------------------  --------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 7.3\r\n  - C++ Version: 201402\r\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX512\r\n  - CUDA Runtime 11.1\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\r\n  - CuDNN 8.0.5\r\n  - Magma 2.5.2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,\r\n\r\n```",
    "comments": [
      {
        "user": "FedericoVasile1",
        "body": "Hi, any news on this? Are the weights ignored on purpose or not?"
      },
      {
        "user": "gugibugy",
        "body": "+1, have same question!"
      },
      {
        "user": "amalshehan",
        "body": "Since the weights are missing in the checkpoint and expected in the model, I am assuming they will be randomly initialized and trained with the downstream task. Any other insights workarounds ?  "
      }
    ]
  },
  {
    "issue_number": 5331,
    "title": "RuntimeError: d.is_cuda() INTERNAL ASSERT FAILED",
    "author": "wenbo-wei",
    "state": "open",
    "created_at": "2024-07-22T06:27:52Z",
    "updated_at": "2024-07-28T20:20:21Z",
    "labels": [],
    "body": "Every time I train Mask2Former with Detectron2, I encounter the same error. The specific error is as follows:\r\n\r\nVariable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\r\nRuntimeError: d.is_cuda() INTERNAL ASSERT FAILED at \"/opt/conda/conda-bld/pytorch_1678402421473/work/c10/cuda/impl/CUDAGuardImpl.h\":31, please report a bug to PyTorch.\r\n\r\nThis error does not appear at the beginning but usually occurs after running for a long time, such as 5 hours. This makes debugging very difficult. I would be very grateful if someone could help me look into this issue.",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "dunyang97",
        "body": "do you have some solution about it?  I also face the totally some error, and i test several different version of cuda, torch, nvidia-driver, even ubuntu systen, it still come out."
      },
      {
        "user": "wenbo-wei",
        "body": "> do you have some solution about it?  I also face the totally some error, and i test several different version of cuda, torch, nvidia-driver, even ubuntu systen, it still come out.\n\nI have tested different combinations of cuda versions, PyTorch versions and Ubuntu versions. For now, I guess this is because your installed cuda version for your system is different from the cuda version used in your Conda environment. After I installed the same cuda version, this error disappeared. But when I run my code in the same cuda version, there is another issue occurs, which is as follows:\n\nreturn Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\nRuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\n\nIt appears once but disappears after I restart my server.\n\nI'm trying to fix this issue by installing PyTorch using Conda (previous I installed PyTorch environment using pip). Different installation methods like pip or Conda may introduce more complex errors I guess. Anyway, any updates, please let me know. Thanks!"
      }
    ]
  },
  {
    "issue_number": 4641,
    "title": "Loading checkpoint for ViTDet raises shape mismatch warning",
    "author": "layadas",
    "state": "open",
    "created_at": "2022-11-04T10:53:12Z",
    "updated_at": "2024-07-26T23:01:59Z",
    "labels": [],
    "body": "\r\n## Instructions To Reproduce the Issue:\r\nI installed Detectron2 and attempted to train the ViTDet base model from the documentation provided here: https://github.com/facebookresearch/detectron2/tree/main/projects/ViTDet\r\n\r\nI have made no changes to the configs, or any other files.\r\n\r\nThe exact command I run is (copy-pasted from the page linked above):\r\n`../../tools/lazyconfig_train_net.py --config-file configs/path/to/config.py`\r\n\r\nEverything works smoothly, and the model also starts to train, but a lot of warning messages are generated, that point to different sizes of the `norm.bias` and `norm.weight` of the checkpoint and the model.\r\nThe relevant part of the output log is:\r\n```\r\n[11/04 11:35:50 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://ImageNetPretrained/MAE/mae_pretrain_vit_base.pth ...\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_2.4.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_2.4.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_2.5.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_2.5.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_3.1.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_3.1.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_3.2.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_3.2.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_4.0.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_4.0.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_4.1.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_4.1.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_5.1.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_5.1.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_5.2.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_5.2.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv1.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv1.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv2.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv2.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv3.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv3.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv4.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv4.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn1.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn1.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn2.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn2.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn3.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn3.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn4.norm.bias in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.bias will not be loaded. Please double check and see if this is desired.\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn4.norm.weight in model is torch.Size([256]).\r\nWARNING [11/04 11:35:50 d2.checkpoint.c2_model_loading]: norm.weight will not be loaded. Please double check and see if this is desired.\r\n[11/04 11:35:50 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.net:\r\n| Names in Model        | Names in Checkpoint               | Shapes               |\r\n|:----------------------|:----------------------------------|:---------------------|\r\n| blocks.0.attn.proj.*  | blocks.0.attn.proj.{bias,weight}  | (768,) (768,768)     |\r\n| blocks.0.attn.qkv.*   | blocks.0.attn.qkv.{bias,weight}   | (2304,) (2304,768)   |\r\n| blocks.0.mlp.fc1.*    | blocks.0.mlp.fc1.{bias,weight}    | (3072,) (3072,768)   |\r\n| blocks.0.mlp.fc2.*    | blocks.0.mlp.fc2.{bias,weight}    | (768,) (768,3072)    |\r\n| blocks.0.norm1.*      | blocks.0.norm1.{bias,weight}      | (768,) (768,)        |\r\n| blocks.0.norm2.*      | blocks.0.norm2.{bias,weight}      | (768,) (768,)        |\r\n| blocks.1.attn.proj.*  | blocks.1.attn.proj.{bias,weight}  | (768,) (768,768)     |\r\n| blocks.1.attn.qkv.*   | blocks.1.attn.qkv.{bias,weight}   | (2304,) (2304,768)   |\r\n| blocks.1.mlp.fc1.*    | blocks.1.mlp.fc1.{bias,weight}    | (3072,) (3072,768)   |\r\n| blocks.1.mlp.fc2.*    | blocks.1.mlp.fc2.{bias,weight}    | (768,) (768,3072)    |\r\n| blocks.1.norm1.*      | blocks.1.norm1.{bias,weight}      | (768,) (768,)        |\r\n| blocks.1.norm2.*      | blocks.1.norm2.{bias,weight}      | (768,) (768,)        |\r\n| blocks.10.attn.proj.* | blocks.10.attn.proj.{bias,weight} | (768,) (768,768)     |\r\n| blocks.10.attn.qkv.*  | blocks.10.attn.qkv.{bias,weight}  | (2304,) (2304,768)   |\r\n| blocks.10.mlp.fc1.*   | blocks.10.mlp.fc1.{bias,weight}   | (3072,) (3072,768)   |\r\n| blocks.10.mlp.fc2.*   | blocks.10.mlp.fc2.{bias,weight}   | (768,) (768,3072)    |\r\n| blocks.10.norm1.*     | blocks.10.norm1.{bias,weight}     | (768,) (768,)        |\r\n| blocks.10.norm2.*     | blocks.10.norm2.{bias,weight}     | (768,) (768,)        |\r\n| blocks.11.attn.proj.* | blocks.11.attn.proj.{bias,weight} | (768,) (768,768)     |\r\n| blocks.11.attn.qkv.*  | blocks.11.attn.qkv.{bias,weight}  | (2304,) (2304,768)   |\r\n| blocks.11.mlp.fc1.*   | blocks.11.mlp.fc1.{bias,weight}   | (3072,) (3072,768)   |\r\n| blocks.11.mlp.fc2.*   | blocks.11.mlp.fc2.{bias,weight}   | (768,) (768,3072)    |\r\n| blocks.11.norm1.*     | blocks.11.norm1.{bias,weight}     | (768,) (768,)        |\r\n| blocks.11.norm2.*     | blocks.11.norm2.{bias,weight}     | (768,) (768,)        |\r\n| blocks.2.attn.proj.*  | blocks.2.attn.proj.{bias,weight}  | (768,) (768,768)     |\r\n| blocks.2.attn.qkv.*   | blocks.2.attn.qkv.{bias,weight}   | (2304,) (2304,768)   |\r\n| blocks.2.mlp.fc1.*    | blocks.2.mlp.fc1.{bias,weight}    | (3072,) (3072,768)   |\r\n| blocks.2.mlp.fc2.*    | blocks.2.mlp.fc2.{bias,weight}    | (768,) (768,3072)    |\r\n| blocks.2.norm1.*      | blocks.2.norm1.{bias,weight}      | (768,) (768,)        |\r\n| blocks.2.norm2.*      | blocks.2.norm2.{bias,weight}      | (768,) (768,)        |\r\n| blocks.3.attn.proj.*  | blocks.3.attn.proj.{bias,weight}  | (768,) (768,768)     |\r\n| blocks.3.attn.qkv.*   | blocks.3.attn.qkv.{bias,weight}   | (2304,) (2304,768)   |\r\n| blocks.3.mlp.fc1.*    | blocks.3.mlp.fc1.{bias,weight}    | (3072,) (3072,768)   |\r\n| blocks.3.mlp.fc2.*    | blocks.3.mlp.fc2.{bias,weight}    | (768,) (768,3072)    |\r\n| blocks.3.norm1.*      | blocks.3.norm1.{bias,weight}      | (768,) (768,)        |\r\n| blocks.3.norm2.*      | blocks.3.norm2.{bias,weight}      | (768,) (768,)        |\r\n| blocks.4.attn.proj.*  | blocks.4.attn.proj.{bias,weight}  | (768,) (768,768)     |\r\n| blocks.4.attn.qkv.*   | blocks.4.attn.qkv.{bias,weight}   | (2304,) (2304,768)   |\r\n| blocks.4.mlp.fc1.*    | blocks.4.mlp.fc1.{bias,weight}    | (3072,) (3072,768)   |\r\n| blocks.4.mlp.fc2.*    | blocks.4.mlp.fc2.{bias,weight}    | (768,) (768,3072)    |\r\n| blocks.4.norm1.*      | blocks.4.norm1.{bias,weight}      | (768,) (768,)        |\r\n| blocks.4.norm2.*      | blocks.4.norm2.{bias,weight}      | (768,) (768,)        |\r\n| blocks.5.attn.proj.*  | blocks.5.attn.proj.{bias,weight}  | (768,) (768,768)     |\r\n| blocks.5.attn.qkv.*   | blocks.5.attn.qkv.{bias,weight}   | (2304,) (2304,768)   |\r\n| blocks.5.mlp.fc1.*    | blocks.5.mlp.fc1.{bias,weight}    | (3072,) (3072,768)   |\r\n| blocks.5.mlp.fc2.*    | blocks.5.mlp.fc2.{bias,weight}    | (768,) (768,3072)    |\r\n| blocks.5.norm1.*      | blocks.5.norm1.{bias,weight}      | (768,) (768,)        |\r\n| blocks.5.norm2.*      | blocks.5.norm2.{bias,weight}      | (768,) (768,)        |\r\n| blocks.6.attn.proj.*  | blocks.6.attn.proj.{bias,weight}  | (768,) (768,768)     |\r\n| blocks.6.attn.qkv.*   | blocks.6.attn.qkv.{bias,weight}   | (2304,) (2304,768)   |\r\n| blocks.6.mlp.fc1.*    | blocks.6.mlp.fc1.{bias,weight}    | (3072,) (3072,768)   |\r\n| blocks.6.mlp.fc2.*    | blocks.6.mlp.fc2.{bias,weight}    | (768,) (768,3072)    |\r\n| blocks.6.norm1.*      | blocks.6.norm1.{bias,weight}      | (768,) (768,)        |\r\n| blocks.6.norm2.*      | blocks.6.norm2.{bias,weight}      | (768,) (768,)        |\r\n| blocks.7.attn.proj.*  | blocks.7.attn.proj.{bias,weight}  | (768,) (768,768)     |\r\n| blocks.7.attn.qkv.*   | blocks.7.attn.qkv.{bias,weight}   | (2304,) (2304,768)   |\r\n| blocks.7.mlp.fc1.*    | blocks.7.mlp.fc1.{bias,weight}    | (3072,) (3072,768)   |\r\n| blocks.7.mlp.fc2.*    | blocks.7.mlp.fc2.{bias,weight}    | (768,) (768,3072)    |\r\n| blocks.7.norm1.*      | blocks.7.norm1.{bias,weight}      | (768,) (768,)        |\r\n| blocks.7.norm2.*      | blocks.7.norm2.{bias,weight}      | (768,) (768,)        |\r\n| blocks.8.attn.proj.*  | blocks.8.attn.proj.{bias,weight}  | (768,) (768,768)     |\r\n| blocks.8.attn.qkv.*   | blocks.8.attn.qkv.{bias,weight}   | (2304,) (2304,768)   |\r\n| blocks.8.mlp.fc1.*    | blocks.8.mlp.fc1.{bias,weight}    | (3072,) (3072,768)   |\r\n| blocks.8.mlp.fc2.*    | blocks.8.mlp.fc2.{bias,weight}    | (768,) (768,3072)    |\r\n| blocks.8.norm1.*      | blocks.8.norm1.{bias,weight}      | (768,) (768,)        |\r\n| blocks.8.norm2.*      | blocks.8.norm2.{bias,weight}      | (768,) (768,)        |\r\n| blocks.9.attn.proj.*  | blocks.9.attn.proj.{bias,weight}  | (768,) (768,768)     |\r\n| blocks.9.attn.qkv.*   | blocks.9.attn.qkv.{bias,weight}   | (2304,) (2304,768)   |\r\n| blocks.9.mlp.fc1.*    | blocks.9.mlp.fc1.{bias,weight}    | (3072,) (3072,768)   |\r\n| blocks.9.mlp.fc2.*    | blocks.9.mlp.fc2.{bias,weight}    | (768,) (768,3072)    |\r\n| blocks.9.norm1.*      | blocks.9.norm1.{bias,weight}      | (768,) (768,)        |\r\n| blocks.9.norm2.*      | blocks.9.norm2.{bias,weight}      | (768,) (768,)        |\r\n| patch_embed.proj.*    | patch_embed.proj.{bias,weight}    | (768,) (768,3,16,16) |\r\n| pos_embed             | pos_embed                         | (1, 197, 768)        |\r\nWARNING [11/04 11:35:50 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:\r\nbackbone.net.blocks.0.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.1.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.10.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.11.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.2.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.3.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.4.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.5.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.6.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.7.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.8.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.net.blocks.9.attn.{rel_pos_h, rel_pos_w}\r\nbackbone.simfp_2.0.{bias, weight}\r\nbackbone.simfp_2.1.{bias, weight}\r\nbackbone.simfp_2.3.{bias, weight}\r\nbackbone.simfp_2.4.norm.{bias, weight}\r\nbackbone.simfp_2.4.weight\r\nbackbone.simfp_2.5.norm.{bias, weight}\r\nbackbone.simfp_2.5.weight\r\nbackbone.simfp_3.0.{bias, weight}\r\nbackbone.simfp_3.1.norm.{bias, weight}\r\nbackbone.simfp_3.1.weight\r\nbackbone.simfp_3.2.norm.{bias, weight}\r\nbackbone.simfp_3.2.weight\r\nbackbone.simfp_4.0.norm.{bias, weight}\r\nbackbone.simfp_4.0.weight\r\nbackbone.simfp_4.1.norm.{bias, weight}\r\nbackbone.simfp_4.1.weight\r\nbackbone.simfp_5.1.norm.{bias, weight}\r\nbackbone.simfp_5.1.weight\r\nbackbone.simfp_5.2.norm.{bias, weight}\r\nbackbone.simfp_5.2.weight\r\nproposal_generator.rpn_head.anchor_deltas.{bias, weight}\r\nproposal_generator.rpn_head.conv.conv0.{bias, weight}\r\nproposal_generator.rpn_head.conv.conv1.{bias, weight}\r\nproposal_generator.rpn_head.objectness_logits.{bias, weight}\r\nroi_heads.box_head.conv1.norm.{bias, weight}\r\nroi_heads.box_head.conv1.weight\r\nroi_heads.box_head.conv2.norm.{bias, weight}\r\nroi_heads.box_head.conv2.weight\r\nroi_heads.box_head.conv3.norm.{bias, weight}\r\nroi_heads.box_head.conv3.weight\r\nroi_heads.box_head.conv4.norm.{bias, weight}\r\nroi_heads.box_head.conv4.weight\r\nroi_heads.box_head.fc1.{bias, weight}\r\nroi_heads.box_predictor.bbox_pred.{bias, weight}\r\nroi_heads.box_predictor.cls_score.{bias, weight}\r\nroi_heads.mask_head.deconv.{bias, weight}\r\nroi_heads.mask_head.mask_fcn1.norm.{bias, weight}\r\nroi_heads.mask_head.mask_fcn1.weight\r\nroi_heads.mask_head.mask_fcn2.norm.{bias, weight}\r\nroi_heads.mask_head.mask_fcn2.weight\r\nroi_heads.mask_head.mask_fcn3.norm.{bias, weight}\r\nroi_heads.mask_head.mask_fcn3.weight\r\nroi_heads.mask_head.mask_fcn4.norm.{bias, weight}\r\nroi_heads.mask_head.mask_fcn4.weight\r\nroi_heads.mask_head.predictor.{bias, weight}\r\nWARNING [11/04 11:35:50 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:\r\n  cls_token\r\n  norm.{bias, weight}\r\n[11/04 11:35:50 d2.engine.train_loop]: Starting training from iteration 0\r\n```\r\n\r\nIt goes on to train the model, but I stop it because I am not sure if the model architecture is correct or not.\r\n\r\n## Expected behavior:\r\n\r\nSince everything is untouched after installation, shape mismatches are should not occur. I am not clear why this is happening. If there is a way to change the model settings so that these warnings do not occur, then that would be of great help. Thank you.\r\n\r\n## Environment:\r\n\r\nPaste the output of the following command:\r\n```\r\n----------------------  -------------------------------------------------------------------------\r\nsys.platform            win32\r\nPython                  3.8.13 (default, Oct 19 2022, 22:38:03) [MSC v.1916 64 bit (AMD64)]\r\nnumpy                   1.23.3\r\ndetectron2              0.6 @c:\\ssl_imbalance\\testproject2\\detectron2\\detectron2\r\nCompiler                MSVC 192930141\r\nCUDA compiler           not available\r\nDETECTRON2_ENV_MODULE   <not set>\r\nPyTorch                 1.12.1 @C:\\APPS\\Anaconda3\\envs\\TestProject2\\lib\\site-packages\\torch\r\nPyTorch debug build     False\r\nGPU available           Yes\r\nGPU 0,1,2               NVIDIA RTX A6000 (arch=8.6)\r\nDriver version\r\nCUDA_HOME               None - invalid!\r\nPillow                  9.2.0\r\ntorchvision             0.13.1 @C:\\APPS\\Anaconda3\\envs\\TestProject2\\lib\\site-packages\\torchvision\r\ntorchvision arch flags  C:\\APPS\\Anaconda3\\envs\\TestProject2\\lib\\site-packages\\torchvision\\_C.pyd\r\nfvcore                  0.1.5.post20220512\r\niopath                  0.1.9\r\ncv2                     Not found\r\n----------------------  -------------------------------------------------------------------------\r\nPyTorch built with:\r\n  - C++ Version: 199711\r\n  - MSVC 192829337\r\n  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\r\n  - OpenMP 2019\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - CPU capability usage: AVX2\r\n  - CUDA Runtime 11.3\r\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\r\n  - CuDNN 8.3.2  (built against CUDA 11.5)\r\n  - Magma 2.5.4\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF,```\r\n",
    "comments": [
      {
        "user": "FedericoVasile1",
        "body": "Hi, any news on this?"
      },
      {
        "user": "gugibugy",
        "body": "+1, have same question!"
      }
    ]
  },
  {
    "issue_number": 5325,
    "title": "introduce torch.compile in DDP mode cause abnormal terminated with signal SIGSEGV",
    "author": "proshanm",
    "state": "open",
    "created_at": "2024-07-15T03:33:04Z",
    "updated_at": "2024-07-24T13:57:46Z",
    "labels": [],
    "body": "## Instructions To Reproduce the Issue:\r\nto speedup training, I add torch.compile operation after DistributedDataParallel in detectron2/engine/defaults.py:\r\n\r\n```\r\n    ddp = DistributedDataParallel(model, **kwargs)\r\n    ddp = torch.compile(ddp, mode=\"max-autotune\")\r\n```\r\nAnd I trained ViTDet model, it terminated abnormally with following exception message:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/jupyterhub/proshm/detectron2/tools/lazyconfig_train_net.py\", line 124, in <module>\r\n    launch(\r\n  File \"/home/jupyterhub/proshm/detectron2/detectron2/engine/launch.py\", line 69, in launch\r\n    mp.start_processes(\r\n  File \"/home/ps/miniconda3/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 202, in start_processes\r\n    while not context.join():\r\n              ^^^^^^^^^^^^^^\r\n  File \"/home/ps/miniconda3/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 145, in join\r\n    raise ProcessExitedException(\r\ntorch.multiprocessing.spawn.ProcessExitedException: process 3 terminated with signal SIGSEGV\r\n```\r\n## Environment:\r\nI installed detectron2 in ubuntu with pytorch 2.1\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "Programmer-RD-AI",
        "body": "Hi,\r\nPlease Check: \r\n[How to fix a SIGSEGV in pytorch when using distributed training (e.g. DDP)?](https://discuss.pytorch.org/t/how-to-fix-a-sigsegv-in-pytorch-when-using-distributed-training-e-g-ddp/113518)\r\n[Process 3 terminated with signal SIGSEGV](https://github.com/facebookresearch/fairseq/issues/1720)\r\n\r\nThank You"
      }
    ]
  },
  {
    "issue_number": 5209,
    "title": "Not able to fetch all text data & Not able to extract text, table data in proper format",
    "author": "reema93jain",
    "state": "open",
    "created_at": "2024-02-06T18:21:19Z",
    "updated_at": "2024-07-17T11:44:25Z",
    "labels": [],
    "body": "Hi Team,\r\n\r\nI am using layout parser & detectron2 to detect everything i.e. text, tables, title, list but not figures from the pdf(which I converted into image using pdf2image). I wanted to then extract the detected text, title, table, list in .txt format\r\n\r\nIssues:\r\n1)It seems like model is not recognizing all of text data properly\r\n2) While extracting data in .txt format , it appears that:\r\n       a)I am not able to print text data in sequence as it appears on pdf\r\n       b) I am not able to extract table data in tabular format\r\n\r\nCan you please suggest how I can resolve above issues? Thank you!\r\n\r\nCode:\r\nInstall necessary libraries\r\n#install detectron2:\r\n!pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2'\r\n#install layoutparser\r\n!pip install layoutparser\r\n!pip install layoutparser[ocr]\r\n##install opencv, numpy, matplotlib\r\n!pip install opencv-python numpy matplotlib\r\n!pip3 install pdf2image\r\n!sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev\r\n!apt-get install poppler-utils\r\n!pip install --upgrade google-cloud-vision\r\n!pip uninstall google-cloud-vision\r\n!pip install google-cloud-vision\r\n!apt install tesseract-ocr\r\n!apt install libtesseract-dev\r\n!pip install pytesseract\r\n\r\nimport os\r\nfrom pdf2image import convert_from_path\r\nimport shutil\r\nimport cv2\r\nimport numpy as np\r\nimport layoutparser as lp\r\nfrom pdf2image import convert_from_path\r\n\r\nDefine Pdf_path\r\npdf_file='7050X_Q_A.pdf'\r\n\r\nDefine your output file name here\r\noutput_file = 'output.txt'\r\n\r\nwith open(output_file, 'w', encoding='utf-8') as f:\r\nfor i, page_img in enumerate(convert_from_path(pdf_file)):\r\nimg = np.asarray(page_img)\r\n\r\n    model3 = lp.models.Detectron2LayoutModel(\r\n        'lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\r\n        extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5],\r\n        label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"}\r\n    )\r\n\r\n    layout_result3 = model3.detect(img)\r\n\r\n    text_blocks = lp.Layout([b for b in layout_result3 if b.type != \"Figure\"])\r\n\r\n    h, w = img.shape[:2]\r\n\r\n    left_interval = lp.Interval(0, w / 2 * 1.05, axis='x').put_on_canvas(img)\r\n\r\n    left_blocks = text_blocks.filter_by(left_interval, center=True)\r\n    left_blocks.sort(key=lambda b: b.coordinates[1])\r\n\r\n    right_blocks = [b for b in text_blocks if b not in left_blocks]\r\n    right_blocks.sort(key=lambda b: b.coordinates[1])\r\n\r\n    text_blocks = lp.Layout([b.set(id=idx) for idx, b in enumerate(left_blocks + right_blocks)])\r\n    viz=lp.draw_box(img, text_blocks,box_width=10,show_element_id=True)\r\n    display(viz)\r\n    ocr_agent = lp.TesseractAgent(languages='eng')\r\n    for block in text_blocks:\r\n           segment_image = (block\r\n                            .pad(left=5, right=5, top=5, bottom=5)\r\n                            .crop_image(img))\r\n\r\n           text = ocr_agent.detect(segment_image)\r\n           block.set(text=text, inplace=True)\r\n\r\n        # Write text to the output file\r\n    for txt in text_blocks.get_texts():\r\n        #print(txt, end='\\n---\\n')\r\n        f.write(txt + '\\n---\\n')\r\nprint(\"Text extraction completed. Check the output file:\", output_file)\r\n\r\nEnvironment\r\n\r\nWindows\r\nLayout Parser & layoutparser[ocr] version 0.3.4\r\nPyTorch version: 2.1.0+cu121\r\n!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\r\ngoogle-cloud-vision-3.5.0\r\ngoogle-api-core Version: 2.11.1\r\n6.Python 3.10.6\r\n\r\nThanks\r\nReema Jain",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "reema93jain",
        "body": "Hi Team,\r\n\r\nI tried to run code on another pdf doc-'Free_Test_Data_1MB_PDF.pdf' as I can't share the original pdf.\r\nIt seems like below code is not fetching text data in sequence & not reflecting tables data (in tabular form) at all.\r\n\r\n Instructions To Reproduce the Issue:\r\n\r\nCode:\r\nInstall necessary libraries\r\n#install detectron2:\r\n!pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2'\r\n#install layoutparser\r\n!pip install layoutparser\r\n!pip install layoutparser[ocr]\r\n##install opencv, numpy, matplotlib\r\n!pip install opencv-python numpy matplotlib\r\n!pip3 install pdf2image\r\n!sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev\r\n!apt-get install poppler-utils\r\n!pip install --upgrade google-cloud-vision\r\n!pip uninstall google-cloud-vision\r\n!pip install google-cloud-vision\r\n!apt install tesseract-ocr\r\n!apt install libtesseract-dev\r\n!pip install pytesseract\r\n\r\nimport os\r\nfrom pdf2image import convert_from_path\r\nimport shutil\r\nimport cv2\r\nimport numpy as np\r\nimport layoutparser as lp\r\nfrom pdf2image import convert_from_path\r\n\r\nDefine Pdf_path\r\npdf_file='Free_Test_Data_1MB_PDF.pdf'\r\n\r\n\r\nDefine your output file name here\r\noutput_file = 'output.txt'\r\n\r\nwith open(output_file, 'w', encoding='utf-8') as f:\r\nfor i, page_img in enumerate(convert_from_path(pdf_file)):\r\nimg = np.asarray(page_img)\r\n\r\nmodel3 = lp.models.Detectron2LayoutModel(\r\n    'lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\r\n    extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5],\r\n    label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"}\r\n)\r\n\r\nlayout_result3 = model3.detect(img)\r\n\r\ntext_blocks = lp.Layout([b for b in layout_result3 if b.type != \"Figure\"])\r\n\r\nh, w = img.shape[:2]\r\n\r\nleft_interval = lp.Interval(0, w / 2 * 1.05, axis='x').put_on_canvas(img)\r\n\r\nleft_blocks = text_blocks.filter_by(left_interval, center=True)\r\nleft_blocks.sort(key=lambda b: b.coordinates[1])\r\n\r\nright_blocks = [b for b in text_blocks if b not in left_blocks]\r\nright_blocks.sort(key=lambda b: b.coordinates[1])\r\n\r\ntext_blocks = lp.Layout([b.set(id=idx) for idx, b in enumerate(left_blocks + right_blocks)])\r\nviz=lp.draw_box(img, text_blocks,box_width=10,show_element_id=True)\r\ndisplay(viz)\r\nocr_agent = lp.TesseractAgent(languages='eng')\r\nfor block in text_blocks:\r\n       segment_image = (block\r\n                        .pad(left=5, right=5, top=5, bottom=5)\r\n                        .crop_image(img))\r\n\r\n       text = ocr_agent.detect(segment_image)\r\n       block.set(text=text, inplace=True)\r\n\r\n    # Write text to the output file\r\nfor txt in text_blocks.get_texts():\r\n    #print(txt, end='\\n---\\n')\r\n    f.write(txt + '\\n---\\n')\r\nprint(\"Text extraction completed. Check the output file:\", output_file)\r\n\r\n\r\n[Free_Test_Data_1MB_PDF.pdf](https://github.com/facebookresearch/detectron2/files/14189910/Free_Test_Data_1MB_PDF.pdf)\r\n\r\n[output (1).txt](https://github.com/facebookresearch/detectron2/files/14189916/output.1.txt)\r\n\r\nPlease guide on above query.\r\n\r\nThank you\r\nReema Jain"
      },
      {
        "user": "IsNeron",
        "body": "Same here, detectron2 faster_rcnn_R_50_FPN_3x and mask_rcnn_X_101_32x8d_FPN_3x simply ignore huge amounts of text"
      }
    ]
  },
  {
    "issue_number": 5327,
    "title": "axis 1 is out of bounds for array of dimension 1",
    "author": "14790897",
    "state": "open",
    "created_at": "2024-07-16T13:32:24Z",
    "updated_at": "2024-07-16T13:41:25Z",
    "labels": [],
    "body": "# code:\r\nhttps://www.kaggle.com/code/liuweiq/coincide-separation-detectron2-training\r\n## Environment:\r\nkaggle \r\n# error:\r\n\r\n``` \r\n[07/16 13:14:44 d2.engine.defaults]: Model:\r\nGeneralizedRCNN(\r\n  (backbone): FPN(\r\n    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\r\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (top_block): LastLevelMaxPool()\r\n    (bottom_up): ResNet(\r\n      (stem): BasicStem(\r\n        (conv1): Conv2d(\r\n          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\r\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n        )\r\n      )\r\n      (res2): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res3): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res4): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (3): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (4): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n        (5): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n      (res5): Sequential(\r\n        (0): BottleneckBlock(\r\n          (shortcut): Conv2d(\r\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n          (conv1): Conv2d(\r\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (1): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n        (2): BottleneckBlock(\r\n          (conv1): Conv2d(\r\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv2): Conv2d(\r\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n          )\r\n          (conv3): Conv2d(\r\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n          )\r\n        )\r\n      )\r\n    )\r\n  )\r\n  (proposal_generator): RPN(\r\n    (rpn_head): StandardRPNHead(\r\n      (conv): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n    (anchor_generator): DefaultAnchorGenerator(\r\n      (cell_anchors): BufferList()\r\n    )\r\n  )\r\n  (roi_heads): StandardROIHeads(\r\n    (box_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (box_head): FastRCNNConvFCHead(\r\n      (flatten): Flatten(start_dim=1, end_dim=-1)\r\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\r\n      (fc_relu1): ReLU()\r\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\r\n      (fc_relu2): ReLU()\r\n    )\r\n    (box_predictor): FastRCNNOutputLayers(\r\n      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\r\n      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\r\n    )\r\n    (mask_pooler): ROIPooler(\r\n      (level_poolers): ModuleList(\r\n        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n      )\r\n    )\r\n    (mask_head): MaskRCNNConvUpsampleHead(\r\n      (mask_fcn1): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn2): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn3): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (mask_fcn4): Conv2d(\r\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\r\n        (activation): ReLU()\r\n      )\r\n      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\r\n      (deconv_relu): ReLU()\r\n      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\r\n    )\r\n  )\r\n)\r\n[07/16 13:14:44 d2.data.datasets.coco]: Loaded 161 images in COCO format from /kaggle/input/coco-data/instances.json\r\n[07/16 13:14:44 d2.data.build]: Removed 0 images with no usable annotations. 161 images left.\r\n[07/16 13:14:44 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\r\n[07/16 13:14:44 d2.data.build]: Using training sampler TrainingSampler\r\n[07/16 13:14:44 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\r\n[07/16 13:14:44 d2.data.common]: Serializing 161 elements to byte tensors and concatenating them all ...\r\n[07/16 13:14:44 d2.data.common]: Serialized dataset takes 0.11 MiB\r\n[07/16 13:14:44 d2.data.build]: Making batched data loader with batch_size=2\r\n[07/16 13:14:44 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\r\n[07/16 13:14:44 d2.engine.train_loop]: Starting training from iteration 0\r\n[07/16 13:14:49 d2.utils.events]:  eta: 0:08:08  iter: 19  total_loss: 2.388  loss_cls: 0.5612  loss_box_reg: 0.5152  loss_mask: 0.6743  loss_rpn_cls: 0.2725  loss_rpn_loc: 0.234    time: 0.2471  last_time: 0.2480  data_time: 0.0182  last_data_time: 0.0076   lr: 0.0005  max_mem: 2758M\r\n[07/16 13:14:54 d2.utils.events]:  eta: 0:08:10  iter: 39  total_loss: 1.896  loss_cls: 0.3904  loss_box_reg: 0.7147  loss_mask: 0.5105  loss_rpn_cls: 0.0675  loss_rpn_loc: 0.2052    time: 0.2511  last_time: 0.2110  data_time: 0.0075  last_data_time: 0.0074   lr: 0.0005  max_mem: 2758M\r\n[07/16 13:14:59 d2.utils.events]:  eta: 0:08:03  iter: 59  total_loss: 1.697  loss_cls: 0.3442  loss_box_reg: 0.682  loss_mask: 0.3977  loss_rpn_cls: 0.0367  loss_rpn_loc: 0.187    time: 0.2512  last_time: 0.2547  data_time: 0.0082  last_data_time: 0.0085   lr: 0.0005  max_mem: 2760M\r\n[07/16 13:15:04 d2.utils.events]:  eta: 0:08:00  iter: 79  total_loss: 1.581  loss_cls: 0.311  loss_box_reg: 0.681  loss_mask: 0.3736  loss_rpn_cls: 0.02267  loss_rpn_loc: 0.1788    time: 0.2510  last_time: 0.2624  data_time: 0.0079  last_data_time: 0.0081   lr: 0.0005  max_mem: 2760M\r\n[07/16 13:15:09 d2.utils.events]:  eta: 0:07:54  iter: 99  total_loss: 1.489  loss_cls: 0.3167  loss_box_reg: 0.6183  loss_mask: 0.3583  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.1595    time: 0.2506  last_time: 0.2538  data_time: 0.0079  last_data_time: 0.0074   lr: 0.0005  max_mem: 2760M\r\n[07/16 13:15:15 d2.utils.events]:  eta: 0:07:51  iter: 119  total_loss: 1.481  loss_cls: 0.3209  loss_box_reg: 0.6435  loss_mask: 0.3739  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.1781    time: 0.2525  last_time: 0.2795  data_time: 0.0081  last_data_time: 0.0086   lr: 0.0005  max_mem: 2760M\r\n[07/16 13:15:20 d2.utils.events]:  eta: 0:07:48  iter: 139  total_loss: 1.421  loss_cls: 0.2869  loss_box_reg: 0.6089  loss_mask: 0.3471  loss_rpn_cls: 0.009652  loss_rpn_loc: 0.1751    time: 0.2532  last_time: 0.2746  data_time: 0.0076  last_data_time: 0.0076   lr: 0.0005  max_mem: 2760M\r\n[07/16 13:15:25 d2.utils.events]:  eta: 0:07:42  iter: 159  total_loss: 1.42  loss_cls: 0.297  loss_box_reg: 0.6114  loss_mask: 0.3572  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.1626    time: 0.2536  last_time: 0.2537  data_time: 0.0074  last_data_time: 0.0081   lr: 0.0005  max_mem: 2760M\r\n[07/16 13:15:30 d2.utils.events]:  eta: 0:07:36  iter: 179  total_loss: 1.343  loss_cls: 0.2586  loss_box_reg: 0.5469  loss_mask: 0.3461  loss_rpn_cls: 0.009276  loss_rpn_loc: 0.1687    time: 0.2530  last_time: 0.2379  data_time: 0.0082  last_data_time: 0.0081   lr: 0.0005  max_mem: 2760M\r\n[07/16 13:15:35 d2.utils.events]:  eta: 0:07:31  iter: 199  total_loss: 1.45  loss_cls: 0.2805  loss_box_reg: 0.6134  loss_mask: 0.3579  loss_rpn_cls: 0.008294  loss_rpn_loc: 0.173    time: 0.2525  last_time: 0.2530  data_time: 0.0081  last_data_time: 0.0081   lr: 0.0005  max_mem: 2760M\r\n[07/16 13:15:40 d2.utils.events]:  eta: 0:07:26  iter: 219  total_loss: 1.382  loss_cls: 0.2553  loss_box_reg: 0.5704  loss_mask: 0.3324  loss_rpn_cls: 0.009328  loss_rpn_loc: 0.1638    time: 0.2528  last_time: 0.2514  data_time: 0.0082  last_data_time: 0.0073   lr: 0.0005  max_mem: 2760M\r\n[07/16 13:15:45 d2.utils.events]:  eta: 0:07:22  iter: 239  total_loss: 1.34  loss_cls: 0.2805  loss_box_reg: 0.5728  loss_mask: 0.3491  loss_rpn_cls: 0.01016  loss_rpn_loc: 0.1435    time: 0.2536  last_time: 0.2491  data_time: 0.0078  last_data_time: 0.0079   lr: 0.0005  max_mem: 2760M\r\n[07/16 13:15:49 d2.data.datasets.coco]: Loaded 135 images in COCO format from /kaggle/input/coco-data-val/instances.json\r\n[07/16 13:15:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\r\n[07/16 13:15:49 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\r\n[07/16 13:15:49 d2.data.common]: Serializing 135 elements to byte tensors and concatenating them all ...\r\n[07/16 13:15:49 d2.data.common]: Serialized dataset takes 0.02 MiB\r\n[07/16 13:15:49 d2.data.datasets.coco]: Loaded 135 images in COCO format from /kaggle/input/coco-data-val/instances.json\r\n[07/16 13:15:49 d2.evaluation.evaluator]: Start inference on 135 batches\r\nERROR [07/16 13:15:49 d2.engine.train_loop]: Exception during training:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py\", line 156, in train\r\n    self.after_step()\r\n  File \"/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py\", line 190, in after_step\r\n    h.after_step()\r\n  File \"/opt/conda/lib/python3.10/site-packages/detectron2/engine/hooks.py\", line 556, in after_step\r\n    self._do_eval()\r\n  File \"/opt/conda/lib/python3.10/site-packages/detectron2/engine/hooks.py\", line 529, in _do_eval\r\n    results = self._func()\r\n  File \"/opt/conda/lib/python3.10/site-packages/detectron2/engine/defaults.py\", line 457, in test_and_save_results\r\n    self._last_eval_results = self.test(self.cfg, self.model)\r\n  File \"/opt/conda/lib/python3.10/site-packages/detectron2/engine/defaults.py\", line 621, in test\r\n    results_i = inference_on_dataset(model, data_loader, evaluator)\r\n  File \"/opt/conda/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py\", line 172, in inference_on_dataset\r\n    evaluator.process(inputs, outputs)\r\n  File \"/tmp/ipykernel_34/3164767280.py\", line 37, in process\r\n    self.scores.append(score(out, targ))\r\n  File \"/tmp/ipykernel_34/3164767280.py\", line 18, in score\r\n    tp, fp, fn = precision_at(t, ious)\r\n  File \"/tmp/ipykernel_34/3164767280.py\", line 6, in precision_at\r\n    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\r\n  File \"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2313, in sum\r\n    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\r\n  File \"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\r\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\nnumpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\r\n[07/16 13:15:49 d2.engine.hooks]: Overall training speed: 247 iterations in 0:01:02 (0.2544 s / it)\r\n[07/16 13:15:49 d2.engine.hooks]: Total training time: 0:01:04 (0:00:01 on hooks)\r\n[07/16 13:15:49 d2.utils.events]:  eta: 0:07:19  iter: 249  total_loss: 1.29  loss_cls: 0.2537  loss_box_reg: 0.5709  loss_mask: 0.3331  loss_rpn_cls: 0.009182  loss_rpn_loc: 0.1365    time: 0.2534  last_time: 0.2509  data_time: 0.0077  last_data_time: 0.0082   lr: 0.0005  max_mem: 2760M\r\n---------------------------------------------------------------------------\r\nAxisError                                 Traceback (most recent call last)\r\nCell In[9], line 34\r\n     32 trainer = Trainer(cfg)  # without data augmentation\r\n     33 trainer.resume_or_load(resume=False)\r\n---> 34 trainer.train()\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/detectron2/engine/defaults.py:488, in DefaultTrainer.train(self)\r\n    481 def train(self):\r\n    482     \"\"\"\r\n    483     Run training.\r\n    484 \r\n    485     Returns:\r\n    486         OrderedDict of results, if evaluation is enabled. Otherwise None.\r\n    487     \"\"\"\r\n--> 488     super().train(self.start_iter, self.max_iter)\r\n    489     if len(self.cfg.TEST.EXPECTED_RESULTS) and comm.is_main_process():\r\n    490         assert hasattr(\r\n    491             self, \"_last_eval_results\"\r\n    492         ), \"No evaluation results obtained during training!\"\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py:156, in TrainerBase.train(self, start_iter, max_iter)\r\n    154     self.before_step()\r\n    155     self.run_step()\r\n--> 156     self.after_step()\r\n    157 # self.iter == max_iter can be used by `after_train` to\r\n    158 # tell whether the training successfully finished or failed\r\n    159 # due to exceptions.\r\n    160 self.iter += 1\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py:190, in TrainerBase.after_step(self)\r\n    188 def after_step(self):\r\n    189     for h in self._hooks:\r\n--> 190         h.after_step()\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/detectron2/engine/hooks.py:556, in EvalHook.after_step(self)\r\n    553 if self._period > 0 and next_iter % self._period == 0:\r\n    554     # do the last eval in after_train\r\n    555     if next_iter != self.trainer.max_iter:\r\n--> 556         self._do_eval()\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/detectron2/engine/hooks.py:529, in EvalHook._do_eval(self)\r\n    528 def _do_eval(self):\r\n--> 529     results = self._func()\r\n    531     if results:\r\n    532         assert isinstance(\r\n    533             results, dict\r\n    534         ), \"Eval function must return a dict. Got {} instead.\".format(results)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/detectron2/engine/defaults.py:457, in DefaultTrainer.build_hooks.<locals>.test_and_save_results()\r\n    456 def test_and_save_results():\r\n--> 457     self._last_eval_results = self.test(self.cfg, self.model)\r\n    458     return self._last_eval_results\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/detectron2/engine/defaults.py:621, in DefaultTrainer.test(cls, cfg, model, evaluators)\r\n    619         results[dataset_name] = {}\r\n    620         continue\r\n--> 621 results_i = inference_on_dataset(model, data_loader, evaluator)\r\n    622 results[dataset_name] = results_i\r\n    623 if comm.is_main_process():\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py:172, in inference_on_dataset(model, data_loader, evaluator, callbacks)\r\n    169 total_compute_time += time.perf_counter() - start_compute_time\r\n    171 start_eval_time = time.perf_counter()\r\n--> 172 evaluator.process(inputs, outputs)\r\n    173 total_eval_time += time.perf_counter() - start_eval_time\r\n    175 iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\r\n\r\nCell In[7], line 37, in MAPIOUEvaluator.process(self, inputs, outputs)\r\n     35 else:\r\n     36     targ = self.annotations_cache[inp['image_id']]\r\n---> 37     self.scores.append(score(out, targ))\r\n\r\nCell In[7], line 18, in score(pred, targ)\r\n     16 prec = []\r\n     17 for t in np.arange(0.5, 1.0, 0.05):\r\n---> 18     tp, fp, fn = precision_at(t, ious)\r\n     19     p = tp / (tp + fp + fn)\r\n     20     prec.append(p)\r\n\r\nCell In[7], line 6, in precision_at(threshold, iou)\r\n      4 def precision_at(threshold, iou):\r\n      5     matches = iou > threshold\r\n----> 6     true_positives = np.sum(matches, axis=1) == 1  # Correct objects\r\n      7     false_positives = np.sum(matches, axis=0) == 0  # Missed objects\r\n      8     false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2313, in sum(a, axis, dtype, out, keepdims, initial, where)\r\n   2310         return out\r\n   2311     return res\r\n-> 2313 return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\r\n   2314                       initial=initial, where=where)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:88, in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs)\r\n     85         else:\r\n     86             return reduction(axis=axis, out=out, **passkwargs)\r\n---> 88 return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n\r\nAxisError: axis 1 is out of bounds for array of dimension 1\r\n```",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      }
    ]
  },
  {
    "issue_number": 5295,
    "title": "C++ and onnx",
    "author": "SylvainArd",
    "state": "open",
    "created_at": "2024-05-25T11:43:10Z",
    "updated_at": "2024-07-15T15:04:23Z",
    "labels": [
      "enhancement"
    ],
    "body": "## üöÄ Feature\r\nA clear and concise description of the feature proposal.\r\nFor easying the distribution of my programs with detectron2 on windows platforms I want to can launch predictions of detectron2 with C++ DLLs and onnx converted models\r\n\r\n## Motivation & Examples\r\n\r\nTell us why the feature is useful.\r\nonnx speeds up prediction and C++ Dlls are more distributables than entire Python environments\r\n\r\nDescribe what the feature would look like, if it is implemented.\r\nBest demonstrated using **code examples** in addition to words.\r\na complete example of code source with detectron2 all models compatible examples sources in Visual Studio C++\r\n\r\n## Note\r\n\r\nWe only consider adding new features if they are relevant to many users.\r\n\r\nIf you request implementation of research papers -- we only consider papers that have enough significance and prevalance in the object detection field.\r\n\r\nWe do not take requests for most projects in the `projects/` directory, because they are research code release that is mainly for other researchers to reproduce results.\r\n\r\n\"Make X faster/accurate\" is not a valid feature request. \"Implement a concrete feature that can make X faster/accurate\" can be a valid feature request.\r\n\r\nInstead of adding features inside detectron2,\r\nyou can implement many features by [extending detectron2](https://detectron2.readthedocs.io/tutorials/extend.html).\r\nThe [projects/](https://github.com/facebookresearch/detectron2/tree/main/projects/) directory contains many of such examples.\r\n\r\n",
    "comments": [
      {
        "user": "SylvainArd",
        "body": "and a Linux C++ source code would be nice too to distribute detectron2 using software on Linux web servers"
      },
      {
        "user": "Programmer-RD-AI",
        "body": "Sounds like an interesting Feature!"
      },
      {
        "user": "SylvainArd",
        "body": "up please"
      }
    ]
  },
  {
    "issue_number": 5323,
    "title": "print_instances_class_histogram raises exception ZeroDivisionError: integer division or modulo by zero",
    "author": "ShulyAvraham",
    "state": "open",
    "created_at": "2024-07-07T13:38:30Z",
    "updated_at": "2024-07-11T10:04:06Z",
    "labels": [],
    "body": "If by mistake we pass an empty list of classes, we get a ZeroDivisionError exception.\r\n\r\n1. Shortest full runnable code:\r\n```\r\nfrom detectron2 import data \r\ndata.print_instances_class_histogram([], [])\r\n```\r\n2. Full output:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/breedingeye/a.py\", line 2, in <module>\r\n    data.print_instances_class_histogram([], [])\r\n  File \"/usr/local/lib/python3.10/site-packages/detectron2/data/build.py\", line 198, in print_instances_class_histogram\r\n    data.extend([None] * (N_COLS - (len(data) % N_COLS)))\r\nZeroDivisionError: integer division or modulo by zero\r\n```\r\n\r\n## Expected behavior:\r\n\r\nAn exception indicating the lack of classes, or no exception at all.\r\n\r\n## Environment:\r\n```\r\n-------------------------------  -----------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.10.11 (main, May  3 2023, 09:31:23) [GCC 8.3.0]\r\nnumpy                            1.22.4\r\ndetectron2                       0.6 @/usr/local/lib/python3.10/site-packages/detectron2\r\nCompiler                         GCC 8.3\r\nCUDA compiler                    not available\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          2.0.1+cu117 @/usr/local/lib/python3.10/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    No: torch.cuda.is_available() == False\r\nPillow                           9.5.0\r\ntorchvision                      0.15.2+cu117 @/usr/local/lib/python3.10/site-packages/torchvision\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.7.0\r\n-------------------------------  -----------------------------------------------------------------\r\nPyTorch built with:\r\n  - GCC 9.3\r\n  - C++ Version: 201703\r\n  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\r\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n  - LAPACK is enabled (usually provided by MKL)\r\n  - NNPACK is enabled\r\n  - CPU capability usage: AVX2\r\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n ```\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "Programmer-RD-AI",
        "body": "Hi,\r\nZeroDivisionError is raised due to the lists being empty, the `print_instances_class_histogram` function expects something as follows... I don't exactly get the point that you are trying to bring up, is it that there should be a better way that this should be informed to the user?\r\n\r\n```\r\ndummy_dataset = [{\r\n    \"file_name\": \"dummy_image.jpg\",\r\n    \"image_id\": 0,\r\n    \"height\": 100,\r\n    \"width\": 100,\r\n    \"annotations\": [{\"category_id\": 0, \"bbox\": [10, 10, 20, 20], \"bbox_mode\": 0}]\r\n}]\r\n\r\n# Call the function with the dummy dataset\r\nprint_instances_class_histogram(dummy_dataset, [\"class_0\"])\r\n```\r\n\r\nThank you"
      },
      {
        "user": "ShulyAvraham",
        "body": "Thanks for your response.\r\nThe problem appeared at a bigger piece of code. This is the shortest example that could reproduce the issue. \r\nIndeed, the exception is raised due to the lists being empty, however, I would expect a better report of the issue. E.g. \"Empty list of classes\" or \"No classes were provided\" (rather than ZeroDivisionError), to indicate that the exception was caused by incorrect parameters provided by the caller and not something internal in detectron2."
      }
    ]
  },
  {
    "issue_number": 5087,
    "title": "I was easily able to retrain with ResNet-18 as backbone, but I don't see any speedup.",
    "author": "Huxwell",
    "state": "closed",
    "created_at": "2023-09-11T08:37:29Z",
    "updated_at": "2024-07-11T02:03:01Z",
    "labels": [],
    "body": "## Instructions To Reproduce the Issue:\r\n\r\nTo retrain a keypoint detector, I've added following lines to my training routine:\r\n```\r\ncfg.MODEL.RESNETS.DEPTH = 18\r\ncfg.MODEL.RESNETS.RES2_OUT_CHANNELS = 64\r\ncfg.MODEL.WEIGHTS = \"\"\r\ncfg.MODEL.BACKBONE.FREEZE_AT = 0\r\n```\r\nThe scores went slightly down (mAP 0.84->0.72), .pth file disc space too (451M->352M), but when I run inference\r\nI will get 98-100% of the original latency (~65ms on Tesla A100).\r\n`nvidia-smi` shows a minor vram usage reduction  1407MiB -> 1289MiB .\r\n\r\nI've run the test multiple times, on 200 imgs, ignoring initiall 1st prediction (warmup).\r\n\r\nI've verified the architecture and it indeed looks like r18 (basic block, no bottleneck blocks).\r\nI based my assumption that resnet18 is supported by detectron2 by reading these files:\r\ndetectron2/detectron2/modeling/backbone/resnet.py\r\ndetectron2/detectron2/modeling/backbone/fpn.py\r\nand it also confirms that I am indeed running with resnet18 backbone.\r\n\r\nMy time measurements looks like this with DefaultPredictor (so no .cpu() or .gpu() calls inside):\r\n ```\r\n  start = time.time()\r\n  outputs = predictor(im)\r\n  elapsed = time.time() - start\r\n  ```\r\n  \r\n  Any ideas why the speedup is not occuring?\r\n  Any suggestions where can I look for speedup (i.e reducing number of conv filters outside of the backbone)?",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "Huxwell",
        "body": "It seems to be related to something that DefaultPredictor does.\r\nI can see almost 2x speedup if I use \r\n```\r\nmodel = build_model(cfg) # from detectron2.modeling import build_model\r\ncheckpointer = DetectionCheckpointer(model)\r\n```\r\nInstead of DefaultPredictor. I don't fully understand what DefaultPredictor does, I plan to update the issue when I understand better."
      },
      {
        "user": "Huxwell",
        "body": "To sum up:\r\n- without DefaultPredictor I can indeed see a speedup\r\n- the ratio is smth like r50 (default backbone) 17fps : r34 20fps : r18 26fps\r\n- surprisingly the mAP gap is very small (1-7% depending on the class and IoU), maybe because by default r50 doesn't get full retraining, only the last layers get to be trained, but r18/r34 force me to train from scratch"
      }
    ]
  },
  {
    "issue_number": 5084,
    "title": "the latest version only support CUDA11.3   with an old torch version 1.10. there are nearly 3 years no update .when to update??",
    "author": "ouyang11111",
    "state": "closed",
    "created_at": "2023-09-07T12:03:58Z",
    "updated_at": "2024-07-11T02:03:01Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\n```\r\nIf making changes to the project itself, please use output of the following command:\r\ngit rev-parse HEAD; git diff\r\n\r\n<put code or diff here>\r\n```\r\n2. What exact command you run:\r\n3. __Full logs__ or other relevant observations:\r\n```\r\n<put logs here>\r\n```\r\n4. please simplify the steps as much as possible so they do not require additional resources to\r\n   run, such as a private dataset.\r\n\r\n## Expected behavior:\r\n\r\nIf there are no obvious error in \"full logs\" provided above,\r\nplease tell us the expected behavior.\r\n\r\n## Environment:\r\n\r\nProvide your environment information using the following command:\r\n```\r\nwget -nc -q https://github.com/facebookresearch/detectron2/raw/main/detectron2/utils/collect_env.py && python collect_env.py\r\n```\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first try to solve it yourself with the instructions in\r\nhttps://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "\nWe found that not enough information is provided about this issue.\nPlease provide details following the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose)."
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 4337,
    "title": "Testing new baselines model",
    "author": "Bill4869",
    "state": "closed",
    "created_at": "2022-06-16T05:12:57Z",
    "updated_at": "2024-07-08T22:55:09Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "Hi, I am trying to test a new baseline on a single image. Below is the code I tried.\r\n```\r\nim = cv2.imread(\"./00153_colors.png\")\r\ncfg = model_zoo.get_config([new baseline path], trained=True)\r\npredictor = DefaultPredictor(cfg)\r\noutputs = predictor(im)\r\n```\r\nHowever, I got the error in the `DefaultPredictor method`\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"debug.py\", line 42, in <module>\r\n    predictor = DefaultPredictor(cfg)\r\n  File \"/home/bill/.local/lib/python3.6/site-packages/detectron2/engine/defaults.py\", line 284, in __init__\r\n    self.cfg = cfg.clone()  #can be modified by model\r\n  File \"/home/bill/.local/lib/python3.6/site-packages/omegaconf/dictconfig.py\", line 358, in __getattr__\r\n    key=key, value=None, cause=e, type_override=ConfigAttributeError\r\n  File \"/home/bill/.local/lib/python3.6/site-packages/omegaconf/base.py\", line 237, in _format_and_raise\r\n    type_override=type_override,\r\n  File \"/home/bill/.local/lib/python3.6/site-packages/omegaconf/_utils.py\", line 873, in format_and_raise\r\n    _raise(ex, cause)\r\n  File \"/home/bill/.local/lib/python3.6/site-packages/omegaconf/_utils.py\", line 771, in _raise\r\n    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace\r\n  File \"/home/bill/.local/lib/python3.6/site-packages/omegaconf/dictconfig.py\", line 354, in __getattr__\r\n    key=key, default_value=_DEFAULT_MARKER_, validate_key=False\r\n  File \"/home/bill/.local/lib/python3.6/site-packages/omegaconf/dictconfig.py\", line 445, in _get_impl\r\n    key=key, throw_on_missing_key=True, validate_key=validate_key\r\n  File \"/home/bill/.local/lib/python3.6/site-packages/omegaconf/basecontainer.py\", line 78, in _get_child\r\n    throw_on_missing_key=throw_on_missing_key,\r\n  File \"/home/bill/.local/lib/python3.6/site-packages/omegaconf/dictconfig.py\", line 482, in _get_node\r\n    raise ConfigKeyError(f\"Missing key {key!s}\")\r\nomegaconf.errors.ConfigAttributeError: Missing key clone\r\n    full_key: clone\r\n    object_type=dict\r\n```\r\nCan anyone tell me how to solve this problem? Or if there is another way to test the new baseline, I would really appreciate it.\r\nI did look at the documentation but maybe due to my lack of understanding, I could not manage to make it work.\r\n\r\nThank you in advances.",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      },
      {
        "user": "alrightkami",
        "body": "Hey there, [as mentioned here](https://github.com/facebookresearch/detectron2/issues/3225#:~:text=DefaultPredictor%20would%20need%20a%20patch%20like%20%233755%20to%20work%20with%20new%20configs.), you'll need to write your own DefaultPredictor to work with new baselines "
      }
    ]
  },
  {
    "issue_number": 1771,
    "title": "Potential bug on drawing segmentation mask with holes ",
    "author": "XiaoSong9905",
    "state": "open",
    "created_at": "2020-07-14T23:06:52Z",
    "updated_at": "2024-07-05T08:35:35Z",
    "labels": [
      "bug",
      "contributions welcome"
    ],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. model has predicted segmentation masks with holes. (white area are predicted mask)\r\n\r\n![mask](https://user-images.githubusercontent.com/39639112/87484601-975f5e80-c604-11ea-9fc8-0868ebc38b10.png)\r\n\r\n2. When `Visualizer.draw_instance_predictions()` create `GenericMask` and call `Visualizer.overlay_instances`\r\n\r\n3. `Visualizer.overlay_instances` draws mask with \"polygon\" formate, which considers the holes inside the prediction (which have it own polygon) as part of the prediction. \r\n\r\n![Screen Shot 2020-07-14 at 7 04 55 PM](https://user-images.githubusercontent.com/39639112/87484744-fde47c80-c604-11ea-9fd6-b8b0523e93ab.png)\r\n\r\n4. This would induce result like this, where the holes are also considered as predicted area. \r\n\r\n![prediciton](https://user-images.githubusercontent.com/39639112/87484757-08067b00-c605-11ea-96f7-47413a7dd845.png)\r\n\r\n5. This is mainly because when the class::GenericMask return the polygon, it does not consider the hole information \r\n\r\n![Screen Shot 2020-07-14 at 7 09 46 PM](https://user-images.githubusercontent.com/39639112/87484967-9975ed00-c605-11ea-9e75-34858d6f0a25.png)\r\n\r\nand this have to do with `cv2.findContours(mask.astype(\"uint8\"), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)` return holes inside the mask but there's not subsequrnce operation to filter out those polygon\r\n![Screen Shot 2020-07-14 at 8 29 30 PM](https://user-images.githubusercontent.com/39639112/87489385-e14e4180-c610-11ea-9602-d885cc63342a.png)\r\n",
    "comments": [
      {
        "user": "alexriedel1",
        "body": "Maybe using the method RETR_EXTERNAL for findContours can solve this, as it only finds outer contours?\r\n`cv2.findContours(input, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)`\r\n\r\nsee: https://docs.opencv.org/trunk/d3/dc0/group__imgproc__shape.html#ga819779b9857cc2f8601e6526a3a5bc71"
      },
      {
        "user": "hiroto01",
        "body": "Hi, is there update regarding this?\r\n@ppwwyyxx ? @XiaoSong9905"
      },
      {
        "user": "MjdMahasneh",
        "body": "@ppwwyyxx any updates on this! I have actually been trying to find a work around over a month now! even RLEs do not account for holes, could you kindly advice? I am using detectron2 as the backend for my industrial research, it would be massively helpful for me and others.\r\n\r\n@XiaoSong9905 @alexriedel1 @hiroto01 any advice on this, please?\r\n\r\nLooking forward."
      }
    ]
  },
  {
    "issue_number": 5318,
    "title": "RuntimeError: nvrtc: error: invalid value for --gpu-architecture (-arch)",
    "author": "lsj1111",
    "state": "open",
    "created_at": "2024-07-01T14:44:44Z",
    "updated_at": "2024-07-03T04:01:01Z",
    "labels": [],
    "body": "the environment is :\r\n-------------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------\r\nsys.platform                     linux\r\nPython                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]\r\nnumpy                            1.24.3\r\ndetectron2                       0.6 @/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/lsj/code/MASKDINO/detectron2-main/detectron2\r\nCompiler                         GCC 7.5\r\nCUDA compiler                    CUDA 11.3\r\ndetectron2 arch flags            /media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/lsj/code/MASKDINO/detectron2-main/detectron2/_C.cpython-38-x86_64-linux-gnu.so; cannot find cuobjdump\r\nDETECTRON2_ENV_MODULE            <not set>\r\nPyTorch                          1.10.0 @/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/anaconda3/envs/maskdino/lib/python3.8/site-packages/torch\r\nPyTorch debug build              False\r\ntorch._C._GLIBCXX_USE_CXX11_ABI  False\r\nGPU available                    Yes\r\nGPU 0,1                          NVIDIA GeForce RTX 4090 (arch=8.9)\r\nDriver version                   535.183.01\r\nCUDA_HOME                        :/usr/local/cuda - invalid!\r\nPillow                           10.3.0\r\ntorchvision                      0.11.0 @/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/anaconda3/envs/maskdino/lib/python3.8/site-packages/torchvision\r\ntorchvision arch flags           /media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/anaconda3/envs/maskdino/lib/python3.8/site-packages/torchvision/_C.so; cannot find cuobjdump\r\nfvcore                           0.1.5.post20221221\r\niopath                           0.1.9\r\ncv2                              4.10.0\r\n-------------------------------  -------------\r\n\r\n\r\n\r\n\r\nThis problem arises when I execute train_net.py:\r\n\r\n\r\n\r\n\r\n[07/01 22:30:46] d2.engine.train_loop INFO: Starting training from iteration 0\r\n[07/01 22:30:47] d2.engine.train_loop ERROR: Exception during training:\r\nTraceback (most recent call last):\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/lsj/code/MASKDINO/detectron2-main/detectron2/engine/train_loop.py\", line 155, in train\r\n    self.run_step()\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/lsj/code/MASKDINO/detectron2-main/detectron2/engine/defaults.py\", line 498, in run_step\r\n    self._trainer.run_step()\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/lsj/code/MASKDINO/detectron2-main/detectron2/engine/train_loop.py\", line 495, in run_step\r\n    loss_dict = self.model(data)\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/anaconda3/envs/maskdino/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/lsj/code/MaskDINO-main/maskdino/maskdino.py\", line 267, in forward\r\n    losses = self.criterion(outputs, targets,mask_dict)\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/anaconda3/envs/maskdino/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/lsj/code/MaskDINO-main/maskdino/modeling/criterion.py\", line 357, in forward\r\n    indices = self.matcher(outputs_without_aux, targets)\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/anaconda3/envs/maskdino/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/anaconda3/envs/maskdino/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/lsj/code/MaskDINO-main/maskdino/modeling/matcher.py\", line 220, in forward\r\n    return self.memory_efficient_forward(outputs, targets, cost)\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/anaconda3/envs/maskdino/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/media/hky/d2bed7b9-228d-4a5b-ae76-f3f34ce12c7b/hky/lsj/code/MaskDINO-main/maskdino/modeling/matcher.py\", line 169, in memory_efficient_forward\r\n    cost_mask = batch_sigmoid_ce_loss_jit(out_mask, tgt_mask)\r\nRuntimeError: nvrtc: error: invalid value for --gpu-architecture (-arch)\r\n\r\nnvrtc compilation failed: \r\n\r\n#define NAN __int_as_float(0x7fffffff)\r\n#define POS_INFINITY __int_as_float(0x7f800000)\r\n#define NEG_INFINITY __int_as_float(0xff800000)\r\n\r\n\r\ntemplate<typename T>\r\n__device__ T maximum(T a, T b) {\r\n  return isnan(a) ? a : (a > b ? a : b);\r\n}\r\n\r\ntemplate<typename T>\r\n__device__ T minimum(T a, T b) {\r\n  return isnan(a) ? a : (a < b ? a : b);\r\n}\r\n\r\nextern \"C\" __global__\r\nvoid fused_neg_add(float* ttargets_1, float* aten_add) {\r\n{\r\n  float v = __ldg(ttargets_1 + (long long)(threadIdx.x) + 512ll * (long long)(blockIdx.x));\r\n  aten_add[(long long)(threadIdx.x) + 512ll * (long long)(blockIdx.x)] = (0.f - v) + 1.f;\r\n}\r\n}",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "Programmer-RD-AI",
        "body": "Hi,\r\nThis issue seems to root from pytorch it self...\r\nCheck: [PyTorch Issue #87595](https://github.com/pytorch/pytorch/issues/87595), The issue was initially found in 2022 and now an update has been pushed... The following command should help you get the latest version\r\n> pip3 install --pre torch torchvision torchaudio -f https://download.pytorch.org/whl/test/cu117/torch_test.html\r\nIf there are any issues till please feel free to comment :)"
      },
      {
        "user": "lsj1111",
        "body": "> Hi, This issue seems to root from pytorch it self... Check: [PyTorch Issue #87595](https://github.com/pytorch/pytorch/issues/87595), The issue was initially found in 2022 and now an update has been pushed... The following command should help you get the latest version\r\n> \r\n> > pip3 install --pre torch torchvision torchaudio -f https://download.pytorch.org/whl/test/cu117/torch_test.html\r\n> > If there are any issues till please feel free to comment :)\r\n\r\nyear,thank you ,I have solved this problem. In the official documentation of detectron2, it seems that only cuda11.3 is supported, so I used cuda11.3 and caused the above problem, but then I found that cuda11.6 can also use detectron2, so the problem was solved. ."
      }
    ]
  },
  {
    "issue_number": 5285,
    "title": "Add device argument for multi-backends access & Ascend NPU support",
    "author": "MengqingCao",
    "state": "open",
    "created_at": "2024-05-11T01:59:44Z",
    "updated_at": "2024-07-03T01:26:06Z",
    "labels": [
      "enhancement"
    ],
    "body": "## üöÄ Feature\r\n\r\n1. Add a `--device` arg to determine the backend, and modify the hard code related to cuda to accelerator.\r\n2. Add Ascend NPU support by introducing `torch-npu` adapter.\r\n## Motivation & Examples\r\n\r\nCurrently, PyTorch supports many accelerators besides NVIDIA GPU, e.g., XLA devices (like TPUs), XPU, MPS and Ascend NPU. Adding a `--device` argument for users to specify the accelerator they would like to use is helpful. If this is acceptable for community, I would like to do this work.\r\n\r\nMoreover, on the basis of `device` arg, I would like to add support for Ascend NPU backend for detectron2.\r\n\r\n**A tiny example**\r\nThe modify of `_distributed_worker` func:\r\n\r\n```python\r\ndef _distributed_worker(\r\n     local_rank,\r\n     main_func,\r\n     world_size,\r\n-    num_gpus_per_machine,\r\n+    num_accelerators_per_machine,\r\n     machine_rank,\r\n     dist_url,\r\n     args,\r\n     timeout=DEFAULT_TIMEOUT,\r\n ):\r\n-    has_gpu = torch.cuda.is_available()\r\n-    if has_gpu:\r\n-        assert num_gpus_per_machine <= torch.cuda.device_count()\r\n-    global_rank = machine_rank * num_gpus_per_machine + local_rank\r\n+    device = args[0].device\r\n+    dist_backend = \"gloo\"\r\n+    if \"cuda\" in device:\r\n+        if torch.cuda.is_available():\r\n+            assert num_accelerators_per_machine <= torch.cuda.device_count()\r\n+            dist_backend = \"nccl\"\r\n+    elif \"npu\" in device:\r\n+        if torch.npu.is_available():\r\n+            assert num_accelerators_per_machine <= torch.npu.device_count()\r\n+            dist_backend = \"hccl\"\r\n+    global_rank = machine_rank * num_accelerators_per_machine + local_rank\r\n     try:\r\n         dist.init_process_group(\r\n-            backend=\"NCCL\" if has_gpu else \"GLOO\",\r\n+            backend=dist_backend,\r\n             init_method=dist_url,\r\n             init_method=dist_url,\r\n             world_size=world_size,\r\n             rank=global_rank,\r\n            timeout=timeout,\r\n        )\r\n     except Exception as e:\r\n        logger = logging.getLogger(__name__)\r\n        logger.error(\"Process group URL: {}\".format(dist_url))\r\n        raise e\r\n \r\n     # Setup the local process group.\r\n-    comm.create_local_process_group(num_gpus_per_machine)\r\n-    if has_gpu:\r\n+    comm.create_local_process_group(num_accelerators_per_machine)\r\n+    if torch.cuda.is_available():\r\n         torch.cuda.set_device(local_rank)\r\n\r\n    # synchronize is needed here to prevent a possible timeout after calling init_process_group\r\n    # See: https://github.com/facebookresearch/maskrcnn-benchmark/issues/172\r\n    comm.synchronize()\r\n\r\n    main_func(*args)\r\n```\r\n\r\n**Related Info**\r\n\r\ntorch.device : https://pytorch.org/docs/stable/tensor_attributes.html#torch-device\r\n\r\ntorch Praviteuse1 (Registering new backend module to Pytorch) : https://pytorch.org/tutorials/advanced/privateuseone.html\r\n\r\n",
    "comments": [
      {
        "user": "Programmer-RD-AI",
        "body": "I think this is an extremely useful feature to add...!"
      },
      {
        "user": "MengqingCao",
        "body": "> I think this is an extremely useful feature to add...!\r\n\r\nThanks for your approval, I‚Äò ll do this work and submit a PR soon"
      },
      {
        "user": "Programmer-RD-AI",
        "body": "ah ok great..\r\nCreate a comment here and I will checkout the PR :)"
      }
    ]
  },
  {
    "issue_number": 4589,
    "title": "How to save Detectron model as Vanilla Pytorch model?",
    "author": "deshwalmahesh",
    "state": "open",
    "created_at": "2022-10-03T07:02:29Z",
    "updated_at": "2024-07-02T15:32:29Z",
    "labels": [
      "documentation"
    ],
    "body": "I have a `Faster-RCNN` model trained with `Detectron2`. Model weights are saved as `model.pth`. \r\n\r\nI have my `config.yml` file and there are a couple of ways to load this model:\r\n\r\n```\r\nfrom detectron2.modeling import build_model\r\nfrom detectron2.checkpoint import DetectionCheckpointer\r\n\r\ncfg = get_cfg()\r\nconfig_name = \"config.yml\" \r\ncfg.merge_from_file(config_name)\r\n\r\ncfg.MODEL.WEIGHTS = './model.pth'\r\nmodel = DefaultPredictor(cfg)\r\n\r\nOR\r\n\r\nmodel_ = build_model(cfg) \r\nmodel = DetectionCheckpointer(model_).load(\"./model.pth\")\r\n```\r\n\r\n\r\nAlso, you can get predictions from this model individually as [given in official documentation](https://detectron2.readthedocs.io/en/latest/tutorials/models.html#model-input-format):\r\n```\r\nimage = np.array(Image.open('page4.jpg'))[:,:,::-1] # RGB to BGR format\r\ntensor_image = torch.from_numpy(image.copy()).permute(2, 0, 1) # B, channels, W, H\r\n\r\n\r\nwith torch.no_grad():\r\n    output = torch_model([{\"image\":tensor_image}])\r\n```\r\n\r\nrunning the following commands:\r\n```\r\nprint(type(model))\r\nprint(type(model.model))\r\nprint(type(model.model.backbone))\r\n```\r\n\r\nGives you: \r\n```\r\n<class 'detectron2.engine.defaults.DefaultPredictor'>\r\n<class 'detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN'>\r\n<class 'detectron2.modeling.backbone.fpn.FPN'>\r\n```\r\n\r\n**Problem: I want to use [GradCam for model explainability](https://github.com/jacobgil/pytorch-grad-cam) and it uses `pytorch` models as [given in this tutorial](https://analyticsindiamag.com/explainable-image-classification-using-faster-r-cnn-and-grad-cam/)**\r\n\r\nHow can I turn `detectron2` model in vanilla `pytorch` model?\r\n\r\nI have tried:\r\n```\r\ntorch.save(model.model.state_dict(), \"torch_weights.pth\")\r\ntorch.save(model.model, \"torch_model.pth\")\r\n\r\n\r\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\r\n\r\ndummy = fasterrcnn_resnet50_fpn(pretrained=False, num_classes=1)\r\n# dummy.load_state_dict(torch.load('./model.pth', map_location = 'cpu')) \r\ndummy.load_state_dict(torch.load('./torch_weights.pth', map_location = 'cpu')) \r\n```\r\n\r\nbut obviously, I'm getting errors due to the different layer names and sizes etc.",
    "comments": [
      {
        "user": "mehi64",
        "body": "Hi Mahesh. I have the same problem. Did you find any solution for that?"
      },
      {
        "user": "deshwalmahesh",
        "body": "@mehi64  Yes, actually the model we save is the pytorch model only.  But it supports 1 image inference only. See the `forward` method\r\n```\r\n\r\nfrom detectron2.modeling import build_model\r\nfrom detectron2.checkpoint import DetectionCheckpointer\r\nfrom detectron2.config import get_cfg\r\n```\r\n\r\n**BUILD CONFIG File**\r\n\r\n```\r\ndef build_cfg(model_weights:str, thresh:float = 0.6):\r\n\r\n    cfg = get_cfg()\r\n\r\n    config_name = \"config.yml\" # Using pre trained layout parser configs\r\n    cfg.merge_from_file(config_name)\r\n\r\n\r\n    cfg.MODEL.DEVICE = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\r\n\r\n    cfg.DATALOADER.NUM_WORKERS: 2\r\n    cfg.TEST.EVAL_PERIOD = 20 # Evaluate after N epochs\r\n\r\n    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 # Default 256 \r\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 # in config file, it is written before weights\r\n\r\n    cfg.MODEL.WEIGHTS = model_weights # layout parser Pre trained weights\r\n\r\n\r\n    cfg.SOLVER.IMS_PER_BATCH = 4 # Batch size\r\n    cfg.SOLVER.BASE_LR = 0.0025\r\n    cfg.SOLVER.WARMUP_ITERS = 50\r\n    cfg.SOLVER.MAX_ITER = 1000 # adjust up if val mAP is still rising, adjust down if overfit\r\n    cfg.SOLVER.STEPS = (300, 800) # must be less than  MAX_ITER \r\n    cfg.SOLVER.GAMMA = 0.05\r\n    cfg.SOLVER.CHECKPOINT_PERIOD = 20  # Save weights after these many epochs\r\n\r\n    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = thresh\r\n    return cfg\r\n```\r\n\r\n**MODEL CLASS**\r\n\r\n```\r\nclass TorchModel(torch.nn.Module):\r\n    def __init__(self, model_weights:str, thresh:float = 0.6, nms:float = 0.3) -> None:\r\n        super().__init__()\r\n        cfg = build_cfg(model_weights, thresh) # Own function in helpers.py to load weights\r\n        self.model = build_model(cfg) # Build Model\r\n        _ = DetectionCheckpointer(self.model).load(cfg.MODEL.WEIGHTS)  # Load weights\r\n        self.model = self.model.eval() # In evaluation mode\r\n        self.nms = nms\r\n    \r\n    def forward(self, INPUT):\r\n        if isinstance(INPUT, (np.ndarray, torch.Tensor)): # it supports just 1 image\r\n            INPUT = [{\"image\":INPUT}]\r\n\r\n        with torch.no_grad():\r\n            outputs = self.model(INPUT)[0]['instances']\r\n        \r\n        boxes, labels, scores = outputs.pred_boxes.tensor, outputs.pred_classes, outputs.scores.detach()\r\n        \r\n        nms_indices = nms(np.int32(boxes.numpy()), scores.numpy(), self.nms)\r\n\r\n        return boxes[nms_indices], labels[nms_indices], scores[nms_indices]\r\n\r\n\r\ndef nms(dets, scores, thresh): # apply NMS as there's issue in single class  original\r\n    x1 = dets[:, 0]\r\n    y1 = dets[:, 1]\r\n    x2 = dets[:, 2]\r\n    y2 = dets[:, 3]\r\n    # scores = dets[:, 4]\r\n\r\n    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\r\n    order = scores.argsort()[::-1]\r\n\r\n    keep = []\r\n    while order.size > 0:\r\n        i = order[0]\r\n        keep.append(i)\r\n        xx1 = np.maximum(x1[i], x1[order[1:]])\r\n        yy1 = np.maximum(y1[i], y1[order[1:]])\r\n        xx2 = np.minimum(x2[i], x2[order[1:]])\r\n        yy2 = np.minimum(y2[i], y2[order[1:]])\r\n\r\n        w = np.maximum(0.0, xx2 - xx1 + 1)\r\n        h = np.maximum(0.0, yy2 - yy1 + 1)\r\n        inter = w * h\r\n        ovr = inter / (areas[i] + areas[order[1:]] - inter)\r\n\r\n        inds = np.where(ovr <= thresh)[0]\r\n        order = order[inds + 1]\r\n\r\n    return keep\r\n```\r\n\r\nThis worked for me. \r\n\r\n\r\n**You can do the inference as:**\r\n\r\n```\r\nWRAPPER = TorchModel(\"../data/column_model.pth\", 0.6, nms = 0.3)\r\n\r\nimage = cv2.imread(IMAGE_PATH) # BGR Formar\r\nfloat_image = np.float32(image/255.) #  Normalized BGR image between 0-1\r\n\r\ntensor_image = torch.from_numpy(image.copy()).permute(2, 0, 1) # [B, channels, W, H]\r\ntensor_boxes, labels, scores = WRAPPER(tensor_image)\r\n```\r\n\r\n**Explainability using GRADCAM**\r\n\r\n```\r\ntargets = [FasterRCNNBoxScoreTarget(labels=labels, bounding_boxes=boxes)] # this not executed in EigenCam just init\r\ntarget_layers = [WRAPPER.model.backbone]\r\n\r\ncam = EigenCAM(WRAPPER,target_layers, use_cuda=torch.cuda.is_available(), reshape_transform=fasterrcnn_reshape_transform)\r\n\r\ngrayscale_cam = cam(tensor_image, targets=targets, eigen_smooth=True)\r\n\r\ngrayscale_cam = grayscale_cam[0, :] # Take the first image in the batch\r\n\r\ncam_image = show_cam_on_image(float_image, grayscale_cam, use_rgb = False) \r\n\r\nRGB_image_with_bounding_boxes = draw_boxes( cam_image, boxes, labels, classes, COLORS) # without normalizing\r\n\r\nImage.fromarray(RGB_image_with_bounding_boxes) # show Image with RGB format\r\n\r\n```\r\n"
      },
      {
        "user": "judahkshitij",
        "body": "@deshwalmahesh @mehi64 I am kind of in the same boat. I have couple trained image segmentation models (MaskDINO and Mask2Former) that I trained using detectron2 framework and I have the final trained model as pth file (model_final.pth) obtained from training. But, now I want to run this model in a Docker container that only has Pytorch installed but not detectron2. Is there a way to take these models and run them inside pure Pytorch without requiring detectron2? Any help on this highly appreciated. Thanks.  "
      }
    ]
  },
  {
    "issue_number": 5070,
    "title": "No pred_mask in the predictor output",
    "author": "vishakhalall",
    "state": "closed",
    "created_at": "2023-08-25T07:10:03Z",
    "updated_at": "2024-06-28T02:02:00Z",
    "labels": [
      "invalid/unrelated",
      "needs-more-info"
    ],
    "body": "I am using this to evaluate a trained model on some test images\r\n\r\n```\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\r\nfrom detectron2.engine import DefaultTrainer, DefaultPredictor\r\n\r\ncfg.MODEL.WEIGHTS = f\"model_final.pth\" \r\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.75\r\npredictor = DefaultPredictor(cfg)\r\n\r\ntest_dir = \"DetectronDataset/val/images\"\r\nfor im_p in os.listdir(test_dir):\r\n    im = cv2.imread(f\"{test_dir}/{im_p}\")\r\n    outputs = predictor(im)  \r\n    v = Visualizer(im,metadata=test_metadata,instance_mode=ColorMode.IMAGE)\r\n    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\r\n    img = out.get_image()\r\n    print(outputs[\"instances\"])\r\n    cv2.imwrite(f'{output_dir}/{im_p}', out.get_image())\r\n```\r\nHowever I noticed that the images do not have the segmentation masks. I tried printing the output of the model and got the following \r\n```\r\nInstances(num_instances=5, image_height=1280, image_width=720, fields=[pred_boxes: Boxes(tensor([[153.3457, 113.8107, 453.8591, 560.3398],\r\n        [ 77.2884, 298.6120, 624.6890, 489.1781],\r\n        [253.5901,  62.7516, 565.4692, 625.5353],\r\n        [367.0150, 172.0205, 574.5746, 541.7480],\r\n        [ 61.4621,  25.3327, 696.5031, 629.1113]], device='cuda:0')), scores: tensor([0.8329, 0.8182, 0.8029, 0.7972, 0.7571], device='cuda:0'), pred_classes: tensor([0, 0, 0, 0, 0], device='cuda:0')])\r\n```\r\nAs observed, there is no `pred_masks` in the output. I'm not sure why.",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "github-actions[bot]",
        "body": "Requested information was not provided in 7 days, so we're closing this issue.\n\nPlease open new issue if information becomes available. Otherwise, use [github discussions](https://github.com/facebookresearch/detectron2/discussions) for free-form discussions."
      }
    ]
  },
  {
    "issue_number": 5315,
    "title": "Does not install via requirements.txt but on command line",
    "author": "imperator-maximus",
    "state": "open",
    "created_at": "2024-06-23T11:35:05Z",
    "updated_at": "2024-06-23T11:36:24Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes you made:\r\nusing a small requirements.txt\r\n```\r\nsegment-anything @ git+https://github.com/facebookresearch/segment-anything.git\r\ndetectron2 @ git+https://github.com/facebookresearch/detectron2.git\r\ngroundingdino-py\r\n\r\n```\r\n3. What exact command you run:\r\n`pip install -r requirements.txt\r\n`\r\n4. __Full logs__ or other relevant observations:\r\n```\r\n          objects = self.compiler.compile(\r\n                    ^^^^^^^^^^^^^^^^^^^^^^\r\n        File \"C:\\Users\\mausz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 842, in win_wrap_ninja_compile\r\n          _write_ninja_file_and_compile_objects(\r\n        File \"C:\\Users\\mausz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 1783, in _write_ninja_file_and_compile_objects\r\n          _run_ninja_build(\r\n        File \"C:\\Users\\mausz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 2123, in _run_ninja_build\r\n          raise RuntimeError(message) from e\r\n      RuntimeError: Error compiling objects for extension\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for detectron2\r\n  Running setup.py clean for detectron2\r\nFailed to build detectron2\r\n\r\nERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (detectron2)\r\n\r\n```\r\nI added full logs via attachment: [logs.txt](https://github.com/user-attachments/files/15944342/logs.txt)\r\n\r\n\r\nBut if I install it via command line:\r\n`\r\npython -m pip install git+https://github.com/facebookresearch/detectron2.git\r\n`\r\n\r\nit works fine without any issue.\r\n\r\n6. \r\n## Environment:\r\n\r\nI am using Windows and so I do not have wget here - any alternative?\r\n\r\n\r\nIf your issue looks like an installation issue / environment issue,\r\nplease first try to solve it yourself with the instructions in\r\nhttps://detectron2.readthedocs.io/tutorials/install.html#common-installation-issues\r\n\r\nI have checked that list already.\r\n\r\nThank you.\r\n\r\n\r\n",
    "comments": []
  },
  {
    "issue_number": 5314,
    "title": "Help with multi-GPU training",
    "author": "Ayadx",
    "state": "open",
    "created_at": "2024-06-21T21:10:34Z",
    "updated_at": "2024-06-22T07:24:56Z",
    "labels": [],
    "body": "Hi,  am trying to use multi-GPU training using kaggle with two Tesla T4.\r\nmy code only runs on 1 GPU, the other are not utilized.\r\nI am able to train with custom dataset and getting acceptable results, but wish to use 2 GPUs for faster training.\r\n\r\ni am using this but is not working: \"python -m torch.distributed.launch --nproc_per_node=2 train_yolo.py\"\r\n\r\nFull runnable code or full changes you made:\r\n\r\n`\r\nimport os\r\nimport json\r\nimport multiprocessing as mp\r\nfrom detectron2.engine import DefaultTrainer, HookBase\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2 import model_zoo\r\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\r\nfrom detectron2.data import build_detection_test_loader, DatasetCatalog, MetadataCatalog\r\nfrom detectron2.structures import BoxMode\r\n\r\n# Define the training script content\r\nscript_content = \"\"\"\r\nimport os\r\nimport json\r\nimport multiprocessing as mp\r\nfrom detectron2.engine import DefaultTrainer, HookBase\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2 import model_zoo\r\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\r\nfrom detectron2.data import build_detection_test_loader, DatasetCatalog, MetadataCatalog\r\nfrom detectron2.structures import BoxMode\r\n\r\n# Unregister the datasets if they are already registered\r\nfor d in [\"pv_anomaly_train\", \"pv_anomaly_val\", \"pv_anomaly_test\"]:\r\n    if d in DatasetCatalog.list():\r\n        DatasetCatalog.remove(d)\r\n    if d in MetadataCatalog.list():\r\n        MetadataCatalog.remove(d)\r\n\r\ndef load_coco_json(json_file, image_root, dataset_name):\r\n    with open(json_file) as f:\r\n        imgs_anns = json.load(f)\r\n\r\n    dataset_dicts = []\r\n    for img_ann in imgs_anns[\"images\"]:\r\n        record = {}\r\n        record[\"file_name\"] = os.path.join(image_root, img_ann[\"file_name\"])\r\n        record[\"image_id\"] = img_ann[\"id\"]\r\n        record[\"height\"] = img_ann[\"height\"]\r\n        record[\"width\"] = img_ann[\"width\"]\r\n\r\n        objs = []\r\n        for ann in imgs_anns[\"annotations\"]:\r\n            if ann[\"image_id\"] != img_ann[\"id\"]:\r\n                continue\r\n            obj = {\r\n                \"bbox\": ann[\"bbox\"],\r\n                \"bbox_mode\": BoxMode.XYWH_ABS,\r\n                \"category_id\": ann[\"category_id\"] - 1,  # Subtract 1 to make the category_id 0-based\r\n                \"iscrowd\": ann[\"iscrowd\"]\r\n            }\r\n            objs.append(obj)\r\n        record[\"annotations\"] = objs\r\n        dataset_dicts.append(record)\r\n    return dataset_dicts\r\n\r\ndef register_datasets():\r\n    DatasetCatalog.register(\r\n        \"pv_anomaly_train\",\r\n        lambda: load_coco_json(\r\n            \"/kaggle/working/0PVProjects/Univpm_DataSet/labels/train_annotations.json\",\r\n            \"/kaggle/working/0PVProjects/Univpm_DataSet/images/train_combined_data\",\r\n            \"pv_anomaly_train\"\r\n        )\r\n    )\r\n    MetadataCatalog.get(\"pv_anomaly_train\").set(thing_classes=[\"anomaly\"])\r\n\r\n    DatasetCatalog.register(\r\n        \"pv_anomaly_val\",\r\n        lambda: load_coco_json(\r\n            \"/kaggle/working/0PVProjects/Univpm_DataSet/labels/val_annotations.json\",\r\n            \"/kaggle/working/0PVProjects/Univpm_DataSet/images/val\",\r\n            \"pv_anomaly_val\"\r\n        )\r\n    )\r\n    MetadataCatalog.get(\"pv_anomaly_val\").set(thing_classes=[\"anomaly\"])\r\n\r\n    DatasetCatalog.register(\r\n        \"pv_anomaly_test\",\r\n        lambda: load_coco_json(\r\n            \"/kaggle/working/0PVProjects/Univpm_DataSet/labels/test_annotations.json\",\r\n            \"/kaggle/working/0PVProjects/Univpm_DataSet/images/test\",\r\n            \"pv_anomaly_test\"\r\n        )\r\n    )\r\n    MetadataCatalog.get(\"pv_anomaly_test\").set(thing_classes=[\"anomaly\"])\r\n\r\n    # Retrieve metadata to ensure it is set correctly\r\n    pv_anomaly_metadata = MetadataCatalog.get(\"pv_anomaly_train\")\r\n    pv_anomaly_metadata1 = MetadataCatalog.get(\"pv_anomaly_val\")\r\n    print(pv_anomaly_metadata)\r\n    print(pv_anomaly_metadata1)\r\n\r\ndef set_multiprocessing_start_method():\r\n    try:\r\n        mp.set_start_method('spawn', force=True)\r\n    except RuntimeError as e:\r\n        if \"context has already been set\" in str(e):\r\n            print(\"Multiprocessing context already set, continuing without changing start method.\")\r\n        else:\r\n            raise\r\n\r\nclass PrintMetricsHook(HookBase):\r\n    def __init__(self, cfg):\r\n        self.cfg = cfg\r\n\r\n    def after_step(self):\r\n        # Every iteration\r\n        iter_num = self.trainer.iter\r\n        # Print the metrics for every iteration\r\n        metrics = self.trainer.storage.latest()\r\n\r\n        # Format and print the metrics\r\n        print(f\"\\\\nIteration {iter_num} Metrics:\")\r\n        print(f\"{'-'*40}\")\r\n\r\n        for key, (value, _) in metrics.items():\r\n            print(f\"{key}: {value:.4f}\")\r\n\r\n        print(f\"{'-'*40}\")\r\n\r\nclass MyTrainer(DefaultTrainer):\r\n    @classmethod\r\n    def build_evaluator(cls, cfg, dataset_name):\r\n        return COCOEvaluator(dataset_name, cfg, False, output_dir=cfg.OUTPUT_DIR)\r\n\r\ndef main():\r\n    register_datasets()\r\n    set_multiprocessing_start_method()\r\n\r\n    # Get default config\r\n    cfg = get_cfg()\r\n\r\n    # Load Faster R-CNN with \"ResNeXt-101-32x8d model trained with Caffe2 at FB\" backbone pre-trained on COCO\r\n    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\r\n\r\n    # Set training and validation datasets\r\n    cfg.DATASETS.TRAIN = (\"pv_anomaly_train\",)  # Training dataset\r\n    cfg.DATASETS.TEST = (\"pv_anomaly_val\",)     # Validation dataset\r\n\r\n    # Number of data loading workers\r\n    cfg.DATALOADER.NUM_WORKERS = 2\r\n\r\n    # Set weights for pre-trained model\r\n    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\r\n\r\n    # Number of images per batch\r\n    cfg.SOLVER.IMS_PER_BATCH = 2  # Reduced batch size to fit into memory\r\n\r\n    # Base learning rate\r\n    cfg.SOLVER.BASE_LR = 0.00025\r\n\r\n    # Maximum number of iterations in detectron2, epoch is MAX_ITER * BATCH_SIZE / TOTAL_NUM_IMAGES\r\n    cfg.SOLVER.MAX_ITER = 3000\r\n\r\n    # ROI Heads batch size per image\r\n    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\r\n\r\n    # Number of classes (in this case, only 1: 'anomaly')\r\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\r\n    \r\n    \r\n    # Create output directory if it doesn't exist\r\n    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\n\r\n    # Set the maximum split size to avoid fragmentation\r\n    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\r\n\r\n    # Create a MyTrainer instance\r\n    trainer = MyTrainer(cfg)\r\n\r\n    # Add the custom hook to print metrics after each iteration\r\n    trainer.register_hooks([PrintMetricsHook(cfg)])\r\n\r\n    # Resume training if checkpoint exists, otherwise start from scratch\r\n    trainer.resume_or_load(resume=False)\r\n\r\n    # Start training\r\n    trainer.train()\r\n\r\n    # Run evaluation\r\n    evaluator = COCOEvaluator(\"pv_anomaly_val\", cfg, False, output_dir=cfg.OUTPUT_DIR)\r\n    val_loader = build_detection_test_loader(cfg, \"pv_anomaly_val\")\r\n    inference_on_dataset(trainer.model, val_loader, evaluator)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\"\"\"\r\n\r\n# Write the script to a file\r\nscript_path = '/kaggle/working/train_yolo.py'\r\nwith open(script_path, 'w') as f:\r\n    f.write(script_content)\r\n\r\n# Define the command to run the training script using torch.distributed.run\r\ntrain_command = f\"\"\"\r\npython -m torch.distributed.run --nproc_per_node=2 {script_path}\r\n\"\"\"\r\n\r\n# Execute the training command\r\nos.system(train_command)\r\n\r\n`\r\nbest regards!",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; \"Your Environment\"; "
      },
      {
        "user": "Programmer-RD-AI",
        "body": "Hi,\r\nCheck the Issues #2442 & #2473\r\n[Example on How to implement multi GPU training](https://github.com/facebookresearch/detectron2/blob/main/tools/train_net.py)\r\nHope this helps, If there are further questions please feel free to comment :)\r\nBest regards,\r\nRanuga"
      }
    ]
  },
  {
    "issue_number": 5311,
    "title": "I can't train the model with batch size : 28 in linux environment but I can get the training results in windows with batch size 28 !",
    "author": "eklahari",
    "state": "open",
    "created_at": "2024-06-19T15:26:18Z",
    "updated_at": "2024-06-20T01:37:01Z",
    "labels": [],
    "body": "from register_dataset import* #register custom dataset\r\nfrom detectron2 import model_zoo\r\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\r\nfrom detectron2.config import get_cfg\r\nfrom detectron2.utils.visualizer import Visualizer\r\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\r\nimport os\r\n\r\n\r\nCUDA_LAUNCH_BLOCKING=1.\r\ncfg = get_cfg()\r\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\r\ncfg.MODEL.MASK_ON = False\r\ncfg.DATASETS.TRAIN = (\"football_train\",)\r\ncfg.DATASETS.TEST = ()\r\ncfg.DATALOADER.NUM_WORKERS = 2\r\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\r\ncfg.SOLVER.IMS_PER_BATCH = 28\r\ncfg.SOLVER.BASE_LR = 0.00025\r\ncfg.SOLVER.MAX_ITER = 1000\r\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\r\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 5  # Number of classes in the dataset\r\n\r\ncfg.OUTPUT_DIR = \"/output1\"\r\n\r\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\r\nwith open(os.path.join(cfg.OUTPUT_DIR, \"config.yaml\"), \"w\") as f:\r\n    f.write(cfg.dump())\r\n\r\ntrainer = DefaultTrainer(cfg) \r\ntrainer.resume_or_load(resume=False)\r\ntrainer.train()\r\nwhen i am running this code with batch size 28 i am getting cuda error\r\n<img width=\"862\" alt=\"Screenshot 2024-06-19 at 9 00 44‚ÄØPM\" src=\"https://github.com/facebookresearch/detectron2/assets/130387083/9aa83269-d62a-4805-944c-8db12dab8e1b\">\r\n\r\nbut i am able to run this file in windows which has same configuration as linux what is issue?how to overcome this could you please provide some code to perform well with increased batch size in linux environment\r\n",
    "comments": [
      {
        "user": "github-actions[bot]",
        "body": "You've chosen to report an unexpected problem or bug. Unless you already know the root cause of it, please include details about it by filling the [issue template](https://github.com/facebookresearch/detectron2/issues/new/choose).\nThe following information is missing: \"Instructions To Reproduce the Issue and __Full__ Logs\"; "
      },
      {
        "user": "Programmer-RD-AI",
        "body": "Hi,\r\nThis is usually because of the different ways CUDA memory is managed in different environments. \r\n\r\nThere isn't any specific method to resolve this, but in a Linux environment where you are unable to train a model of batch size of 28, you could try and:\r\n1. Reduce the Batch Size\r\n2. Go for a Smaller Model\r\n3. Using something like `torch.cuda.memory_allocated()` and `torch.cuda.memory_cached()` to  check up on GPU Memory allocation\r\n\r\nThese aren't solutions but other possibilities in which you can still train your model in a Linux environment...\r\nHope that explains the issues,\r\nIf there are any more questions please let me know\r\n\r\nThank you"
      }
    ]
  },
  {
    "issue_number": 5218,
    "title": "Detectron2 issue on Mac intel",
    "author": "valentinamisi",
    "state": "open",
    "created_at": "2024-02-13T16:14:58Z",
    "updated_at": "2024-06-18T23:13:51Z",
    "labels": [],
    "body": "## Instructions To Reproduce the üêõ Bug:\r\n1. Full runnable code or full changes made:\r\n```\r\n# I want to have detectron2 to be able to use layoutparser. \r\n# On the webpage (https://layout-parser.github.io/tutorials/installation) it says to run \r\n\r\npip3 install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2' \r\n\r\n# if not working then it directs to a page (https://github.com/facebookresearch/detectron2/blob/main/INSTALL.md) \r\n# which explains the requirements. It did not work for me with the first method. The requirements I looked at and \r\n# followed the steps:\r\n# 1) Linux or macOS with Python ‚â• 3.7\r\n# 2) PyTorch ‚â• 1.8 and [torchvision](https://github.com/pytorch/vision/) that matches the PyTorch installation. \r\n# Install them together at [pytorch.org](https://pytorch.org/) to make sure of this\r\n# 3) OpenCV is optional but needed by demo and visualization\r\n\r\n# To get these I run:\r\n\r\npython --version\r\n# output: Python 3.11.5\r\npip install torch torchvision torchaudio\r\npip install opencv-python\r\n\r\n# Then, to build Detectron2 from Source gcc & g++ ‚â• 5.4 are required, so I run:\r\n\r\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\r\nbrew install gcc\r\nxcode-select --install\r\n\r\n# Then, as I understood now I can build detectron2, I tried to run with all these three methods:\r\n\r\npython -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\r\n# (add --user if you don't have permission)\r\n\r\n# Or, to install it from a local clone:\r\ngit clone https://github.com/facebookresearch/detectron2.git\r\npython -m pip install -e detectron2\r\n\r\n# On macOS, you may need to prepend the above commands with a few environment variables:\r\nCC=clang CXX=clang++ ARCHFLAGS=\"-arch x86_64\" python -m pip install ...\r\n\r\n# But none worked. \r\n\r\n# My error message:\r\n#     fatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n#     20 errors generated.\r\n#     error: command '/usr/bin/clang' failed with exit code 1\r\n#     [end of output]\r\n\r\n# note: This error originates from a subprocess, and is likely not a problem with pip.\r\n#  ERROR: Failed building wheel for detectron2\r\n#  Running setup.py clean for detectron2\r\n# Failed to build detectron2\r\n# ERROR: Could not build wheels for detectron2, which is required to install pyproject.toml-based projects\r\n\r\n```\r\n\r\n\r\n",
    "comments": [
      {
        "user": "fishspeech",
        "body": "I'm having the same issue. Full error message seems to show that some value() flag (on MacOS 13.2) is not being parsed correctly.\r\n\r\n```\r\nCollecting git+https://github.com/facebookresearch/detectron2.git\r\n  Cloning https://github.com/facebookresearch/detectron2.git to /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd\r\n  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd\r\n  Resolved https://github.com/facebookresearch/detectron2.git to commit 3ff5dd1cff4417af07097064813c9f28d7461d3c\r\n  Preparing metadata (setup.py) ... done\r\nRequirement already satisfied: Pillow>=7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from detectron2==0.6) (10.2.0)\r\nRequirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from detectron2==0.6) (3.8.0)\r\nRequirement already satisfied: pycocotools>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from detectron2==0.6) (2.0.7)\r\nRequirement already satisfied: termcolor>=1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from detectron2==0.6) (2.4.0)\r\nCollecting yacs>=0.1.8 (from detectron2==0.6)\r\n  Using cached yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\nCollecting tabulate (from detectron2==0.6)\r\n  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\r\nCollecting cloudpickle (from detectron2==0.6)\r\n  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\r\nRequirement already satisfied: tqdm>4.29.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from detectron2==0.6) (4.66.1)\r\nRequirement already satisfied: tensorboard in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from detectron2==0.6) (2.15.1)\r\nCollecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\r\n  Using cached fvcore-0.1.5.post20221221-py3-none-any.whl\r\nCollecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\r\n  Using cached iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\r\nCollecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\r\n  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\r\nCollecting hydra-core>=1.1 (from detectron2==0.6)\r\n  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\r\nCollecting black (from detectron2==0.6)\r\n  Using cached black-24.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (74 kB)\r\nRequirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from detectron2==0.6) (23.1)\r\nRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.1)\r\nRequirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\r\nCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\r\n  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\r\nCollecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\r\n  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\r\nRequirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (1.1.1)\r\nRequirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (0.12.1)\r\nRequirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (4.43.1)\r\nRequirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (1.4.5)\r\nRequirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (3.1.1)\r\nRequirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (2.8.2)\r\nRequirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from black->detectron2==0.6) (8.1.7)\r\nCollecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\r\n  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\r\nCollecting pathspec>=0.9.0 (from black->detectron2==0.6)\r\n  Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\r\nRequirement already satisfied: platformdirs>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from black->detectron2==0.6) (3.10.0)\r\nRequirement already satisfied: absl-py>=0.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (1.4.0)\r\nRequirement already satisfied: grpcio>=1.48.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (1.60.0)\r\nRequirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (2.26.1)\r\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (1.2.0)\r\nRequirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (3.5.2)\r\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (3.20.3)\r\nRequirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (2.31.0)\r\nRequirement already satisfied: setuptools>=41.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (65.5.0)\r\nRequirement already satisfied: six>1.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (1.16.0)\r\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (0.7.2)\r\nRequirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (3.0.1)\r\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.2)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\r\nRequirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.2.0)\r\nRequirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.18)\r\nRequirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.11.17)\r\nRequirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\r\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.1)\r\nRequirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\r\nUsing cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\r\nUsing cached iopath-0.1.9-py3-none-any.whl (27 kB)\r\nUsing cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\r\nUsing cached yacs-0.1.8-py3-none-any.whl (14 kB)\r\nUsing cached black-24.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.4 MB)\r\nUsing cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\r\nUsing cached tabulate-0.9.0-py3-none-any.whl (35 kB)\r\nUsing cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\r\nUsing cached pathspec-0.12.1-py3-none-any.whl (31 kB)\r\nUsing cached portalocker-2.8.2-py3-none-any.whl (17 kB)\r\nBuilding wheels for collected packages: detectron2\r\n  Building wheel for detectron2 (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  √ó python setup.py bdist_wheel did not run successfully.\r\n  ‚îÇ exit code: 1\r\n  ‚ï∞‚îÄ> [639 lines of output]\r\n      running bdist_wheel\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\r\n        warnings.warn(msg.format('we could not find ninja.'))\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build/lib.macosx-10.9-universal2-cpython-311\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/lightning_train_net.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/convert-torchvision-to-d2.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/benchmark.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/visualize_data.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/plain_train_net.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/visualize_json_results.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/analyze_model.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/lazyconfig_train_net.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      copying tools/train_net.py -> build/lib.macosx-10.9-universal2-cpython-311/tools\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2\r\n      copying detectron2/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/checkpoint\r\n      copying detectron2/checkpoint/catalog.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/checkpoint\r\n      copying detectron2/checkpoint/c2_model_loading.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/checkpoint\r\n      copying detectron2/checkpoint/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/checkpoint\r\n      copying detectron2/checkpoint/detection_checkpoint.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/checkpoint\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/deform_conv.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/shape_spec.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/roi_align.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/roi_align_rotated.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/nms.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/aspp.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/mask_ops.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/wrappers.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/losses.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/blocks.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/batch_norm.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      copying detectron2/layers/rotated_boxes.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/layers\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/structures\r\n      copying detectron2/structures/instances.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/structures\r\n      copying detectron2/structures/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/structures\r\n      copying detectron2/structures/boxes.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/structures\r\n      copying detectron2/structures/keypoints.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/structures\r\n      copying detectron2/structures/masks.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/structures\r\n      copying detectron2/structures/image_list.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/structures\r\n      copying detectron2/structures/rotated_boxes.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/structures\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/config\r\n      copying detectron2/config/config.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/config\r\n      copying detectron2/config/compat.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/config\r\n      copying detectron2/config/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/config\r\n      copying detectron2/config/instantiate.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/config\r\n      copying detectron2/config/defaults.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/config\r\n      copying detectron2/config/lazy.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/config\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects\r\n      copying detectron2/projects/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/serialize.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/colormap.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/tracing.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/env.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/analysis.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/comm.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/memory.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/video_visualizer.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/registry.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/events.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/collect_env.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/logger.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/file_io.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/develop.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/testing.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      copying detectron2/utils/visualizer.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/utils\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/solver\r\n      copying detectron2/solver/build.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/solver\r\n      copying detectron2/solver/lr_scheduler.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/solver\r\n      copying detectron2/solver/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/solver\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo\r\n      copying detectron2/model_zoo/model_zoo.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo\r\n      copying detectron2/model_zoo/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling\r\n      copying detectron2/modeling/test_time_augmentation.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling\r\n      copying detectron2/modeling/poolers.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling\r\n      copying detectron2/modeling/matcher.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling\r\n      copying detectron2/modeling/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling\r\n      copying detectron2/modeling/box_regression.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling\r\n      copying detectron2/modeling/mmdet_wrapper.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling\r\n      copying detectron2/modeling/anchor_generator.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling\r\n      copying detectron2/modeling/sampling.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling\r\n      copying detectron2/modeling/postprocessing.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/fast_eval_api.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/panoptic_evaluation.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/cityscapes_evaluation.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/coco_evaluation.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/sem_seg_evaluation.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/pascal_voc_evaluation.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/lvis_evaluation.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/testing.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/evaluator.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      copying detectron2/evaluation/rotated_coco_evaluation.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/evaluation\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/tracking\r\n      copying detectron2/tracking/bbox_iou_tracker.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/tracking\r\n      copying detectron2/tracking/vanilla_hungarian_bbox_iou_tracker.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/tracking\r\n      copying detectron2/tracking/hungarian_tracker.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/tracking\r\n      copying detectron2/tracking/base_tracker.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/tracking\r\n      copying detectron2/tracking/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/tracking\r\n      copying detectron2/tracking/utils.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/tracking\r\n      copying detectron2/tracking/iou_weighted_hungarian_bbox_iou_tracker.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/tracking\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/c10.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/caffe2_export.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/flatten.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/caffe2_patch.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/caffe2_modeling.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/shared.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/api.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/caffe2_inference.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/torchscript_patch.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      copying detectron2/export/torchscript.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/export\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/data\r\n      copying detectron2/data/catalog.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data\r\n      copying detectron2/data/build.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data\r\n      copying detectron2/data/benchmark.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data\r\n      copying detectron2/data/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data\r\n      copying detectron2/data/detection_utils.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data\r\n      copying detectron2/data/dataset_mapper.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data\r\n      copying detectron2/data/common.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/engine\r\n      copying detectron2/engine/hooks.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/engine\r\n      copying detectron2/engine/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/engine\r\n      copying detectron2/engine/train_loop.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/engine\r\n      copying detectron2/engine/launch.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/engine\r\n      copying detectron2/engine/defaults.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/engine\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/meta_arch\r\n      copying detectron2/modeling/meta_arch/build.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/meta_arch\r\n      copying detectron2/modeling/meta_arch/rcnn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/meta_arch\r\n      copying detectron2/modeling/meta_arch/panoptic_fpn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/meta_arch\r\n      copying detectron2/modeling/meta_arch/dense_detector.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/meta_arch\r\n      copying detectron2/modeling/meta_arch/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/meta_arch\r\n      copying detectron2/modeling/meta_arch/fcos.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/meta_arch\r\n      copying detectron2/modeling/meta_arch/retinanet.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/meta_arch\r\n      copying detectron2/modeling/meta_arch/semantic_seg.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/meta_arch\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/proposal_generator\r\n      copying detectron2/modeling/proposal_generator/build.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/proposal_generator\r\n      copying detectron2/modeling/proposal_generator/rpn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/proposal_generator\r\n      copying detectron2/modeling/proposal_generator/rrpn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/proposal_generator\r\n      copying detectron2/modeling/proposal_generator/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/proposal_generator\r\n      copying detectron2/modeling/proposal_generator/proposal_utils.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/proposal_generator\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/roi_heads\r\n      copying detectron2/modeling/roi_heads/mask_head.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/roi_heads\r\n      copying detectron2/modeling/roi_heads/fast_rcnn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/roi_heads\r\n      copying detectron2/modeling/roi_heads/box_head.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/roi_heads\r\n      copying detectron2/modeling/roi_heads/keypoint_head.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/roi_heads\r\n      copying detectron2/modeling/roi_heads/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/roi_heads\r\n      copying detectron2/modeling/roi_heads/rotated_fast_rcnn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/roi_heads\r\n      copying detectron2/modeling/roi_heads/cascade_rcnn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/roi_heads\r\n      copying detectron2/modeling/roi_heads/roi_heads.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/roi_heads\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      copying detectron2/modeling/backbone/build.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      copying detectron2/modeling/backbone/fpn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      copying detectron2/modeling/backbone/regnet.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      copying detectron2/modeling/backbone/swin.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      copying detectron2/modeling/backbone/backbone.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      copying detectron2/modeling/backbone/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      copying detectron2/modeling/backbone/vit.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      copying detectron2/modeling/backbone/resnet.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      copying detectron2/modeling/backbone/utils.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      copying detectron2/modeling/backbone/mvit.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/modeling/backbone\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/coco.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/register_coco.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/cityscapes.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/cityscapes_panoptic.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/lvis_v1_categories.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/lvis.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/coco_panoptic.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/builtin.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/lvis_v1_category_image_count.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/pascal_voc.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/lvis_v0_5_categories.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      copying detectron2/data/datasets/builtin_meta.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/datasets\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/transforms\r\n      copying detectron2/data/transforms/augmentation_impl.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/transforms\r\n      copying detectron2/data/transforms/augmentation.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/transforms\r\n      copying detectron2/data/transforms/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/transforms\r\n      copying detectron2/data/transforms/transform.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/transforms\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/samplers\r\n      copying detectron2/data/samplers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/samplers\r\n      copying detectron2/data/samplers/grouped_batch_sampler.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/samplers\r\n      copying detectron2/data/samplers/distributed_sampler.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/data/samplers\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/point_rend\r\n      copying projects/PointRend/point_rend/point_features.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/point_rend\r\n      copying projects/PointRend/point_rend/mask_head.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/point_rend\r\n      copying projects/PointRend/point_rend/config.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/point_rend\r\n      copying projects/PointRend/point_rend/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/point_rend\r\n      copying projects/PointRend/point_rend/point_head.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/point_rend\r\n      copying projects/PointRend/point_rend/roi_heads.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/point_rend\r\n      copying projects/PointRend/point_rend/color_augmentation.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/point_rend\r\n      copying projects/PointRend/point_rend/semantic_seg.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/point_rend\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/deeplab\r\n      copying projects/DeepLab/deeplab/lr_scheduler.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/deeplab\r\n      copying projects/DeepLab/deeplab/config.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/deeplab\r\n      copying projects/DeepLab/deeplab/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/deeplab\r\n      copying projects/DeepLab/deeplab/loss.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/deeplab\r\n      copying projects/DeepLab/deeplab/resnet.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/deeplab\r\n      copying projects/DeepLab/deeplab/build_solver.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/deeplab\r\n      copying projects/DeepLab/deeplab/semantic_seg.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/deeplab\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/panoptic_deeplab\r\n      copying projects/Panoptic-DeepLab/panoptic_deeplab/config.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/panoptic_deeplab\r\n      copying projects/Panoptic-DeepLab/panoptic_deeplab/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/panoptic_deeplab\r\n      copying projects/Panoptic-DeepLab/panoptic_deeplab/dataset_mapper.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/panoptic_deeplab\r\n      copying projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/panoptic_deeplab\r\n      copying projects/Panoptic-DeepLab/panoptic_deeplab/post_processing.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/panoptic_deeplab\r\n      copying projects/Panoptic-DeepLab/panoptic_deeplab/target_generator.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/projects/panoptic_deeplab\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs\r\n      copying detectron2/model_zoo/configs/Base-RetinaNet.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs\r\n      copying detectron2/model_zoo/configs/Base-RCNN-FPN.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs\r\n      copying detectron2/model_zoo/configs/Base-RCNN-C4.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs\r\n      copying detectron2/model_zoo/configs/Base-RCNN-DilatedC5.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/scratch_mask_rcnn_R_50_FPN_9x_syncbn.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/semantic_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/scratch_mask_rcnn_R_50_FPN_3x_gn.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/panoptic_fpn_R_101_dconv_cascade_gn_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/scratch_mask_rcnn_R_50_FPN_9x_gn.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_gn.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_1x_dconv_c3-c5.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_1x_cls_agnostic.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_syncbn.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Keypoints\r\n      copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Keypoints\r\n      copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Keypoints\r\n      copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Keypoints\r\n      copying detectron2/model_zoo/configs/COCO-Keypoints/Base-Keypoint-RCNN-FPN.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Keypoints\r\n      copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Keypoints\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/PascalVOC-Detection\r\n      copying detectron2/model_zoo/configs/PascalVOC-Detection/faster_rcnn_R_50_FPN.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/PascalVOC-Detection\r\n      copying detectron2/model_zoo/configs/PascalVOC-Detection/faster_rcnn_R_50_C4.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/PascalVOC-Detection\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Detectron1-Comparisons\r\n      copying detectron2/model_zoo/configs/Detectron1-Comparisons/mask_rcnn_R_50_FPN_noaug_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Detectron1-Comparisons\r\n      copying detectron2/model_zoo/configs/Detectron1-Comparisons/keypoint_rcnn_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Detectron1-Comparisons\r\n      copying detectron2/model_zoo/configs/Detectron1-Comparisons/faster_rcnn_R_50_FPN_noaug_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Detectron1-Comparisons\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/rpn_R_50_C4_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/rpn_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_C4_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_DC5_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_C4_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_C4_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/fast_rcnn_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-PanopticSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-PanopticSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/Base-Panoptic-FPN.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-PanopticSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-PanopticSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-PanopticSegmentation\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/LVISv1-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/LVISv1-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/LVISv1-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/LVISv1-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/LVISv1-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/LVISv1-InstanceSegmentation\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/LVISv0.5-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/LVISv0.5-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/LVISv0.5-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/LVISv0.5-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/LVISv0.5-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/LVISv0.5-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/LVISv0.5-InstanceSegmentation\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_training_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_training_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/cascade_mask_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_GCV_instant_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_instant_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_instant_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_instant_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/retinanet_R_50_FPN_inference_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_DC5_inference_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/retinanet_R_50_FPN_instant_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_pred_boxes_training_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_training_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/rpn_R_50_FPN_instant_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_training_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_normalized_training_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_inference_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/cascade_mask_rcnn_R_50_FPN_instant_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/fast_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_inference_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/rpn_R_50_FPN_inference_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_instant_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_training_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_inference_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_instant_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      copying detectron2/model_zoo/configs/quick_schedules/fast_rcnn_R_50_FPN_instant_test.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/quick_schedules\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Cityscapes\r\n      copying detectron2/model_zoo/configs/Cityscapes/mask_rcnn_R_50_FPN.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Cityscapes\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_giou.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_C4_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_DC5_3x.yaml -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/Misc/mmdet_mask_rcnn_R_50_FPN_1x.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/Misc/torchvision_imagenet_R_50.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/Misc\r\n      copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_1x.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Keypoints\r\n      copying detectron2/model_zoo/configs/COCO-Detection/fcos_R_50_FPN_1x.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-Detection\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common\r\n      copying detectron2/model_zoo/configs/common/coco_schedule.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common\r\n      copying detectron2/model_zoo/configs/common/train.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common\r\n      copying detectron2/model_zoo/configs/common/optim.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/models\r\n      copying detectron2/model_zoo/configs/common/models/panoptic_fpn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/models\r\n      copying detectron2/model_zoo/configs/common/models/keypoint_rcnn_fpn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/models\r\n      copying detectron2/model_zoo/configs/common/models/mask_rcnn_vitdet.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/models\r\n      copying detectron2/model_zoo/configs/common/models/fcos.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/models\r\n      copying detectron2/model_zoo/configs/common/models/mask_rcnn_c4.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/models\r\n      copying detectron2/model_zoo/configs/common/models/retinanet.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/models\r\n      copying detectron2/model_zoo/configs/common/models/cascade_rcnn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/models\r\n      copying detectron2/model_zoo/configs/common/models/mask_rcnn_fpn.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/models\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/data\r\n      copying detectron2/model_zoo/configs/common/data/coco.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/data\r\n      copying detectron2/model_zoo/configs/common/data/constants.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/data\r\n      copying detectron2/model_zoo/configs/common/data/coco_panoptic_separated.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/data\r\n      copying detectron2/model_zoo/configs/common/data/coco_keypoint.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/common/data\r\n      copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_1x.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-PanopticSegmentation\r\n      creating build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_R_101_FPN_200ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_R_50_FPN_50ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_regnetx_4gf_dds_FPN_100ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_regnetx_4gf_dds_FPN_400ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_regnety_4gf_dds_FPN_400ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_R_50_FPN_200ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_regnety_4gf_dds_FPN_100ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_R_50_FPN_100ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_regnety_4gf_dds_FPN_200ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_R_50_FPN_400ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_R_101_FPN_400ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_R_101_FPN_100ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/new_baselines/mask_rcnn_regnetx_4gf_dds_FPN_200ep_LSJ.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/new_baselines\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_regnetx_4gf_dds_fpn_1x.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_regnety_4gf_dds_fpn_1x.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.py -> build/lib.macosx-10.9-universal2-cpython-311/detectron2/model_zoo/configs/COCO-InstanceSegmentation\r\n      running build_ext\r\n      building 'detectron2._C' extension\r\n      creating build/temp.macosx-10.9-universal2-cpython-311\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/box_iou_rotated\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/cocoeval\r\n      creating build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/nms_rotated\r\n      clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch arm64 -arch x86_64 -g -I/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc -I/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include -I/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/TH -I/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/THC -I/Library/Frameworks/Python.framework/Versions/3.11/include/python3.11 -c /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp -o build/temp.macosx-10.9-universal2-cpython-311/private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:28:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/c10/util/OptionalArrayRef.h:159:34: error: 'value' is unavailable: introduced in macOS 10.13\r\n          return wrapped_opt_array_ref.value();\r\n                                       ^\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/c10/util/OptionalArrayRef.h:222:13: note: in instantiation of member function 'c10::OptionalArrayRef<long long>::value' requested here\r\n        return a1.value() == other;\r\n                  ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1005:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:31:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/CheckMemoryFormat.h:11:35: error: 'value' is unavailable: introduced in macOS 10.13\r\n            options.requires_grad_opt().value() == false,\r\n                                        ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1023:28: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type&& value() &&\r\n                                 ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:33:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/DeprecatedTypeProperties.h:110:34: error: 'value' is unavailable: introduced in macOS 10.13\r\n            Device device = device_opt.value();\r\n                                       ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1014:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:442:26: error: 'value' is unavailable: introduced in macOS 10.13\r\n            TORCH_CHECK(inputs.value().size() > 0, \"'inputs' argument to backward cannot be empty\")\r\n                               ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1014:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:443:30: error: 'value' is unavailable: introduced in macOS 10.13\r\n            this->_backward(inputs.value(), gradient, retain_graph, create_graph);\r\n                                   ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1014:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:28:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/c10/util/OptionalArrayRef.h:131:34: error: 'value' is unavailable: introduced in macOS 10.13\r\n          return wrapped_opt_array_ref.value();\r\n                                       ^\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:5606:152: note: in instantiation of member function 'c10::OptionalArrayRef<long long>::operator*' requested here\r\n          return at::_ops::to_padded_tensor::call(const_cast<Tensor&>(*this), padding, output_size.has_value() ? c10::make_optional(c10::fromIntArrayRefSlow(*output_size)) : c10::nullopt);\r\n                                                                                                                                                             ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1014:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:12:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:662:24: error: 'value' is unavailable: introduced in macOS 10.13\r\n            prod *= shape[i].value();\r\n                             ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1005:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:12:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:1512:28: error: 'value' is unavailable: introduced in macOS 10.13\r\n          const auto& n = name().value();\r\n                                 ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1005:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:12:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:2129:20: error: 'value' is unavailable: introduced in macOS 10.13\r\n          return reason_.value();\r\n                         ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1005:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:16:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/c10/core/DeviceGuard.h:3:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/c10/core/impl/InlineDeviceGuard.h:230:33: error: 'value' is unavailable: introduced in macOS 10.13\r\n            guard_.emplace(device_opt.value());\r\n                                      ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1014:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:16:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/c10/core/DeviceGuard.h:3:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/c10/core/impl/InlineDeviceGuard.h:242:39: error: 'value' is unavailable: introduced in macOS 10.13\r\n            guard_.emplace(device_index_opt.value());\r\n                                            ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1014:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef.h:631:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/IListRef_inl.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List.h:490:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/List_inl.h:4:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue.h:1551:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/ivalue_inl.h:20:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/c10/core/StreamGuard.h:3:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/c10/core/impl/InlineStreamGuard.h:146:33: error: 'value' is unavailable: introduced in macOS 10.13\r\n            guard_.emplace(stream_opt.value());\r\n                                      ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1014:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:9:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/DeviceGuard.h:27:38: error: 'value' is unavailable: introduced in macOS 10.13\r\n        return t.has_value() ? device_of(t.value()) : c10::nullopt;\r\n                                           ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1005:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:18:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorIndexing.h:13:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/NativeFunctions.h:37:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ops/_addmm_activation_native.h:15:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ops/_addmm_activation_meta.h:12:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorIterator.h:311:34: error: 'value' is unavailable: introduced in macOS 10.13\r\n          return operands_[arg].device.value();\r\n                                       ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1005:33: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type const& value() const&\r\n                                      ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:18:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorIndexing.h:48:37: error: 'value' is unavailable: introduced in macOS 10.13\r\n            step_ = std::move(step_index).value();\r\n                                          ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1023:28: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type&& value() &&\r\n                                 ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:18:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorIndexing.h:56:39: error: 'value' is unavailable: introduced in macOS 10.13\r\n            start_ = std::move(start_index).value();\r\n                                            ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1023:28: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type&& value() &&\r\n                                 ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:18:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorIndexing.h:62:37: error: 'value' is unavailable: introduced in macOS 10.13\r\n            stop_ = std::move(stop_index).value();\r\n                                          ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1023:28: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type&& value() &&\r\n                                 ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3:\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/ATen.h:18:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorIndexing.h:243:25: error: 'value' is unavailable: introduced in macOS 10.13\r\n                !(maybe_index.value() == 0 && dim == 0 && self_sizes->empty()),\r\n                              ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1014:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      In file included from /private/var/folders/zh/g93pmx9d149g67sv7nxzytqh0000gn/T/pip-req-build-nqwbbqkd/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:2:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/TensorUtils.h:5:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3:\r\n      In file included from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:28:\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/c10/util/OptionalArrayRef.h:155:34: error: 'value' is unavailable: introduced in macOS 10.13\r\n          return wrapped_opt_array_ref.value();\r\n                                       ^\r\n      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/include/ATen/WrapDimUtilsMulti.h:26:26: note: in instantiation of member function 'c10::OptionalArrayRef<long long>::value' requested here\r\n          auto dims = opt_dims.value();\r\n                               ^\r\n      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/optional:1014:27: note: 'value' has been explicitly marked unavailable here\r\n          constexpr value_type& value() &\r\n                                ^\r\n      fatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n      20 errors generated.\r\n      error: command '/usr/bin/clang' failed with exit code 1\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for detectron2\r\n  Running setup.py clean for detectron2\r\nFailed to build detectron2\r\nERROR: Could not build wheels for detectron2, which is required to install pyproject.toml-based projects\r\n```"
      },
      {
        "user": "ziyu-zhang",
        "body": "Same issue. Did you guys figure out?"
      },
      {
        "user": "lavanya-vaddavalli",
        "body": "Same issue, how to fix this?\r\n"
      }
    ]
  }
]